GPUS: '0'
DATA_DIR: ''
OUTPUT_DIR: 'output'
LOG_DIR: 'log'
WORKERS: 8
PRINT_FREQ: 100

DATASET:
  DATASET: 'coco'
  ROOT: '/home/ytwang/dataset/COCO2017'
  TEST_SET: 'val2017'
  TRAIN_SET: 'train2017'
  FLIP: true
  ROT_FACTOR: 40
  SCALE_FACTOR: 0.3
MODEL:
  NAME: 'pose_mobilenet_relu'
  PRETRAINED: 'output/coco_quan/mobile_quant_relu_int_deconv3_w8a8_bnfuse1/final_state_560_140.pth.tar' #'output/coco/256x192_d256x3_adam_lr1e-3_mobile8_relu/final_state_560.pth.tar'  output/coco_quan/mobile_quant_relu_w8a8_bnfuse0_resume/final_state.pth.tar
  IMAGE_SIZE:              # 'output/coco/256x192_d256x3_adam_lr1e-3_mobile8_relu_deconv3/final_state_560.pth.tar'       #output/coco_quan/mobile_quant_relu_w8a8_bnfuse0/final_state_140.pth.tar
  - 192
  - 256
  NUM_JOINTS: 17
  EXTRA:
    TARGET_TYPE: 'gaussian'
    HEATMAP_SIZE:
    - 48
    - 64
    SIGMA: 2
    FINAL_CONV_KERNEL: 1
    DECONV_WITH_BIAS: false
    NUM_DECONV_LAYERS: 3
    NUM_DECONV_FILTERS:
    - 128
    - 128
    - 128
    NUM_DECONV_KERNELS:
    - 3
    - 3
    - 3
    NUM_LAYERS: 50
LOSS:
  USE_TARGET_WEIGHT: true
TRAIN:
  BATCH_SIZE: 256
  SHUFFLE: true
  BEGIN_EPOCH: 0
  END_EPOCH: 140
  RESUME: false
  OPTIMIZER: 'adam'
  LR: 0.001
  LR_FACTOR: 0.1
  LR_STEP:
  - 90
  - 120 
  WD: 0.0001
  GAMMA1: 0.99
  GAMMA2: 0.0
  MOMENTUM: 0.9
  NESTEROV: false
TEST:
  BATCH_SIZE: 128 
  COCO_BBOX_FILE: 'models/person_detection_results/COCO_val2017_detections_AP_H_56_person.json'
  BBOX_THRE: 1.0
  FLIP_TEST: false
  IMAGE_THRE: 0.0
  IN_VIS_THRE: 0.2
  MODEL_FILE: 'output/coco_quan/mobile_quant_relu_int_deconv3_w8a8_bnfuse1/model_best_560_280.pth.tar' #'output/coco_quan/mobile_quant_relu_int_deconv3_w8a8_bnfuse1/model_best.pth.tar'  valid_quan.py
  NMS_THRE: 1.0  #'output/weights_quan_deconv3/int8_mobilenet8_relu_bnfuse_deconv3_float.pt' .ipynb  'output/weights_quan/float_mobilenetpose_nobn.pt' 
  OKS_THRE: 0.9
  USE_GT_BBOX: true
DEBUG:
  DEBUG: true
  SAVE_BATCH_IMAGES_GT: true
  SAVE_BATCH_IMAGES_PRED: true
  SAVE_HEATMAPS_GT: true
  SAVE_HEATMAPS_PRED: true
QUANTIZATION:
  W_BITS: 8
  A_BITS: 8
  BN_FUSE: 1
  Q_TYPE: 0
  Q_LEVEL: 0
  WEIGHT_OBSERVER: 0
  QUANT_INFERENCE: false
  QUANT_METHOD: 0
