{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import _init_paths\n",
    "from core.config import config\n",
    "from core.config import update_config\n",
    "from core.config import update_dir\n",
    "from core.loss import JointsMSELoss\n",
    "from core.function import validate\n",
    "from utils.utils import create_logger\n",
    "\n",
    "import dataset\n",
    "import models\n",
    "\n",
    "import quantize_dorefa\n",
    "from quantize_iao import *\n",
    "# from quantize_iao_uint import *  #对feature map进行uint对称量化\n",
    "\n",
    "import numpy as np\n",
    "# 保证所有数据能够显示，而不是用省略号表示，np.inf表示一个足够大的数\n",
    "np.set_printoptions(threshold = np.inf) \n",
    "\n",
    "# # 若想不以科学计数显示:\n",
    "# np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_fuse_conv(bn_conv,device):\n",
    "    # ******************** bn参数 *********************\n",
    "    mean = bn_conv.running_mean\n",
    "    std = torch.sqrt(bn_conv.running_var + bn_conv.eps)\n",
    "    gamma = bn_conv.gamma\n",
    "    beta = bn_conv.beta\n",
    "    # ******************* conv参数 ********************\n",
    "    w = bn_conv.weight\n",
    "    w_fused = w.clone()\n",
    "    if bn_conv.bias is not None:\n",
    "        b = bn_conv.bias\n",
    "    else:\n",
    "        b = mean.new_zeros(mean.shape)\n",
    "    b_fused = b.clone()\n",
    "    # ******************* bn融合 *******************\n",
    "    w_fused = w * (gamma / std).reshape([bn_conv.out_channels, 1, 1, 1])\n",
    "    b_fused = beta + (b - mean) * (gamma / std)\n",
    "    bn_fused_conv = QuantConv2d(bn_conv.in_channels,\n",
    "                                         bn_conv.out_channels,\n",
    "                                         bn_conv.kernel_size,\n",
    "                                         stride=bn_conv.stride,\n",
    "                                         padding=bn_conv.padding,\n",
    "                                         dilation=bn_conv.dilation,\n",
    "                                         groups=bn_conv.groups,\n",
    "                                         bias=True,\n",
    "                                         padding_mode=bn_conv.padding_mode,\n",
    "                                         a_bits=config.QUANTIZATION.A_BITS,\n",
    "                                         w_bits=config.QUANTIZATION.W_BITS,\n",
    "                                         q_type=config.QUANTIZATION.Q_TYPE,\n",
    "                                         q_level=config.QUANTIZATION.Q_LEVEL,\n",
    "                                         device=device,\n",
    "                                         quant_inference=True)\n",
    "    bn_fused_conv.weight.data = w_fused\n",
    "    bn_fused_conv.bias.data = b_fused\n",
    "    bn_fused_conv.activation_quantizer.scale.copy_(bn_conv.activation_quantizer.scale)\n",
    "    bn_fused_conv.activation_quantizer.zero_point.copy_(bn_conv.activation_quantizer.zero_point)\n",
    "    bn_fused_conv.activation_quantizer.eps = bn_conv.activation_quantizer.eps\n",
    "    bn_fused_conv.weight_quantizer.scale.copy_(bn_conv.weight_quantizer.scale)\n",
    "    bn_fused_conv.weight_quantizer.zero_point.copy_(bn_conv.weight_quantizer.zero_point)\n",
    "    bn_fused_conv.weight_quantizer.eps = bn_conv.weight_quantizer.eps\n",
    "    return bn_fused_conv\n",
    "\n",
    "def bn_fuse_deconv(bn_conv,device):\n",
    "    # ******************** bn参数 *********************\n",
    "    mean = bn_conv.running_mean\n",
    "    std = torch.sqrt(bn_conv.running_var + bn_conv.eps)\n",
    "    gamma = bn_conv.gamma\n",
    "    beta = bn_conv.beta\n",
    "    # ******************* conv参数 ********************\n",
    "    w = bn_conv.weight\n",
    "    w_fused = w.clone()\n",
    "    if bn_conv.bias is not None:\n",
    "        b = bn_conv.bias\n",
    "    else:\n",
    "        b = mean.new_zeros(mean.shape)\n",
    "    b_fused = b.clone()\n",
    "    # ******************* bn融合 *******************\n",
    "    w_fused = w * (gamma / std).reshape([bn_conv.out_channels, 1, 1, 1])\n",
    "    b_fused = beta + (b - mean) * (gamma / std)\n",
    "    bn_fused_conv = QuantConvTranspose2d(bn_conv.in_channels,\n",
    "                                         bn_conv.out_channels,\n",
    "                                         bn_conv.kernel_size,\n",
    "                                         stride=bn_conv.stride,\n",
    "                                         padding=bn_conv.padding,\n",
    "                                         output_padding=bn_conv.output_padding,\n",
    "                                         dilation=bn_conv.dilation,\n",
    "                                         groups=bn_conv.groups,\n",
    "                                         bias=True,\n",
    "                                         padding_mode=bn_conv.padding_mode,\n",
    "                                         a_bits=config.QUANTIZATION.A_BITS,\n",
    "                                         w_bits=config.QUANTIZATION.W_BITS,\n",
    "                                         q_type=config.QUANTIZATION.Q_TYPE,\n",
    "                                         q_level=config.QUANTIZATION.Q_LEVEL,\n",
    "                                         device=device,\n",
    "                                         quant_inference=True)\n",
    "    bn_fused_conv.weight.data = w_fused\n",
    "    bn_fused_conv.bias.data = b_fused\n",
    "    bn_fused_conv.activation_quantizer.scale.copy_(bn_conv.activation_quantizer.scale)\n",
    "    bn_fused_conv.activation_quantizer.zero_point.copy_(bn_conv.activation_quantizer.zero_point)\n",
    "    bn_fused_conv.activation_quantizer.eps = bn_conv.activation_quantizer.eps\n",
    "    bn_fused_conv.weight_quantizer.scale.copy_(bn_conv.weight_quantizer.scale)\n",
    "    bn_fused_conv.weight_quantizer.zero_point.copy_(bn_conv.weight_quantizer.zero_point)\n",
    "    bn_fused_conv.weight_quantizer.eps = bn_conv.weight_quantizer.eps\n",
    "    return bn_fused_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_fuse_module(module, device):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, QuantBNFuseConv2d):\n",
    "            bn_fused_conv = bn_fuse_conv(child, device)\n",
    "            module._modules[name] = bn_fused_conv\n",
    "        elif isinstance(child, QuantBNFuseConvTranspose2d):\n",
    "            bn_fused_deconv = bn_fuse_deconv(child, device)\n",
    "            module._modules[name] = bn_fused_deconv\n",
    "        else:\n",
    "            bn_fuse_module(child, device)\n",
    "\n",
    "\n",
    "def model_bn_fuse(model, inplace=False):\n",
    "    if not inplace:\n",
    "        model = copy.deepcopy(model)\n",
    "    device = next(model.parameters()).device\n",
    "    bn_fuse_module(model,device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_device(device='', apex=False, batch_size=None):\n",
    "    # device = 'cpu' or '0' or '0,1,2,3'\n",
    "    cpu_request = device.lower() == 'cpu'\n",
    "    if device and not cpu_request:  # if device requested other than 'cpu'\n",
    "        # os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n",
    "        assert torch.cuda.is_available(), 'CUDA unavailable, invalid device %s requested' % device  # check availablity\n",
    "\n",
    "    cuda = False if cpu_request else torch.cuda.is_available()\n",
    "    if cuda:\n",
    "        c = 1024 ** 2  # bytes to MB\n",
    "        ng = torch.cuda.device_count()\n",
    "        if ng > 1 and batch_size:  # check that batch_size is compatible with device_count\n",
    "            assert batch_size % ng == 0, 'batch-size %g not multiple of GPU count %g' % (batch_size, ng)\n",
    "        x = [torch.cuda.get_device_properties(i) for i in range(ng)]\n",
    "        s = 'Using CUDA ' + ('Apex ' if apex else '')  # apex for mixed precision https://github.com/NVIDIA/apex\n",
    "        for i in range(0, ng):\n",
    "            if i == 1:\n",
    "                s = ' ' * len(s)\n",
    "            print(\"%sdevice%g _CudaDeviceProperties(name='%s', total_memory=%dMB)\" %\n",
    "                  (s, i, x[i].name, x[i].total_memory / c))\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "\n",
    "    print('')  # skip a line\n",
    "    return torch.device('cuda:0' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "models.pose_mobilenet_relu.get_pose_net\n",
      "/home/ytwang/wyt_workspace/quantization/human-pose-estimation.pytorch/pose_estimation/../lib/core/config.py:196: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  exp_config = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "cfg='../experiments/coco/resnet50/mobile_quant_relu_int.yaml'   #MODEL_FILE:'output/weights_quan/int8_mobilenet8_relu_bnfuse_inference.pt' 生成 'output/weights_quan/float_mobilenetpose_nobn.pt'\n",
    "update_config(cfg)\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = config.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = config.CUDNN.ENABLED\n",
    "\n",
    "# for shufflenetv2\n",
    "shufflenetv2_spec = {'0.5': ([4, 8, 4], [24, 48, 96, 192, 1024]),\n",
    "                        '1.0': ([4, 8, 4], [24, 116, 232, 464, 1024]),\n",
    "                        '1.5': ([4, 8, 4], [24, 176, 352, 704, 1024]),\n",
    "                        '2.0': ([4, 8, 4], [24, 244, 488, 976, 2048])}\n",
    "stages_repeats, stages_out_channels = shufflenetv2_spec['1.0']\n",
    "print('models.'+config.MODEL.NAME+'.get_pose_net')\n",
    "model = eval('models.'+config.MODEL.NAME+'.get_pose_net')(\n",
    "        config, \n",
    "        stages_repeats, stages_out_channels,\n",
    "        is_train=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################### bnfuse model ############################################\n",
    "bnfuse_model = eval('models.pose_mobilenet_relu_bnfuse.get_pose_net')(\n",
    "    config, \n",
    "    stages_repeats, stages_out_channels,\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2080 Ti', total_memory=11019MB)\n\n"
     ]
    }
   ],
   "source": [
    "gpus = [int(i) for i in config.GPUS.split(',')]\n",
    "device = select_device(config.GPUS, batch_size=config.TEST.BATCH_SIZE*len(gpus))\n",
    "\n",
    "model = model.to(device)\n",
    "# summary(model,input_size=(3, 256, 192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a_bits= 8 \tw_bits= 8 \tq_type= 0 \tq_level= 0 \tdevice= cuda:0 \tweight_observer= 0 \tbn_fuse= 1 \tquant_inference= False\n"
     ]
    }
   ],
   "source": [
    "#print('*******************ori_model*******************\\n', model)\n",
    "if(config.QUANTIZATION.QUANT_METHOD == 1): # DoReFa\n",
    "    quantize_dorefa.prepare(model, inplace=True, a_bits=config.QUANTIZATION.A_BITS, w_bits=config.QUANTIZATION.W_BITS, quant_inference=config.QUANTIZATION.QUANT_INFERENCE, is_activate=False)\n",
    "else: #default quant_method == 0   IAO\n",
    "    prepare(model, inplace=True, a_bits=config.QUANTIZATION.A_BITS, w_bits=config.QUANTIZATION.W_BITS,q_type=config.QUANTIZATION.Q_TYPE, q_level=config.QUANTIZATION.Q_LEVEL, device=device,#device=next(model.parameters()).device, \n",
    "                        weight_observer=config.QUANTIZATION.WEIGHT_OBSERVER, bn_fuse=config.QUANTIZATION.BN_FUSE, quant_inference=config.QUANTIZATION.QUANT_INFERENCE)\n",
    "#print('\\n*******************quant_model*******************\\n', model)\n",
    "# print('\\n*******************Using quant_model in test*******************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if config.TEST.MODEL_FILE:\n",
    "#     # logger.info('=> loading model from {}'.format(config.TEST.MODEL_FILE))\n",
    "#     if(config.TEST.MODEL_FILE.split('/')[-1]=='checkpoint.pth.tar'):\n",
    "#         model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "#         #model.load_state_dict(torch.load(config.TEST.MODEL_FILE,map_location=torch.device('cuda'))['state_dict'])\n",
    "#         model.load_state_dict(torch.load(config.TEST.MODEL_FILE,map_location=device)['state_dict'])\n",
    "#         #torch.save(model.module.state_dict(), 'output/coco_quan/mobile_quant_relu_w8a8_bnfuse0/checkpoint_nomodule.pth.tar')\n",
    "#     elif(config.TEST.MODEL_FILE.split('/')[-1]=='model_best.pth.tar'):  #multiGPU has model.module.\n",
    "#         model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "#         model.load_state_dict(torch.load(config.TEST.MODEL_FILE,map_location=device))\n",
    "#     elif(config.TEST.MODEL_FILE.split('/')[-1]=='checkpoint_resave.pth.tar'):  #multiGPU has model.module.\n",
    "#         model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "#         model.load_state_dict(torch.load(config.TEST.MODEL_FILE,map_location=device))\n",
    "#     else:  #final_state.pth.tar\n",
    "#         model.load_state_dict(torch.load(config.TEST.MODEL_FILE,map_location=device))\n",
    "#         model = torch.nn.DataParallel(model, device_ids=gpus).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*******************For inference bn_fuse quant_model*******************\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# ********************* quant_bn_fused_model_inference **********************\n",
    "model.to(device)\n",
    "model_bn_fuse(model, inplace=True)  # bn融合\n",
    "# print('\\n*******************For inference bn_fuse quant_model*******************\\n', model)\n",
    "# ckpt = {'model': model.module.state_dict() if hasattr(model, 'module') else model.state_dict()}\n",
    "# torch.save(ckpt, '../output/weights_quan/int8_mobilenet8_relu_bnfuse_inference.pt')\n",
    "print('*******************For inference bn_fuse quant_model*******************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "output/weights_quan/int8_mobilenet8_relu_bnfuse_inference.pt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "print(config.TEST.MODEL_FILE)\n",
    "model.load_state_dict(torch.load('../'+config.TEST.MODEL_FILE,map_location=device)['model'])  ##为什么还在'model'里面呀？\n",
    "# model.load_state_dict(torch.load('../'+config.TEST.MODEL_FILE,map_location=device))  ##为什么还在'model'里面呀？\n",
    "# model = torch.nn.DataParallel(model, device_ids=gpus).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model.state_dict:\n"
     ]
    }
   ],
   "source": [
    "remapped_state = {}\n",
    "print('Model.state_dict:')\n",
    "# ######################################## before #######################################\n",
    "# for n,param_tensor in enumerate(model.state_dict()):\n",
    "#     #打印 key value字典\n",
    "#     print(n, param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    "#     # if(n<5):\n",
    "#     #     print(n, param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    "#     #     # print(model.state_dict()[param_tensor])\n",
    "\n",
    "# ######################################### after #######################################\n",
    "# for n,param_tensor in enumerate(bnfuse_model.state_dict()):\n",
    "#     #打印 key value字典\n",
    "#     print(n, param_tensor,'\\t',bnfuse_model.state_dict()[param_tensor].size())\n",
    "#     # if(n<4):\n",
    "#     #     print(n, param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    "#     #     print(model.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################# 生成浮点权重 refactor后 #############################\n",
    "# import re\n",
    "# remapped_state = {}\n",
    "# for n,state_key in enumerate(bnfuse_model.state_dict().keys()):\n",
    "#     k = state_key.split('.') # pytorch  ['features', '0', '0', 'weight']\n",
    "#     if(k[0]=='features'):\n",
    "#         k[1]=str(int(k[1])+1)\n",
    "#         k[-2]=str((int(k[2][-1])-1)*3)\n",
    "#         k[2]='conv'\n",
    "#         remapped_state_key=('.').join(k) #进行重映射\n",
    "#     elif(k[0].startswith('deconv_layers')): #final_layer\n",
    "#         number=3*int(k[0][-1])\n",
    "#         remapped_state_key='deconv_layers.'+str(number)+'.'+k[-1] #weight/bias\n",
    "#     elif(k[0]=='conv1'): #final_layer\n",
    "#         remapped_state_key='features.0.0.'+k[-1] #weight/bias\n",
    "#     else: #final_layer  conv2\n",
    "#         remapped_state_key=state_key\n",
    "#     # print(n, state_key, remapped_state_key, model.state_dict()[remapped_state_key].shape)\n",
    "#     remapped_state[state_key]= model.state_dict()[remapped_state_key]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################# 生成浮点权重 refactor前 #############################\n",
    "# remapped_state = {}\n",
    "# for n,state_key in enumerate(bnfuse_model.state_dict().keys()):\n",
    "#     k = state_key.split('.') # pytorch  ['features', '0', '0', 'weight']\n",
    "#     if(k[0]!='final_layer'):\n",
    "#         number = int(k[-2])//2*3 \n",
    "#         # print(number)\n",
    "#         k[-2]=str(number)\n",
    "#         # print(k)\n",
    "#         remapped_state_key=('.').join(k) #进行重映射\n",
    "#     else: #final_layer\n",
    "#         remapped_state_key=state_key\n",
    "#     print(n, state_key, model.state_dict()[remapped_state_key].shape)\n",
    "#     remapped_state[state_key]= model.state_dict()[remapped_state_key]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### 量化步骤 ##############################\n",
    "## 对称量化，因此zero_point均为0\n",
    "def quantize_tensor(weight, bias, wscale, ascale, num_bits=8):\n",
    "    qmin = -2**(num_bits-1)  #8bit [-128,127]\n",
    "    qmax = 2**(num_bits-1) - 1\n",
    "    q_weight= torch.round(weight/wscale).clamp_(qmin, qmax).type(torch.int32)\n",
    "    # print('0:', torch.max(torch.round(weight/wscale)), torch.min(torch.round(weight/wscale)))\n",
    "    q_bias= torch.round(bias/wscale.flatten()/ascale).type(torch.int32)  #bias没有进行截断\n",
    "    return q_weight, q_bias\n",
    "\n",
    "#反量化回浮点结果\n",
    "def dequantize_tensor(q_weight, q_bias, wscale, ascale):\n",
    "    return wscale*q_weight.float(), wscale.flatten()*ascale*q_bias.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model.state_dict:\n",
      "features.0.0.weight features.0.2\n",
      "torch.Size([16, 3, 3, 3]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.0207]) torch.Size([1]) \n",
      "wscale= tensor([3.2806e-02, 3.5383e-07, 6.9110e-03, 1.2938e-02, 1.1094e-02, 4.6062e-02,\n",
      "        5.6726e-02, 4.9625e-02, 2.8893e-02, 2.8007e-05, 1.7617e-02, 1.5632e-06,\n",
      "        2.1120e-02, 2.3379e-07, 1.3260e-06, 4.4465e-02]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.9272]) torch.Size([1])\n",
      "###: M= tensor([7.3260e-04, 7.9017e-09, 1.5433e-04, 2.8893e-04, 2.4775e-04, 1.0286e-03,\n",
      "        1.2668e-03, 1.1082e-03, 6.4523e-04, 6.2544e-07, 3.9341e-04, 3.4910e-08,\n",
      "        4.7164e-04, 5.2209e-09, 2.9611e-08, 9.9298e-04])\n",
      "torch.Size([16, 3, 3, 3]) torch.Size([16])\n",
      "conv_weight: tensor([[[[-1.7921e-01,  7.3493e-01,  2.8327e-01],\n",
      "          [ 3.1658e-02,  1.0855e+00,  2.7640e-01],\n",
      "          [ 1.1607e-01,  5.1940e-01,  3.0053e-01]],\n",
      "\n",
      "         [[-2.2042e-01, -4.3684e-01, -1.0990e+00],\n",
      "          [-1.3602e+00, -1.8952e+00, -4.0465e+00],\n",
      "          [-6.7470e-01,  1.8189e-01, -2.2336e+00]],\n",
      "\n",
      "         [[-1.7365e-01,  6.1672e-01,  3.5628e-01],\n",
      "          [-6.1048e-01,  2.9419e+00,  1.7364e+00],\n",
      "          [ 1.7706e-01,  3.3205e+00,  2.1474e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4822e-05, -9.5277e-06, -1.7073e-05],\n",
      "          [-1.7501e-05, -3.0215e-05,  3.4911e-06],\n",
      "          [-2.7478e-05, -3.1973e-05,  1.0358e-05]],\n",
      "\n",
      "         [[ 5.6683e-08, -6.2256e-07,  6.6703e-06],\n",
      "          [-4.2640e-06, -2.3636e-05,  4.5760e-06],\n",
      "          [-7.8695e-06,  1.8608e-07,  4.2223e-06]],\n",
      "\n",
      "         [[ 3.2503e-05,  4.4813e-05,  3.3683e-05],\n",
      "          [ 1.5486e-05,  2.8259e-05,  2.5988e-05],\n",
      "          [ 1.3538e-05,  1.3542e-05,  4.2030e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4662e-02, -2.8969e-01, -1.8041e-01],\n",
      "          [-1.7222e-02, -8.4645e-01, -4.7034e-01],\n",
      "          [ 2.5451e-01, -1.6757e-01,  2.9974e-01]],\n",
      "\n",
      "         [[ 3.5879e-01,  2.0144e-01,  2.2877e-01],\n",
      "          [ 6.1542e-02, -7.8918e-01, -4.4781e-01],\n",
      "          [ 1.8424e-01,  1.0639e-01,  3.1992e-01]],\n",
      "\n",
      "         [[ 1.6270e-01,  9.2135e-02, -1.9797e-01],\n",
      "          [-5.6690e-02, -6.2024e-01, -4.3444e-01],\n",
      "          [-2.1235e-01, -4.9089e-01, -4.8161e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5742e-03, -2.5600e-01,  3.0317e-01],\n",
      "          [ 9.0896e-02, -2.0139e-01, -3.8204e-01],\n",
      "          [-8.3283e-02, -4.3013e-01, -5.8019e-01]],\n",
      "\n",
      "         [[ 3.6565e-02,  1.8387e-01,  1.1891e+00],\n",
      "          [ 4.3470e-01, -3.6708e-01, -7.9309e-01],\n",
      "          [ 2.9509e-01, -1.1274e+00, -1.5698e+00]],\n",
      "\n",
      "         [[-1.2066e-01,  2.8764e-01,  1.0456e+00],\n",
      "          [ 5.1799e-01, -2.0708e-01, -7.6669e-01],\n",
      "          [ 4.8074e-01, -8.9327e-01, -1.5837e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9103e-02, -1.0235e-01, -1.8420e-01],\n",
      "          [ 8.5128e-02,  2.2466e-01,  9.0830e-02],\n",
      "          [ 8.3695e-02,  5.6890e-02, -5.6582e-02]],\n",
      "\n",
      "         [[-6.6944e-01, -2.4013e-01, -2.0062e-01],\n",
      "          [-3.6079e-01,  1.1671e+00,  1.2605e+00],\n",
      "          [-4.9231e-01,  1.3005e-01,  4.6960e-02]],\n",
      "\n",
      "         [[ 5.9191e-01,  1.6689e-01,  8.0086e-01],\n",
      "          [ 2.6713e-01, -8.7909e-01, -7.3806e-01],\n",
      "          [ 7.3439e-01, -2.7486e-01,  2.3233e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6108e-01, -1.8334e-01,  1.1788e-01],\n",
      "          [-5.1640e-01, -1.1388e+00, -1.8923e-01],\n",
      "          [ 6.8418e-01,  7.1658e-01,  3.2529e-01]],\n",
      "\n",
      "         [[-4.8550e-01, -3.3012e-01,  1.3311e+00],\n",
      "          [-5.6245e-01, -5.5642e+00, -1.4566e+00],\n",
      "          [ 2.0358e+00,  2.4543e+00,  2.8901e+00]],\n",
      "\n",
      "         [[ 9.8229e-03, -3.3810e-01,  6.9166e-01],\n",
      "          [-7.7013e-01, -4.0775e+00, -1.4067e+00],\n",
      "          [ 2.0891e+00,  1.2382e+00,  1.6708e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1997e+00, -2.0407e-01, -9.8837e-01],\n",
      "          [ 2.0941e+00,  2.6897e-02, -1.8246e+00],\n",
      "          [ 1.3779e+00, -5.4085e-02, -1.6043e+00]],\n",
      "\n",
      "         [[ 2.3261e+00,  4.5013e-01, -2.4839e+00],\n",
      "          [ 2.7801e+00,  2.2091e+00, -6.9971e+00],\n",
      "          [ 1.6253e+00,  2.9629e+00, -2.9562e+00]],\n",
      "\n",
      "         [[ 1.9762e+00,  4.0773e-01, -2.0454e+00],\n",
      "          [ 2.2640e+00,  1.9361e+00, -4.6838e+00],\n",
      "          [ 1.0588e+00,  2.0956e+00, -2.7309e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1733e+00, -2.7729e+00, -1.7499e+00],\n",
      "          [ 3.5866e-01,  8.2942e-01,  2.6163e-01],\n",
      "          [ 8.7565e-01,  2.1464e+00,  1.2149e+00]],\n",
      "\n",
      "         [[-2.7854e+00, -6.0865e+00, -4.0350e+00],\n",
      "          [ 6.7674e-01,  2.2204e+00,  1.1464e+00],\n",
      "          [ 1.5138e+00,  4.7692e+00,  2.5181e+00]],\n",
      "\n",
      "         [[-1.9750e+00, -3.2870e+00, -2.2396e+00],\n",
      "          [ 1.4092e-01,  9.3969e-01,  2.3869e-01],\n",
      "          [ 1.4179e+00,  3.1532e+00,  1.6456e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.7871e-01, -8.7981e-01, -1.2766e+00],\n",
      "          [-8.1388e-01, -1.0796e+00, -1.8633e+00],\n",
      "          [-4.7098e-01, -1.3827e+00, -1.8523e+00]],\n",
      "\n",
      "         [[ 1.5711e-01,  1.4340e+00,  1.1901e+00],\n",
      "          [ 1.8079e-02,  2.8383e+00,  1.8065e+00],\n",
      "          [ 4.2325e-01,  3.5249e+00,  2.3787e+00]],\n",
      "\n",
      "         [[-1.4742e-01,  1.6849e-02, -3.0093e-01],\n",
      "          [-4.2318e-01, -3.8822e-01, -1.3402e+00],\n",
      "          [-9.6164e-02, -1.3735e-02, -5.6644e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6447e-03, -1.8409e-03, -5.1892e-04],\n",
      "          [-1.7787e-03, -2.0455e-03, -2.0477e-03],\n",
      "          [-6.2765e-04, -8.3364e-04,  4.8243e-04]],\n",
      "\n",
      "         [[ 1.2635e-03, -4.9726e-04,  8.7828e-04],\n",
      "          [-5.3243e-04, -3.4650e-03, -2.4240e-03],\n",
      "          [ 1.1583e-03, -1.0884e-03,  1.0517e-03]],\n",
      "\n",
      "         [[ 1.4506e-03, -1.7678e-04,  2.0314e-03],\n",
      "          [-5.6690e-04, -3.1178e-03, -1.3729e-03],\n",
      "          [ 7.1481e-04, -9.1992e-04,  1.1404e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1301e-01,  1.2201e+00,  8.2837e-01],\n",
      "          [ 5.3810e-01,  2.0795e+00,  1.4958e+00],\n",
      "          [ 5.6250e-01,  2.1517e+00,  1.5210e+00]],\n",
      "\n",
      "         [[-2.5055e-01,  1.2587e-01, -2.1229e-01],\n",
      "          [-1.5278e-01,  5.7696e-01, -1.4731e-01],\n",
      "          [-2.2991e-01,  5.4600e-01,  1.5077e-02]],\n",
      "\n",
      "         [[-3.5617e-01, -6.5537e-01, -6.3880e-01],\n",
      "          [-1.0006e+00, -1.3598e+00, -1.8171e+00],\n",
      "          [-4.9149e-01, -8.6150e-01, -1.3855e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5149e-05, -1.2261e-05,  7.7667e-07],\n",
      "          [ 6.7261e-05, -1.6265e-05,  1.9869e-05],\n",
      "          [-1.4543e-05, -1.6220e-04, -1.0762e-04]],\n",
      "\n",
      "         [[ 3.6989e-05, -2.6363e-05, -5.7226e-05],\n",
      "          [ 6.0943e-05, -7.7950e-06,  1.4932e-05],\n",
      "          [-8.5327e-05, -1.9436e-04, -1.4946e-04]],\n",
      "\n",
      "         [[ 1.5198e-05, -1.3461e-05, -1.3127e-05],\n",
      "          [ 3.2630e-05,  6.8084e-07,  2.0728e-05],\n",
      "          [-2.5122e-05, -1.0187e-04, -6.5982e-05]]],\n",
      "\n",
      "\n",
      "        [[[-2.2736e-01, -2.8255e-01,  2.4754e-01],\n",
      "          [ 1.4710e-01,  2.5922e-01,  7.8402e-01],\n",
      "          [ 8.1816e-02,  1.0730e-02,  3.7887e-01]],\n",
      "\n",
      "         [[-4.5854e-01, -1.2932e+00, -5.6359e-01],\n",
      "          [ 4.6283e-01,  1.8193e+00,  2.2658e+00],\n",
      "          [-7.8963e-01, -1.2513e+00,  5.5860e-02]],\n",
      "\n",
      "         [[-6.1207e-01, -1.2115e+00, -8.2625e-01],\n",
      "          [ 5.9614e-01,  1.8612e+00,  2.2263e+00],\n",
      "          [-3.5473e-01, -2.3251e-01,  7.4126e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7082e-05, -6.7861e-06, -2.9466e-05],\n",
      "          [ 5.6829e-06, -1.5180e-05, -2.4663e-05],\n",
      "          [-1.7183e-05, -1.1255e-05, -1.0335e-05]],\n",
      "\n",
      "         [[-5.0465e-06, -1.7906e-05, -1.3794e-05],\n",
      "          [ 1.2852e-05,  8.4162e-06, -2.8190e-06],\n",
      "          [-1.1875e-05,  5.2404e-06, -4.9197e-06]],\n",
      "\n",
      "         [[-1.0886e-05, -1.7122e-05, -1.2608e-05],\n",
      "          [-6.1066e-06, -2.7529e-05,  1.3082e-06],\n",
      "          [-1.8349e-05, -7.3425e-06, -1.0883e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4470e-05,  2.8592e-05,  6.1130e-06],\n",
      "          [-3.4086e-05, -1.0966e-04, -1.5394e-04],\n",
      "          [ 4.3749e-05,  1.2475e-05, -2.2999e-05]],\n",
      "\n",
      "         [[ 1.6148e-05, -2.1611e-06, -4.5601e-05],\n",
      "          [-7.8785e-05, -1.2939e-04, -1.6481e-04],\n",
      "          [-2.2955e-06, -7.6295e-06, -4.5257e-05]],\n",
      "\n",
      "         [[ 1.2335e-05, -9.2498e-06, -1.2562e-05],\n",
      "          [-3.9911e-05, -4.7529e-05, -8.9187e-05],\n",
      "          [-3.7376e-06,  2.1035e-05,  6.6711e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.7460e-01,  4.8523e-01,  6.0815e-01],\n",
      "          [ 4.5948e-01,  1.5254e-01,  5.1088e-01],\n",
      "          [ 4.6595e-01,  5.1054e-02,  9.5947e-02]],\n",
      "\n",
      "         [[ 6.5237e-01,  7.2784e-01,  7.3151e-01],\n",
      "          [ 7.8388e-01, -2.9308e+00, -2.0079e+00],\n",
      "          [-9.7896e-02, -5.2494e+00, -3.7617e+00]],\n",
      "\n",
      "         [[ 1.5342e-01, -3.1574e-01, -1.8108e-02],\n",
      "          [ 5.5608e-01, -6.2295e-01,  7.4962e-01],\n",
      "          [ 5.4856e-01, -5.7621e-01,  1.1804e+00]]]]) conv_bias: tensor([ 1.8194e+00, -4.6134e-04, -5.0178e+00,  6.3187e+00, -3.0287e+00,\n",
      "         5.9636e+00,  5.1741e+00,  3.8572e+00,  3.8592e+00, -7.6353e-02,\n",
      "         1.5772e+01, -3.8195e-03,  7.8675e+00, -2.0567e-04, -3.6811e-03,\n",
      "        -4.1723e+00])\n",
      "torch.Size([16, 3, 3, 3]) torch.Size([16])\n",
      "q_weight: tensor([  -5,   22,    9,    1,   33,    8,    4,   16,    9,   -7,  -13,  -33,\n",
      "         -41,  -58, -123,  -21,    6,  -68,   -5,   19,   11,  -19,   90,   53,\n",
      "           5,  101,   65,  -42,  -27,  -48,  -49,  -85,   10,  -78,  -90,   29,\n",
      "           0,   -2,   19,  -12,  -67,   13,  -22,    1,   12,   92,  127,   95,\n",
      "          44,   80,   73,   38,   38,  119,    9,  -42,  -26,   -2, -122,  -68,\n",
      "          37,  -24,   43,   52,   29,   33,    9, -114,  -65,   27,   15,   46,\n",
      "          24,   13,  -29,   -8,  -90,  -63,  -31,  -71,  -70,    1,  -20,   23,\n",
      "           7,  -16,  -30,   -6,  -33,  -45,    3,   14,   92,   34,  -28,  -61,\n",
      "          23,  -87, -121,   -9,   22,   81,   40,  -16,  -59,   37,  -69, -122,\n",
      "           4,   -9,  -17,    8,   20,    8,    8,    5,   -5,  -60,  -22,  -18,\n",
      "         -33,  105,  114,  -44,   12,    4,   53,   15,   72,   24,  -79,  -67,\n",
      "          66,  -25,   21,   -3,   -4,    3,  -11,  -25,   -4,   15,   16,    7,\n",
      "         -11,   -7,   29,  -12, -121,  -32,   44,   53,   63,    0,   -7,   15,\n",
      "         -17,  -89,  -31,   45,   27,   36,   21,   -4,  -17,   37,    0,  -32,\n",
      "          24,   -1,  -28,   41,    8,  -44,   49,   39, -123,   29,   52,  -52,\n",
      "          35,    7,  -36,   40,   34,  -83,   19,   37,  -48,  -24,  -56,  -35,\n",
      "           7,   17,    5,   18,   43,   24,  -56, -123,  -81,   14,   45,   23,\n",
      "          31,   96,   51,  -40,  -66,  -45,    3,   19,    5,   29,   64,   33,\n",
      "         -17,  -30,  -44,  -28,  -37,  -64,  -16,  -48,  -64,    5,   50,   41,\n",
      "           1,   98,   63,   15,  122,   82,   -5,    1,  -10,  -15,  -13,  -46,\n",
      "          -3,    0,  -20,  -59,  -66,  -19,  -64,  -73,  -73,  -22,  -30,   17,\n",
      "          45,  -18,   31,  -19, -124,  -87,   41,  -39,   38,   52,   -6,   73,\n",
      "         -20, -111,  -49,   26,  -33,   41,   18,   69,   47,   31,  118,   85,\n",
      "          32,  122,   86,  -14,    7,  -12,   -9,   33,   -8,  -13,   31,    1,\n",
      "         -20,  -37,  -36,  -57,  -77, -103,  -28,  -49,  -79,   16,   -8,    0,\n",
      "          43,  -10,   13,   -9, -104,  -69,   24,  -17,  -37,   39,   -5,   10,\n",
      "         -55, -124,  -96,   10,   -9,   -8,   21,    0,   13,  -16,  -65,  -42,\n",
      "         -11,  -13,   12,    7,   12,   37,    4,    1,   18,  -22,  -61,  -27,\n",
      "          22,   86,  107,  -37,  -59,    3,  -29,  -57,  -39,   28,   88,  105,\n",
      "         -17,  -11,   35,  -73,  -29, -126,   24,  -65, -105,  -73,  -48,  -44,\n",
      "         -22,  -77,  -59,   55,   36,  -12,  -51,   22,  -21,  -47,  -73,  -54,\n",
      "         -26, -118,    6,  -78,  -31,  -47,   26,   22,    5,  -26,  -83, -116,\n",
      "          33,    9,  -17,   12,   -2,  -34,  -59,  -98, -124,   -2,   -6,  -34,\n",
      "           9,   -7,   -9,  -30,  -36,  -67,   -3,   16,    5,   -4,   11,   14,\n",
      "          10,    3,   11,   10,    1,    2,   15,   16,   16,   18,  -66,  -45,\n",
      "          -2, -118,  -85,    3,   -7,    0,   13,  -14,   17,   12,  -13,   27],\n",
      "       dtype=torch.int32) q_bias: tensor([   2678,  -62969,  -35066,   23586,  -13185,    6253,    4405,    3754,\n",
      "           6451, -131665,   43238, -118002,   17991,  -42486, -134076,   -4532],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0004) tensor(0.0269)   bias tensor(4.6534e-06) tensor(0.0003)\n",
      "features.1.conv.0.weight features.1.conv.2\n",
      "torch.Size([16, 1, 3, 3]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.9150]) torch.Size([1]) \n",
      "wscale= tensor([2.0231e-02, 1.1921e-07, 9.6402e-02, 3.6751e-02, 7.0179e-02, 1.8813e-02,\n",
      "        2.2307e-02, 1.3546e-02, 2.1835e-02, 4.9273e-03, 2.2337e-02, 5.1404e-06,\n",
      "        3.5159e-02, 3.0039e-07, 9.0166e-06, 1.3852e-02]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([1.1763]) torch.Size([1])\n",
      "###: M= tensor([1.5736e-02, 9.2725e-08, 7.4985e-02, 2.8586e-02, 5.4587e-02, 1.4633e-02,\n",
      "        1.7351e-02, 1.0536e-02, 1.6984e-02, 3.8326e-03, 1.7374e-02, 3.9984e-06,\n",
      "        2.7348e-02, 2.3365e-07, 7.0134e-06, 1.0775e-02])\n",
      "torch.Size([16, 1, 3, 3]) torch.Size([16])\n",
      "conv_weight: tensor([[[-1.2236e-01, -1.9260e-01, -1.5167e-01],\n",
      "         [-3.1449e-01,  1.9771e+00, -2.1277e-01],\n",
      "         [-6.7444e-02, -1.1966e-01, -8.0968e-02]],\n",
      "\n",
      "        [[ 7.9461e-07, -3.6255e-06, -3.1106e-06],\n",
      "         [-6.2434e-06, -1.1379e-06,  3.8460e-06],\n",
      "         [ 4.1406e-06, -2.8958e-06, -5.1026e-06]],\n",
      "\n",
      "        [[ 2.5926e-01,  3.3278e-01,  7.4221e-01],\n",
      "         [-5.6647e-01, -2.7212e+00,  4.8120e-02],\n",
      "         [ 1.5743e-01, -7.0520e-01,  6.7363e-01]],\n",
      "\n",
      "        [[ 2.5121e-01, -1.4537e-01, -3.0009e-01],\n",
      "         [ 1.9372e+00, -1.7054e-01, -1.3664e+00],\n",
      "         [-2.2420e-03, -3.5198e-01,  2.0748e-02]],\n",
      "\n",
      "        [[-9.0778e-01,  2.4274e-01, -8.9436e-01],\n",
      "         [ 1.6957e+00,  5.3500e+00, -7.3166e-01],\n",
      "         [-5.8182e-01,  1.2988e+00, -1.3398e-01]],\n",
      "\n",
      "        [[-4.5564e-02,  1.4151e-01, -9.4054e-03],\n",
      "         [ 1.3190e-01, -1.6086e+00,  6.5114e-02],\n",
      "         [ 9.4319e-03,  1.1659e-01,  1.0480e-01]],\n",
      "\n",
      "        [[ 1.8700e-02, -9.8228e-02,  1.1189e-02],\n",
      "         [ 1.9200e-02,  1.1408e+00, -1.0016e-01],\n",
      "         [ 3.3104e-02,  7.8034e-02,  6.0818e-03]],\n",
      "\n",
      "        [[ 6.8497e-03, -6.7198e-03, -1.3150e-03],\n",
      "         [-2.6885e-02, -6.1214e-02, -1.3330e-02],\n",
      "         [ 6.0883e-02, -1.4750e+00,  8.2132e-03]],\n",
      "\n",
      "        [[-1.9127e-01, -2.4938e-01, -1.9536e-01],\n",
      "         [-1.9041e-01,  2.0835e+00, -2.0762e-01],\n",
      "         [-1.1427e-01,  7.3296e-02, -3.2223e-02]],\n",
      "\n",
      "        [[-1.0489e-03,  3.5538e-02, -4.1547e-02],\n",
      "         [-7.4724e-02,  6.2577e-01, -9.5487e-02],\n",
      "         [-2.6463e-02, -1.1887e-02, -7.2626e-02]],\n",
      "\n",
      "        [[-3.3521e-02, -2.6770e-01, -8.6255e-02],\n",
      "         [-3.4527e-01,  2.0177e+00, -2.5637e-01],\n",
      "         [-5.5361e-02, -6.4847e-02, -1.1713e-01]],\n",
      "\n",
      "        [[ 3.9422e-05,  3.3610e-04,  7.4842e-05],\n",
      "         [-1.9915e-04,  6.5283e-04, -1.8023e-04],\n",
      "         [-4.5758e-05, -5.0517e-04, -2.2444e-04]],\n",
      "\n",
      "        [[ 4.0156e-02, -8.4839e-02,  1.7770e-02],\n",
      "         [ 1.0163e-01, -1.5463e+00, -5.1380e-02],\n",
      "         [ 2.2368e-01,  1.4071e+00,  1.9168e-01]],\n",
      "\n",
      "        [[-1.5404e-06, -3.0917e-06, -6.0540e-06],\n",
      "         [-1.0678e-05, -3.8149e-05, -8.2485e-06],\n",
      "         [-8.0739e-06, -1.0955e-05, -1.3437e-05]],\n",
      "\n",
      "        [[ 1.6235e-05, -1.6622e-04, -8.2191e-05],\n",
      "         [-1.0663e-04,  1.1451e-03, -5.7541e-05],\n",
      "         [-5.4637e-05,  4.7010e-05, -4.4611e-05]],\n",
      "\n",
      "        [[ 1.1125e-01, -2.2749e-01,  1.6822e-01],\n",
      "         [ 1.6059e-01, -1.2859e+00,  1.2946e-01],\n",
      "         [ 6.7019e-02,  1.4124e-01,  1.4522e-01]]]) conv_bias: tensor([ 4.0063e+00, -7.6094e-05,  4.5670e+00,  4.9899e+00,  3.5424e-01,\n",
      "         1.2647e+01,  2.9678e-01,  1.1794e+01,  1.7300e+00, -3.9836e-02,\n",
      "         3.2458e-02,  1.6637e-03,  4.2365e+00, -2.4523e-04, -2.2347e-03,\n",
      "         8.0277e+00])\n",
      "torch.Size([16, 1, 3, 3]) torch.Size([16])\n",
      "q_weight: tensor([  -6,  -10,   -7,  -16,   98,  -11,   -3,   -6,   -4,    7,  -30,  -26,\n",
      "         -52,  -10,   32,   35,  -24,  -43,    3,    3,    8,   -6,  -28,    0,\n",
      "           2,   -7,    7,    7,   -4,   -8,   53,   -5,  -37,    0,  -10,    1,\n",
      "         -13,    3,  -13,   24,   76,  -10,   -8,   19,   -2,   -2,    8,    0,\n",
      "           7,  -86,    3,    1,    6,    6,    1,   -4,    1,    1,   51,   -4,\n",
      "           1,    3,    0,    1,    0,    0,   -2,   -5,   -1,    4, -109,    1,\n",
      "          -9,  -11,   -9,   -9,   95,  -10,   -5,    3,   -1,    0,    7,   -8,\n",
      "         -15,  127,  -19,   -5,   -2,  -15,   -2,  -12,   -4,  -15,   90,  -11,\n",
      "          -2,   -3,   -5,    8,   65,   15,  -39,  127,  -35,   -9,  -98,  -44,\n",
      "           1,   -2,    1,    3,  -44,   -1,    6,   40,    5,   -5,  -10,  -20,\n",
      "         -36, -127,  -27,  -27,  -36,  -45,    2,  -18,   -9,  -12,  127,   -6,\n",
      "          -6,    5,   -5,    8,  -16,   12,   12,  -93,    9,    5,   10,   10],\n",
      "       dtype=torch.int32) q_bias: tensor([ 216, -698,   52,  148,    6,  735,   15,  952,   87,   -9,    2,  354,\n",
      "         132, -892, -271,  633], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0007) tensor(0.0481)   bias tensor(-0.0043) tensor(0.0134)\n",
      "features.1.conv.3.weight features.1.conv.5\n",
      "torch.Size([8, 16, 1, 1]) conv_bias= torch.Size([8]) \n",
      "ascale= tensor([1.0306]) torch.Size([1]) \n",
      "wscale= tensor([0.0211, 0.0107, 0.0078, 0.0080, 0.0078, 0.0122, 0.0090, 0.0104]) torch.Size([8, 1, 1, 1]) \n",
      "oscale= tensor([0.2329]) torch.Size([1])\n",
      "###: M= tensor([0.0933, 0.0472, 0.0345, 0.0354, 0.0345, 0.0539, 0.0397, 0.0461])\n",
      "torch.Size([8, 16, 1, 1]) torch.Size([8])\n",
      "conv_weight: tensor([[ 5.4598e-02,  1.6691e-05, -2.5569e-02,  6.2992e-03,  5.4212e-02,\n",
      "         -4.5821e-03,  6.1991e-03, -1.0470e-02,  6.0277e-02,  2.4185e-03,\n",
      "         -4.0685e-01,  8.2382e-05, -1.4066e-02, -1.0986e-05,  1.0133e-04,\n",
      "         -5.3852e-02],\n",
      "        [-2.9604e-01,  1.1096e-05,  2.9526e-02,  5.0217e-02, -2.6106e-01,\n",
      "         -4.8092e-02,  6.8796e-02, -1.0182e-02,  9.7409e-02, -3.3280e-03,\n",
      "         -5.2508e-02,  1.7246e-05,  3.1504e-02, -1.3142e-05, -3.3247e-05,\n",
      "          1.4133e-01],\n",
      "        [-7.3992e-02,  8.7512e-07, -1.0425e-01,  1.3533e-01, -4.2962e-02,\n",
      "         -1.6584e-01, -1.8073e-01, -9.8369e-02, -1.3078e-01,  4.5309e-03,\n",
      "         -3.4865e-02, -6.5069e-06,  6.6202e-02, -2.5281e-05,  2.5163e-04,\n",
      "         -1.8060e-01],\n",
      "        [-9.1346e-02,  6.4541e-05, -4.4011e-02, -1.2534e-01, -1.5815e-02,\n",
      "         -2.2744e-01,  1.4531e-01, -1.4028e-01, -1.3075e-01, -2.3040e-04,\n",
      "         -2.7897e-02,  9.4738e-05,  1.5872e-02, -2.7260e-05,  1.9464e-05,\n",
      "         -1.3376e-01],\n",
      "        [ 8.9767e-02,  3.6560e-05,  1.6379e-01, -2.7435e-02, -1.0516e-01,\n",
      "         -8.2036e-02, -1.5950e-01, -2.7468e-02, -1.4447e-01, -3.9126e-03,\n",
      "         -4.2819e-02,  1.1257e-04, -7.4321e-02, -2.2134e-05, -1.8321e-04,\n",
      "          2.3494e-01],\n",
      "        [-9.5786e-02, -5.6813e-05, -5.9914e-02, -6.1569e-03, -2.9377e-02,\n",
      "         -8.0336e-02, -1.7354e-02,  3.4374e-01, -1.1657e-01,  2.5791e-03,\n",
      "         -4.2148e-02, -2.0487e-04, -1.5195e-01,  5.6672e-06,  1.9765e-05,\n",
      "         -1.1276e-01],\n",
      "        [-1.2303e-01, -1.1615e-05, -5.8478e-02, -4.9716e-02,  8.3467e-02,\n",
      "         -2.1209e-02, -1.7536e-01, -3.7900e-02,  2.0135e-01,  9.3717e-04,\n",
      "          2.7882e-02,  2.4724e-05, -9.0618e-02, -1.2356e-05,  1.1194e-04,\n",
      "         -8.9925e-03],\n",
      "        [ 1.3298e-01,  2.0763e-05, -8.7803e-03, -5.2794e-03, -1.3733e-02,\n",
      "         -3.6462e-01,  5.2021e-03,  1.2302e-01,  1.6153e-01,  1.9729e-03,\n",
      "          5.0666e-02,  1.2456e-04,  8.6110e-02, -7.4515e-05,  8.3427e-05,\n",
      "          8.7264e-02]]) conv_bias: tensor([ 2.7001,  0.4657,  4.7292,  4.3405,  0.7493,  2.1542,  1.9424, -1.7372])\n",
      "torch.Size([8, 16, 1, 1]) torch.Size([8])\n",
      "q_weight: tensor([  3,   0,  -1,   0,   3,   0,   0,   0,   3,   0, -19,   0,  -1,   0,\n",
      "          0,  -3, -28,   0,   3,   5, -24,  -5,   6,  -1,   9,   0,  -5,   0,\n",
      "          3,   0,   0,  13, -10,   0, -13,  17,  -6, -21, -23, -13, -17,   1,\n",
      "         -4,   0,   9,   0,   0, -23, -11,   0,  -6, -16,  -2, -28,  18, -18,\n",
      "        -16,   0,  -3,   0,   2,   0,   0, -17,  12,   0,  21,  -4, -14, -11,\n",
      "        -20,  -4, -19,  -1,  -5,   0, -10,   0,   0,  30,  -8,   0,  -5,  -1,\n",
      "         -2,  -7,  -1,  28, -10,   0,  -3,   0, -12,   0,   0,  -9, -14,   0,\n",
      "         -7,  -6,   9,  -2, -20,  -4,  22,   0,   3,   0, -10,   0,   0,  -1,\n",
      "         13,   0,  -1,  -1,  -1, -35,   0,  12,  16,   0,   5,   0,   8,   0,\n",
      "          0,   8], dtype=torch.int32) q_bias: tensor([ 124,   42,  589,  526,   93,  172,  210, -162], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0002) tensor(0.0094)   bias tensor(0.0020) tensor(0.0045)\n",
      "features.2.conv.0.weight features.2.conv.2\n",
      "torch.Size([48, 8, 1, 1]) conv_bias= torch.Size([48]) \n",
      "ascale= tensor([0.2329]) torch.Size([1]) \n",
      "wscale= tensor([0.0062, 0.0112, 0.0092, 0.0055, 0.0068, 0.0092, 0.0050, 0.0048, 0.0081,\n",
      "        0.0076, 0.0057, 0.0053, 0.0082, 0.0068, 0.0114, 0.0163, 0.0072, 0.0192,\n",
      "        0.0098, 0.0083, 0.0170, 0.0135, 0.0148, 0.0124, 0.0085, 0.0184, 0.0110,\n",
      "        0.0150, 0.0080, 0.0083, 0.0123, 0.0153, 0.0147, 0.0174, 0.0064, 0.0069,\n",
      "        0.0146, 0.0091, 0.0104, 0.0058, 0.0088, 0.0112, 0.0196, 0.0108, 0.0058,\n",
      "        0.0201, 0.0051, 0.0076]) torch.Size([48, 1, 1, 1]) \n",
      "oscale= tensor([0.8437]) torch.Size([1])\n",
      "###: M= tensor([0.0017, 0.0031, 0.0025, 0.0015, 0.0019, 0.0025, 0.0014, 0.0013, 0.0022,\n",
      "        0.0021, 0.0016, 0.0015, 0.0023, 0.0019, 0.0032, 0.0045, 0.0020, 0.0053,\n",
      "        0.0027, 0.0023, 0.0047, 0.0037, 0.0041, 0.0034, 0.0024, 0.0051, 0.0030,\n",
      "        0.0041, 0.0022, 0.0023, 0.0034, 0.0042, 0.0040, 0.0048, 0.0018, 0.0019,\n",
      "        0.0040, 0.0025, 0.0029, 0.0016, 0.0024, 0.0031, 0.0054, 0.0030, 0.0016,\n",
      "        0.0055, 0.0014, 0.0021])\n",
      "torch.Size([48, 8, 1, 1]) torch.Size([48])\n",
      "conv_weight: tensor([[ 4.5758e-02, -5.8502e-01, -6.7729e-01, -4.1052e-01,  7.4027e-01,\n",
      "         -4.3905e-01,  5.8682e-01,  1.3932e-01],\n",
      "        [ 4.4223e-03,  1.7709e-01, -1.2979e+00,  9.2208e-01, -4.2500e-01,\n",
      "         -1.7155e-02, -6.5789e-01, -2.4685e-03],\n",
      "        [-1.1599e+00,  8.7394e-02, -1.8614e-02, -2.3070e-03,  1.5539e-01,\n",
      "         -5.6237e-02,  3.1694e-02, -5.0640e-02],\n",
      "        [ 7.9857e-02, -2.5243e-01,  6.3179e-01,  6.3093e-01, -6.6333e-01,\n",
      "          6.2871e-01,  5.2089e-01, -2.0428e-01],\n",
      "        [ 2.1509e-01,  2.3245e-01,  8.4000e-01,  3.0081e-01,  4.6109e-01,\n",
      "          4.1568e-01,  3.6066e-01, -2.1893e-01],\n",
      "        [ 1.5091e-02, -2.7962e-03,  4.0173e-01, -1.0891e+00,  1.8505e-01,\n",
      "          4.9958e-01,  9.8059e-02, -5.4596e-01],\n",
      "        [ 4.8400e-01,  3.0230e-01,  5.9606e-01,  5.9617e-01, -1.0887e-01,\n",
      "          4.3596e-01, -1.6135e-01, -1.9743e-01],\n",
      "        [ 1.5058e-01, -5.9293e-01,  1.3285e-01,  1.0313e-01, -5.2232e-02,\n",
      "          7.9666e-02, -1.6348e-01, -6.6611e-02],\n",
      "        [ 1.0466e-01, -2.1661e-02,  6.3509e-01,  1.8940e-01, -3.2865e-01,\n",
      "         -3.8083e-01, -3.8054e-01,  9.3841e-01],\n",
      "        [ 2.0220e-02, -3.0889e-01, -9.3341e-01,  6.5764e-03,  7.1693e-01,\n",
      "          4.8177e-01,  5.4322e-01, -2.6165e-01],\n",
      "        [-1.0553e-01, -2.1401e-01, -6.4020e-01, -2.4084e-01, -2.4839e-01,\n",
      "          6.4739e-02, -3.4460e-01,  6.3876e-01],\n",
      "        [-3.5961e-01,  1.1334e-03,  2.9971e-02,  7.4823e-02, -6.1241e-01,\n",
      "          6.8608e-02,  5.9982e-01,  1.8501e-01],\n",
      "        [ 3.5756e-01, -1.3443e-01,  8.5483e-01,  2.9729e-01, -5.3045e-01,\n",
      "         -9.0543e-01, -2.2421e-01, -2.5090e-01],\n",
      "        [ 4.4111e-02, -2.5358e-01,  4.1302e-02,  5.6464e-02,  8.3379e-01,\n",
      "         -4.4803e-03,  6.5717e-01,  7.3026e-01],\n",
      "        [ 1.7286e-02, -1.5665e-01, -6.9113e-01,  1.4273e+00,  3.9268e-02,\n",
      "         -3.4310e-01,  3.0410e-02,  6.3585e-01],\n",
      "        [ 2.0452e+00, -9.9895e-01,  1.3218e-01, -3.2789e-02, -6.4084e-01,\n",
      "         -3.3424e-02,  2.4328e-01,  1.4478e-01],\n",
      "        [ 2.3117e-01, -3.7315e-02,  4.8625e-01,  8.1394e-01, -2.8381e-01,\n",
      "         -1.8880e-01, -3.7120e-02,  1.7320e-01],\n",
      "        [ 1.0304e-01, -2.1414e+00, -3.2945e-01, -5.6967e-01, -1.1330e+00,\n",
      "         -7.3026e-01,  4.6466e-01,  5.0674e-01],\n",
      "        [-2.3536e-02, -3.6949e-01,  1.1747e+00, -1.1591e+00,  1.1235e+00,\n",
      "          1.8634e-01,  1.0370e+00,  9.6457e-02],\n",
      "        [ 1.2092e-02, -1.1611e-01, -2.3679e-01, -1.0193e+00,  2.8251e-01,\n",
      "         -5.9183e-02,  1.3074e-01, -4.7760e-01],\n",
      "        [ 1.2504e-01, -3.7589e-01,  2.1341e+00, -1.6396e+00,  1.0245e-01,\n",
      "          5.2142e-01,  8.4297e-01, -2.6485e-01],\n",
      "        [-1.6644e+00,  1.3363e-01,  4.3639e-03,  4.0860e-01,  2.5743e-01,\n",
      "          9.4467e-02,  1.5767e-01, -1.7548e-01],\n",
      "        [ 1.1045e-02,  4.3838e-02,  1.5899e-01,  4.4511e-01,  3.0018e-01,\n",
      "          4.4102e-01, -2.7510e-01,  1.7911e+00],\n",
      "        [ 8.2146e-02,  2.8164e-01,  6.9757e-01,  8.4389e-01,  4.2333e-01,\n",
      "         -1.3969e+00, -1.0196e-01,  3.6648e-01],\n",
      "        [-1.3198e-02, -1.6195e-01,  1.0705e+00, -1.3349e-01,  5.3229e-01,\n",
      "         -3.8229e-01,  5.9203e-01,  5.1345e-01],\n",
      "        [ 1.6515e-01, -2.8621e-01,  1.3035e+00,  1.3540e+00, -6.0016e-01,\n",
      "         -2.2701e+00,  5.9359e-01, -8.6126e-01],\n",
      "        [-4.6713e-01,  1.3506e+00, -3.4202e-01, -2.7973e-01, -1.4899e-01,\n",
      "         -1.1788e-01,  7.1394e-01,  2.8052e-02],\n",
      "        [ 1.6517e-01, -5.1261e-03, -1.2083e-01, -1.9765e-01,  2.9587e-02,\n",
      "         -2.1572e-01,  2.1927e-01, -1.8609e+00],\n",
      "        [-8.6546e-02, -2.7213e-01, -6.4239e-01, -5.5967e-01, -8.8429e-01,\n",
      "         -2.9660e-01, -7.2105e-01,  1.5175e-01],\n",
      "        [ 1.3157e-01,  1.8659e-01,  1.0281e+00,  1.8341e-01, -2.1653e-01,\n",
      "         -5.2108e-01, -1.7056e-01,  4.0282e-01],\n",
      "        [ 6.4409e-02, -3.6322e-01, -5.0453e-01, -7.7425e-01, -2.6004e-01,\n",
      "          1.4471e+00,  1.8478e-01,  4.8920e-02],\n",
      "        [-2.0321e-02, -1.0112e+00,  1.9651e-01,  2.6677e-01,  1.4043e+00,\n",
      "          1.3358e-01, -1.8645e+00, -3.4910e-01],\n",
      "        [-1.8363e+00,  6.8483e-02,  1.8438e-01,  2.2000e-01,  1.4083e-01,\n",
      "          8.4404e-02,  5.5940e-02, -1.5493e-01],\n",
      "        [ 3.6965e-02, -1.3635e-01, -7.8784e-01, -1.0428e+00,  2.4923e-01,\n",
      "          2.1300e+00, -1.7249e-01,  6.9800e-01],\n",
      "        [ 6.0074e-01,  6.0829e-01, -3.9672e-01, -4.6410e-01, -5.2438e-01,\n",
      "         -3.8116e-01,  7.7437e-01,  4.7323e-01],\n",
      "        [ 9.9942e-02,  2.6322e-01,  8.3658e-01,  1.5373e-01, -8.1068e-01,\n",
      "         -2.3358e-01, -6.1080e-01, -2.4046e-01],\n",
      "        [ 8.7075e-02, -2.5881e-01, -1.4484e+00,  1.8049e+00, -6.6985e-02,\n",
      "          1.8802e-01,  5.0195e-01, -2.2805e-01],\n",
      "        [ 4.5743e-02, -9.5887e-02, -6.8039e-01,  4.0696e-01, -1.1408e+00,\n",
      "          2.7696e-01, -4.8851e-01, -4.0892e-01],\n",
      "        [ 1.2935e+00, -9.1457e-01, -1.0014e-01,  1.3693e-01,  9.0865e-01,\n",
      "         -4.1039e-02, -7.7305e-01,  2.3901e-02],\n",
      "        [ 5.5517e-02,  1.8361e-03, -1.2570e-01,  6.6091e-01, -5.4680e-02,\n",
      "         -2.1750e-01, -3.3826e-04,  2.7010e-01],\n",
      "        [-1.0653e+00,  4.6673e-02,  8.3898e-02,  1.4221e-01, -4.9295e-02,\n",
      "          8.9785e-02,  5.9194e-02, -1.0209e-01],\n",
      "        [-9.1522e-01, -1.3318e+00,  8.6359e-01,  5.4570e-01, -2.1353e-01,\n",
      "          5.1218e-01, -9.6427e-01, -6.0829e-01],\n",
      "        [-7.8147e-02, -5.8206e-01, -1.1911e+00, -7.4641e-01, -1.7026e-01,\n",
      "          2.4192e+00,  1.8571e-01,  1.6727e-01],\n",
      "        [ 5.4212e-02, -7.1198e-01,  7.4567e-01, -5.7611e-01,  9.3833e-01,\n",
      "          3.5352e-02,  1.3115e+00,  4.9460e-03],\n",
      "        [ 1.3406e-01, -2.0067e-01, -7.2041e-01,  1.2127e-01,  6.8203e-01,\n",
      "          3.5328e-01,  2.5583e-01,  5.9465e-01],\n",
      "        [ 2.4139e+00, -9.4012e-01,  2.1288e-01,  1.6511e-01, -6.0350e-01,\n",
      "          2.1562e-01,  1.4956e-01, -1.0975e-02],\n",
      "        [ 3.0675e-01, -5.4077e-01, -5.1243e-01, -5.3026e-01, -1.6760e-02,\n",
      "         -5.9163e-01, -6.3549e-02,  2.4346e-01],\n",
      "        [ 9.6935e-02,  1.1067e-02, -1.6865e-01,  3.7046e-01, -9.4802e-01,\n",
      "          1.9996e-02, -7.1181e-01,  5.9780e-02]]) conv_bias: tensor([ 4.2766,  0.4242,  2.0056,  2.3587,  4.2949,  2.7548,  4.4008, -1.6699,\n",
      "         3.0137,  4.9582,  3.2810, -1.1494,  1.6506,  4.4749,  1.3940,  1.7679,\n",
      "         3.4186,  0.2509,  1.0000,  3.6003,  1.2879,  0.5392, -1.1613,  0.7463,\n",
      "         2.0331,  0.9933,  1.6621, -0.8348,  4.4048,  3.7557,  1.2241,  1.6071,\n",
      "         0.5314,  0.0355,  0.9658,  3.7645,  0.6094,  0.4446,  0.9689, -1.0605,\n",
      "         2.3912,  1.0315,  0.6047,  2.3979,  4.6601,  1.8253,  3.9314,  3.4067])\n",
      "torch.Size([48, 8, 1, 1]) torch.Size([48])\n",
      "q_weight: tensor([   7,  -94, -109,  -66,  119,  -70,   94,   22,    0,   16, -115,   82,\n",
      "         -38,   -2,  -58,    0, -126,    9,   -2,    0,   17,   -6,    3,   -6,\n",
      "          15,  -46,  115,  115, -121,  114,   95,  -37,   32,   34,  124,   44,\n",
      "          68,   61,   53,  -32,    2,    0,   44, -119,   20,   55,   11,  -60,\n",
      "          97,   60,  119,  119,  -22,   87,  -32,  -40,   31, -123,   27,   21,\n",
      "         -11,   16,  -34,  -14,   13,   -3,   78,   23,  -41,  -47,  -47,  116,\n",
      "           3,  -41, -123,    1,   94,   63,   72,  -34,  -18,  -37, -112,  -42,\n",
      "         -43,   11,  -60,  111,  -67,    0,    6,   14, -115,   13,  112,   35,\n",
      "          44,  -16,  105,   36,  -65, -111,  -27,  -31,    7,  -37,    6,    8,\n",
      "         123,   -1,   97,  108,    2,  -14,  -60,  125,    3,  -30,    3,   56,\n",
      "         125,  -61,    8,   -2,  -39,   -2,   15,    9,   32,   -5,   67,  112,\n",
      "         -39,  -26,   -5,   24,    5, -111,  -17,  -30,  -59,  -38,   24,   26,\n",
      "          -2,  -38,  120, -119,  115,   19,  106,   10,    1,  -14,  -28, -123,\n",
      "          34,   -7,   16,  -57,    7,  -22,  126,  -97,    6,   31,   50,  -16,\n",
      "        -123,   10,    0,   30,   19,    7,   12,  -13,    1,    3,   11,   30,\n",
      "          20,   30,  -19,  121,    7,   23,   56,   68,   34, -113,   -8,   30,\n",
      "          -2,  -19,  125,  -16,   62,  -45,   69,   60,    9,  -16,   71,   74,\n",
      "         -33, -124,   32,  -47,  -42,  122,  -31,  -25,  -13,  -11,   65,    3,\n",
      "          11,    0,   -8,  -13,    2,  -14,   15, -124,  -11,  -34,  -80,  -70,\n",
      "        -110,  -37,  -90,   19,   16,   22,  124,   22,  -26,  -63,  -21,   48,\n",
      "           5,  -29,  -41,  -63,  -21,  117,   15,    4,   -1,  -66,   13,   17,\n",
      "          92,    9, -122,  -23, -125,    5,   13,   15,   10,    6,    4,  -11,\n",
      "           2,   -8,  -45,  -60,   14,  122,  -10,   40,   94,   95,  -62,  -73,\n",
      "         -82,  -60,  121,   74,   14,   38,  121,   22, -117,  -34,  -88,  -35,\n",
      "           6,  -18,  -99,  123,   -5,   13,   34,  -16,    5,  -10,  -74,   45,\n",
      "        -125,   30,  -53,  -45,  124,  -88,  -10,   13,   87,   -4,  -74,    2,\n",
      "          10,    0,  -22,  115,  -10,  -38,    0,   47, -121,    5,   10,   16,\n",
      "          -6,   10,    7,  -12,  -82, -119,   77,   49,  -19,   46,  -86,  -54,\n",
      "          -4,  -30,  -61,  -38,   -9,  123,    9,    9,    5,  -66,   69,  -53,\n",
      "          87,    3,  121,    0,   23,  -35, -124,   21,  118,   61,   44,  102,\n",
      "         120,  -47,   11,    8,  -30,   11,    7,   -1,   60, -106, -101, -104,\n",
      "          -3, -116,  -12,   48,   13,    1,  -22,   49, -124,    3,  -93,    8],\n",
      "       dtype=torch.int32) q_bias: tensor([ 2942,   162,   935,  1841,  2716,  1292,  3781, -1484,  1595,  2805,\n",
      "         2456,  -923,   867,  2832,   523,   465,  2026,    56,   440,  1860,\n",
      "          325,   172,  -337,   258,  1022,   232,   646,  -240,  2350,  1939,\n",
      "          426,   452,   156,     9,   649,  2334,   179,   209,   399,  -792,\n",
      "         1167,   397,   133,   953,  3448,   390,  3312,  1917],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0002) tensor(0.0094)   bias tensor(-7.0021e-05) tensor(0.0017)\n",
      "features.2.conv.3.weight features.2.conv.5\n",
      "torch.Size([48, 1, 3, 3]) conv_bias= torch.Size([48]) \n",
      "ascale= tensor([0.5631]) torch.Size([1]) \n",
      "wscale= tensor([0.0238, 0.0043, 0.0332, 0.0087, 0.0353, 0.0079, 0.0487, 0.0212, 0.0192,\n",
      "        0.0126, 0.0214, 0.0102, 0.0062, 0.0263, 0.0071, 0.0104, 0.0261, 0.0031,\n",
      "        0.0036, 0.0457, 0.0030, 0.0067, 0.0028, 0.0024, 0.0082, 0.0025, 0.0041,\n",
      "        0.0054, 0.0215, 0.0088, 0.0038, 0.0028, 0.0068, 0.0026, 0.0064, 0.0252,\n",
      "        0.0057, 0.0077, 0.0050, 0.0105, 0.0318, 0.0024, 0.0029, 0.0090, 0.0125,\n",
      "        0.0061, 0.0193, 0.0155]) torch.Size([48, 1, 1, 1]) \n",
      "oscale= tensor([0.2438]) torch.Size([1])\n",
      "###: M= tensor([0.0549, 0.0099, 0.0766, 0.0201, 0.0814, 0.0183, 0.1125, 0.0490, 0.0444,\n",
      "        0.0291, 0.0494, 0.0237, 0.0143, 0.0607, 0.0164, 0.0241, 0.0604, 0.0072,\n",
      "        0.0084, 0.1054, 0.0069, 0.0155, 0.0064, 0.0056, 0.0190, 0.0058, 0.0095,\n",
      "        0.0124, 0.0498, 0.0203, 0.0088, 0.0065, 0.0157, 0.0061, 0.0147, 0.0582,\n",
      "        0.0131, 0.0178, 0.0116, 0.0244, 0.0734, 0.0055, 0.0067, 0.0207, 0.0289,\n",
      "        0.0141, 0.0446, 0.0357])\n",
      "torch.Size([48, 1, 3, 3]) torch.Size([48])\n",
      "conv_weight: tensor([[[ 1.5259e-01, -2.1925e-01,  3.6271e-02],\n",
      "         [ 4.1359e-01, -4.9113e-01,  7.8948e-02],\n",
      "         [ 2.1885e-01, -2.5620e-01, -2.9772e-03]],\n",
      "\n",
      "        [[-1.1963e-01, -1.3387e-01, -7.4361e-02],\n",
      "         [-2.0430e-01, -2.1612e-01, -1.5235e-01],\n",
      "         [-6.4871e-02, -1.0920e-01, -7.7353e-02]],\n",
      "\n",
      "        [[ 2.5190e-01,  3.3972e-01,  2.1717e-01],\n",
      "         [ 1.5043e-01,  2.5072e-01,  5.1283e-02],\n",
      "         [-2.8280e-01, -6.1707e-01, -4.4183e-01]],\n",
      "\n",
      "        [[ 3.8399e-02,  7.7046e-02,  4.3578e-02],\n",
      "         [ 7.9849e-02,  2.0310e-01,  1.6163e-01],\n",
      "         [ 8.1757e-02,  1.6743e-01,  1.2549e-01]],\n",
      "\n",
      "        [[ 1.7813e-01, -3.4774e-01,  1.4872e-01],\n",
      "         [ 4.4246e-01, -6.3196e-01,  2.6510e-01],\n",
      "         [ 2.6304e-01, -2.6687e-01,  1.7618e-02]],\n",
      "\n",
      "        [[-9.0694e-02, -2.6955e-01, -1.6434e-02],\n",
      "         [ 1.9335e-01, -6.1491e-02, -3.1676e-01],\n",
      "         [ 1.0005e-01,  2.9972e-01,  4.5793e-02]],\n",
      "\n",
      "        [[ 1.2611e-01,  6.5875e-02, -1.5466e-01],\n",
      "         [-2.4392e-02,  4.6116e-01, -5.0538e-01],\n",
      "         [-7.7359e-02,  4.3690e-01, -3.6589e-01]],\n",
      "\n",
      "        [[ 1.9940e-01,  2.8950e-01,  2.5426e-01],\n",
      "         [ 4.0946e-01,  6.8290e-01,  4.8711e-01],\n",
      "         [ 4.1595e-01,  5.8702e-01,  4.1278e-01]],\n",
      "\n",
      "        [[ 1.0166e-01,  1.3501e-01,  9.5861e-03],\n",
      "         [-2.6827e-01, -4.3178e-01, -2.2729e-01],\n",
      "         [ 1.2428e-01,  3.3671e-01,  1.6962e-01]],\n",
      "\n",
      "        [[ 7.0354e-02,  2.0784e-01,  1.9469e-01],\n",
      "         [-2.2236e-01, -4.3932e-01, -3.4230e-01],\n",
      "         [ 1.5794e-01,  2.7594e-01,  1.7922e-01]],\n",
      "\n",
      "        [[ 1.8145e-01, -3.6044e-01,  1.6418e-01],\n",
      "         [-3.2374e-01,  6.2093e-01, -3.4734e-01],\n",
      "         [ 7.1573e-02, -2.0304e-01,  1.6092e-01]],\n",
      "\n",
      "        [[ 2.1493e-01,  1.8398e-01,  9.6353e-02],\n",
      "         [ 2.0729e-01,  3.7281e-01,  2.1061e-01],\n",
      "         [ 2.0065e-01,  2.5485e-01,  2.2489e-01]],\n",
      "\n",
      "        [[-1.0511e-01, -2.8740e-01, -1.3668e-01],\n",
      "         [ 1.6765e-01,  2.7316e-01,  1.0108e-01],\n",
      "         [ 4.5343e-02,  8.2122e-03, -3.9928e-04]],\n",
      "\n",
      "        [[ 1.3142e-02, -1.7066e-01,  6.5455e-02],\n",
      "         [-1.9727e-01,  2.2151e-02,  2.8066e-01],\n",
      "         [ 3.9367e-02,  1.7106e-01, -3.7739e-01]],\n",
      "\n",
      "        [[-8.9280e-02, -5.3122e-02,  6.7227e-02],\n",
      "         [-1.0514e-01, -2.7011e-01, -5.5974e-02],\n",
      "         [ 3.1262e-02, -2.2921e-01, -1.8543e-01]],\n",
      "\n",
      "        [[-4.7164e-02,  1.6141e-01,  2.3273e-01],\n",
      "         [-1.3011e-01,  1.2181e-01,  2.9351e-01],\n",
      "         [-9.2354e-02, -1.1461e-01, -3.6736e-02]],\n",
      "\n",
      "        [[ 1.8839e-03, -2.9128e-01,  2.2011e-01],\n",
      "         [ 1.3796e-01,  3.9745e-01, -6.6896e-01],\n",
      "         [-1.1493e-01, -1.3572e-01,  4.3369e-01]],\n",
      "\n",
      "        [[-1.2271e-03,  3.6537e-02,  5.1760e-02],\n",
      "         [ 7.3111e-02,  1.5356e-01,  1.1334e-01],\n",
      "         [ 8.0262e-02,  1.1474e-01,  6.0125e-02]],\n",
      "\n",
      "        [[-3.3999e-03, -1.5282e-01, -1.3470e-01],\n",
      "         [-1.0027e-01, -1.8244e-01, -2.4590e-01],\n",
      "         [-7.5366e-02, -1.6388e-01, -1.3245e-01]],\n",
      "\n",
      "        [[ 6.8401e-02,  1.7884e-02, -6.8958e-02],\n",
      "         [-2.9630e-01,  5.7073e-01, -3.1845e-01],\n",
      "         [ 1.5513e-01, -5.6743e-01,  4.0838e-01]],\n",
      "\n",
      "        [[ 8.6012e-02,  3.7970e-02, -4.6010e-02],\n",
      "         [ 1.3726e-01,  1.9066e-01,  3.3931e-02],\n",
      "         [ 3.6773e-02,  1.8019e-01,  9.2276e-02]],\n",
      "\n",
      "        [[-1.3547e-01,  6.5857e-02,  1.7460e-01],\n",
      "         [-1.5615e-01,  1.7532e-01,  2.3749e-01],\n",
      "         [ 3.4391e-03,  6.5787e-02, -5.6915e-02]],\n",
      "\n",
      "        [[-7.8340e-02, -1.7648e-01, -9.8890e-02],\n",
      "         [-1.5087e-01, -2.7204e-01, -2.5444e-01],\n",
      "         [-8.7263e-02, -1.9968e-01, -1.9373e-01]],\n",
      "\n",
      "        [[-1.3655e-01, -1.2760e-01, -1.6575e-01],\n",
      "         [-1.5939e-01, -1.3047e-01, -1.5346e-01],\n",
      "         [-5.2860e-02, -1.6514e-01, -2.4210e-02]],\n",
      "\n",
      "        [[ 7.6877e-02,  5.0016e-03, -3.7089e-02],\n",
      "         [-7.5997e-02, -3.1962e-01, -6.9631e-02],\n",
      "         [-2.4634e-01, -2.6531e-01,  4.8052e-02]],\n",
      "\n",
      "        [[-6.0976e-02, -1.4272e-01, -9.3181e-02],\n",
      "         [-2.5425e-02, -1.1903e-01, -1.1924e-01],\n",
      "         [-1.0517e-02, -2.3005e-02, -2.3284e-02]],\n",
      "\n",
      "        [[ 4.3638e-02,  7.2302e-02,  4.2477e-02],\n",
      "         [ 1.0332e-01,  2.1863e-01,  1.1253e-01],\n",
      "         [ 6.3663e-02,  1.3009e-01,  6.4197e-02]],\n",
      "\n",
      "        [[ 8.7945e-02,  9.6337e-02,  1.0138e-01],\n",
      "         [ 1.6340e-01,  3.6305e-01,  2.3005e-01],\n",
      "         [ 1.0796e-01,  2.8463e-01,  2.2650e-01]],\n",
      "\n",
      "        [[ 2.2425e-02, -9.6531e-02,  1.0371e-03],\n",
      "         [ 1.6076e-01, -3.8360e-01,  2.0472e-01],\n",
      "         [-2.6562e-01,  4.6286e-01, -1.7367e-01]],\n",
      "\n",
      "        [[ 5.8827e-03, -2.9222e-01, -5.5451e-02],\n",
      "         [-2.2233e-01, -2.0185e-01,  2.7853e-01],\n",
      "         [-2.9507e-02,  2.1561e-01,  1.1176e-01]],\n",
      "\n",
      "        [[-1.1567e-01, -7.2720e-02,  1.9343e-01],\n",
      "         [-1.1494e-01, -2.2293e-01, -5.2015e-02],\n",
      "         [-8.4305e-02, -1.0973e-01, -8.5699e-02]],\n",
      "\n",
      "        [[ 4.2529e-02,  6.9031e-02,  3.8204e-02],\n",
      "         [ 7.7878e-02,  1.5603e-01,  8.2056e-02],\n",
      "         [ 6.6549e-02,  1.1413e-01,  6.7877e-02]],\n",
      "\n",
      "        [[-1.5583e-01, -2.9027e-01, -8.5779e-02],\n",
      "         [ 1.2098e-01,  1.3325e-01, -6.0257e-03],\n",
      "         [ 2.1662e-01,  3.4710e-01,  3.2152e-02]],\n",
      "\n",
      "        [[-4.6060e-02, -1.4702e-01, -1.6255e-01],\n",
      "         [-7.7326e-02, -1.2976e-01, -1.6871e-01],\n",
      "         [-5.5993e-02, -1.2178e-01, -9.0937e-02]],\n",
      "\n",
      "        [[-5.4142e-02, -8.5114e-02, -5.7829e-02],\n",
      "         [-1.1226e-01, -1.6044e-01, -1.4200e-01],\n",
      "         [-9.2317e-02, -1.4753e-01, -1.0895e-01]],\n",
      "\n",
      "        [[-1.9009e-01, -3.7614e-02,  1.8873e-01],\n",
      "         [-1.9279e-01,  3.2654e-01, -1.3522e-01],\n",
      "         [ 2.4487e-01, -7.7702e-02, -1.6106e-01]],\n",
      "\n",
      "        [[ 4.2488e-02,  1.5443e-02,  5.5943e-02],\n",
      "         [ 1.3166e-01,  1.6799e-01,  1.4010e-01],\n",
      "         [ 6.7256e-02,  7.0193e-02,  7.7607e-02]],\n",
      "\n",
      "        [[ 7.6097e-02,  7.7116e-02, -1.7190e-03],\n",
      "         [ 5.1312e-02,  3.1918e-02, -2.5605e-01],\n",
      "         [-2.2532e-02, -2.3320e-01, -3.1959e-01]],\n",
      "\n",
      "        [[-7.4238e-02, -1.1761e-01, -5.8763e-02],\n",
      "         [-1.2148e-01, -1.4720e-01, -1.1509e-01],\n",
      "         [-8.8443e-02, -1.2135e-01, -1.2172e-01]],\n",
      "\n",
      "        [[-9.7672e-02, -8.7987e-02,  7.4486e-02],\n",
      "         [ 2.8810e-01,  7.1584e-02, -1.4864e-01],\n",
      "         [ 3.9587e-01,  5.4623e-01, -1.1868e-03]],\n",
      "\n",
      "        [[ 2.4199e-01,  3.9760e-02, -3.3493e-01],\n",
      "         [ 4.2224e-01,  1.4372e-01, -5.8844e-01],\n",
      "         [ 2.7111e-01,  1.6664e-01, -4.0979e-01]],\n",
      "\n",
      "        [[ 2.9597e-02,  5.8839e-02,  3.8117e-02],\n",
      "         [ 8.3083e-02,  1.8007e-01,  1.0167e-01],\n",
      "         [ 6.6709e-02,  1.1430e-01,  6.4027e-02]],\n",
      "\n",
      "        [[ 9.7014e-03,  1.1156e-01,  1.5882e-01],\n",
      "         [ 3.2368e-02,  1.5002e-01,  1.3559e-01],\n",
      "         [ 1.0114e-02,  5.5791e-02,  2.6797e-02]],\n",
      "\n",
      "        [[ 5.4860e-02, -4.4587e-03, -1.0147e-01],\n",
      "         [ 1.0207e-01,  3.8130e-02, -3.2090e-01],\n",
      "         [ 9.4117e-02,  1.3026e-02, -2.5855e-01]],\n",
      "\n",
      "        [[-9.8723e-02, -2.5941e-01, -8.5189e-02],\n",
      "         [ 2.5624e-01,  4.9510e-01,  2.3709e-01],\n",
      "         [-1.4396e-01, -3.2084e-01, -1.3657e-01]],\n",
      "\n",
      "        [[-7.3963e-02, -1.1741e-01, -3.4937e-02],\n",
      "         [ 8.6458e-02,  1.3041e-01,  3.4453e-02],\n",
      "         [ 1.4035e-01,  2.3760e-01,  5.2167e-02]],\n",
      "\n",
      "        [[ 5.6671e-02, -3.7127e-02,  2.8676e-02],\n",
      "         [ 1.0669e-01,  3.0787e-01, -3.8238e-01],\n",
      "         [ 1.1584e-01,  3.1897e-01, -5.5020e-01]],\n",
      "\n",
      "        [[ 7.7360e-03, -4.9943e-02, -4.1482e-03],\n",
      "         [ 1.3680e-01, -2.8233e-01,  1.7246e-01],\n",
      "         [ 1.7910e-01, -3.9040e-01,  1.9427e-01]]]) conv_bias: tensor([ 4.9079e-01,  1.7457e+00, -2.6642e-01,  1.7470e-01, -4.9670e-01,\n",
      "         2.0568e+00, -1.8817e-01,  6.0276e-01,  1.4655e-02, -5.7443e-01,\n",
      "        -1.3884e-01, -3.3797e-01,  2.1738e-01,  3.3905e+00,  2.9656e+00,\n",
      "         2.0422e+00, -1.9159e-02, -4.2868e-04,  1.7600e+00, -1.5224e-02,\n",
      "         5.5456e-01,  4.7093e-02,  5.7930e+00,  1.3174e+00,  3.2232e+00,\n",
      "         5.8024e+00, -1.6239e-01,  1.2088e-01,  9.6810e-02,  3.1285e+00,\n",
      "         3.9854e+00, -3.4108e-02,  5.3584e-01,  1.1640e+00,  2.4076e+00,\n",
      "         2.6821e+00, -7.5470e-01,  1.8256e+00,  2.1317e+00,  9.2240e-03,\n",
      "        -1.8700e-01, -4.4535e-01, -1.7579e-01,  4.7999e+00,  1.5638e-01,\n",
      "         7.0452e-01,  1.4998e-01,  9.6791e-02])\n",
      "torch.Size([48, 1, 3, 3]) torch.Size([48])\n",
      "q_weight: tensor([  6,  -9,   2,  17, -21,   3,   9, -11,   0, -28, -31, -17, -48, -50,\n",
      "        -36, -15, -25, -18,   8,  10,   7,   5,   8,   2,  -9, -19, -13,   4,\n",
      "          9,   5,   9,  23,  19,   9,  19,  14,   5, -10,   4,  13, -18,   8,\n",
      "          7,  -8,   0, -11, -34,  -2,  24,  -8, -40,  13,  38,   6,   3,   1,\n",
      "         -3,  -1,   9, -10,  -2,   9,  -8,   9,  14,  12,  19,  32,  23,  20,\n",
      "         28,  19,   5,   7,   0, -14, -22, -12,   6,  18,   9,   6,  16,  15,\n",
      "        -18, -35, -27,  13,  22,  14,   8, -17,   8, -15,  29, -16,   3,  -9,\n",
      "          8,  21,  18,   9,  20,  36,  21,  20,  25,  22, -17, -46, -22,  27,\n",
      "         44,  16,   7,   1,   0,   1,  -6,   2,  -8,   1,  11,   1,   7, -14,\n",
      "        -13,  -7,   9, -15, -38,  -8,   4, -32, -26,  -5,  15,  22, -12,  12,\n",
      "         28,  -9, -11,  -4,   0, -11,   8,   5,  15, -26,  -4,  -5,  17,   0,\n",
      "         12,  17,  23,  49,  36,  26,  37,  19,  -1, -42, -37, -28, -50, -68,\n",
      "        -21, -45, -36,   1,   0,  -2,  -6,  13,  -7,   3, -12,   9,  29,  13,\n",
      "        -15,  46,  64,  11,  12,  60,  31, -20,  10,  26, -23,  26,  35,   1,\n",
      "         10,  -8, -28, -64, -36, -54, -98, -92, -32, -72, -70, -57, -53, -69,\n",
      "        -66, -54, -64, -22, -68, -10,   9,   1,  -5,  -9, -39,  -8, -30, -32,\n",
      "          6, -24, -57, -37, -10, -48, -48,  -4,  -9,  -9,  11,  18,  10,  25,\n",
      "         53,  27,  15,  32,  16,  16,  18,  19,  30,  68,  43,  20,  53,  42,\n",
      "          1,  -4,   0,   7, -18,  10, -12,  21,  -8,   1, -33,  -6, -25, -23,\n",
      "         32,  -3,  25,  13, -30, -19,  51, -30, -58, -14, -22, -29, -22,  15,\n",
      "         25,  14,  28,  56,  29,  24,  41,  24, -23, -43, -13,  18,  20,  -1,\n",
      "         32,  51,   5, -17, -56, -62, -29, -49, -64, -21, -46, -34,  -8, -13,\n",
      "         -9, -18, -25, -22, -14, -23, -17,  -8,  -1,   7,  -8,  13,  -5,  10,\n",
      "         -3,  -6,   8,   3,  10,  23,  30,  25,  12,  12,  14,  10,  10,   0,\n",
      "          7,   4, -33,  -3, -30, -41, -15, -23, -12, -24, -29, -23, -18, -24,\n",
      "        -24,  -9,  -8,   7,  27,   7, -14,  38,  52,   0,   8,   1, -11,  13,\n",
      "          5, -19,   9,   5, -13,  12,  24,  16,  35,  75,  42,  28,  48,  27,\n",
      "          3,  39,  55,  11,  52,  47,   4,  19,   9,   6,   0, -11,  11,   4,\n",
      "        -36,  10,   1, -29,  -8, -21,  -7,  20,  40,  19, -12, -26, -11, -12,\n",
      "        -19,  -6,  14,  21,   6,  23,  39,   9,   3,  -2,   1,   6,  16, -20,\n",
      "          6,  17, -28,   0,  -3,   0,   9, -18,  11,  12, -25,  13],\n",
      "       dtype=torch.int32) q_bias: tensor([  37,  723,  -14,   36,  -25,  460,   -7,   50,    1,  -81,  -12,  -59,\n",
      "          62,  229,  740,  348,   -1,    0,  860,   -1,  328,   12, 3714,  970,\n",
      "         697, 4128,  -70,   40,    8,  631, 1849,  -22,  140,  783,  671,  189,\n",
      "        -237,  420,  752,    2,  -10, -329, -108,  950,   22,  204,   14,   11],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(1.5956e-05) tensor(0.0243)   bias tensor(0.0003) tensor(0.0105)\n",
      "features.2.conv.6.weight features.2.conv.8\n",
      "torch.Size([16, 48, 1, 1]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.1964]) torch.Size([1]) \n",
      "wscale= tensor([0.0026, 0.0057, 0.0038, 0.0034, 0.0037, 0.0041, 0.0077, 0.0040, 0.0049,\n",
      "        0.0042, 0.0043, 0.0042, 0.0044, 0.0051, 0.0055, 0.0033]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.0793]) torch.Size([1])\n",
      "###: M= tensor([0.0064, 0.0141, 0.0093, 0.0083, 0.0091, 0.0100, 0.0191, 0.0099, 0.0123,\n",
      "        0.0104, 0.0105, 0.0105, 0.0110, 0.0125, 0.0136, 0.0082])\n",
      "torch.Size([16, 48, 1, 1]) torch.Size([16])\n",
      "conv_weight: tensor([[ 2.6679e-02, -4.5411e-02,  1.5957e-02,  1.4105e-01, -1.0504e-01,\n",
      "         -3.3656e-02, -1.3999e-02, -5.5505e-02, -8.1284e-02, -3.7325e-02,\n",
      "          1.4265e-01,  4.0269e-02, -7.8905e-03,  8.5022e-02, -6.9502e-02,\n",
      "         -1.5111e-01,  1.6542e-01, -8.3180e-02, -1.3265e-02,  1.3615e-01,\n",
      "         -5.3581e-02,  8.3923e-02, -9.8058e-02, -6.0497e-02,  6.2220e-02,\n",
      "         -1.1123e-01, -6.0495e-02,  9.1729e-02,  1.1903e-01,  5.2564e-02,\n",
      "         -2.2636e-02,  9.9899e-02, -2.5676e-02, -1.0238e-01,  1.0957e-01,\n",
      "          8.9056e-02, -8.3981e-02,  5.1290e-02, -6.2156e-02,  8.3677e-02,\n",
      "         -1.0619e-01, -7.9950e-04,  9.6210e-02, -1.8686e-01, -1.0917e-01,\n",
      "         -1.1491e-02, -2.1555e-02, -8.3916e-02],\n",
      "        [ 8.6767e-03, -1.9558e-02,  1.1135e-01,  8.2361e-02, -4.2118e-02,\n",
      "         -1.0206e-01, -1.4107e-02,  2.8379e-01,  3.7039e-02,  5.0779e-02,\n",
      "         -8.4834e-02, -2.3532e-01,  6.8107e-02,  3.0620e-02, -7.6423e-02,\n",
      "          7.5043e-03, -3.1522e-02, -8.0700e-02,  3.5643e-02, -9.4584e-02,\n",
      "         -4.4665e-02, -3.0523e-02, -1.1669e-02,  3.0927e-02,  1.4268e-02,\n",
      "         -4.7783e-02,  2.9621e-01, -8.5396e-03, -3.7616e-02, -3.1000e-02,\n",
      "          1.2155e-01, -3.0469e-01, -4.1762e-04,  4.0474e-02, -1.7793e-01,\n",
      "         -2.1812e-02,  7.0844e-02, -1.3084e-02,  2.6072e-01, -1.5701e-03,\n",
      "          2.2263e-02,  7.1210e-02,  4.2131e-02, -1.0413e-01, -8.4251e-03,\n",
      "         -4.3141e-02,  8.6426e-02, -5.5173e-02],\n",
      "        [ 7.9851e-02,  2.8549e-03,  5.8681e-03, -4.8805e-02,  1.1584e-01,\n",
      "         -9.8556e-03,  8.4555e-02, -3.4578e-02,  1.5440e-01,  1.8254e-01,\n",
      "         -1.5492e-01, -2.7487e-02, -5.0344e-04,  1.1381e-01, -1.6036e-03,\n",
      "         -1.7546e-01, -1.1837e-01, -5.4433e-02, -3.1385e-02, -1.9118e-01,\n",
      "         -1.1104e-01,  1.6005e-01,  6.7583e-04,  3.9942e-02, -4.9128e-02,\n",
      "          9.1603e-02, -6.4032e-02,  2.0977e-02, -1.0053e-01, -1.5107e-01,\n",
      "          3.5167e-03, -5.7080e-03, -1.6444e-01,  3.7172e-02, -1.1821e-02,\n",
      "          3.7863e-02, -8.7656e-02,  3.4858e-02, -1.1899e-01, -7.8511e-02,\n",
      "         -3.0143e-02, -8.0504e-02, -5.2931e-02, -3.4510e-02,  1.8486e-01,\n",
      "          8.9528e-02,  7.4683e-02,  1.5918e-01],\n",
      "        [-4.2948e-02,  1.8304e-02,  4.2840e-02, -2.3838e-01, -9.3822e-02,\n",
      "         -5.1399e-02, -2.9007e-02, -9.5800e-02, -6.9752e-02, -9.3058e-02,\n",
      "          5.8632e-02, -5.6819e-02, -4.9365e-02,  9.6789e-02,  7.3976e-03,\n",
      "          6.2888e-02,  1.2432e-01, -9.0176e-02,  1.0616e-02,  6.6230e-02,\n",
      "         -7.0049e-03, -9.1770e-02,  5.1842e-02, -1.6276e-02,  6.0607e-02,\n",
      "          6.3485e-02, -1.0443e-01,  6.8131e-02,  7.2408e-02, -1.3492e-01,\n",
      "         -1.0268e-01, -4.1669e-02,  4.5245e-02, -1.4280e-01, -8.0449e-02,\n",
      "         -5.2409e-02, -2.3411e-02, -1.0901e-01, -1.4355e-01,  3.8128e-02,\n",
      "         -5.9238e-03, -2.3788e-01,  1.9030e-01,  3.5544e-02, -4.5710e-02,\n",
      "         -3.1653e-02,  1.3363e-02, -6.9666e-02],\n",
      "        [ 9.7471e-04, -2.4260e-02, -7.5182e-02, -2.3122e-02, -1.4590e-01,\n",
      "          5.5896e-02, -8.6839e-02,  1.9365e-02, -1.5158e-01, -9.0315e-02,\n",
      "         -1.3117e-02,  2.4597e-02, -1.1734e-02,  1.6314e-01, -4.9244e-02,\n",
      "          1.6376e-02,  9.7335e-02,  5.8624e-02,  1.2928e-01,  1.4310e-02,\n",
      "         -1.5858e-01, -3.4544e-02,  1.6889e-03, -3.1402e-02,  1.8697e-02,\n",
      "         -2.1120e-02,  4.3692e-02, -7.6266e-02, -6.4875e-02,  8.8700e-02,\n",
      "         -3.9906e-02, -3.8504e-02, -9.4285e-03,  2.3631e-02, -4.6403e-02,\n",
      "          1.4637e-01, -1.4111e-03,  4.6405e-02,  4.4090e-02,  2.2706e-02,\n",
      "         -8.4163e-02,  5.8691e-02, -1.1405e-01,  1.2756e-01, -1.4517e-01,\n",
      "          6.6261e-02, -1.7022e-01, -1.6828e-01],\n",
      "        [ 1.0002e-01, -1.1410e-02,  7.8595e-02, -1.0193e-01, -2.1663e-02,\n",
      "         -1.1624e-01, -3.0086e-02, -8.1084e-02,  1.6404e-01,  1.4376e-01,\n",
      "         -2.0175e-01,  3.3143e-02,  1.1001e-01, -1.2496e-01,  6.3913e-03,\n",
      "          2.5970e-02, -9.4097e-02,  3.1020e-02,  1.2866e-01, -1.4505e-01,\n",
      "         -3.8843e-02, -8.9820e-03,  3.3710e-02,  7.9382e-02,  1.5694e-01,\n",
      "          1.0078e-01, -7.6112e-02,  5.8084e-02, -2.0517e-01,  9.6436e-02,\n",
      "         -3.2755e-02,  5.8808e-02,  2.6143e-02, -8.6602e-02,  8.6874e-02,\n",
      "         -6.9963e-02,  1.0543e-01,  2.9601e-02, -2.9602e-02, -9.5298e-03,\n",
      "         -4.6253e-02,  6.0693e-03,  1.3534e-01, -1.3020e-02,  1.1577e-01,\n",
      "         -3.2914e-02, -5.5669e-02, -1.5019e-01],\n",
      "        [-3.4776e-02,  2.4387e-02,  2.0450e-01,  4.4637e-03, -2.4472e-02,\n",
      "          4.2111e-02, -2.7161e-02,  1.1439e-02,  2.2578e-01,  2.5938e-01,\n",
      "          7.3541e-02, -4.4376e-03,  1.1055e-01,  2.3790e-02, -2.9490e-02,\n",
      "          5.0443e-02,  1.4200e-01,  1.6617e-01,  1.5667e-02,  5.3382e-02,\n",
      "         -7.2528e-02, -8.0945e-02, -3.2216e-01, -1.5920e-01, -3.7496e-02,\n",
      "         -2.0628e-01,  8.3416e-02,  2.7899e-01,  2.6751e-02,  2.5646e-02,\n",
      "         -7.0031e-02,  8.9974e-03,  7.3580e-02, -1.2066e-01, -2.6847e-02,\n",
      "          2.6685e-02, -6.7868e-02, -2.0630e-02,  6.5329e-02, -7.7383e-03,\n",
      "         -1.0402e-01,  1.0745e-01,  2.5803e-02,  7.6344e-02,  2.1319e-01,\n",
      "         -1.7255e-02, -6.9558e-02, -2.6591e-02],\n",
      "        [-1.1743e-01,  4.1528e-02,  4.6978e-02, -2.0770e-02, -1.1302e-01,\n",
      "         -9.7506e-03, -9.2287e-02, -9.1590e-03, -4.6283e-02, -5.8329e-02,\n",
      "          2.9055e-02, -5.0256e-03,  1.8515e-02, -6.9915e-02,  2.2691e-02,\n",
      "         -2.5655e-01,  4.3468e-02,  2.5315e-02,  4.2614e-02,  2.8050e-02,\n",
      "          4.0853e-02,  1.9282e-01, -3.3096e-03, -4.2185e-02,  1.1318e-02,\n",
      "         -3.7032e-02, -1.7550e-02, -5.9387e-03, -9.7113e-03,  4.9132e-02,\n",
      "          1.3846e-02, -1.5210e-02, -2.5619e-01, -6.5228e-02, -1.7612e-02,\n",
      "         -7.1231e-02,  1.2299e-02, -3.7586e-02,  9.5548e-03,  6.7695e-02,\n",
      "         -1.3887e-02, -3.7232e-02,  7.0355e-02,  1.3523e-01, -5.7399e-02,\n",
      "          1.9577e-01, -5.6560e-02, -1.2636e-01],\n",
      "        [-9.9388e-03,  1.9309e-01, -3.2307e-02,  1.7537e-01, -3.9322e-02,\n",
      "         -1.1129e-01,  2.4154e-02,  2.5195e-03,  4.2172e-02,  7.8585e-02,\n",
      "         -7.1291e-02, -1.1429e-02,  5.0951e-02,  2.2746e-02,  7.9078e-02,\n",
      "          5.6132e-02,  6.9324e-03, -1.6449e-01, -8.3078e-02, -3.7600e-02,\n",
      "          1.1507e-01, -9.0409e-02, -2.2127e-02, -5.1956e-02, -1.3457e-01,\n",
      "         -6.6617e-02, -2.2371e-02,  3.1239e-02, -8.0149e-02, -5.5615e-02,\n",
      "         -1.7180e-02, -4.7420e-02, -4.8524e-02, -2.4352e-02, -3.0972e-02,\n",
      "         -2.6340e-02, -6.5360e-02,  1.2455e-01, -3.1330e-02,  1.8309e-01,\n",
      "         -7.6467e-03, -8.0142e-02, -2.9965e-02,  2.1994e-03,  4.6917e-02,\n",
      "          4.8952e-02, -1.5063e-01, -3.6810e-02],\n",
      "        [-8.6789e-02,  2.6732e-02, -2.0720e-02,  1.8246e-02, -4.0819e-02,\n",
      "         -1.5339e-01, -4.0912e-02, -5.7891e-02,  6.1194e-02,  4.1239e-02,\n",
      "          1.5668e-02,  4.1630e-02,  1.6241e-01,  6.0361e-02, -6.3512e-03,\n",
      "          9.9097e-03,  7.7509e-02,  3.9677e-02,  3.7345e-02, -1.2297e-02,\n",
      "         -1.3792e-03, -1.3263e-02, -3.2739e-03,  6.3887e-02, -9.8462e-02,\n",
      "          9.4909e-02, -5.2299e-02,  5.6697e-02,  4.0604e-02,  6.0765e-02,\n",
      "          1.5545e-01,  2.2523e-02,  3.5691e-02, -6.2352e-02,  6.9183e-02,\n",
      "          5.8635e-02, -7.7633e-02, -9.0716e-02, -9.5267e-03,  9.2381e-02,\n",
      "         -4.0609e-02,  3.1878e-02,  2.6157e-02,  1.3873e-01, -4.0004e-02,\n",
      "         -6.5463e-02,  1.9243e-02,  4.9294e-02],\n",
      "        [-8.4612e-02,  1.6035e-02,  6.9919e-02, -6.5103e-02, -6.5358e-02,\n",
      "          1.1209e-01, -7.8793e-02,  8.9843e-02,  8.5224e-02,  1.1608e-01,\n",
      "         -9.2540e-02, -1.8973e-01,  2.4600e-02,  5.1172e-04, -2.1704e-02,\n",
      "         -1.0446e-01, -3.4735e-02, -1.2644e-01,  5.9747e-02, -7.8203e-02,\n",
      "         -5.1830e-02,  8.3668e-02, -6.0043e-02, -1.3158e-01, -2.3575e-02,\n",
      "         -1.9488e-01,  3.9780e-02,  3.8598e-02, -1.3261e-01,  3.5455e-03,\n",
      "         -1.2406e-02, -4.1365e-02,  1.1270e-01, -3.9948e-02,  6.1971e-02,\n",
      "          5.6354e-03,  7.2032e-02,  3.3455e-02, -2.3677e-02, -8.9932e-02,\n",
      "         -8.7980e-02, -6.9483e-02,  7.7742e-03,  1.3273e-01,  1.0087e-01,\n",
      "         -2.5334e-01, -7.0593e-02, -1.2246e-01],\n",
      "        [ 6.0036e-03, -6.5249e-02,  3.1521e-02, -7.4366e-02,  5.1549e-02,\n",
      "          7.9803e-02,  7.6018e-02, -1.1581e-02, -2.8418e-02, -1.8183e-02,\n",
      "          2.7629e-02, -4.6511e-02,  6.2493e-02,  6.6657e-02,  1.0789e-01,\n",
      "         -3.5478e-02, -2.2806e-02, -5.1249e-03, -4.1443e-02,  3.4552e-02,\n",
      "          1.5630e-01,  3.0420e-02,  4.1443e-02,  1.1092e-01, -1.4617e-02,\n",
      "          5.7749e-02, -1.0442e-02,  9.9424e-03,  1.0753e-02,  1.9692e-01,\n",
      "         -1.1555e-01, -2.5437e-02, -6.9712e-02, -2.3376e-02, -3.9330e-02,\n",
      "          2.2710e-01,  5.5464e-02,  2.9469e-02, -2.1108e-02, -4.8530e-02,\n",
      "          1.0754e-01, -6.9347e-02,  5.6232e-02, -9.0893e-02, -9.0238e-02,\n",
      "          2.3868e-02,  4.1102e-02,  9.2181e-02],\n",
      "        [-2.6050e-02, -3.0058e-03,  2.4075e-02,  2.8944e-01, -2.5458e-02,\n",
      "          1.7152e-02,  9.9044e-03,  9.7865e-02, -3.2717e-02, -2.3961e-02,\n",
      "         -3.4754e-02,  7.4595e-02, -7.2557e-02,  1.1790e-01,  1.0926e-02,\n",
      "          4.7055e-03,  9.9887e-03, -7.8656e-03, -1.1293e-02, -3.7265e-02,\n",
      "          3.6066e-02,  1.5790e-03,  7.7259e-02,  8.1583e-02,  1.7136e-02,\n",
      "          1.2607e-01,  1.1854e-01,  6.4589e-02, -5.6596e-03, -1.0073e-01,\n",
      "         -1.6065e-01,  9.3425e-02, -4.1609e-03, -1.1360e-01,  8.9958e-02,\n",
      "         -1.2568e-03,  3.3512e-02, -1.0519e-01,  1.0841e-01,  1.8949e-02,\n",
      "          1.3123e-02,  1.7001e-01,  1.5050e-01,  5.5822e-02,  3.4139e-02,\n",
      "          1.6956e-02, -8.9938e-03,  3.2235e-02],\n",
      "        [ 2.4284e-01, -2.4466e-01, -1.4356e-01,  5.2626e-03,  2.2208e-01,\n",
      "         -6.7759e-02,  2.1293e-01,  9.8356e-03, -3.6693e-02, -1.2686e-02,\n",
      "          5.6556e-02, -7.8005e-02, -2.8507e-03,  2.1441e-02, -1.3918e-01,\n",
      "         -6.0093e-02,  7.3035e-02, -9.0917e-03, -5.0841e-02,  1.1290e-01,\n",
      "          9.3398e-02,  7.0464e-02,  1.4821e-02, -2.9422e-02,  5.5470e-02,\n",
      "         -8.0044e-03,  4.8150e-02, -3.6576e-02,  1.0545e-01,  2.2776e-02,\n",
      "          3.6178e-02, -2.9181e-02, -3.8168e-02,  2.0737e-02, -4.5077e-02,\n",
      "         -8.9619e-03,  1.8954e-01, -1.1084e-01, -1.2307e-02, -1.5718e-02,\n",
      "          2.1942e-01, -3.7499e-02, -8.0343e-02,  1.1269e-01, -4.8500e-02,\n",
      "         -3.7816e-02,  8.9890e-02,  1.8281e-01],\n",
      "        [ 2.0393e-02,  1.0998e-01, -6.1830e-03, -2.8604e-01, -1.1442e-02,\n",
      "         -9.7771e-02,  3.0045e-02,  5.3880e-02, -4.1712e-02, -4.7836e-02,\n",
      "          7.5450e-03, -1.2535e-01, -2.2578e-02,  8.1890e-03,  1.1091e-01,\n",
      "         -1.0306e-01,  1.9301e-02,  2.7004e-01, -7.1716e-02,  2.3362e-02,\n",
      "          1.0305e-01,  1.9394e-01, -1.9195e-02, -8.9608e-03, -5.8905e-02,\n",
      "          4.3809e-02,  1.3401e-01, -2.9296e-02,  2.4682e-02, -9.9395e-02,\n",
      "         -2.4418e-02, -4.4356e-02,  6.3211e-02,  4.3376e-02, -5.2238e-03,\n",
      "         -1.9372e-02, -7.9104e-02,  8.9825e-02,  8.5555e-02,  7.4512e-02,\n",
      "          1.1429e-02,  1.2703e-01,  2.6838e-03, -1.0717e-01, -5.3691e-02,\n",
      "         -1.5452e-01, -2.4321e-02, -8.1113e-04],\n",
      "        [ 1.4488e-04,  1.9984e-02, -9.2225e-02,  7.3802e-02,  3.5564e-02,\n",
      "          6.4220e-02,  9.7856e-03,  1.4214e-01,  1.1807e-02, -2.1503e-02,\n",
      "          8.9286e-02, -7.4493e-02, -2.3727e-02, -9.5220e-02,  8.2069e-02,\n",
      "         -4.1331e-02,  3.9264e-02, -7.9531e-02,  8.1126e-03,  8.9175e-02,\n",
      "         -5.7945e-02,  2.0660e-02, -1.4192e-02,  1.3387e-01,  7.1064e-02,\n",
      "          1.7975e-01,  1.2633e-01,  8.6476e-02,  3.6864e-02,  1.2444e-01,\n",
      "         -1.1863e-01, -1.7315e-01, -2.4668e-02, -9.6324e-02, -1.2059e-01,\n",
      "          1.4638e-02, -1.1223e-01,  9.3673e-03,  4.8246e-02,  8.6008e-02,\n",
      "         -7.9497e-02,  1.5466e-02,  4.8365e-02,  7.5401e-02,  3.5289e-02,\n",
      "         -2.9719e-02, -7.4103e-02,  3.8638e-02]]) conv_bias: tensor([ 1.2955,  0.1649,  0.8520,  1.3271, -0.9358, -0.5277,  1.5131,  0.4714,\n",
      "         0.5270, -1.4741,  1.5605, -1.3054, -2.6299, -0.1363,  0.8779, -1.2006])\n",
      "torch.Size([16, 48, 1, 1]) torch.Size([16])\n",
      "q_weight: tensor([ 10, -18,   6,  55, -41, -13,  -5, -22, -32, -15,  56,  16,  -3,  33,\n",
      "        -27, -59,  65, -32,  -5,  53, -21,  33, -38, -24,  24, -43, -24,  36,\n",
      "         46,  21,  -9,  39, -10, -40,  43,  35, -33,  20, -24,  33, -41,   0,\n",
      "         38, -73, -43,  -4,  -8, -33,   2,  -3,  20,  14,  -7, -18,  -2,  50,\n",
      "          6,   9, -15, -41,  12,   5, -13,   1,  -6, -14,   6, -17,  -8,  -5,\n",
      "         -2,   5,   3,  -8,  52,  -1,  -7,  -5,  21, -53,   0,   7, -31,  -4,\n",
      "         12,  -2,  46,   0,   4,  12,   7, -18,  -1,  -8,  15, -10,  21,   1,\n",
      "          2, -13,  31,  -3,  23,  -9,  41,  49, -41,  -7,   0,  30,   0, -47,\n",
      "        -32, -14,  -8, -51, -30,  43,   0,  11, -13,  24, -17,   6, -27, -40,\n",
      "          1,  -2, -44,  10,  -3,  10, -23,   9, -32, -21,  -8, -21, -14,  -9,\n",
      "         49,  24,  20,  42, -13,   5,  13, -71, -28, -15,  -9, -29, -21, -28,\n",
      "         17, -17, -15,  29,   2,  19,  37, -27,   3,  20,  -2, -27,  15,  -5,\n",
      "         18,  19, -31,  20,  22, -40, -31, -12,  13, -43, -24, -16,  -7, -33,\n",
      "        -43,  11,  -2, -71,  57,  11, -14,  -9,   4, -21,   0,  -7, -21,  -6,\n",
      "        -40,  15, -24,   5, -41, -25,  -4,   7,  -3,  45, -13,   4,  27,  16,\n",
      "         35,   4, -43,  -9,   0,  -9,   5,  -6,  12, -21, -18,  24, -11, -11,\n",
      "         -3,   6, -13,  40,   0,  13,  12,   6, -23,  16, -31,  35, -40,  18,\n",
      "        -46, -46,  25,  -3,  19, -25,  -5, -29,  -7, -20,  40,  35, -50,   8,\n",
      "         27, -31,   2,   6, -23,   8,  32, -36, -10,  -2,   8,  20,  39,  25,\n",
      "        -19,  14, -51,  24,  -8,  15,   6, -21,  21, -17,  26,   7,  -7,  -2,\n",
      "        -11,   1,  33,  -3,  29,  -8, -14, -37,  -5,   3,  27,   1,  -3,   5,\n",
      "         -4,   1,  29,  34,  10,  -1,  14,   3,  -4,   7,  18,  22,   2,   7,\n",
      "         -9, -11, -42, -21,  -5, -27,  11,  36,   3,   3,  -9,   1,  10, -16,\n",
      "         -3,   3,  -9,  -3,   8,  -1, -14,  14,   3,  10,  28,  -2,  -9,  -3,\n",
      "        -30,  10,  12,  -5, -28,  -2, -23,  -2, -12, -15,   7,  -1,   5, -18,\n",
      "          6, -64,  11,   6,  11,   7,  10,  48,  -1, -11,   3,  -9,  -4,  -1,\n",
      "         -2,  12,   3,  -4, -64, -16,  -4, -18,   3,  -9,   2,  17,  -3,  -9,\n",
      "         18,  34, -14,  49, -14, -32,  -2,  39,  -7,  35,  -8, -22,   5,   1,\n",
      "          9,  16, -14,  -2,  10,   5,  16,  11,   1, -33, -17,  -8,  23, -18,\n",
      "         -4, -11, -27, -13,  -5,   6, -16, -11,  -3, -10, -10,  -5,  -6,  -5,\n",
      "        -13,  25,  -6,  37,  -2, -16,  -6,   0,   9,  10, -30,  -7, -21,   6,\n",
      "         -5,   4, -10, -36, -10, -14,  15,  10,   4,  10,  39,  14,  -2,   2,\n",
      "         18,   9,   9,  -3,   0,  -3,  -1,  15, -23,  23, -12,  13,  10,  14,\n",
      "         37,   5,   8, -15,  16,  14, -18, -22,  -2,  22, -10,   8,   6,  33,\n",
      "        -10, -16,   5,  12, -20,   4,  16, -15, -15,  26, -19,  21,  20,  27,\n",
      "        -22, -45,   6,   0,  -5, -25,  -8, -30,  14, -18, -12,  20, -14, -31,\n",
      "         -6, -46,   9,   9, -31,   1,  -3, -10,  27,  -9,  15,   1,  17,   8,\n",
      "         -6, -21, -21, -16,   2,  31,  24, -60, -17, -29,   1, -15,   7, -18,\n",
      "         12,  19,  18,  -3,  -7,  -4,   7, -11,  15,  16,  26,  -8,  -5,  -1,\n",
      "        -10,   8,  37,   7,  10,  26,  -3,  14,  -2,   2,   3,  47, -27,  -6,\n",
      "        -16,  -6,  -9,  54,  13,   7,  -5, -11,  25, -16,  13, -21, -21,   6,\n",
      "         10,  22,  -6,  -1,   5,  65,  -6,   4,   2,  22,  -7,  -5,  -8,  17,\n",
      "        -16,  27,   2,   1,   2,  -2,  -3,  -8,   8,   0,  17,  18,   4,  29,\n",
      "         27,  15,  -1, -23, -36,  21,  -1, -26,  20,   0,   8, -24,  25,   4,\n",
      "          3,  38,  34,  13,   8,   4,  -2,   7,  48, -48, -28,   1,  44, -13,\n",
      "         42,   2,  -7,  -3,  11, -15,  -1,   4, -28, -12,  14,  -2, -10,  22,\n",
      "         18,  14,   3,  -6,  11,  -2,  10,  -7,  21,   5,   7,  -6,  -8,   4,\n",
      "         -9,  -2,  38, -22,  -2,  -3,  43,  -7, -16,  22, -10,  -7,  18,  36,\n",
      "          4,  20,  -1, -52,  -2, -18,   5,  10,  -8,  -9,   1, -23,  -4,   1,\n",
      "         20, -19,   4,  49, -13,   4,  19,  35,  -3,  -2, -11,   8,  24,  -5,\n",
      "          4, -18,  -4,  -8,  11,   8,  -1,  -4, -14,  16,  16,  14,   2,  23,\n",
      "          0, -19, -10, -28,  -4,   0,   0,   6, -28,  22,  11,  19,   3,  43,\n",
      "          4,  -6,  27, -22,  -7, -29,  25, -12,  12, -24,   2,  27, -17,   6,\n",
      "         -4,  40,  21,  54,  38,  26,  11,  38, -36, -52,  -7, -29, -36,   4,\n",
      "        -34,   3,  15,  26, -24,   5,  15,  23,  11,  -9, -22,  12],\n",
      "       dtype=torch.int32) q_bias: tensor([ 2574,   147,  1155,  2015, -1300,  -663,  1002,   603,   542, -1784,\n",
      "         1868, -1572, -3029,  -137,   813, -1846], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(3.0225e-05) tensor(0.0038)   bias tensor(-4.4049e-05) tensor(0.0005)\n",
      "features.3.conv.0.weight features.3.conv.2\n",
      "torch.Size([96, 16, 1, 1]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.0793]) torch.Size([1]) \n",
      "wscale= tensor([0.0146, 0.0114, 0.0061, 0.0092, 0.0033, 0.0111, 0.0074, 0.0053, 0.0076,\n",
      "        0.0039, 0.0157, 0.0027, 0.0075, 0.0010, 0.0063, 0.0054, 0.0131, 0.0051,\n",
      "        0.0082, 0.0107, 0.0065, 0.0047, 0.0108, 0.0076, 0.0080, 0.0053, 0.0055,\n",
      "        0.0082, 0.0058, 0.0043, 0.0077, 0.0056, 0.0045, 0.0055, 0.0146, 0.0058,\n",
      "        0.0053, 0.0099, 0.0069, 0.0080, 0.0034, 0.0102, 0.0073, 0.0072, 0.0105,\n",
      "        0.0054, 0.0118, 0.0076, 0.0116, 0.0063, 0.0058, 0.0090, 0.0044, 0.0075,\n",
      "        0.0051, 0.0272, 0.0110, 0.0204, 0.0054, 0.0073, 0.0074, 0.0081, 0.0061,\n",
      "        0.0047, 0.0090, 0.0125, 0.0130, 0.0047, 0.0073, 0.0205, 0.0181, 0.0079,\n",
      "        0.0046, 0.0092, 0.0179, 0.0029, 0.0086, 0.0099, 0.0245, 0.0104, 0.0051,\n",
      "        0.0191, 0.0064, 0.0115, 0.0052, 0.0103, 0.0064, 0.0044, 0.0065, 0.0148,\n",
      "        0.0062, 0.0049, 0.0068, 0.0057, 0.0073, 0.0059]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.2108]) torch.Size([1])\n",
      "###: M= tensor([0.0055, 0.0043, 0.0023, 0.0035, 0.0012, 0.0042, 0.0028, 0.0020, 0.0029,\n",
      "        0.0015, 0.0059, 0.0010, 0.0028, 0.0004, 0.0024, 0.0020, 0.0049, 0.0019,\n",
      "        0.0031, 0.0040, 0.0024, 0.0018, 0.0041, 0.0029, 0.0030, 0.0020, 0.0021,\n",
      "        0.0031, 0.0022, 0.0016, 0.0029, 0.0021, 0.0017, 0.0021, 0.0055, 0.0022,\n",
      "        0.0020, 0.0037, 0.0026, 0.0030, 0.0013, 0.0038, 0.0028, 0.0027, 0.0039,\n",
      "        0.0020, 0.0044, 0.0029, 0.0043, 0.0024, 0.0022, 0.0034, 0.0017, 0.0028,\n",
      "        0.0019, 0.0102, 0.0041, 0.0077, 0.0020, 0.0028, 0.0028, 0.0030, 0.0023,\n",
      "        0.0018, 0.0034, 0.0047, 0.0049, 0.0018, 0.0028, 0.0077, 0.0068, 0.0030,\n",
      "        0.0017, 0.0035, 0.0067, 0.0011, 0.0032, 0.0037, 0.0092, 0.0039, 0.0019,\n",
      "        0.0072, 0.0024, 0.0043, 0.0020, 0.0039, 0.0024, 0.0017, 0.0024, 0.0056,\n",
      "        0.0023, 0.0018, 0.0026, 0.0021, 0.0028, 0.0022])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "conv_weight: tensor([[-0.0791, -0.1542,  0.4692,  ..., -1.8056, -0.0374,  0.6052],\n",
      "        [-0.1673,  0.2934, -0.3342,  ...,  0.2061,  0.0713, -0.0081],\n",
      "        [ 0.2436,  0.1650,  0.2746,  ...,  0.1239, -0.1277,  0.2706],\n",
      "        ...,\n",
      "        [-0.2747,  0.1158, -0.3217,  ..., -0.3547, -0.2630, -0.0651],\n",
      "        [-0.2566, -0.0969,  0.1094,  ..., -0.9054,  0.2638, -0.0694],\n",
      "        [-0.4292, -0.2631,  0.1948,  ..., -0.3363, -0.3316, -0.2938]]) conv_bias: tensor([ 1.5545,  1.4120,  2.2797,  1.4057, -0.9299,  1.3912,  0.9576,  1.4512,\n",
      "         1.5373,  1.0888,  0.5537,  2.0222, -0.8252,  3.5651,  1.7988,  1.4789,\n",
      "         0.2860,  1.2447,  1.4422,  0.6578,  1.3915,  1.5509,  1.6251,  0.9531,\n",
      "         1.6870,  1.1231,  0.9534,  1.3526,  1.5860,  1.0601,  0.9502,  1.7013,\n",
      "         1.9576,  2.0752, -0.7407,  1.3741,  1.3646,  1.1664,  1.6100,  0.6083,\n",
      "        -0.8231, -0.2284,  2.0501,  1.6952, -0.4682,  1.8434,  1.6997,  1.4480,\n",
      "         0.8042,  0.3559,  2.3217,  0.3502,  1.7821,  1.0294,  1.0004, -0.7884,\n",
      "         0.9222,  0.8740,  1.1989,  2.4867,  1.3926,  2.4964,  0.9870,  0.9737,\n",
      "         1.2729, -0.2655, -0.6896,  1.6552,  1.0180,  1.3254,  1.1641,  0.2113,\n",
      "         1.6515,  0.4665,  0.5107, -1.2160,  0.6641,  0.3593,  0.0170,  0.5566,\n",
      "         1.3881,  1.7019,  0.5375,  0.9315,  0.8432,  0.5627,  1.5203,  1.2611,\n",
      "         1.1302, -0.4887, -0.2875,  2.0215,  2.4003,  1.6409,  0.9894,  2.1531])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "q_weight: tensor([ -5, -11,  32,  ..., -57, -56, -50], dtype=torch.int32) q_bias: tensor([ 1346,  1557,  4746,  1925, -3561,  1583,  1628,  3441,  2555,  3541,\n",
      "          446,  9569, -1394, 43602,  3629,  3474,   275,  3092,  2219,   772,\n",
      "         2698,  4154,  1895,  1580,  2671,  2654,  2202,  2076,  3467,  3080,\n",
      "         1548,  3858,  5437,  4771,  -640,  2969,  3227,  1488,  2951,   954,\n",
      "        -3067,  -283,  3532,  2988,  -564,  4270,  1815,  2398,   878,   709,\n",
      "         5038,   489,  5123,  1735,  2458,  -365,  1059,   540,  2798,  4281,\n",
      "         2386,  3897,  2039,  2633,  1779,  -267,  -669,  4405,  1749,   815,\n",
      "          811,   339,  4528,   637,   361, -5241,   976,   460,     9,   677,\n",
      "         3403,  1127,  1061,  1023,  2032,   690,  2979,  3584,  2211,  -417,\n",
      "         -581,  5256,  4423,  3647,  1705,  4608], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-8.5836e-05) tensor(0.0136)   bias tensor(-5.9354e-06) tensor(0.0005)\n",
      "features.3.conv.3.weight features.3.conv.5\n",
      "torch.Size([96, 1, 3, 3]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.1950]) torch.Size([1]) \n",
      "wscale= tensor([0.0076, 0.0113, 0.0275, 0.0120, 0.0179, 0.0052, 0.0078, 0.0082, 0.0129,\n",
      "        0.0095, 0.0053, 0.0114, 0.0035, 0.0544, 0.0186, 0.0097, 0.0096, 0.0074,\n",
      "        0.0226, 0.0111, 0.0125, 0.0197, 0.0067, 0.0154, 0.0192, 0.0128, 0.0120,\n",
      "        0.0143, 0.0182, 0.0167, 0.0139, 0.0145, 0.0128, 0.0180, 0.0085, 0.0138,\n",
      "        0.0195, 0.0055, 0.0171, 0.0136, 0.0113, 0.0074, 0.0424, 0.0131, 0.0058,\n",
      "        0.0165, 0.0212, 0.0247, 0.0131, 0.0094, 0.0214, 0.0067, 0.0163, 0.0056,\n",
      "        0.0158, 0.0046, 0.0097, 0.0143, 0.0155, 0.0190, 0.0328, 0.0182, 0.0081,\n",
      "        0.0070, 0.0155, 0.0056, 0.0096, 0.0151, 0.0089, 0.0182, 0.0147, 0.0437,\n",
      "        0.0163, 0.0141, 0.0150, 0.1783, 0.0135, 0.0073, 0.0054, 0.0062, 0.0105,\n",
      "        0.0064, 0.0148, 0.0060, 0.0120, 0.0137, 0.0200, 0.0109, 0.0079, 0.0050,\n",
      "        0.0126, 0.0226, 0.0206, 0.0232, 0.0112, 0.0298]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.1052]) torch.Size([1])\n",
      "###: M= tensor([0.0140, 0.0210, 0.0509, 0.0222, 0.0332, 0.0097, 0.0145, 0.0151, 0.0240,\n",
      "        0.0177, 0.0098, 0.0211, 0.0065, 0.1009, 0.0344, 0.0180, 0.0179, 0.0137,\n",
      "        0.0419, 0.0205, 0.0231, 0.0364, 0.0123, 0.0286, 0.0355, 0.0237, 0.0222,\n",
      "        0.0265, 0.0338, 0.0309, 0.0257, 0.0269, 0.0237, 0.0334, 0.0157, 0.0256,\n",
      "        0.0361, 0.0102, 0.0316, 0.0251, 0.0210, 0.0137, 0.0786, 0.0242, 0.0108,\n",
      "        0.0306, 0.0393, 0.0458, 0.0243, 0.0175, 0.0397, 0.0125, 0.0302, 0.0103,\n",
      "        0.0292, 0.0086, 0.0179, 0.0265, 0.0288, 0.0353, 0.0607, 0.0338, 0.0149,\n",
      "        0.0130, 0.0287, 0.0103, 0.0177, 0.0279, 0.0164, 0.0337, 0.0272, 0.0809,\n",
      "        0.0302, 0.0261, 0.0277, 0.3303, 0.0250, 0.0136, 0.0100, 0.0115, 0.0195,\n",
      "        0.0119, 0.0274, 0.0110, 0.0223, 0.0254, 0.0370, 0.0201, 0.0146, 0.0093,\n",
      "        0.0233, 0.0420, 0.0381, 0.0430, 0.0208, 0.0551])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "conv_weight: tensor([[[ 1.2496e-01, -1.5558e-02,  1.7681e-01],\n",
      "         [ 1.6225e-01, -8.6639e-01,  1.3847e-02],\n",
      "         [ 1.7908e-01, -9.8981e-02,  1.8749e-01]],\n",
      "\n",
      "        [[ 1.2539e-01,  2.3145e-01,  1.3575e-01],\n",
      "         [-9.7320e-02, -7.8180e-01, -3.3547e-01],\n",
      "         [ 3.8373e-02,  4.0088e-01,  2.2807e-01]],\n",
      "\n",
      "        [[ 2.5847e-01,  9.1019e-01,  1.2826e-01],\n",
      "         [ 4.4613e-01,  4.0383e-02, -7.6719e-01],\n",
      "         [-2.7601e-02, -6.4178e-01, -2.8006e-01]],\n",
      "\n",
      "        [[-5.9971e-02, -1.1250e-01, -1.3868e-01],\n",
      "         [ 2.7465e-01,  3.1147e-01, -1.9294e-01],\n",
      "         [ 3.0453e-01,  2.1748e-01, -1.9251e-01]],\n",
      "\n",
      "        [[ 4.4711e-01,  1.0933e+00,  4.8902e-01],\n",
      "         [-5.3337e-01, -1.4390e+00,  1.0396e-01],\n",
      "         [-8.7457e-01, -1.4876e-01, -6.3831e-01]],\n",
      "\n",
      "        [[ 7.9349e-03,  2.8235e-01, -1.7712e-01],\n",
      "         [-1.8790e-01,  4.9461e-01, -2.7819e-01],\n",
      "         [-2.5963e-02,  7.7913e-02, -5.2930e-02]],\n",
      "\n",
      "        [[-8.4439e-02,  7.7261e-02,  8.9973e-03],\n",
      "         [-2.6496e-01,  5.8094e-01, -2.7473e-01],\n",
      "         [-1.2211e-01,  2.0043e-01, -8.9156e-02]],\n",
      "\n",
      "        [[ 4.0460e-02, -6.4280e-01,  5.7303e-02],\n",
      "         [ 4.5806e-01, -2.0225e-01,  5.7174e-01],\n",
      "         [ 5.4725e-02, -7.4693e-01, -8.7912e-02]],\n",
      "\n",
      "        [[-1.3350e-01,  4.2197e-02,  4.4946e-02],\n",
      "         [ 2.3292e-01,  5.9916e-01,  2.3954e-02],\n",
      "         [ 2.3557e-02, -6.2536e-01, -1.9325e-02]],\n",
      "\n",
      "        [[-3.0885e-01, -4.1318e-01, -2.6878e-01],\n",
      "         [-1.2930e-01, -8.6119e-01,  1.3819e-01],\n",
      "         [ 8.1674e-02,  1.0463e+00,  3.8626e-01]],\n",
      "\n",
      "        [[ 9.4110e-02,  6.1747e-02, -1.0634e-01],\n",
      "         [ 2.9685e-01,  2.4415e-01, -2.8537e-01],\n",
      "         [ 6.8336e-02,  1.0240e-01, -2.3905e-01]],\n",
      "\n",
      "        [[ 4.1036e-01, -4.4993e-01, -1.3568e-01],\n",
      "         [ 2.3301e-01,  1.6944e-01, -5.5932e-01],\n",
      "         [-1.0845e-01,  9.5274e-02,  1.2267e-01]],\n",
      "\n",
      "        [[-1.4938e-01,  2.9202e-01,  1.5994e-02],\n",
      "         [ 7.8779e-02,  3.9094e-01,  9.1235e-02],\n",
      "         [-8.0138e-02,  1.7682e-01, -5.6346e-02]],\n",
      "\n",
      "        [[-2.1175e-01,  2.7197e-01, -6.9434e-01],\n",
      "         [-3.4300e-01,  2.5382e+00, -1.8922e-01],\n",
      "         [-6.3043e-01, -2.4595e-01, -1.1055e+00]],\n",
      "\n",
      "        [[ 3.2171e-02, -3.6995e-01,  1.0256e-01],\n",
      "         [ 4.1113e-01, -8.8746e-01,  5.5392e-01],\n",
      "         [ 1.4078e-01, -6.1105e-01,  1.1941e-01]],\n",
      "\n",
      "        [[-1.1913e-01, -4.6681e-01,  3.3912e-02],\n",
      "         [ 7.2497e-02,  1.0096e+00, -7.5231e-01],\n",
      "         [-1.6316e-02, -3.9296e-01,  4.8651e-01]],\n",
      "\n",
      "        [[-1.6269e-01,  2.8151e-01,  7.3368e-02],\n",
      "         [-2.9554e-01,  2.1415e-01,  3.1011e-01],\n",
      "         [-2.6608e-01, -3.2474e-01,  1.2847e-01]],\n",
      "\n",
      "        [[-4.1795e-02, -9.1425e-02, -1.3486e-01],\n",
      "         [-9.6536e-02, -2.1731e-01, -3.4210e-01],\n",
      "         [-6.3002e-02, -5.3062e-01, -1.3948e-01]],\n",
      "\n",
      "        [[ 7.6675e-02,  7.0635e-02,  7.5673e-02],\n",
      "         [ 3.7996e-01,  7.5099e-01, -1.0563e-02],\n",
      "         [-4.2523e-01, -9.1204e-01, -6.3669e-02]],\n",
      "\n",
      "        [[-5.5940e-03,  2.1973e-01, -1.0593e-01],\n",
      "         [-2.0391e-01,  4.3100e-01,  1.5643e-01],\n",
      "         [-1.5261e-01, -2.0113e-01,  4.8011e-02]],\n",
      "\n",
      "        [[-1.4479e-02, -2.2389e-01,  8.1153e-02],\n",
      "         [ 1.8080e-01,  6.6621e-01,  1.1621e-01],\n",
      "         [-1.9276e-01, -4.3294e-01, -1.8653e-01]],\n",
      "\n",
      "        [[-1.0834e-01, -3.8552e-02,  1.0323e-01],\n",
      "         [ 7.6162e-03, -6.3088e-01,  6.3516e-01],\n",
      "         [ 2.9283e-02, -1.6696e-01,  2.4855e-01]],\n",
      "\n",
      "        [[ 5.7617e-02, -1.2404e-01, -1.6891e-02],\n",
      "         [-1.2998e-01,  3.0285e-02, -4.0269e-01],\n",
      "         [ 5.7313e-02, -2.5094e-01, -3.0295e-02]],\n",
      "\n",
      "        [[ 4.6622e-02, -1.5725e-01,  1.1072e-01],\n",
      "         [-1.2689e-01, -5.4187e-01, -1.3069e-01],\n",
      "         [ 1.1505e-01, -9.0800e-02,  8.9815e-03]],\n",
      "\n",
      "        [[-9.7737e-02, -5.7563e-02,  7.4987e-02],\n",
      "         [-1.0914e-01,  7.5923e-01, -1.9763e-01],\n",
      "         [ 6.9452e-02, -8.3551e-03, -8.7007e-02]],\n",
      "\n",
      "        [[ 9.6980e-02,  4.0006e-01,  2.2556e-01],\n",
      "         [-1.4221e-01, -6.8813e-01, -3.4770e-01],\n",
      "         [ 3.6970e-02,  3.5860e-01,  9.4306e-02]],\n",
      "\n",
      "        [[-2.1119e-01, -8.0416e-01, -2.2703e-01],\n",
      "         [ 1.0341e-01,  3.8325e-01,  6.7331e-02],\n",
      "         [ 2.1603e-01,  1.6871e-01,  1.1317e-01]],\n",
      "\n",
      "        [[ 6.4908e-02,  3.1302e-01, -2.5000e-01],\n",
      "         [-1.5224e-01, -5.6222e-01,  7.0220e-01],\n",
      "         [ 6.4342e-02,  2.4883e-01, -1.6613e-01]],\n",
      "\n",
      "        [[-4.9701e-02, -7.3068e-01,  4.0300e-01],\n",
      "         [ 4.5038e-01, -3.7979e-01, -6.3965e-01],\n",
      "         [ 2.7692e-01,  8.0230e-01, -2.4199e-01]],\n",
      "\n",
      "        [[-2.6911e-01, -1.0473e+00, -1.3988e-01],\n",
      "         [ 1.7034e-01,  1.1316e+00,  3.6583e-01],\n",
      "         [-1.5563e-01, -4.0440e-01, -3.1275e-01]],\n",
      "\n",
      "        [[-2.3944e-02, -1.4150e-01,  9.1900e-02],\n",
      "         [ 1.8448e-02, -5.1616e-01,  7.7184e-01],\n",
      "         [-1.2467e-01, -1.9273e-01,  1.1526e-01]],\n",
      "\n",
      "        [[ 4.3976e-03, -1.9316e-01,  1.6080e-01],\n",
      "         [ 9.1337e-02, -6.8716e-01, -1.0302e-02],\n",
      "         [-1.0057e-01,  8.8193e-01, -4.0991e-02]],\n",
      "\n",
      "        [[-3.5279e-02,  6.1300e-01,  3.1648e-01],\n",
      "         [-6.1510e-01, -5.4807e-02,  5.8879e-01],\n",
      "         [-1.1579e-01, -6.6554e-01,  3.4304e-02]],\n",
      "\n",
      "        [[ 4.6329e-02,  1.3513e-01, -1.5227e-01],\n",
      "         [ 3.5386e-02, -9.0075e-01,  8.7167e-01],\n",
      "         [-8.9745e-03,  5.8772e-01, -5.7804e-01]],\n",
      "\n",
      "        [[-1.3788e-03, -1.9511e-01, -2.9565e-02],\n",
      "         [-4.7782e-02, -4.6390e-01,  7.5714e-04],\n",
      "         [ 4.6864e-03, -2.2115e-03,  8.6915e-02]],\n",
      "\n",
      "        [[ 1.8017e-02, -6.8231e-01, -2.4486e-01],\n",
      "         [ 2.0167e-01,  7.8645e-03, -3.2645e-01],\n",
      "         [ 8.1949e-02,  3.8902e-01,  7.9656e-02]],\n",
      "\n",
      "        [[ 4.1620e-01, -5.6262e-01,  2.2469e-01],\n",
      "         [-1.6105e-02, -1.0078e+00, -1.6431e-01],\n",
      "         [ 4.2408e-02, -6.8777e-02,  2.4292e-01]],\n",
      "\n",
      "        [[-1.0576e-01, -9.0045e-03,  1.6882e-01],\n",
      "         [-2.4070e-01,  1.4083e-01,  3.4543e-01],\n",
      "         [-2.1305e-01,  4.4958e-02,  7.1329e-02]],\n",
      "\n",
      "        [[ 2.6009e-01,  2.0658e-01,  2.2976e-01],\n",
      "         [ 2.4420e-01, -1.0988e+00,  3.4803e-02],\n",
      "         [ 2.1426e-01, -1.3057e-01,  3.7375e-01]],\n",
      "\n",
      "        [[ 8.1559e-02,  8.1215e-02,  1.0222e-01],\n",
      "         [ 5.9268e-02,  7.4503e-02,  6.1494e-02],\n",
      "         [-3.7900e-02, -4.8040e-01, -1.9784e-01]],\n",
      "\n",
      "        [[ 3.6954e-01, -5.5251e-01,  6.9006e-01],\n",
      "         [ 7.7031e-01,  8.6760e-01,  9.0355e-01],\n",
      "         [ 1.6630e-01,  7.4643e-02,  2.7239e-01]],\n",
      "\n",
      "        [[ 2.6981e-02,  2.0348e-01,  2.6707e-01],\n",
      "         [ 1.6599e-01, -2.4775e-02,  3.4446e-01],\n",
      "         [-7.9715e-02, -3.1535e-01,  1.5790e-01]],\n",
      "\n",
      "        [[-3.1994e-01,  1.4684e-01, -3.9760e-01],\n",
      "         [-1.3313e-02,  1.3858e+00,  1.7126e-01],\n",
      "         [-4.2694e-01,  8.3047e-03, -6.2169e-01]],\n",
      "\n",
      "        [[ 1.0026e-01,  3.8735e-01,  9.8158e-02],\n",
      "         [-1.8230e-01, -6.5127e-01, -3.6105e-01],\n",
      "         [ 3.9419e-03,  4.4906e-01,  1.2823e-01]],\n",
      "\n",
      "        [[-1.0788e-01,  1.5154e-02,  6.8211e-02],\n",
      "         [-3.1965e-01,  5.5379e-02,  1.1207e-01],\n",
      "         [-9.6396e-02, -7.9470e-02,  1.9928e-01]],\n",
      "\n",
      "        [[ 7.4379e-02, -1.9130e-01,  1.2531e-01],\n",
      "         [ 4.7489e-01, -6.3372e-01, -3.9457e-03],\n",
      "         [-6.5279e-01,  7.9321e-01,  8.3282e-03]],\n",
      "\n",
      "        [[-4.3207e-02, -9.6495e-02, -7.1631e-03],\n",
      "         [-2.7206e-02,  8.5923e-01, -9.2963e-02],\n",
      "         [-9.4535e-02, -1.1164e-02, -1.1403e-02]],\n",
      "\n",
      "        [[ 9.4114e-02,  4.0611e-02, -2.2164e-01],\n",
      "         [-2.8110e-01,  7.7561e-01, -3.4229e-01],\n",
      "         [ 1.5110e-01, -6.3433e-01,  4.3266e-01]],\n",
      "\n",
      "        [[-1.9153e-01,  8.0398e-03,  3.2911e-01],\n",
      "         [ 2.0885e-01, -6.8404e-01, -3.2670e-02],\n",
      "         [ 2.9388e-01,  1.5093e-01, -7.6172e-02]],\n",
      "\n",
      "        [[ 6.4606e-02,  7.2287e-01,  7.1419e-02],\n",
      "         [-1.8694e-01, -4.2658e-01, -1.4162e-01],\n",
      "         [-2.4428e-01, -3.8606e-02, -2.9502e-01]],\n",
      "\n",
      "        [[ 1.9671e-01, -2.5884e-03, -2.6494e-01],\n",
      "         [ 8.8758e-01,  1.7834e-01, -1.0405e+00],\n",
      "         [ 3.7374e-01,  4.9458e-02, -3.4264e-01]],\n",
      "\n",
      "        [[ 2.0361e-02, -2.7877e-01,  1.0621e-01],\n",
      "         [ 2.9162e-01, -6.7895e-01,  4.3075e-01],\n",
      "         [ 3.1952e-03, -1.3208e-01, -2.7842e-02]],\n",
      "\n",
      "        [[-9.0164e-02, -2.1127e-01,  9.2457e-01],\n",
      "         [ 2.8418e-01,  1.8188e-01, -1.0668e+00],\n",
      "         [-2.7045e-01,  1.2938e-01,  7.6568e-02]],\n",
      "\n",
      "        [[-1.3326e-01, -1.9187e-01, -1.5810e-01],\n",
      "         [-2.9923e-02,  5.5438e-02, -4.3860e-02],\n",
      "         [-2.2070e-02,  6.0700e-01,  8.0036e-02]],\n",
      "\n",
      "        [[-7.4740e-02, -3.7795e-01, -2.3059e-01],\n",
      "         [-3.5889e-01,  1.1143e+00, -1.9111e-01],\n",
      "         [-1.4851e-01, -2.4657e-01, -1.1509e-01]],\n",
      "\n",
      "        [[-6.0344e-02, -6.5630e-02,  2.0583e-02],\n",
      "         [-2.8141e-02,  3.6947e-01,  1.7208e-01],\n",
      "         [-2.2468e-04,  1.1570e-01, -4.9344e-02]],\n",
      "\n",
      "        [[-3.2036e-01,  2.4888e-01,  7.9476e-02],\n",
      "         [ 2.3704e-02,  4.9169e-01, -3.8446e-01],\n",
      "         [ 1.2796e-01, -2.6325e-01, -1.2814e-01]],\n",
      "\n",
      "        [[-3.5942e-02,  8.9262e-02, -3.0421e-02],\n",
      "         [-1.5070e-01,  5.7655e-01, -1.2826e-01],\n",
      "         [-1.7264e-02,  9.2262e-02, -5.0413e-02]],\n",
      "\n",
      "        [[ 5.3957e-02, -2.2974e-01,  7.1118e-03],\n",
      "         [-1.0227e-01,  8.2534e-01,  1.6562e-01],\n",
      "         [-1.6372e-01, -4.5841e-01, -1.9257e-01]],\n",
      "\n",
      "        [[ 3.3199e-01,  6.6381e-01, -8.6272e-02],\n",
      "         [ 6.1892e-01,  2.4749e-01, -6.9032e-01],\n",
      "         [-4.2164e-02, -5.7649e-01, -4.8613e-01]],\n",
      "\n",
      "        [[-4.3048e-02, -9.3655e-02, -8.2244e-02],\n",
      "         [-8.0178e-03,  7.3362e-01,  4.8981e-02],\n",
      "         [-1.8171e-02, -7.0665e-01, -1.3072e-02]],\n",
      "\n",
      "        [[-4.4244e-01, -5.8564e-01,  7.9158e-02],\n",
      "         [-5.8436e-01,  5.6393e-01,  5.3724e-01],\n",
      "         [-2.6665e-02,  6.7744e-01, -2.1795e-01]],\n",
      "\n",
      "        [[-1.2236e-02,  1.1312e-02, -4.2638e-01],\n",
      "         [ 5.4111e-02,  4.9343e-01, -1.8188e-01],\n",
      "         [-2.0298e-02,  2.0942e-01,  1.6159e-02]],\n",
      "\n",
      "        [[-5.3683e-02,  2.0208e-03, -4.0377e-02],\n",
      "         [-8.0472e-02, -2.2128e-01, -1.1579e-01],\n",
      "         [-1.8988e-02, -4.6209e-01, -1.1024e-01]],\n",
      "\n",
      "        [[-1.6457e-01,  5.4490e-01,  1.1106e-01],\n",
      "         [-2.3961e-01,  6.0103e-01, -1.2399e-02],\n",
      "         [-1.5064e-01, -3.8412e-01, -3.3423e-01]],\n",
      "\n",
      "        [[-3.0980e-01, -1.6617e-01,  2.5729e-01],\n",
      "         [-2.6149e-01, -2.6282e-01, -2.3089e-01],\n",
      "         [ 1.9964e-01, -1.7108e-02, -4.0588e-01]],\n",
      "\n",
      "        [[-1.2063e-01, -7.0371e-03, -2.4386e-01],\n",
      "         [-7.2947e-02,  8.9505e-01,  9.8393e-02],\n",
      "         [-1.5267e-01,  4.0650e-02, -1.7556e-01]],\n",
      "\n",
      "        [[ 3.4023e-01, -5.0408e-01, -4.2200e-01],\n",
      "         [ 2.2318e-01,  4.3897e-01, -3.2750e-01],\n",
      "         [-2.0968e-01,  4.3578e-01, -2.2306e-02]],\n",
      "\n",
      "        [[-1.1389e-01,  1.5546e-01,  1.0976e-01],\n",
      "         [-3.6344e-01, -1.1019e-01,  5.2707e-01],\n",
      "         [-1.2195e-01, -2.2006e-01,  2.0578e-01]],\n",
      "\n",
      "        [[-8.2257e-02,  3.6802e-02, -6.3790e-02],\n",
      "         [ 4.7061e-02,  6.0209e-01, -1.7760e-02],\n",
      "         [-2.8860e-02, -8.6625e-03, -4.3092e-02]],\n",
      "\n",
      "        [[ 1.4993e-02,  6.5678e-02, -3.5446e-02],\n",
      "         [-9.5317e-04,  5.7991e-01, -2.2305e-01],\n",
      "         [-3.8462e-02,  6.9504e-02, -2.1605e-01]],\n",
      "\n",
      "        [[ 2.0868e-02,  3.0400e-01,  7.9056e-01],\n",
      "         [ 1.3644e-01, -2.3118e+00, -2.1530e-01],\n",
      "         [ 5.5307e-01,  7.5087e-01, -1.8498e-01]],\n",
      "\n",
      "        [[ 1.3331e-01, -1.2304e-01, -9.4036e-03],\n",
      "         [-2.1010e-01,  3.2256e-01, -3.0655e-01],\n",
      "         [ 1.0191e-01,  5.7629e-01, -7.5454e-01]],\n",
      "\n",
      "        [[ 1.0839e-01,  3.4313e-01,  1.1410e-01],\n",
      "         [-4.1121e-02,  2.4476e-01, -4.2148e-02],\n",
      "         [-1.3106e-01, -4.3389e-02, -2.3479e-01]],\n",
      "\n",
      "        [[-1.7425e-01, -8.2794e-02, -1.7803e-01],\n",
      "         [ 2.2680e-02,  6.2667e-01,  1.0136e-01],\n",
      "         [-1.9362e-01,  5.1986e-02, -2.3092e-01]],\n",
      "\n",
      "        [[ 8.0152e-01,  1.5077e+00,  7.2523e-02],\n",
      "         [ 5.0819e-01,  7.4745e-01,  9.6790e-02],\n",
      "         [-1.0370e-01,  1.6138e-02, -1.5383e-01]],\n",
      "\n",
      "        [[-5.9461e-02,  2.4191e-01, -4.6264e-02],\n",
      "         [ 1.0786e-01,  6.4281e-01, -2.3388e-01],\n",
      "         [-5.8532e-02, -1.0115e-01, -2.2899e-01]],\n",
      "\n",
      "        [[-9.6469e-02, -3.7014e-01, -7.0154e-02],\n",
      "         [-2.4710e-01,  3.7107e-01,  3.6374e-01],\n",
      "         [ 1.3946e-02,  1.9668e-01, -1.1874e-01]],\n",
      "\n",
      "        [[ 4.1418e-02, -8.6756e-03, -4.4976e-02],\n",
      "         [-9.8242e-03,  3.6542e-01,  1.1659e-01],\n",
      "         [-1.6541e-02,  1.9235e-02, -6.2819e-02]],\n",
      "\n",
      "        [[ 5.9985e-02, -4.3840e-01, -3.9470e-02],\n",
      "         [ 2.1032e-01,  3.1093e-01, -1.9931e-01],\n",
      "         [-1.4874e-02,  1.5586e-01, -1.5323e-02]],\n",
      "\n",
      "        [[ 2.2488e-01,  7.5267e-01,  3.7414e-01],\n",
      "         [ 1.8456e-01,  1.8709e-01, -2.6353e-01],\n",
      "         [-1.5001e-01, -6.7626e-01, -5.2024e-01]],\n",
      "\n",
      "        [[ 7.3923e-02,  1.0844e-01, -7.9323e-03],\n",
      "         [ 3.9605e-02,  6.5844e-01,  9.7709e-02],\n",
      "         [-1.0883e-01,  9.5787e-02,  1.0749e-01]],\n",
      "\n",
      "        [[ 1.0231e-01,  7.2206e-02, -1.6023e-01],\n",
      "         [ 4.3300e-01,  4.5748e-02, -9.9588e-02],\n",
      "         [ 6.7537e-02,  1.6328e-02, -6.4893e-02]],\n",
      "\n",
      "        [[ 1.2534e-01,  9.1736e-02, -1.5740e-01],\n",
      "         [ 2.9012e-01,  1.8827e-01, -1.1751e-01],\n",
      "         [ 6.1496e-02, -1.5143e-01, -2.4863e-01]],\n",
      "\n",
      "        [[ 3.3824e-02,  4.1888e-01, -3.3467e-01],\n",
      "         [ 5.8661e-01, -7.5108e-01,  2.4017e-02],\n",
      "         [-2.3421e-01,  5.0312e-02,  6.6130e-02]],\n",
      "\n",
      "        [[ 8.4623e-03,  2.4785e-01, -1.2467e-01],\n",
      "         [ 4.5036e-01, -1.0182e+00,  4.3715e-03],\n",
      "         [-1.1275e-01,  2.7994e-01,  2.9656e-01]],\n",
      "\n",
      "        [[-9.1345e-02, -4.1872e-01, -1.3483e-01],\n",
      "         [ 4.4160e-02,  8.7421e-01,  3.8143e-01],\n",
      "         [ 4.2016e-02, -3.6947e-01, -1.4949e-01]],\n",
      "\n",
      "        [[ 9.5918e-02,  6.5072e-01,  1.4835e-01],\n",
      "         [-3.3177e-01,  2.5888e-01,  1.6284e-02],\n",
      "         [-1.5313e-01, -2.5229e-01, -3.3381e-01]],\n",
      "\n",
      "        [[-3.9514e-01, -1.1592e-01, -2.3205e-02],\n",
      "         [-1.9698e-01,  4.6178e-01,  2.5792e-01],\n",
      "         [-6.9477e-02,  2.9060e-01, -4.0401e-02]],\n",
      "\n",
      "        [[ 3.1520e-02,  2.3293e-01,  2.0268e-01],\n",
      "         [-2.2714e-02, -5.2308e-01, -1.2302e-01],\n",
      "         [ 1.8590e-01, -2.3400e-02,  1.7231e-02]],\n",
      "\n",
      "        [[-1.7576e-02, -4.8195e-02, -4.2365e-02],\n",
      "         [ 1.7109e-01,  5.2873e-01,  2.5158e-01],\n",
      "         [ 1.9997e-01, -1.0622e-02, -3.3319e-02]],\n",
      "\n",
      "        [[-4.7846e-02,  5.5752e-01,  7.9240e-02],\n",
      "         [ 4.3136e-01,  6.9910e-01, -4.4912e-01],\n",
      "         [ 1.2384e-01, -9.0046e-01, -4.6873e-01]],\n",
      "\n",
      "        [[ 5.1514e-02,  6.7056e-01,  3.1217e-01],\n",
      "         [-3.9485e-01, -3.1245e-02,  4.9570e-01],\n",
      "         [-1.4503e-01, -7.5805e-01, -1.9638e-01]],\n",
      "\n",
      "        [[ 5.0225e-03,  3.5222e-02,  1.6653e-01],\n",
      "         [-1.4829e-02, -1.0855e+00, -1.6878e-01],\n",
      "         [ 3.1727e-01, -1.5345e-01, -2.3831e-01]],\n",
      "\n",
      "        [[ 3.2501e-01, -2.9376e-01,  7.1636e-02],\n",
      "         [ 2.9226e-01, -4.1660e-01,  3.6110e-01],\n",
      "         [ 6.2554e-02, -1.6684e-01,  3.0856e-01]],\n",
      "\n",
      "        [[-7.0945e-01, -2.4433e-01,  4.3373e-01],\n",
      "         [-3.6308e-01,  1.3963e+00, -9.3896e-02],\n",
      "         [ 1.7737e-01,  2.7826e-01, -7.5162e-01]]]) conv_bias: tensor([ 3.1005,  0.0662, -0.3709, -0.3041,  1.2458, -0.4257, -0.1113,  0.8705,\n",
      "        -0.4059, -0.1976,  1.9234,  2.2754, -0.8026,  1.3233,  0.7092,  0.2012,\n",
      "         0.0412,  2.5715, -0.0302, -0.1718, -0.0070, -0.0993,  2.3246,  1.5701,\n",
      "        -0.7591, -0.1270,  0.3244, -0.3957,  0.0322, -0.0640, -0.0859, -0.1730,\n",
      "        -0.2240, -0.1415,  2.1379,  0.7028,  1.6302,  1.1679,  2.2252,  2.6166,\n",
      "         0.5687, -0.3937,  0.5081,  0.0246,  2.4566,  0.0137, -1.0143, -0.2159,\n",
      "        -0.0583,  0.4072, -0.1767, -0.0427,  0.1136,  0.1553,  4.7046,  1.2004,\n",
      "         0.0542, -0.5943, -0.0602, -0.0506,  0.3142, -0.0845, -0.2205,  2.4219,\n",
      "         0.6131,  1.3896,  0.8329,  0.0072, -0.3132, -0.5311, -0.4135,  0.1515,\n",
      "         0.3788, -0.0854,  1.3433, -0.8879, -0.4466, -0.0309,  0.0142, -0.0056,\n",
      "        -0.5325, -1.8808,  1.1336, -0.0109,  0.1656, -0.0759, -0.6360, -0.1910,\n",
      "        -0.1956,  1.8275, -0.1079, -0.0857, -0.0247,  1.5978, -1.0656, -0.5059])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "q_weight: tensor([  17,   -2,   23,   21, -114,    2,   24,  -13,   25,   11,   20,   12,\n",
      "          -9,  -69,  -30,    3,   35,   20,    9,   33,    5,   16,    1,  -28,\n",
      "          -1,  -23,  -10,   -5,   -9,  -12,   23,   26,  -16,   25,   18,  -16,\n",
      "          25,   61,   27,  -30,  -80,    6,  -49,   -8,  -36,    2,   54,  -34,\n",
      "         -36,   95,  -53,   -5,   15,  -10,  -11,   10,    1,  -34,   74,  -35,\n",
      "         -16,   26,  -11,    5,  -79,    7,   56,  -25,   70,    7,  -92,  -11,\n",
      "         -10,    3,    3,   18,   46,    2,    2,  -48,   -1,  -32,  -43,  -28,\n",
      "         -14,  -90,   15,    9,  110,   41,   18,   12,  -20,   56,   46,  -54,\n",
      "          13,   19,  -45,   36,  -39,  -12,   20,   15,  -49,  -10,    8,   11,\n",
      "         -43,   84,    5,   23,  112,   26,  -23,   51,  -16,   -4,    5,  -13,\n",
      "          -6,   47,   -3,  -12,   -5,  -20,    2,  -20,    6,   22,  -48,   30,\n",
      "           8,  -33,    6,  -12,  -48,    3,    7,  104,  -77,   -2,  -40,   50,\n",
      "         -17,   29,    8,  -31,   22,   32,  -28,  -34,   13,   -6,  -12,  -18,\n",
      "         -13,  -29,  -46,   -8,  -72,  -19,    3,    3,    3,   17,   33,    0,\n",
      "         -19,  -40,   -3,   -1,   20,  -10,  -18,   39,   14,  -14,  -18,    4,\n",
      "          -1,  -18,    7,   15,   53,    9,  -15,  -35,  -15,   -6,   -2,    5,\n",
      "           0,  -32,   32,    1,   -8,   13,    9,  -19,   -3,  -20,    5,  -61,\n",
      "           9,  -38,   -5,    3,  -10,    7,   -8,  -35,   -8,    7,   -6,    1,\n",
      "          -5,   -3,    4,   -6,   40,  -10,    4,    0,   -5,    8,   31,   18,\n",
      "         -11,  -54,  -27,    3,   28,    7,  -18,  -67,  -19,    9,   32,    6,\n",
      "          18,   14,    9,    5,   22,  -17,  -11,  -39,   49,    4,   17,  -12,\n",
      "          -3,  -40,   22,   25,  -21,  -35,   15,   44,  -13,  -16,  -63,   -8,\n",
      "          10,   68,   22,   -9,  -24,  -19,   -2,  -10,    7,    1,  -37,   56,\n",
      "          -9,  -14,    8,    0,  -13,   11,    6,  -47,   -1,   -7,   61,   -3,\n",
      "          -3,   48,   25,  -48,   -4,   46,   -9,  -52,    3,    3,    8,   -8,\n",
      "           2,  -50,   48,    0,   33,  -32,    0,  -23,   -3,   -6,  -55,    0,\n",
      "           1,    0,   10,    1,  -49,  -18,   15,    1,  -24,    6,   28,    6,\n",
      "          21,  -29,   12,   -1,  -52,   -8,    2,   -4,   12,  -19,   -2,   31,\n",
      "         -44,   26,   63,  -39,    8,   13,   15,   12,   13,   14,  -64,    2,\n",
      "          13,   -8,   22,    6,    6,    8,    4,    5,    5,   -3,  -35,  -15,\n",
      "          33,  -49,   61,   68,   77,   80,   15,    7,   24,    4,   28,   36,\n",
      "          22,   -3,   47,  -11,  -43,   21,   -8,    3,   -9,    0,   33,    4,\n",
      "         -10,    0,  -15,    8,   30,    8,  -14,  -50,  -28,    0,   34,   10,\n",
      "         -19,    3,   12,  -55,   10,   19,  -17,  -14,   34,    5,  -12,    8,\n",
      "          29,  -38,    0,  -40,   48,    1,   -2,   -5,    0,   -1,   40,   -4,\n",
      "          -4,   -1,   -1,    4,    2,   -9,  -11,   31,  -14,    6,  -26,   18,\n",
      "         -15,    1,   25,   16,  -52,   -2,   22,   12,   -6,    7,   77,    8,\n",
      "         -20,  -45,  -15,  -26,   -4,  -31,    9,    0,  -12,   41,    8,  -49,\n",
      "          17,    2,  -16,    3,  -41,   16,   43, -101,   64,    0,  -20,   -4,\n",
      "          -6,  -13,   57,   17,   11,  -65,  -17,    8,    5,  -24,  -34,  -28,\n",
      "          -5,   10,   -8,   -4,  109,   14,   -5,  -24,  -15,  -23,   71,  -12,\n",
      "          -9,  -16,   -7,  -13,  -14,    4,   -6,   80,   37,    0,   25,  -11,\n",
      "         -33,   26,    8,    2,   51,  -40,   13,  -27,  -13,   -3,    6,   -2,\n",
      "         -11,   40,   -9,   -1,    6,   -4,    3,  -15,    0,   -7,   53,   11,\n",
      "         -11,  -30,  -12,   17,   35,   -5,   33,   13,  -36,   -2,  -30,  -26,\n",
      "          -1,   -3,   -3,    0,   22,    1,   -1,  -22,    0,  -24,  -32,    4,\n",
      "         -32,   31,   29,   -1,   37,  -12,   -2,    1,  -53,    7,   61,  -23,\n",
      "          -3,   26,    2,   -8,    0,   -6,  -12,  -32,  -17,   -3,  -66,  -16,\n",
      "         -11,   35,    7,  -15,   39,   -1,  -10,  -25,  -22,  -55,  -30,   46,\n",
      "         -47,  -47,  -41,   36,   -3,  -73,  -13,   -1,  -26,   -8,   94,   10,\n",
      "         -16,    4,  -18,   23,  -33,  -28,   15,   29,  -22,  -14,   29,   -1,\n",
      "         -13,   18,   12,  -41,  -12,   59,  -14,  -25,   23,   -5,    2,   -4,\n",
      "           3,   33,   -1,   -2,    0,   -2,    1,    4,   -2,    0,   40,  -15,\n",
      "          -3,    5,  -15,    0,    7,   18,    3,  -53,   -5,   13,   17,   -4,\n",
      "           8,   -8,   -1,  -13,   20,  -19,    6,   35,  -46,    8,   24,    8,\n",
      "          -3,   17,   -3,   -9,   -3,  -17,  -12,   -6,  -12,    2,   42,    7,\n",
      "         -13,    3,  -15,    4,    8,    0,    3,    4,    1,   -1,    0,   -1,\n",
      "          -4,   18,   -3,    8,   48,  -17,   -4,   -7,  -17,  -13,  -50,  -10,\n",
      "         -34,   50,   49,    2,   27,  -16,    8,   -2,   -8,   -2,   68,   22,\n",
      "          -3,    4,  -12,   10,  -71,   -6,   34,   50,  -32,   -2,   25,   -2,\n",
      "          21,   71,   36,   18,   18,  -25,  -14,  -64,  -49,   11,   17,   -1,\n",
      "           6,  102,   15,  -17,   15,   17,    7,    5,  -11,   29,    3,   -7,\n",
      "           5,    1,   -4,   21,   15,  -26,   49,   32,  -20,   10,  -25,  -42,\n",
      "           3,   35,  -28,   49,  -63,    2,  -20,    4,    6,    1,   18,   -9,\n",
      "          33,  -74,    0,   -8,   20,   22,   -5,  -21,   -7,    2,   44,   19,\n",
      "           2,  -19,   -7,    9,   60,   14,  -31,   24,    1,  -14,  -23,  -31,\n",
      "         -50,  -15,   -3,  -25,   59,   33,   -9,   37,   -5,    6,   46,   40,\n",
      "          -5, -104,  -24,   37,   -5,    3,   -1,   -4,   -3,   14,   42,   20,\n",
      "          16,   -1,   -3,   -2,   25,    3,   19,   31,  -20,    5,  -40,  -21,\n",
      "           3,   33,   15,  -19,   -2,   24,   -7,  -37,  -10,    0,    2,    7,\n",
      "          -1,  -47,   -7,   14,   -7,  -10,   29,  -26,    6,   26,  -37,   32,\n",
      "           6,  -15,   27,  -24,   -8,   15,  -12,   47,   -3,    6,    9,  -25],\n",
      "       dtype=torch.int32) q_bias: tensor([ 2100,    30,   -69,  -130,   356,  -418,   -73,   547,  -161,  -106,\n",
      "         1874,  1023, -1178,   125,   196,   106,    22,  1777,    -7,   -80,\n",
      "           -3,   -26,  1791,   521,  -203,   -51,   139,  -142,     9,   -20,\n",
      "          -32,   -61,   -90,   -40,  1297,   261,   429,  1087,   669,   990,\n",
      "          257,  -273,    61,    10,  2162,     4,  -245,   -45,   -23,   221,\n",
      "          -42,   -33,    36,   143,  1530,  1331,    29,  -213,   -20,   -14,\n",
      "           49,   -24,  -140,  1777,   203,  1276,   447,     2,  -181,  -150,\n",
      "         -145,    18,   119,   -31,   460,   -26,  -170,   -22,    14,    -5,\n",
      "         -259, -1497,   393,    -9,    71,   -28,  -163,   -90,  -127,  1859,\n",
      "          -44,   -19,    -6,   353,  -487,   -87], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0005) tensor(0.0884)   bias tensor(0.0002) tensor(0.0159)\n",
      "features.3.conv.6.weight features.3.conv.8\n",
      "torch.Size([16, 96, 1, 1]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.1028]) torch.Size([1]) \n",
      "wscale= tensor([0.0052, 0.0054, 0.0058, 0.0040, 0.0070, 0.0043, 0.0052, 0.0067, 0.0051,\n",
      "        0.0073, 0.0053, 0.0069, 0.0044, 0.0053, 0.0034, 0.0044]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.1077]) torch.Size([1])\n",
      "###: M= tensor([0.0050, 0.0051, 0.0055, 0.0038, 0.0066, 0.0041, 0.0050, 0.0064, 0.0049,\n",
      "        0.0070, 0.0050, 0.0065, 0.0042, 0.0050, 0.0032, 0.0042])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "conv_weight: tensor([[-0.0242, -0.2122, -0.0959,  ..., -0.1670,  0.1413, -0.0518],\n",
      "        [ 0.0293,  0.1826,  0.3869,  ..., -0.1645,  0.0490,  0.2090],\n",
      "        [-0.2859,  0.2672, -0.1541,  ...,  0.2366,  0.2335,  0.0556],\n",
      "        ...,\n",
      "        [ 0.1859, -0.2172, -0.0887,  ...,  0.3322,  0.2943, -0.0590],\n",
      "        [-0.0750, -0.1096, -0.0128,  ..., -0.0692,  0.0455,  0.1387],\n",
      "        [-0.1589,  0.0066,  0.0068,  ...,  0.2035, -0.0341, -0.2471]]) conv_bias: tensor([ 0.4419, -0.1452,  2.8116,  0.5151,  5.0902, -1.0114, -1.7808, -1.2521,\n",
      "         0.6300,  2.1636, -1.3415, -0.9086, -0.8095, -2.9619,  0.9899,  1.9475])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "q_weight: tensor([ -5, -41, -18,  ...,  47,  -8, -57], dtype=torch.int32) q_bias: tensor([  822,  -262,  4750,  1264,  7122, -2291, -3311, -1807,  1197,  2884,\n",
      "        -2485, -1289, -1803, -5472,  2832,  4345], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-4.0570e-05) tensor(0.0036)   bias tensor(-5.2968e-05) tensor(0.0004)\n",
      "features.4.conv.0.weight features.4.conv.2\n",
      "torch.Size([96, 16, 1, 1]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.1077]) torch.Size([1]) \n",
      "wscale= tensor([0.0013, 0.0019, 0.0084, 0.0048, 0.0018, 0.0040, 0.0033, 0.0015, 0.0028,\n",
      "        0.0024, 0.0018, 0.0018, 0.0021, 0.0017, 0.0030, 0.0016, 0.0016, 0.0029,\n",
      "        0.0056, 0.0049, 0.0026, 0.0017, 0.0019, 0.0034, 0.0039, 0.0031, 0.0025,\n",
      "        0.0029, 0.0019, 0.0027, 0.0025, 0.0029, 0.0041, 0.0016, 0.0019, 0.0015,\n",
      "        0.0017, 0.0044, 0.0027, 0.0014, 0.0036, 0.0018, 0.0012, 0.0016, 0.0036,\n",
      "        0.0014, 0.0016, 0.0023, 0.0036, 0.0020, 0.0071, 0.0052, 0.0020, 0.0030,\n",
      "        0.0035, 0.0025, 0.0049, 0.0050, 0.0036, 0.0061, 0.0021, 0.0027, 0.0031,\n",
      "        0.0025, 0.0045, 0.0016, 0.0023, 0.0022, 0.0018, 0.0027, 0.0021, 0.0010,\n",
      "        0.0030, 0.0025, 0.0013, 0.0025, 0.0025, 0.0031, 0.0038, 0.0017, 0.0022,\n",
      "        0.0030, 0.0032, 0.0027, 0.0069, 0.0037, 0.0038, 0.0011, 0.0028, 0.0032,\n",
      "        0.0030, 0.0024, 0.0022, 0.0026, 0.0034, 0.0017]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.1516]) torch.Size([1])\n",
      "###: M= tensor([0.0009, 0.0013, 0.0060, 0.0034, 0.0013, 0.0028, 0.0024, 0.0011, 0.0020,\n",
      "        0.0017, 0.0013, 0.0013, 0.0015, 0.0012, 0.0022, 0.0012, 0.0011, 0.0021,\n",
      "        0.0040, 0.0035, 0.0019, 0.0012, 0.0013, 0.0024, 0.0028, 0.0022, 0.0018,\n",
      "        0.0021, 0.0014, 0.0019, 0.0018, 0.0020, 0.0029, 0.0011, 0.0013, 0.0011,\n",
      "        0.0012, 0.0032, 0.0019, 0.0010, 0.0026, 0.0012, 0.0008, 0.0011, 0.0026,\n",
      "        0.0010, 0.0011, 0.0016, 0.0025, 0.0014, 0.0050, 0.0037, 0.0014, 0.0021,\n",
      "        0.0025, 0.0017, 0.0035, 0.0035, 0.0026, 0.0043, 0.0015, 0.0019, 0.0022,\n",
      "        0.0018, 0.0032, 0.0011, 0.0016, 0.0015, 0.0013, 0.0020, 0.0015, 0.0007,\n",
      "        0.0022, 0.0018, 0.0009, 0.0018, 0.0018, 0.0022, 0.0027, 0.0012, 0.0016,\n",
      "        0.0021, 0.0023, 0.0019, 0.0049, 0.0026, 0.0027, 0.0008, 0.0020, 0.0023,\n",
      "        0.0021, 0.0017, 0.0015, 0.0018, 0.0024, 0.0012])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "conv_weight: tensor([[-0.0242, -0.0467, -0.0219,  ..., -0.1364, -0.0257,  0.0234],\n",
      "        [ 0.0646,  0.1810,  0.1105,  ...,  0.1485,  0.1524,  0.2182],\n",
      "        [-0.0557, -0.6717, -0.1720,  ...,  0.2241,  0.0383,  0.2366],\n",
      "        ...,\n",
      "        [ 0.0922,  0.0901, -0.0255,  ..., -0.0107, -0.0474,  0.0057],\n",
      "        [-0.2601, -0.2163, -0.2098,  ..., -0.0183, -0.1068,  0.0377],\n",
      "        [ 0.0178, -0.1046, -0.0429,  ..., -0.1044, -0.1212, -0.0799]]) conv_bias: tensor([ 1.5104,  0.9519,  0.9136, -0.2948,  0.4226,  0.8776, -0.0262,  2.4897,\n",
      "        -0.1932,  1.1938,  0.6277,  0.4485,  0.6449, -0.7762, -0.4725, -0.9006,\n",
      "        -0.6345,  1.4179,  0.4653, -0.4534,  1.8978,  1.4293,  1.5168, -0.4591,\n",
      "        -0.3873,  0.4455,  0.7308, -0.4622,  1.5989,  0.5145, -0.7726, -0.7469,\n",
      "        -0.1739,  1.2858, -0.6797,  0.8614,  2.6197, -0.4792,  0.3706,  0.8652,\n",
      "         0.6935, -0.6939,  1.0145,  1.6184,  0.1520,  1.0831,  0.7454,  2.0281,\n",
      "        -0.5644,  0.9640, -0.9024,  0.7622, -1.1234,  1.0564, -0.3301, -0.5669,\n",
      "         0.3050,  0.0883,  0.4425, -0.4194, -0.6985, -0.4186,  0.6412, -0.4992,\n",
      "        -0.3868,  1.1996,  0.4640,  1.0346,  1.1160,  0.7653,  0.3554,  2.1640,\n",
      "        -0.8060,  1.3069,  1.7483, -0.6183, -0.8810,  0.5762, -0.3583, -0.9579,\n",
      "         2.0164, -0.4275, -0.3795, -0.7051, -0.0195,  0.7972,  0.5772, -1.0406,\n",
      "        -0.8406, -0.5252, -0.6544,  0.8192,  1.5369,  0.4910,  0.6881, -0.7930])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "q_weight: tensor([-19, -37, -17,  ..., -61, -71, -47], dtype=torch.int32) q_bias: tensor([11031,  4751,  1005,  -569,  2202,  2054,   -73, 15464,  -650,  4568,\n",
      "         3211,  2320,  2856, -4279, -1441, -5088, -3653,  4503,   767,  -861,\n",
      "         6719,  7652,  7504, -1266,  -916,  1351,  2681, -1467,  7666,  1755,\n",
      "        -2875, -2408,  -395,  7656, -3372,  5369, 14266, -1002,  1270,  5734,\n",
      "         1767, -3678,  8101,  9602,   389,  7435,  4386,  8145, -1474,  4479,\n",
      "        -1180,  1372, -5192,  3305,  -866, -2137,   575,   165,  1139,  -636,\n",
      "        -3035, -1460,  1950, -1821,  -806,  6998,  1913,  4453,  5733,  2588,\n",
      "         1594, 19248, -2459,  4813, 12625, -2308, -3279,  1729,  -871, -5367,\n",
      "         8376, -1329, -1089, -2432,   -26,  2004,  1428, -8870, -2767, -1539,\n",
      "        -2060,  3204,  6582,  1753,  1903, -4322], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(1.0595e-05) tensor(0.0040)   bias tensor(-9.6315e-06) tensor(0.0002)\n",
      "features.4.conv.3.weight features.4.conv.5\n",
      "torch.Size([96, 1, 3, 3]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.1491]) torch.Size([1]) \n",
      "wscale= tensor([0.0190, 0.0064, 0.0021, 0.0047, 0.0061, 0.0028, 0.0030, 0.0165, 0.0044,\n",
      "        0.0050, 0.0080, 0.0045, 0.0081, 0.0531, 0.0068, 0.0255, 0.0188, 0.0053,\n",
      "        0.0037, 0.0026, 0.0149, 0.0083, 0.0111, 0.0047, 0.0074, 0.0028, 0.0059,\n",
      "        0.0034, 0.0052, 0.0059, 0.0163, 0.0118, 0.0032, 0.0118, 0.0206, 0.0102,\n",
      "        0.0140, 0.0044, 0.0045, 0.0102, 0.0038, 0.0143, 0.0109, 0.0086, 0.0026,\n",
      "        0.0102, 0.0075, 0.0047, 0.0068, 0.0112, 0.0025, 0.0026, 0.0296, 0.0036,\n",
      "        0.0033, 0.0120, 0.0027, 0.0022, 0.0040, 0.0020, 0.0106, 0.0112, 0.0039,\n",
      "        0.0092, 0.0018, 0.0080, 0.0040, 0.0050, 0.0078, 0.0094, 0.0032, 0.0152,\n",
      "        0.0107, 0.0082, 0.0132, 0.0109, 0.0053, 0.0032, 0.0097, 0.0138, 0.0130,\n",
      "        0.0061, 0.0049, 0.0082, 0.0017, 0.0044, 0.0017, 0.0202, 0.0385, 0.0136,\n",
      "        0.0125, 0.0041, 0.0103, 0.0049, 0.0039, 0.0251]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.0934]) torch.Size([1])\n",
      "###: M= tensor([0.0303, 0.0102, 0.0033, 0.0075, 0.0098, 0.0045, 0.0048, 0.0263, 0.0070,\n",
      "        0.0080, 0.0127, 0.0072, 0.0129, 0.0848, 0.0109, 0.0407, 0.0300, 0.0084,\n",
      "        0.0058, 0.0041, 0.0238, 0.0133, 0.0177, 0.0074, 0.0118, 0.0044, 0.0093,\n",
      "        0.0054, 0.0084, 0.0094, 0.0260, 0.0189, 0.0051, 0.0189, 0.0329, 0.0162,\n",
      "        0.0223, 0.0070, 0.0072, 0.0162, 0.0061, 0.0228, 0.0175, 0.0137, 0.0041,\n",
      "        0.0162, 0.0120, 0.0075, 0.0108, 0.0179, 0.0041, 0.0041, 0.0472, 0.0057,\n",
      "        0.0052, 0.0192, 0.0043, 0.0035, 0.0064, 0.0032, 0.0169, 0.0179, 0.0063,\n",
      "        0.0147, 0.0029, 0.0127, 0.0064, 0.0079, 0.0124, 0.0150, 0.0051, 0.0242,\n",
      "        0.0172, 0.0130, 0.0210, 0.0174, 0.0084, 0.0050, 0.0155, 0.0220, 0.0207,\n",
      "        0.0097, 0.0079, 0.0131, 0.0027, 0.0071, 0.0028, 0.0322, 0.0615, 0.0218,\n",
      "        0.0200, 0.0065, 0.0164, 0.0078, 0.0062, 0.0400])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "conv_weight: tensor([[[ 1.0871e-01,  3.4205e-01,  1.4264e-01],\n",
      "         [-3.3912e-01, -1.0523e+00, -7.1334e-01],\n",
      "         [ 2.2466e-01,  7.1184e-01,  4.5833e-01]],\n",
      "\n",
      "        [[-1.5334e-01, -3.0055e-01, -2.1700e-01],\n",
      "         [-3.1586e-01, -5.9496e-01, -3.5952e-01],\n",
      "         [-1.6376e-01, -2.5006e-01, -1.7333e-01]],\n",
      "\n",
      "        [[-6.5492e-02, -1.1661e-01, -6.9970e-02],\n",
      "         [-8.4655e-02, -1.8132e-01, -1.1063e-01],\n",
      "         [-5.8454e-02, -1.1352e-01, -7.0755e-02]],\n",
      "\n",
      "        [[ 1.3467e-01,  2.1462e-01,  1.4458e-01],\n",
      "         [ 1.3834e-01,  2.9621e-01,  2.4600e-01],\n",
      "         [ 8.1011e-02,  1.5080e-01,  1.2428e-01]],\n",
      "\n",
      "        [[ 4.7657e-03, -2.4196e-01, -4.5008e-01],\n",
      "         [-2.4305e-01, -4.9227e-01, -4.4856e-01],\n",
      "         [-4.1275e-01, -3.9483e-01, -1.1244e-01]],\n",
      "\n",
      "        [[ 9.8162e-02,  1.5395e-01,  9.7897e-02],\n",
      "         [ 1.4309e-01,  2.6047e-01,  1.6827e-01],\n",
      "         [ 8.8897e-02,  1.4990e-01,  1.0401e-01]],\n",
      "\n",
      "        [[ 9.8801e-02,  1.7153e-01,  1.0306e-01],\n",
      "         [ 1.1564e-01,  2.3866e-01,  1.8635e-01],\n",
      "         [ 3.1849e-02,  1.3492e-01,  1.1691e-01]],\n",
      "\n",
      "        [[ 2.9669e-01,  7.8344e-01,  1.5461e-01],\n",
      "         [ 6.3160e-01,  1.8796e-01, -4.0905e-01],\n",
      "         [-2.1292e-01, -7.1040e-01, -5.2293e-01]],\n",
      "\n",
      "        [[ 1.1910e-01,  2.4563e-01,  2.1778e-01],\n",
      "         [ 2.8517e-01,  5.1459e-01,  3.0968e-01],\n",
      "         [ 2.1752e-01,  3.1052e-01,  1.7432e-01]],\n",
      "\n",
      "        [[-1.7296e-01, -1.9609e-01, -1.6581e-01],\n",
      "         [-2.1308e-01, -3.4775e-01, -2.3462e-01],\n",
      "         [-1.0970e-01, -1.9628e-01, -1.1499e-01]],\n",
      "\n",
      "        [[-2.2579e-01,  3.1437e-01, -1.6154e-01],\n",
      "         [-2.9635e-01,  4.8943e-01, -4.2663e-01],\n",
      "         [-3.6815e-02,  3.1118e-01, -2.3296e-01]],\n",
      "\n",
      "        [[-6.8377e-02, -1.8966e-02, -1.1822e-01],\n",
      "         [-5.0321e-01, -1.5129e-01, -4.6790e-01],\n",
      "         [-3.0130e-01, -1.7220e-01, -3.3335e-01]],\n",
      "\n",
      "        [[-3.9246e-01, -4.2449e-01, -2.8136e-01],\n",
      "         [-1.7961e-01, -3.0654e-01, -2.4728e-01],\n",
      "         [-1.3393e-01, -3.3718e-01, -2.5097e-01]],\n",
      "\n",
      "        [[-1.4573e-01,  8.7013e-01,  1.6035e+00],\n",
      "         [ 1.2653e+00,  2.0254e+00,  1.5328e+00],\n",
      "         [ 1.7438e+00,  1.7254e+00,  6.3478e-01]],\n",
      "\n",
      "        [[ 1.6344e-01,  3.0256e-01,  1.3419e-01],\n",
      "         [ 2.5018e-01,  5.4214e-01,  3.2059e-01],\n",
      "         [ 1.1584e-01,  2.7673e-01,  2.5578e-01]],\n",
      "\n",
      "        [[ 6.7414e-01,  8.4666e-01,  7.8634e-01],\n",
      "         [ 8.8167e-01,  1.2579e+00,  8.8040e-01],\n",
      "         [ 2.5006e-01,  5.1928e-01,  2.8877e-01]],\n",
      "\n",
      "        [[ 8.0714e-01,  1.2590e+00,  8.8161e-01],\n",
      "         [ 1.1038e+00,  1.8425e+00,  1.0345e+00],\n",
      "         [ 7.4260e-01,  9.8656e-01,  5.2963e-01]],\n",
      "\n",
      "        [[ 8.4596e-02,  1.6740e-01,  1.0542e-01],\n",
      "         [ 1.7661e-01,  3.4150e-01,  2.1381e-01],\n",
      "         [ 1.1408e-01,  2.1213e-01,  1.2668e-01]],\n",
      "\n",
      "        [[-6.7090e-02, -1.3356e-01, -7.3388e-02],\n",
      "         [-1.3341e-01, -3.0075e-01, -1.6126e-01],\n",
      "         [-8.9505e-02, -1.8633e-01, -1.1548e-01]],\n",
      "\n",
      "        [[-1.4065e-01, -2.1542e-01, -1.5244e-01],\n",
      "         [-2.2661e-01, -2.5893e-01, -2.6491e-01],\n",
      "         [-2.2720e-01, -2.2526e-01, -1.9086e-01]],\n",
      "\n",
      "        [[ 2.1525e-01,  5.5924e-01,  4.2620e-01],\n",
      "         [-9.7317e-02,  5.9124e-02,  2.6114e-01],\n",
      "         [-3.8463e-01, -6.9606e-01, -3.0152e-01]],\n",
      "\n",
      "        [[ 3.3768e-01,  6.3276e-01,  2.2248e-01],\n",
      "         [ 1.8928e-01,  1.0281e-01, -9.1681e-02],\n",
      "         [-4.6469e-01, -7.7986e-01, -5.9857e-01]],\n",
      "\n",
      "        [[-3.8881e-01,  1.1894e-01,  1.7076e-01],\n",
      "         [ 8.5117e-02,  4.8236e-01, -2.0659e-01],\n",
      "         [ 2.7351e-01, -1.4679e-01, -3.1185e-01]],\n",
      "\n",
      "        [[ 1.8392e-01,  3.0670e-01,  1.2419e-01],\n",
      "         [ 2.3855e-01,  4.1977e-01,  3.3062e-01],\n",
      "         [ 5.0164e-02,  1.9509e-01,  2.2662e-01]],\n",
      "\n",
      "        [[ 1.9004e-01,  4.1597e-01,  1.3319e-01],\n",
      "         [ 3.1835e-01,  6.5848e-01,  3.4584e-01],\n",
      "         [ 1.9777e-01,  3.8400e-01,  2.5468e-01]],\n",
      "\n",
      "        [[ 2.2557e-02,  1.1878e-01,  8.3410e-02],\n",
      "         [ 9.4691e-02,  2.2983e-01,  1.8682e-01],\n",
      "         [ 9.0262e-02,  1.4730e-01,  1.4333e-01]],\n",
      "\n",
      "        [[-1.2368e-01, -2.7263e-01, -1.7411e-01],\n",
      "         [-2.9438e-01, -5.0523e-01, -2.7358e-01],\n",
      "         [-1.8952e-01, -2.6940e-01, -1.6367e-01]],\n",
      "\n",
      "        [[ 1.9471e-01,  2.2384e-01,  1.7755e-01],\n",
      "         [ 2.6669e-01,  3.9487e-01,  3.2747e-01],\n",
      "         [ 1.8841e-01,  2.7556e-01,  2.7451e-01]],\n",
      "\n",
      "        [[ 2.3020e-01,  3.5828e-01,  2.3673e-01],\n",
      "         [ 1.5346e-01,  2.8998e-01,  2.5736e-01],\n",
      "         [ 1.2744e-01,  1.5457e-01,  1.4756e-01]],\n",
      "\n",
      "        [[ 2.7375e-01,  6.6543e-02, -2.5834e-01],\n",
      "         [ 3.8857e-01,  8.5812e-02, -4.6125e-01],\n",
      "         [ 3.0482e-01, -2.4189e-02, -4.1720e-01]],\n",
      "\n",
      "        [[ 4.5011e-01,  8.6192e-01,  5.6149e-01],\n",
      "         [ 8.6984e-01,  1.6600e+00,  1.1838e+00],\n",
      "         [ 6.4134e-01,  9.8697e-01,  6.4378e-01]],\n",
      "\n",
      "        [[ 5.3954e-01,  6.2615e-01,  3.2239e-01],\n",
      "         [ 6.4771e-01,  8.4437e-01,  5.3388e-01],\n",
      "         [ 3.8312e-01,  5.3563e-01,  4.7391e-01]],\n",
      "\n",
      "        [[-1.1540e-01, -2.7560e-01, -2.0217e-01],\n",
      "         [-1.6822e-01, -2.6067e-01, -2.4207e-01],\n",
      "         [-1.5464e-01, -2.2089e-01, -1.6404e-01]],\n",
      "\n",
      "        [[-9.9738e-02, -5.2953e-01,  1.1985e-01],\n",
      "         [-3.4174e-01,  1.0299e-01,  4.6084e-01],\n",
      "         [-6.5455e-02,  4.9142e-01, -1.1189e-01]],\n",
      "\n",
      "        [[ 3.6662e-01,  7.0950e-01,  7.3707e-01],\n",
      "         [ 8.2530e-01,  1.7856e+00,  1.4495e+00],\n",
      "         [ 6.0271e-01,  1.2720e+00,  1.1995e+00]],\n",
      "\n",
      "        [[-6.6596e-01, -7.1963e-01, -5.1389e-01],\n",
      "         [ 3.1484e-01,  7.3936e-01,  4.0243e-01],\n",
      "         [ 2.7311e-01,  1.5528e-01,  1.1296e-01]],\n",
      "\n",
      "        [[ 3.7857e-01,  4.2826e-01, -2.2779e-01],\n",
      "         [ 6.7181e-01,  1.0379e-01, -6.8276e-01],\n",
      "         [ 3.0839e-01, -3.1396e-01, -5.2080e-01]],\n",
      "\n",
      "        [[ 1.4911e-01,  1.7742e-01,  1.2578e-01],\n",
      "         [ 2.9309e-01,  4.2695e-01,  3.0618e-01],\n",
      "         [ 2.3477e-01,  3.3198e-01,  2.4839e-01]],\n",
      "\n",
      "        [[-3.9866e-03, -1.9469e-01, -2.6632e-01],\n",
      "         [-2.1617e-01, -3.9113e-01, -3.6424e-01],\n",
      "         [-2.3092e-01, -3.7603e-01, -2.0734e-01]],\n",
      "\n",
      "        [[ 2.9310e-01, -3.2930e-01, -6.1042e-01],\n",
      "         [ 5.5778e-01,  8.7135e-02, -8.1796e-01],\n",
      "         [ 3.1892e-01,  3.3402e-01, -3.9762e-01]],\n",
      "\n",
      "        [[-1.0282e-01, -2.2120e-01, -5.1713e-02],\n",
      "         [-2.7411e-01, -2.9164e-01, -1.6162e-01],\n",
      "         [-1.4256e-01, -3.0444e-01, -2.1405e-01]],\n",
      "\n",
      "        [[ 8.2707e-01,  9.1686e-01,  8.6818e-01],\n",
      "         [ 9.1216e-01,  1.0731e+00,  9.5142e-01],\n",
      "         [ 5.3843e-01,  6.9231e-01,  7.2168e-01]],\n",
      "\n",
      "        [[ 1.5969e-01,  4.9285e-01,  4.1198e-01],\n",
      "         [-6.4084e-01, -1.0464e+00, -8.6088e-01],\n",
      "         [ 3.7306e-01,  6.6970e-01,  3.7599e-01]],\n",
      "\n",
      "        [[-5.3183e-01, -7.8594e-02,  6.2282e-01],\n",
      "         [-1.1156e-01, -1.6168e-01,  2.9494e-02],\n",
      "         [ 4.5695e-01, -1.2435e-02, -5.2873e-01]],\n",
      "\n",
      "        [[-4.7518e-02, -4.9342e-02, -4.1150e-02],\n",
      "         [-1.2726e-01, -1.8932e-01, -1.4174e-01],\n",
      "         [-1.4398e-01, -2.4844e-01, -1.5048e-01]],\n",
      "\n",
      "        [[ 1.7171e-01, -4.7406e-01,  3.0160e-01],\n",
      "         [ 4.0393e-01, -7.8213e-01,  4.1419e-01],\n",
      "         [ 2.4148e-01, -5.3817e-01,  2.0901e-01]],\n",
      "\n",
      "        [[ 2.9069e-01,  4.2383e-01,  3.7204e-01],\n",
      "         [ 1.7181e-01,  3.4548e-01,  2.5393e-01],\n",
      "         [-5.6277e-01, -7.4069e-01, -6.1897e-01]],\n",
      "\n",
      "        [[ 1.5077e-01,  1.8408e-01,  1.7328e-01],\n",
      "         [ 1.9458e-01,  2.1355e-01,  2.2572e-01],\n",
      "         [ 1.7525e-01,  1.8570e-01,  2.2315e-01]],\n",
      "\n",
      "        [[ 2.5062e-01,  2.7046e-01,  8.5266e-02],\n",
      "         [ 2.9132e-01,  5.2574e-01,  3.3809e-01],\n",
      "         [ 9.0049e-02,  3.2433e-01,  3.4388e-01]],\n",
      "\n",
      "        [[ 3.9339e-01,  5.7426e-01,  2.2650e-01],\n",
      "         [ 6.6725e-02, -1.8784e-01, -2.3450e-02],\n",
      "         [-3.5735e-01, -4.8503e-01, -2.3961e-01]],\n",
      "\n",
      "        [[ 9.6748e-02,  2.1945e-01,  1.6861e-01],\n",
      "         [ 1.5638e-01,  3.0763e-01,  1.9309e-01],\n",
      "         [ 7.8718e-02,  1.4234e-01,  1.2276e-01]],\n",
      "\n",
      "        [[-9.1985e-02, -1.0104e-01, -7.8812e-02],\n",
      "         [-1.5056e-01, -3.0237e-01, -1.7716e-01],\n",
      "         [-1.1452e-01, -1.9113e-01, -9.4753e-02]],\n",
      "\n",
      "        [[ 8.9870e-01,  1.5662e+00,  1.4116e+00],\n",
      "         [ 1.1859e+00,  1.9767e+00,  1.7287e+00],\n",
      "         [ 1.3459e+00,  1.6871e+00,  1.5601e+00]],\n",
      "\n",
      "        [[ 4.0931e-02,  1.0030e-01,  8.4057e-02],\n",
      "         [ 9.5253e-02,  2.9617e-01,  1.8146e-01],\n",
      "         [ 6.8345e-02,  1.9466e-01,  1.1918e-01]],\n",
      "\n",
      "        [[ 1.3935e-01,  2.1907e-01,  1.5271e-01],\n",
      "         [ 2.1544e-01,  3.3117e-01,  2.4035e-01],\n",
      "         [ 1.4408e-01,  2.6946e-01,  1.9193e-01]],\n",
      "\n",
      "        [[ 3.9089e-01,  7.6958e-01,  4.9015e-01],\n",
      "         [ 6.5745e-01,  1.0885e+00,  7.9404e-01],\n",
      "         [ 2.4610e-01,  4.5912e-01,  3.9295e-01]],\n",
      "\n",
      "        [[-1.7813e-01, -2.4704e-01, -1.3722e-01],\n",
      "         [-1.6914e-01, -2.0708e-01, -1.9131e-01],\n",
      "         [-8.0345e-02, -2.5886e-01, -1.3648e-01]],\n",
      "\n",
      "        [[-9.9842e-02, -1.3422e-01, -1.6478e-01],\n",
      "         [-1.9059e-01, -1.8597e-01, -2.2285e-01],\n",
      "         [-9.6371e-02, -1.3272e-01, -1.0822e-01]],\n",
      "\n",
      "        [[ 9.4179e-02,  1.8139e-01,  1.1460e-01],\n",
      "         [ 1.6200e-01,  3.2870e-01,  2.0812e-01],\n",
      "         [ 9.5553e-02,  1.7810e-01,  1.1072e-01]],\n",
      "\n",
      "        [[-5.8071e-03, -1.1959e-01, -1.0859e-01],\n",
      "         [-1.0701e-01, -2.2172e-01, -1.8135e-01],\n",
      "         [-7.4256e-02, -1.8819e-01, -6.1205e-02]],\n",
      "\n",
      "        [[-2.4430e-01, -6.1626e-01, -4.2390e-01],\n",
      "         [-5.5571e-01, -8.2998e-01, -7.3713e-01],\n",
      "         [-3.1801e-01, -4.0773e-01, -3.7378e-01]],\n",
      "\n",
      "        [[ 3.9321e-01,  5.2995e-01,  3.4960e-01],\n",
      "         [ 2.8780e-01,  6.1197e-01,  5.5400e-01],\n",
      "         [ 1.6044e-01,  4.5412e-01,  4.7935e-01]],\n",
      "\n",
      "        [[-2.5109e-01, -2.5106e-01, -1.9962e-03],\n",
      "         [-2.9437e-01, -4.2115e-01, -2.5244e-01],\n",
      "         [-9.8928e-02, -3.1915e-01, -3.2764e-01]],\n",
      "\n",
      "        [[ 2.9466e-01,  3.9430e-01,  2.6157e-01],\n",
      "         [ 4.0013e-01,  7.3262e-01,  5.9569e-01],\n",
      "         [ 9.5317e-02,  4.8835e-01,  4.2186e-01]],\n",
      "\n",
      "        [[-7.6804e-02, -1.2486e-01, -1.0433e-01],\n",
      "         [-1.0503e-01, -1.9806e-01, -1.3621e-01],\n",
      "         [-5.8683e-02, -9.1666e-02, -5.1873e-02]],\n",
      "\n",
      "        [[-3.1063e-01, -5.5697e-01, -4.4733e-01],\n",
      "         [-3.8566e-02, -9.1250e-02, -1.3936e-01],\n",
      "         [ 3.7201e-01,  6.2615e-01,  4.8043e-01]],\n",
      "\n",
      "        [[-1.1366e-01, -2.6481e-01, -1.7521e-01],\n",
      "         [-2.4123e-01, -3.3244e-01, -2.9359e-01],\n",
      "         [-1.9115e-01, -2.1579e-01, -1.7398e-01]],\n",
      "\n",
      "        [[ 1.6944e-02, -2.4082e-01, -2.2852e-01],\n",
      "         [-9.1921e-02, -3.4595e-01, -3.6618e-01],\n",
      "         [-8.0287e-02, -1.8385e-01, -1.8580e-01]],\n",
      "\n",
      "        [[ 3.8721e-01, -2.4597e-02, -5.0440e-01],\n",
      "         [ 5.0285e-01,  6.8870e-02, -6.6739e-01],\n",
      "         [ 3.3128e-01,  1.7533e-01, -4.1599e-01]],\n",
      "\n",
      "        [[-3.7189e-01, -7.0296e-01, -4.0124e-01],\n",
      "         [ 3.7315e-02, -6.3740e-02, -7.8650e-02],\n",
      "         [ 2.9770e-01,  7.4784e-01,  5.0223e-01]],\n",
      "\n",
      "        [[-1.7936e-01, -3.1702e-01, -2.6010e-01],\n",
      "         [-2.8961e-01, -2.7661e-01, -3.2419e-01],\n",
      "         [-2.6423e-01, -1.9659e-01, -1.9097e-01]],\n",
      "\n",
      "        [[ 1.3143e-01,  7.6803e-01,  7.3125e-01],\n",
      "         [-2.7468e-01, -1.5793e-01,  4.9461e-01],\n",
      "         [-3.8856e-01, -8.5470e-01, -3.3468e-01]],\n",
      "\n",
      "        [[ 3.0941e-01,  4.8041e-01,  3.6993e-01],\n",
      "         [ 4.2305e-01,  8.2779e-01,  5.7585e-01],\n",
      "         [ 2.9677e-01,  5.9774e-01,  2.7621e-01]],\n",
      "\n",
      "        [[ 2.5850e-01,  2.7514e-02, -3.0327e-01],\n",
      "         [ 5.0698e-01,  1.7873e-02, -5.2197e-01],\n",
      "         [ 3.3955e-01,  4.5085e-02, -4.1412e-01]],\n",
      "\n",
      "        [[ 2.6820e-01, -7.0326e-03, -5.2773e-01],\n",
      "         [ 4.9628e-01,  1.9055e-01, -7.6144e-01],\n",
      "         [ 5.3628e-01,  3.6436e-01, -5.0108e-01]],\n",
      "\n",
      "        [[ 2.1563e-01,  2.7286e-01,  2.0320e-01],\n",
      "         [ 7.3109e-01,  1.2589e+00,  6.0209e-01],\n",
      "         [ 5.7620e-01,  1.0025e+00,  4.8192e-01]],\n",
      "\n",
      "        [[ 2.5426e-01,  4.2929e-01,  3.2157e-01],\n",
      "         [ 3.1273e-01,  5.4966e-01,  3.8106e-01],\n",
      "         [ 1.4544e-01,  1.8195e-01,  1.5911e-01]],\n",
      "\n",
      "        [[-1.2067e-01, -1.9903e-01, -1.0995e-01],\n",
      "         [-1.5678e-01, -3.3858e-01, -2.3638e-01],\n",
      "         [-9.6151e-02, -2.0261e-01, -1.6007e-01]],\n",
      "\n",
      "        [[-8.9760e-02, -2.4470e-01, -1.7591e-01],\n",
      "         [-2.6406e-01, -5.0966e-01, -3.7885e-01],\n",
      "         [-1.1293e-01, -2.5835e-01, -2.3009e-01]],\n",
      "\n",
      "        [[ 4.0068e-01,  7.6906e-01,  5.4045e-01],\n",
      "         [ 7.3630e-01,  1.2009e+00,  9.6105e-01],\n",
      "         [ 4.2193e-01,  7.9740e-01,  7.4213e-01]],\n",
      "\n",
      "        [[ 9.3492e-02,  4.2732e-01,  2.6696e-01],\n",
      "         [-1.0970e-01,  7.6409e-02,  1.5333e-01],\n",
      "         [-4.8373e-01, -5.7620e-01, -3.0800e-01]],\n",
      "\n",
      "        [[-2.6616e-01, -2.4807e-01, -3.5924e-01],\n",
      "         [-4.0824e-01, -5.5284e-01, -4.2314e-01],\n",
      "         [-2.9557e-01, -4.9734e-01, -3.6099e-01]],\n",
      "\n",
      "        [[-1.0846e-01, -1.2289e-01, -5.5598e-02],\n",
      "         [-2.2011e-01, -3.5946e-01, -2.1015e-01],\n",
      "         [-1.5855e-01, -3.1035e-01, -1.8278e-01]],\n",
      "\n",
      "        [[ 2.8587e-01,  3.9830e-01,  3.1189e-01],\n",
      "         [ 4.1736e-01,  6.1021e-01,  4.9673e-01],\n",
      "         [ 2.1980e-01,  4.7529e-01,  3.4108e-01]],\n",
      "\n",
      "        [[-1.3813e-01, -6.3664e-02, -8.6388e-02],\n",
      "         [-1.7450e-01, -1.4471e-01, -1.8296e-01],\n",
      "         [-6.8566e-02, -8.4540e-02, -1.2349e-01]],\n",
      "\n",
      "        [[ 7.5976e-02,  1.6469e-01,  1.5853e-01],\n",
      "         [ 1.5321e-01,  3.0018e-01,  2.4497e-01],\n",
      "         [ 1.0200e-01,  1.8539e-01,  1.5442e-01]],\n",
      "\n",
      "        [[-6.1951e-02, -1.2191e-01, -8.2717e-02],\n",
      "         [-1.5364e-01, -2.0074e-01, -1.4371e-01],\n",
      "         [-7.5009e-02, -8.5678e-02, -1.1736e-01]],\n",
      "\n",
      "        [[ 3.3999e-01,  3.2514e-01,  3.6258e-01],\n",
      "         [ 7.5522e-01,  1.1574e+00,  9.0539e-01],\n",
      "         [ 6.8209e-01,  1.1308e+00,  7.6661e-01]],\n",
      "\n",
      "        [[-5.5343e-01, -6.9363e-01, -5.1736e-01],\n",
      "         [-1.3135e+00, -2.2997e+00, -1.6710e+00],\n",
      "         [-1.0533e+00, -1.6997e+00, -1.2722e+00]],\n",
      "\n",
      "        [[ 3.0803e-01,  5.2164e-01,  3.5079e-01],\n",
      "         [ 3.8276e-01,  8.1649e-01,  5.4993e-01],\n",
      "         [ 1.7329e-01,  3.8112e-01,  3.5355e-01]],\n",
      "\n",
      "        [[ 2.5578e-01,  6.6328e-01,  6.6170e-01],\n",
      "         [ 6.8193e-01,  1.0895e+00,  1.0263e+00],\n",
      "         [ 6.5481e-01,  8.4884e-01,  5.5684e-01]],\n",
      "\n",
      "        [[ 7.1783e-02,  1.5004e-01,  1.2181e-01],\n",
      "         [ 1.3888e-01,  3.4772e-01,  2.2167e-01],\n",
      "         [ 8.1558e-02,  2.0819e-01,  1.3420e-01]],\n",
      "\n",
      "        [[ 2.8351e-01,  1.4584e-02, -2.9484e-01],\n",
      "         [ 4.3498e-01, -1.2983e-01, -2.4585e-01],\n",
      "         [ 2.4343e-01, -1.8256e-01, -2.2113e-01]],\n",
      "\n",
      "        [[-2.8783e-01, -2.3864e-01, -9.2468e-02],\n",
      "         [-3.7583e-01, -3.9835e-01, -2.7904e-01],\n",
      "         [-1.3067e-01, -3.0601e-01, -4.6627e-01]],\n",
      "\n",
      "        [[-1.5209e-02, -1.8941e-01, -1.8580e-01],\n",
      "         [-2.1443e-01, -3.8149e-01, -2.1357e-01],\n",
      "         [-2.7773e-01, -3.0487e-01, -1.0245e-01]],\n",
      "\n",
      "        [[ 2.8082e-01,  7.0535e-01,  3.9310e-01],\n",
      "         [ 8.9630e-01,  1.6636e+00,  1.2669e+00],\n",
      "         [ 6.8257e-01,  1.3349e+00,  1.2851e+00]]]) conv_bias: tensor([-6.5459e-02,  3.0816e+00,  4.4227e+00, -2.4662e-01,  1.5862e+00,\n",
      "         6.9521e-02,  1.1420e-01, -4.2500e-01,  1.5580e-01,  2.5781e+00,\n",
      "        -3.6529e-02,  8.6699e-01,  1.8041e+00,  2.5097e-01, -3.1713e-02,\n",
      "         1.4557e-01,  1.7494e-01, -8.0624e-01,  2.6311e+00,  1.0192e+00,\n",
      "        -5.4331e-02,  5.4537e-01, -4.4463e-01,  8.5326e-02,  3.4389e-02,\n",
      "         1.3497e-01,  2.8298e+00, -1.0232e-01, -2.8190e+00, -1.6663e-01,\n",
      "         1.8018e-01, -2.4939e-01,  1.1465e+00, -9.6430e-02,  1.7475e-01,\n",
      "        -3.8163e-01, -4.9804e-01,  1.0484e-01,  1.9870e+00,  3.1168e-01,\n",
      "         2.2021e+00, -4.9382e-01, -5.3426e-01,  2.0505e+00,  2.2597e+00,\n",
      "        -2.2337e-01, -1.7825e-01, -2.6372e+00, -2.8064e-01, -7.5094e-02,\n",
      "        -1.5484e-01,  5.9857e+00,  2.3714e-01,  4.3233e-02, -5.6290e-01,\n",
      "         1.3195e-01,  8.0772e-01,  1.0057e+00,  2.6679e-02,  1.9419e+00,\n",
      "         1.8961e+00, -2.4328e-01,  2.2780e+00,  3.7652e-02,  2.1013e+00,\n",
      "         1.1069e-01,  1.8253e+00,  3.4295e+00,  8.5361e-02, -2.2531e-01,\n",
      "         1.0532e+00, -3.8078e-01, -9.0253e-04,  7.0694e-02, -1.3758e-01,\n",
      "         2.3431e-01,  8.1644e-02,  2.3067e+00,  1.6243e+00,  1.0032e-02,\n",
      "         1.3680e+00,  8.9355e-01,  1.6908e+00, -2.4501e-02,  1.2273e+00,\n",
      "         8.3068e-02,  3.5017e+00,  9.5157e-02,  4.5583e+00, -2.1805e-01,\n",
      "        -1.5021e-01,  1.1439e-01,  1.3782e-01,  1.1799e+00,  2.4840e+00,\n",
      "         1.2272e-01])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "q_weight: tensor([   6,   18,    8,  -18,  -55,  -38,   12,   37,   24,  -24,  -47,  -34,\n",
      "         -49,  -93,  -56,  -26,  -39,  -27,  -32,  -57,  -34,  -41,  -88,  -54,\n",
      "         -28,  -55,  -34,   29,   45,   31,   29,   63,   52,   17,   32,   26,\n",
      "           1,  -39,  -73,  -40,  -80,  -73,  -67,  -64,  -18,   35,   55,   35,\n",
      "          51,   92,   60,   32,   53,   37,   33,   57,   34,   38,   79,   61,\n",
      "          10,   44,   39,   18,   48,    9,   38,   11,  -25,  -13,  -43,  -32,\n",
      "          27,   56,   50,   65,  118,   71,   50,   71,   40,  -35,  -39,  -33,\n",
      "         -43,  -70,  -47,  -22,  -39,  -23,  -28,   39,  -20,  -37,   61,  -54,\n",
      "          -5,   39,  -29,  -15,   -4,  -26, -112,  -34, -104,  -67,  -38,  -74,\n",
      "         -49,  -53,  -35,  -22,  -38,  -31,  -17,  -42,  -31,   -3,   16,   30,\n",
      "          24,   38,   29,   33,   32,   12,   24,   44,   20,   37,   80,   47,\n",
      "          17,   41,   38,   26,   33,   31,   35,   49,   35,   10,   20,   11,\n",
      "          43,   67,   47,   59,   98,   55,   40,   53,   28,   16,   32,   20,\n",
      "          34,   65,   41,   22,   40,   24,  -18,  -36,  -20,  -36,  -82,  -44,\n",
      "         -24,  -51,  -32,  -54,  -83,  -59,  -88, -100, -102,  -88,  -87,  -74,\n",
      "          14,   38,   29,   -7,    4,   18,  -26,  -47,  -20,   41,   76,   27,\n",
      "          23,   12,  -11,  -56,  -94,  -72,  -35,   11,   15,    8,   43,  -19,\n",
      "          25,  -13,  -28,   39,   66,   27,   51,   90,   71,   11,   42,   49,\n",
      "          26,   56,   18,   43,   89,   47,   27,   52,   34,    8,   43,   30,\n",
      "          34,   83,   68,   33,   53,   52,  -21,  -47,  -30,  -50,  -86,  -47,\n",
      "         -32,  -46,  -28,   57,   66,   52,   79,  116,   96,   55,   81,   81,\n",
      "          44,   68,   45,   29,   55,   49,   24,   29,   28,   46,   11,  -44,\n",
      "          66,   15,  -78,   52,   -4,  -71,   28,   53,   34,   53,  102,   73,\n",
      "          39,   61,   39,   46,   53,   27,   55,   71,   45,   32,   45,   40,\n",
      "         -36,  -87,  -63,  -53,  -82,  -76,  -49,  -69,  -51,   -8,  -45,   10,\n",
      "         -29,    9,   39,   -6,   42,   -9,   18,   34,   36,   40,   87,   70,\n",
      "          29,   62,   58,  -66,  -71,  -51,   31,   73,   40,   27,   15,   11,\n",
      "          27,   31,  -16,   48,    7,  -49,   22,  -22,  -37,   34,   40,   29,\n",
      "          67,   97,   70,   53,   75,   56,   -1,  -43,  -59,  -48,  -87,  -81,\n",
      "         -51,  -84,  -46,   29,  -32,  -60,   55,    9,  -80,   31,   33,  -39,\n",
      "         -27,  -58,  -14,  -72,  -77,  -42,  -37,  -80,  -56,   58,   64,   61,\n",
      "          64,   75,   67,   38,   48,   50,   15,   45,   38,  -59,  -96,  -79,\n",
      "          34,   61,   34,  -62,   -9,   73,  -13,  -19,    3,   53,   -1,  -62,\n",
      "         -19,  -19,  -16,  -50,  -74,  -55,  -56,  -97,  -59,   17,  -47,   30,\n",
      "          40,  -77,   41,   24,  -53,   21,   39,   56,   50,   23,   46,   34,\n",
      "         -75,  -99,  -82,   32,   39,   37,   41,   46,   48,   37,   40,   48,\n",
      "          37,   40,   13,   43,   78,   50,   13,   48,   51,   35,   51,   20,\n",
      "           6,  -17,   -2,  -32,  -43,  -21,   38,   86,   66,   61,  121,   76,\n",
      "          31,   56,   48,  -36,  -39,  -31,  -59, -118,  -69,  -45,  -74,  -37,\n",
      "          30,   53,   48,   40,   67,   58,   46,   57,   53,   11,   28,   23,\n",
      "          27,   83,   51,   19,   54,   33,   42,   67,   46,   66,  101,   73,\n",
      "          44,   82,   58,   32,   64,   41,   55,   90,   66,   20,   38,   33,\n",
      "         -66,  -92,  -51,  -63,  -77,  -71,  -30,  -96,  -51,  -45,  -61,  -74,\n",
      "         -86,  -84, -101,  -44,  -60,  -49,   24,   45,   29,   40,   82,   52,\n",
      "          24,   44,   28,   -3,  -60,  -55,  -54, -112,  -92,  -38,  -95,  -31,\n",
      "         -23,  -58,  -40,  -53,  -78,  -70,  -30,  -39,  -35,   35,   47,   31,\n",
      "          26,   55,   50,   14,   41,   43,  -64,  -64,   -1,  -75, -107,  -64,\n",
      "         -25,  -81,  -84,   32,   43,   28,   43,   80,   65,   10,   53,   46,\n",
      "         -42,  -69,  -58,  -58, -109,  -75,  -32,  -51,  -29,  -39,  -70,  -56,\n",
      "          -5,  -11,  -17,   47,   79,   60,  -28,  -66,  -44,  -60,  -83,  -73,\n",
      "         -48,  -54,  -44,    3,  -48,  -46,  -18,  -70,  -74,  -16,  -37,  -37,\n",
      "          50,   -3,  -65,   65,    9,  -86,   43,   23,  -54,  -39,  -75,  -43,\n",
      "           4,   -7,   -8,   32,   79,   53,  -56,  -99,  -81,  -90,  -86, -101,\n",
      "         -82,  -61,  -59,    9,   51,   48,  -18,  -10,   33,  -26,  -56,  -22,\n",
      "          29,   45,   34,   39,   77,   54,   28,   56,   26,   32,    3,  -37,\n",
      "          62,    2,  -64,   42,    6,  -51,   20,   -1,  -40,   38,   14,  -58,\n",
      "          41,   28,  -38,   20,   25,   19,   67,  115,   55,   53,   92,   44,\n",
      "          48,   81,   61,   59,  104,   72,   28,   35,   30,  -38,  -63,  -35,\n",
      "         -50, -107,  -75,  -30,  -64,  -51,   -9,  -25,  -18,  -27,  -52,  -39,\n",
      "         -12,  -27,  -24,   29,   56,   39,   53,   87,   70,   31,   58,   54,\n",
      "           7,   33,   21,   -8,    6,   12,  -37,  -44,  -24,  -44,  -41,  -59,\n",
      "         -67,  -91,  -70,  -49,  -82,  -59,  -22,  -25,  -11,  -44,  -73,  -42,\n",
      "         -32,  -63,  -37,   35,   48,   38,   51,   74,   60,   27,   58,   42,\n",
      "         -82,  -38,  -51, -103,  -86, -108,  -41,  -50,  -73,   17,   37,   36,\n",
      "          34,   68,   55,   23,   42,   35,  -35,  -70,  -47,  -88, -115,  -82,\n",
      "         -43,  -49,  -67,   17,   16,   18,   37,   57,   45,   34,   56,   38,\n",
      "         -14,  -18,  -13,  -34,  -60,  -43,  -27,  -44,  -33,   23,   38,   26,\n",
      "          28,   60,   40,   13,   28,   26,   20,   53,   53,   54,   87,   82,\n",
      "          52,   68,   44,   18,   37,   30,   34,   85,   54,   20,   51,   33,\n",
      "          28,    1,  -29,   42,  -13,  -24,   24,  -18,  -22,  -59,  -49,  -19,\n",
      "         -77,  -81,  -57,  -27,  -62,  -95,   -4,  -49,  -48,  -55,  -98,  -55,\n",
      "         -71,  -78,  -26,   11,   28,   16,   36,   66,   51,   27,   53,   51],\n",
      "       dtype=torch.int32) q_bias: tensor([  -23,  3231, 14453,  -350,  1730,   165,   252,  -173,   240,  3470,\n",
      "          -31,  1297,  1501,    32,   -31,    38,    62, -1028,  4822,  2640,\n",
      "          -24,   440,  -269,   123,    31,   328,  3243,  -202, -3606,  -189,\n",
      "           74,  -141,  2413,   -55,    57,  -252,  -239,   160,  2967,   205,\n",
      "         3879,  -232,  -328,  1601,  5913,  -147,  -159, -3771,  -278,   -45,\n",
      "         -408, 15626,    54,    81, -1148,    74,  2019,  3048,    45,  6585,\n",
      "         1203,  -146,  3898,    27,  7771,    93,  3062,  4628,    74,  -160,\n",
      "         2197,  -168,    -1,    58,   -70,   144,   104,  4895,  1118,     5,\n",
      "          708,   985,  2293,   -20,  4868,   125, 13435,    32,   794,  -107,\n",
      "          -80,   188,    90,  1613,  4277,    33], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0001) tensor(0.0250)   bias tensor(-5.2595e-05) tensor(0.0013)\n",
      "features.4.conv.6.weight features.4.conv.8\n",
      "torch.Size([16, 96, 1, 1]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.0807]) torch.Size([1]) \n",
      "wscale= tensor([0.0065, 0.0037, 0.0034, 0.0050, 0.0055, 0.0042, 0.0045, 0.0057, 0.0047,\n",
      "        0.0055, 0.0048, 0.0044, 0.0038, 0.0047, 0.0036, 0.0038]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.0530]) torch.Size([1])\n",
      "###: M= tensor([0.0099, 0.0056, 0.0051, 0.0076, 0.0084, 0.0064, 0.0068, 0.0087, 0.0071,\n",
      "        0.0084, 0.0073, 0.0067, 0.0058, 0.0071, 0.0055, 0.0058])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "conv_weight: tensor([[-0.1108,  0.0807,  0.0168,  ...,  0.3007,  0.1122, -0.0765],\n",
      "        [ 0.0283, -0.1091, -0.1596,  ...,  0.1317, -0.0549, -0.1270],\n",
      "        [ 0.0433,  0.0465, -0.1564,  ...,  0.0632, -0.0575, -0.0022],\n",
      "        ...,\n",
      "        [-0.0138, -0.1017, -0.2510,  ...,  0.2631,  0.1101, -0.0043],\n",
      "        [ 0.1327,  0.2043,  0.0227,  ...,  0.2275, -0.0599, -0.0446],\n",
      "        [-0.0376,  0.0595,  0.1161,  ..., -0.3285,  0.2400, -0.1263]]) conv_bias: tensor([-0.5615,  0.9041,  1.3894,  0.5125, -1.9044,  0.9970, -1.4814,  1.8547,\n",
      "        -2.5171, -1.8990,  3.0848, -3.5017, -1.3701,  1.9732,  0.7291, -0.2646])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "q_weight: tensor([-17,  12,   3,  ..., -86,  62, -33], dtype=torch.int32) q_bias: tensor([-1071,  3032,  5120,  1276, -4267,  2934, -4119,  4042, -6671, -4275,\n",
      "         7940, -9849, -4433,  5229,  2500,  -854], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-6.0243e-05) tensor(0.0032)   bias tensor(2.0174e-05) tensor(0.0002)\n",
      "features.5.conv.0.weight features.5.conv.2\n",
      "torch.Size([96, 16, 1, 1]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.0530]) torch.Size([1]) \n",
      "wscale= tensor([8.2280e-03, 1.1803e-06, 2.4095e-03, 4.6718e-03, 2.5737e-03, 1.7639e-03,\n",
      "        4.3996e-03, 1.3762e-03, 6.4670e-03, 2.6115e-03, 1.6861e-03, 2.8890e-03,\n",
      "        2.4383e-03, 2.2011e-03, 2.5737e-03, 3.2721e-03, 2.9209e-03, 3.7091e-03,\n",
      "        3.5738e-03, 1.8070e-03, 2.0306e-03, 2.6329e-03, 3.5752e-03, 2.7043e-03,\n",
      "        6.5870e-03, 2.9921e-03, 1.6289e-03, 2.1857e-03, 1.9111e-03, 2.5827e-03,\n",
      "        2.4901e-03, 2.7825e-03, 5.3305e-03, 2.7790e-03, 2.7509e-03, 2.6384e-03,\n",
      "        2.3452e-03, 3.5510e-03, 1.8588e-03, 1.8710e-03, 7.0248e-04, 1.7751e-03,\n",
      "        2.4117e-03, 3.8323e-03, 1.9402e-03, 2.6436e-03, 2.8748e-03, 5.4480e-05,\n",
      "        2.6466e-03, 3.9897e-03, 1.1214e-02, 1.4454e-02, 4.0442e-03, 2.4395e-03,\n",
      "        1.8639e-06, 1.7421e-03, 3.1519e-03, 3.0712e-03, 1.7985e-03, 2.4867e-03,\n",
      "        3.2392e-03, 2.1899e-03, 2.2729e-03, 2.3662e-03, 6.2374e-03, 2.1876e-03,\n",
      "        3.2815e-03, 2.7426e-03, 3.3096e-03, 5.7164e-03, 2.1635e-03, 1.6372e-03,\n",
      "        2.2663e-03, 3.4163e-03, 5.6824e-03, 9.9995e-03, 6.5098e-04, 4.3024e-03,\n",
      "        7.1620e-03, 5.6796e-03, 4.0231e-03, 1.7048e-03, 5.2929e-03, 1.9493e-03,\n",
      "        2.4095e-03, 2.4433e-03, 6.4514e-03, 2.7801e-03, 2.9157e-03, 2.5712e-03,\n",
      "        3.2484e-03, 2.5574e-03, 1.5082e-03, 3.2068e-03, 1.7343e-03, 7.1681e-03]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.0838]) torch.Size([1])\n",
      "###: M= tensor([5.2072e-03, 7.4694e-07, 1.5249e-03, 2.9566e-03, 1.6288e-03, 1.1163e-03,\n",
      "        2.7843e-03, 8.7094e-04, 4.0927e-03, 1.6527e-03, 1.0671e-03, 1.8283e-03,\n",
      "        1.5431e-03, 1.3930e-03, 1.6288e-03, 2.0708e-03, 1.8485e-03, 2.3473e-03,\n",
      "        2.2617e-03, 1.1436e-03, 1.2851e-03, 1.6663e-03, 2.2626e-03, 1.7115e-03,\n",
      "        4.1687e-03, 1.8936e-03, 1.0309e-03, 1.3833e-03, 1.2095e-03, 1.6345e-03,\n",
      "        1.5759e-03, 1.7609e-03, 3.3735e-03, 1.7587e-03, 1.7409e-03, 1.6697e-03,\n",
      "        1.4842e-03, 2.2473e-03, 1.1764e-03, 1.1841e-03, 4.4457e-04, 1.1234e-03,\n",
      "        1.5263e-03, 2.4253e-03, 1.2279e-03, 1.6730e-03, 1.8193e-03, 3.4478e-05,\n",
      "        1.6749e-03, 2.5249e-03, 7.0967e-03, 9.1474e-03, 2.5594e-03, 1.5438e-03,\n",
      "        1.1796e-06, 1.1025e-03, 1.9947e-03, 1.9437e-03, 1.1382e-03, 1.5737e-03,\n",
      "        2.0500e-03, 1.3859e-03, 1.4385e-03, 1.4975e-03, 3.9474e-03, 1.3845e-03,\n",
      "        2.0767e-03, 1.7357e-03, 2.0945e-03, 3.6177e-03, 1.3692e-03, 1.0361e-03,\n",
      "        1.4342e-03, 2.1621e-03, 3.5962e-03, 6.3283e-03, 4.1198e-04, 2.7228e-03,\n",
      "        4.5326e-03, 3.5944e-03, 2.5460e-03, 1.0789e-03, 3.3497e-03, 1.2336e-03,\n",
      "        1.5249e-03, 1.5462e-03, 4.0828e-03, 1.7594e-03, 1.8453e-03, 1.6272e-03,\n",
      "        2.0558e-03, 1.6185e-03, 9.5447e-04, 2.0294e-03, 1.0976e-03, 4.5364e-03])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "conv_weight: tensor([[ 9.6482e-01, -1.1559e-03,  1.2611e-01,  ..., -4.4470e-01,\n",
      "          3.6484e-01, -4.1409e-02],\n",
      "        [ 1.2511e-04, -5.6834e-05, -1.1690e-04,  ...,  2.7593e-06,\n",
      "         -9.0653e-06,  4.5203e-05],\n",
      "        [ 2.6901e-01, -1.4222e-02,  4.9549e-02,  ..., -8.2002e-02,\n",
      "         -8.7464e-02,  4.6659e-02],\n",
      "        ...,\n",
      "        [ 3.1057e-01, -2.2143e-01, -2.6364e-01,  ...,  3.6025e-02,\n",
      "          2.5400e-01,  5.4118e-02],\n",
      "        [-6.5680e-02, -1.0358e-01, -4.3540e-02,  ...,  1.5601e-01,\n",
      "         -4.4100e-02,  1.2563e-02],\n",
      "        [ 8.6207e-01,  1.4058e-01, -2.3354e-01,  ..., -2.0292e-01,\n",
      "         -4.7927e-02, -1.8781e-02]]) conv_bias: tensor([ 4.0441e-01, -1.7312e-03,  1.3229e+00,  9.9811e-02, -4.4691e-01,\n",
      "         5.0613e-01,  3.6557e-01,  8.2761e-01, -1.3958e-01,  1.3304e+00,\n",
      "         8.9935e-01,  1.3753e+00,  7.9808e-01,  9.6032e-01,  1.2256e+00,\n",
      "         5.0189e-01,  1.3590e+00,  1.3059e+00,  1.2030e+00,  1.3331e+00,\n",
      "         1.5704e+00,  1.0914e+00,  1.0110e+00, -5.2437e-01, -2.9652e-01,\n",
      "         1.2821e+00,  1.2328e+00,  6.5066e-01,  1.0480e+00,  1.1386e+00,\n",
      "         8.4322e-01,  1.2188e+00,  2.1364e-01,  1.2135e+00,  9.3291e-01,\n",
      "         8.5866e-01,  1.5423e+00,  2.4995e-01,  7.1262e-01,  1.0288e+00,\n",
      "         2.0688e+00,  1.0240e+00,  8.5750e-01,  9.4651e-01,  1.4121e+00,\n",
      "         1.4281e+00,  1.4457e+00, -1.5935e-02,  8.7890e-01, -3.0582e-01,\n",
      "        -2.9412e-01, -2.2029e-01,  2.1189e-01,  7.7220e-01, -3.2438e-03,\n",
      "         1.0579e+00,  3.8394e-01,  1.3882e+00,  1.4752e+00,  8.0623e-01,\n",
      "        -4.5183e-01,  1.8346e+00,  1.3750e+00,  1.3924e+00, -4.4811e-01,\n",
      "         1.2585e+00,  1.2595e-01,  1.3413e+00,  4.4991e-01,  3.5048e-01,\n",
      "         1.0118e+00,  1.5672e+00,  1.0837e+00,  5.8997e-01,  4.1555e-01,\n",
      "        -1.0346e-01,  2.2839e+00,  5.0115e-01, -1.0527e-02,  3.2247e-01,\n",
      "         5.7338e-01, -5.5088e-01,  2.6179e-01,  7.6932e-01,  1.0257e+00,\n",
      "         2.0001e+00, -3.4262e-01,  1.3010e+00,  1.1646e+00,  8.1776e-01,\n",
      "         1.5801e+00,  1.3715e+00,  2.0928e+00,  3.1541e-01,  1.3499e+00,\n",
      "        -2.6793e-01])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "q_weight: tensor([117,   0,  15,  ..., -28,  -7,  -3], dtype=torch.int32) q_bias: tensor([   927, -27658,  10353,    403,  -3274,   5410,   1567,  11340,   -407,\n",
      "          9606,  10058,   8976,   6172,   8227,   8979,   2892,   8773,   6639,\n",
      "          6347,  13912,  14583,   7816,   5332,  -3656,   -849,   8080,  14270,\n",
      "          5613,  10340,   8312,   6385,   8260,    756,   8234,   6395,   6137,\n",
      "         12401,   1327,   7229,  10368,  55531,  10878,   6704,   4657,  13724,\n",
      "         10186,   9482,  -5515,   6262,  -1445,   -495,   -287,    988,   5969,\n",
      "        -32816,  11451,   2297,   8523,  15466,   6114,  -2630,  15796,  11407,\n",
      "         11096,  -1355,  10848,    724,   9222,   2563,   1156,   8819,  18050,\n",
      "          9017,   3256,   1379,   -195,  66154,   2196,    -28,   1071,   2687,\n",
      "         -6093,    933,   7442,   8027,  15436,  -1001,   8824,   7532,   5997,\n",
      "          9172,  10112,  26166,   1855,  14677,   -705], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-3.0550e-05) tensor(0.0070)   bias tensor(-1.8151e-06) tensor(0.0003)\n",
      "features.5.conv.3.weight features.5.conv.5\n",
      "torch.Size([96, 1, 3, 3]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.0814]) torch.Size([1]) \n",
      "wscale= tensor([2.8685e-03, 7.3240e-06, 2.4503e-02, 2.7716e-03, 2.0453e-02, 4.7472e-03,\n",
      "        7.4009e-03, 1.5054e-02, 7.8332e-03, 1.7088e-02, 1.0720e-02, 1.3451e-02,\n",
      "        2.3919e-02, 1.6476e-02, 1.7830e-02, 6.4357e-03, 1.2358e-02, 1.7477e-02,\n",
      "        1.3983e-02, 2.2548e-02, 1.8715e-02, 1.1085e-02, 8.4424e-03, 2.4524e-02,\n",
      "        1.3111e-02, 2.7994e-02, 1.0321e-02, 1.4489e-02, 1.4795e-02, 8.8772e-03,\n",
      "        9.0350e-03, 9.7077e-03, 2.3999e-03, 1.4098e-02, 1.7243e-02, 7.6598e-03,\n",
      "        2.8220e-02, 1.0324e-02, 1.0631e-02, 2.4091e-02, 3.6344e-02, 1.0704e-02,\n",
      "        2.5461e-02, 1.6713e-02, 1.6254e-02, 1.4689e-02, 2.4392e-02, 2.1413e-04,\n",
      "        7.1082e-03, 1.8803e-02, 5.5525e-03, 3.0154e-03, 8.8633e-03, 1.3850e-02,\n",
      "        2.2765e-05, 1.2346e-02, 8.3908e-03, 2.3191e-02, 2.6454e-02, 8.3760e-03,\n",
      "        1.5723e-02, 1.5192e-02, 2.5070e-02, 1.8176e-02, 6.6358e-03, 1.7197e-02,\n",
      "        1.2680e-02, 1.4632e-02, 5.9905e-03, 7.2958e-03, 1.0222e-02, 2.0125e-02,\n",
      "        8.8668e-03, 1.9177e-02, 6.5309e-03, 1.1630e-03, 4.6330e-02, 9.0111e-03,\n",
      "        6.2502e-03, 5.5386e-03, 1.4998e-02, 2.3749e-02, 3.8456e-03, 1.5282e-02,\n",
      "        7.7342e-03, 2.9020e-02, 7.3459e-03, 1.3337e-02, 8.1167e-03, 1.0565e-02,\n",
      "        1.9349e-02, 1.3133e-02, 1.3868e-02, 1.0874e-02, 1.3174e-02, 5.5747e-03]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.0668]) torch.Size([1])\n",
      "###: M= tensor([3.4955e-03, 8.9249e-06, 2.9859e-02, 3.3775e-03, 2.4923e-02, 5.7848e-03,\n",
      "        9.0186e-03, 1.8344e-02, 9.5453e-03, 2.0823e-02, 1.3064e-02, 1.6391e-02,\n",
      "        2.9148e-02, 2.0078e-02, 2.1728e-02, 7.8424e-03, 1.5059e-02, 2.1297e-02,\n",
      "        1.7040e-02, 2.7477e-02, 2.2806e-02, 1.3508e-02, 1.0288e-02, 2.9884e-02,\n",
      "        1.5977e-02, 3.4113e-02, 1.2577e-02, 1.7656e-02, 1.8029e-02, 1.0818e-02,\n",
      "        1.1010e-02, 1.1830e-02, 2.9244e-03, 1.7179e-02, 2.1012e-02, 9.3341e-03,\n",
      "        3.4389e-02, 1.2581e-02, 1.2954e-02, 2.9356e-02, 4.4288e-02, 1.3043e-02,\n",
      "        3.1026e-02, 2.0366e-02, 1.9807e-02, 1.7900e-02, 2.9723e-02, 2.6093e-04,\n",
      "        8.6619e-03, 2.2913e-02, 6.7662e-03, 3.6745e-03, 1.0801e-02, 1.6878e-02,\n",
      "        2.7740e-05, 1.5044e-02, 1.0225e-02, 2.8260e-02, 3.2236e-02, 1.0207e-02,\n",
      "        1.9160e-02, 1.8513e-02, 3.0549e-02, 2.2149e-02, 8.0863e-03, 2.0956e-02,\n",
      "        1.5451e-02, 1.7830e-02, 7.2999e-03, 8.8905e-03, 1.2456e-02, 2.4523e-02,\n",
      "        1.0805e-02, 2.3369e-02, 7.9585e-03, 1.4172e-03, 5.6456e-02, 1.0981e-02,\n",
      "        7.6164e-03, 6.7492e-03, 1.8276e-02, 2.8940e-02, 4.6861e-03, 1.8622e-02,\n",
      "        9.4248e-03, 3.5363e-02, 8.9515e-03, 1.6252e-02, 9.8909e-03, 1.2875e-02,\n",
      "        2.3578e-02, 1.6004e-02, 1.6899e-02, 1.3251e-02, 1.6054e-02, 6.7932e-03])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "conv_weight: tensor([[[-1.1914e-01, -1.9212e-01, -6.8458e-02],\n",
      "         [-2.3523e-02, -2.5091e-01, -3.3720e-02],\n",
      "         [ 1.1764e-02,  3.5144e-02,  2.1623e-03]],\n",
      "\n",
      "        [[ 5.8364e-04,  9.3649e-05, -3.7447e-04],\n",
      "         [ 4.8833e-04, -9.3015e-04, -1.2651e-04],\n",
      "         [-3.5763e-04, -1.5890e-04,  5.9351e-04]],\n",
      "\n",
      "        [[ 5.0024e-02,  1.0171e+00,  9.7508e-02],\n",
      "         [-3.2087e-01, -1.5334e+00, -1.5721e-01],\n",
      "         [ 9.5154e-02,  6.2297e-01,  3.6614e-02]],\n",
      "\n",
      "        [[-1.3563e-01, -2.0488e-01, -2.1981e-01],\n",
      "         [-5.8336e-02,  7.8917e-03, -8.8349e-03],\n",
      "         [-1.4335e-01, -3.0081e-01, -1.6234e-01]],\n",
      "\n",
      "        [[-1.2172e-01, -5.9417e-01, -6.5419e-01],\n",
      "         [-3.2708e-01,  1.5984e+00, -2.0511e-01],\n",
      "         [-3.8059e-01, -3.9695e-01, -4.8226e-01]],\n",
      "\n",
      "        [[-2.3481e-01, -4.6631e-02, -2.8301e-01],\n",
      "         [-3.4263e-01, -3.3827e-01, -3.4606e-01],\n",
      "         [-2.5013e-01, -1.7879e-01, -1.9007e-01]],\n",
      "\n",
      "        [[-7.5015e-01,  5.2159e-02,  3.7562e-01],\n",
      "         [-1.2092e-01,  4.5020e-01, -7.9494e-03],\n",
      "         [ 3.6381e-01, -1.2967e-01, -4.0917e-01]],\n",
      "\n",
      "        [[ 9.5567e-02, -1.5588e+00,  5.7231e-02],\n",
      "         [-5.1274e-01,  4.6976e-01, -1.9206e-01],\n",
      "         [-1.8355e-01,  2.6218e-01, -2.0833e-01]],\n",
      "\n",
      "        [[ 4.5225e-01,  1.7030e-01, -4.4466e-01],\n",
      "         [ 1.4929e-01,  1.0963e-01,  2.7562e-01],\n",
      "         [-6.2266e-02,  2.2907e-01,  1.6829e-01]],\n",
      "\n",
      "        [[-1.7679e-01, -9.3359e-01, -2.0731e-01],\n",
      "         [-1.1531e-01, -1.7141e-01, -1.6941e-01],\n",
      "         [ 2.6555e-01,  1.2238e+00,  2.5448e-01]],\n",
      "\n",
      "        [[-3.0204e-01, -6.3457e-01,  1.4688e-01],\n",
      "         [ 5.5770e-01, -4.4592e-01, -8.3891e-01],\n",
      "         [ 2.4160e-01,  9.0635e-01,  2.8809e-01]],\n",
      "\n",
      "        [[-2.4340e-01, -6.8672e-02,  2.9353e-01],\n",
      "         [-9.5192e-01,  6.8385e-03,  9.4921e-01],\n",
      "         [-3.8703e-01, -2.9241e-02,  4.1692e-01]],\n",
      "\n",
      "        [[-4.2259e-01,  8.7440e-01, -5.0503e-01],\n",
      "         [-5.6469e-01,  1.5217e+00, -5.9358e-01],\n",
      "         [-4.3190e-01,  5.6085e-01, -2.0727e-01]],\n",
      "\n",
      "        [[-1.7990e-01, -9.1797e-02,  3.7318e-01],\n",
      "         [-1.9197e-01, -9.0768e-01,  1.1366e+00],\n",
      "         [-8.4198e-02, -2.7135e-01,  1.0036e-01]],\n",
      "\n",
      "        [[-2.8242e-01, -7.2856e-01, -1.1111e-01],\n",
      "         [-2.2426e-01,  1.0674e+00, -1.8311e-01],\n",
      "         [-2.2735e-01, -3.6612e-01, -2.5249e-01]],\n",
      "\n",
      "        [[ 1.8521e-02,  5.2951e-02,  5.1924e-03],\n",
      "         [ 9.0084e-04,  4.5623e-01,  4.8116e-02],\n",
      "         [-2.9352e-02,  4.8986e-01, -3.6145e-02]],\n",
      "\n",
      "        [[-1.8914e-01,  1.6676e-01,  1.9628e-01],\n",
      "         [-7.2212e-01, -1.1281e-01,  8.1340e-01],\n",
      "         [-3.7506e-01, -2.3089e-01,  4.2597e-01]],\n",
      "\n",
      "        [[-6.0026e-02,  1.1508e-01, -4.3708e-02],\n",
      "         [-5.5092e-01,  9.8855e-01, -5.3031e-01],\n",
      "         [-6.6281e-02,  3.4272e-01, -4.6096e-02]],\n",
      "\n",
      "        [[-2.6140e-01, -9.3805e-01, -2.0754e-01],\n",
      "         [-1.4685e-01,  7.8259e-02,  2.2296e-01],\n",
      "         [ 1.4612e-01,  8.6825e-01,  2.4458e-01]],\n",
      "\n",
      "        [[ 1.9582e-01, -1.2008e+00,  2.0344e-01],\n",
      "         [-3.4574e-02,  4.1069e-01, -1.8054e-01],\n",
      "         [-6.4991e-02,  8.3974e-01, -4.3392e-02]],\n",
      "\n",
      "        [[ 8.0176e-02, -4.1386e-01,  1.0277e-01],\n",
      "         [ 6.2734e-01, -1.0251e+00,  7.2932e-01],\n",
      "         [ 8.5550e-02, -5.1663e-01,  8.4586e-02]],\n",
      "\n",
      "        [[ 1.8916e-01,  8.1062e-01,  1.8027e-01],\n",
      "         [-2.5619e-01,  9.3738e-02,  2.6055e-01],\n",
      "         [-2.5150e-01, -9.1005e-01, -1.0622e-01]],\n",
      "\n",
      "        [[-3.0534e-01,  3.5741e-01,  2.5039e-01],\n",
      "         [ 3.9654e-01,  3.0628e-02,  3.9298e-01],\n",
      "         [ 1.2718e-01,  3.6056e-01, -2.5593e-02]],\n",
      "\n",
      "        [[-5.9179e-01, -5.3038e-01, -4.2750e-02],\n",
      "         [-4.9162e-01,  1.9637e+00, -3.6276e-01],\n",
      "         [-1.0997e-01, -6.6500e-01, -4.1130e-01]],\n",
      "\n",
      "        [[-1.6403e-01, -3.4401e-01, -2.1428e-01],\n",
      "         [-1.6425e-01,  9.6629e-01, -2.2733e-01],\n",
      "         [-1.1301e-01, -2.7976e-02, -1.5482e-01]],\n",
      "\n",
      "        [[-3.2856e-01, -4.6871e-01,  4.4653e-01],\n",
      "         [-4.3966e-01,  1.5152e+00, -4.4694e-01],\n",
      "         [ 3.3642e-01, -1.5504e-01, -2.4231e-01]],\n",
      "\n",
      "        [[-2.9185e-01, -6.1717e-01, -3.0456e-01],\n",
      "         [-5.3207e-01,  8.6020e-01, -6.0811e-01],\n",
      "         [-3.1031e-01, -1.5794e-01, -2.1421e-01]],\n",
      "\n",
      "        [[-3.2314e-01, -6.9415e-01, -3.5316e-01],\n",
      "         [-5.3978e-01,  1.3314e+00, -5.0580e-01],\n",
      "         [-4.7002e-01,  3.6922e-02, -5.6450e-01]],\n",
      "\n",
      "        [[ 2.8203e-01, -2.4207e-02, -1.2169e-01],\n",
      "         [ 1.0569e+00, -8.8258e-01, -1.7791e-01],\n",
      "         [ 1.4157e-01, -3.0288e-01, -5.7258e-02]],\n",
      "\n",
      "        [[-4.9829e-01,  3.9000e-01,  2.8516e-01],\n",
      "         [-1.1405e-02,  4.2367e-01,  4.0397e-01],\n",
      "         [-4.4499e-02,  8.9157e-02, -5.2103e-01]],\n",
      "\n",
      "        [[ 6.4838e-02, -7.2954e-01, -1.2730e-01],\n",
      "         [ 6.6010e-01, -4.1802e-03, -6.5407e-01],\n",
      "         [ 2.3968e-01,  5.5751e-01, -1.0253e-01]],\n",
      "\n",
      "        [[-3.4740e-01, -1.0497e-01,  2.9332e-01],\n",
      "         [-7.8318e-01, -4.0344e-02,  8.8016e-01],\n",
      "         [-3.0662e-01,  5.4219e-02,  3.4785e-01]],\n",
      "\n",
      "        [[ 8.7319e-02, -1.0251e-01,  5.5393e-02],\n",
      "         [-2.6633e-01, -1.3824e-01, -2.2728e-01],\n",
      "         [-1.2998e-01, -8.4994e-02, -9.7416e-02]],\n",
      "\n",
      "        [[-2.0763e-02,  2.8958e-01, -3.5267e-02],\n",
      "         [ 3.5127e-01, -4.8990e-01,  3.2519e-01],\n",
      "         [-3.7172e-02,  5.0191e-01, -1.8478e-02]],\n",
      "\n",
      "        [[-1.7084e-01, -8.3784e-02, -2.0087e-01],\n",
      "         [ 9.8617e-03, -1.2267e+00, -4.2950e-02],\n",
      "         [ 1.4397e-01,  1.1190e+00,  2.7659e-01]],\n",
      "\n",
      "        [[-2.6499e-01, -4.3449e-01,  6.7668e-02],\n",
      "         [-5.1580e-01, -2.1833e-02,  5.2945e-01],\n",
      "         [-8.0942e-02,  3.9760e-01,  2.7203e-01]],\n",
      "\n",
      "        [[ 1.3608e-01,  3.8883e-01, -3.5727e-01],\n",
      "         [-5.1803e-01,  1.2412e+00, -4.4088e-01],\n",
      "         [ 1.4589e-01, -1.5833e+00,  8.2015e-01]],\n",
      "\n",
      "        [[ 1.9603e-01,  1.6668e-01,  2.6654e-01],\n",
      "         [ 1.4519e-01, -1.2166e+00,  9.5104e-02],\n",
      "         [ 2.1262e-01, -7.8351e-02,  2.9598e-01]],\n",
      "\n",
      "        [[ 1.6089e-01, -5.1036e-01, -3.6537e-01],\n",
      "         [-7.0281e-01, -6.9241e-01,  5.3943e-01],\n",
      "         [ 4.5494e-02,  1.0589e+00,  3.7490e-01]],\n",
      "\n",
      "        [[-5.2424e-01, -1.2965e+00, -2.8489e-01],\n",
      "         [-1.0299e-01,  2.0463e+00, -1.3098e-01],\n",
      "         [-1.3372e-02, -4.5546e-01, -2.0606e-01]],\n",
      "\n",
      "        [[-7.9991e-01, -1.4133e+00, -8.8396e-01],\n",
      "         [ 1.3111e+00,  2.4529e+00,  1.3740e+00],\n",
      "         [-7.4750e-01, -3.4549e-01, -7.3712e-01]],\n",
      "\n",
      "        [[-1.9345e-01,  1.0914e-01,  2.8378e-01],\n",
      "         [-9.8567e-01,  8.9205e-02,  9.2810e-01],\n",
      "         [-3.6424e-01,  4.5011e-02,  1.2476e-01]],\n",
      "\n",
      "        [[-2.4047e-01,  6.1384e-02, -2.1747e-01],\n",
      "         [-2.1629e-01,  1.7805e+00, -2.3013e-01],\n",
      "         [-1.6493e-01, -2.7298e-01, -2.4190e-01]],\n",
      "\n",
      "        [[-1.1273e-01, -4.2169e-02, -8.1015e-03],\n",
      "         [ 1.1594e-01,  8.5270e-01,  1.1172e-01],\n",
      "         [-1.5464e-01, -2.8554e-01, -2.7391e-01]],\n",
      "\n",
      "        [[ 3.5201e-01,  3.2103e-01, -4.4483e-01],\n",
      "         [-4.0053e-01,  7.1277e-01, -2.7009e-01],\n",
      "         [-4.3190e-01,  3.4629e-01,  4.4259e-01]],\n",
      "\n",
      "        [[-5.7044e-02, -4.1819e-01, -5.5081e-02],\n",
      "         [ 3.1009e-01,  8.4301e-01,  2.5647e-01],\n",
      "         [-1.3363e-01, -6.0512e-01, -9.5628e-02]],\n",
      "\n",
      "        [[ 9.1468e-02, -5.9830e-01,  9.9748e-02],\n",
      "         [-8.9108e-02, -8.5398e-01, -2.0209e-01],\n",
      "         [-6.2002e-02, -4.1957e-01, -6.6655e-02]],\n",
      "\n",
      "        [[-1.0035e-02,  2.1642e-02,  2.7605e-03],\n",
      "         [-2.7194e-02,  4.8859e-03,  2.1994e-02],\n",
      "         [-1.5407e-02,  1.3688e-02,  6.6427e-03]],\n",
      "\n",
      "        [[ 7.1285e-02, -4.9970e-01, -3.6211e-01],\n",
      "         [ 4.1981e-01, -1.4672e-01, -5.1978e-01],\n",
      "         [ 4.8737e-01,  4.7172e-01, -2.5716e-02]],\n",
      "\n",
      "        [[-3.0240e-01, -1.2112e-01, -2.7673e-01],\n",
      "         [-3.5649e-01,  1.3132e+00, -2.5996e-01],\n",
      "         [-2.1560e-01, -3.8403e-01, -2.6041e-01]],\n",
      "\n",
      "        [[-5.8619e-02,  1.0367e-01,  1.1169e-02],\n",
      "         [ 7.1085e-02,  3.5832e-01,  7.4865e-02],\n",
      "         [-3.6111e-02, -1.5862e-02, -6.3051e-02]],\n",
      "\n",
      "        [[ 2.9934e-02,  1.7269e-01,  9.0797e-02],\n",
      "         [ 1.2945e-01,  1.0930e-01,  2.0238e-01],\n",
      "         [ 4.9692e-02,  1.3236e-01,  7.2517e-03]],\n",
      "\n",
      "        [[-2.8856e-01, -6.8501e-01, -2.9095e-01],\n",
      "         [-9.7419e-02,  6.9927e-01, -2.5178e-01],\n",
      "         [ 6.6651e-02,  6.3389e-01, -1.7588e-03]],\n",
      "\n",
      "        [[-2.2808e-02, -1.1727e+00, -4.9424e-02],\n",
      "         [ 5.8598e-01,  2.7341e-01,  5.5588e-01],\n",
      "         [-9.0610e-02, -4.3568e-01, -1.1958e-01]],\n",
      "\n",
      "        [[ 5.1014e-05, -3.5223e-05,  1.2453e-04],\n",
      "         [ 1.2955e-03, -2.8911e-03,  6.8875e-04],\n",
      "         [ 1.5718e-04, -1.6520e-04,  1.2299e-04]],\n",
      "\n",
      "        [[ 6.5655e-02, -7.9971e-01,  5.9289e-01],\n",
      "         [-7.8709e-01, -3.4135e-01, -8.3823e-01],\n",
      "         [ 1.9140e-01, -6.9363e-01,  4.4056e-02]],\n",
      "\n",
      "        [[-3.3785e-01, -7.9013e-02, -1.0711e-01],\n",
      "         [-1.4783e-01, -1.1758e-01, -2.7254e-01],\n",
      "         [ 8.8773e-01, -1.0914e-03, -3.3211e-01]],\n",
      "\n",
      "        [[-3.2103e-01, -1.0639e+00, -2.6050e-01],\n",
      "         [ 3.7075e-02,  1.5231e+00, -3.4655e-02],\n",
      "         [ 5.6257e-02, -8.4345e-02,  3.5031e-02]],\n",
      "\n",
      "        [[-1.7908e-01, -1.3473e+00, -1.8199e-01],\n",
      "         [-1.3332e-01,  1.3517e+00,  1.6818e-01],\n",
      "         [ 1.6250e-01, -6.9759e-02,  1.2415e-02]],\n",
      "\n",
      "        [[ 2.1004e-01,  7.7537e-01,  3.7023e-01],\n",
      "         [-9.6675e-02, -7.9443e-01,  4.2731e-01],\n",
      "         [-3.3643e-01, -4.1502e-01, -2.4714e-02]],\n",
      "\n",
      "        [[ 2.2535e-01,  5.8772e-01,  5.6179e-01],\n",
      "         [ 6.5866e-01, -1.5064e+00,  5.0666e-01],\n",
      "         [ 2.9341e-01,  2.0688e-01,  2.2669e-01]],\n",
      "\n",
      "        [[ 1.8199e-01,  8.8234e-01,  4.2559e-01],\n",
      "         [ 5.7758e-02, -3.4632e-01, -7.1748e-02],\n",
      "         [-1.2886e-01, -9.0210e-01, -2.0212e-01]],\n",
      "\n",
      "        [[-1.2069e-01, -4.1472e-01, -6.3458e-02],\n",
      "         [-4.4440e-01,  1.4466e+00, -5.1462e-01],\n",
      "         [-3.7421e-02, -4.7728e-01, -5.4654e-02]],\n",
      "\n",
      "        [[ 2.1721e-01,  9.9252e-01,  2.8286e-01],\n",
      "         [-5.1303e-02, -9.0317e-01, -2.0939e-01],\n",
      "         [-1.2457e-01, -1.2513e-01, -1.0391e-01]],\n",
      "\n",
      "        [[ 6.9965e-02,  1.7496e-01,  1.4012e-01],\n",
      "         [ 1.7913e-01,  4.8294e-01,  2.0265e-01],\n",
      "         [ 5.2654e-02,  2.2354e-01,  4.8531e-02]],\n",
      "\n",
      "        [[ 5.1467e-01,  1.2005e+00,  5.0774e-02],\n",
      "         [ 5.7158e-02, -1.3575e+00, -4.3984e-02],\n",
      "         [-1.7144e-01,  6.9885e-02, -1.7559e-01]],\n",
      "\n",
      "        [[ 1.6754e-01, -1.9282e-01,  2.0135e-01],\n",
      "         [ 3.3014e-01, -1.4738e+00,  5.0878e-01],\n",
      "         [ 3.2201e-01, -6.5408e-02,  4.2149e-01]],\n",
      "\n",
      "        [[-1.0234e-01, -5.2229e-01, -1.0409e-01],\n",
      "         [ 6.2170e-01, -6.7379e-01,  6.2340e-01],\n",
      "         [-9.8784e-02, -5.5969e-02, -4.4494e-02]],\n",
      "\n",
      "        [[-3.8408e-01, -2.9746e-01, -3.8179e-01],\n",
      "         [-3.8062e-01, -5.2719e-01, -3.6883e-01],\n",
      "         [ 4.7336e-01, -5.2126e-01,  4.2008e-01]],\n",
      "\n",
      "        [[ 1.5350e-02,  1.8313e-01,  7.3209e-02],\n",
      "         [ 1.7086e-01,  4.1292e-01,  2.1216e-01],\n",
      "         [ 1.0080e-02,  8.2057e-02,  5.8812e-02]],\n",
      "\n",
      "        [[-1.6168e-01, -8.2757e-02,  2.8758e-01],\n",
      "         [-3.6447e-01, -3.3113e-01,  7.5114e-01],\n",
      "         [-7.0141e-02, -2.5010e-01,  1.5440e-01]],\n",
      "\n",
      "        [[-1.7819e-01,  9.2964e-02,  1.1499e-01],\n",
      "         [-3.5292e-01, -9.4980e-01,  1.2536e+00],\n",
      "         [-1.3302e-01, -1.3379e-01,  3.1673e-01]],\n",
      "\n",
      "        [[-5.2838e-01, -3.6642e-01, -4.6387e-01],\n",
      "         [ 1.4286e-01,  1.1452e-01,  2.4414e-02],\n",
      "         [-1.4115e-01, -7.5689e-01, -7.5518e-02]],\n",
      "\n",
      "        [[-2.9983e-01, -1.0085e-01, -2.2206e-01],\n",
      "         [-2.5963e-01,  1.5361e+00, -7.2448e-02],\n",
      "         [-4.0051e-01, -1.7355e-01, -3.4693e-01]],\n",
      "\n",
      "        [[-4.0943e-02,  2.8256e-01, -2.0354e-02],\n",
      "         [ 1.5966e-01,  5.6093e-01,  1.8152e-01],\n",
      "         [-2.3402e-02,  2.8679e-01, -5.8350e-02]],\n",
      "\n",
      "        [[-7.9818e-02, -7.1984e-02, -7.3783e-02],\n",
      "         [-9.9141e-02, -9.6744e-02, -1.1131e-01],\n",
      "         [-4.8951e-02, -1.1408e-01, -8.3455e-02]],\n",
      "\n",
      "        [[-9.0948e-01,  3.0644e-01, -7.1970e-01],\n",
      "         [-7.4098e-01,  3.2893e+00, -1.9594e-01],\n",
      "         [-7.5213e-01,  5.9045e-01, -2.7183e-01]],\n",
      "\n",
      "        [[ 3.9274e-01,  6.2211e-02, -7.1192e-01],\n",
      "         [-2.1679e-02,  2.8363e-01, -1.4407e-01],\n",
      "         [-4.7074e-01, -1.9475e-01,  3.3799e-01]],\n",
      "\n",
      "        [[ 2.1015e-01,  1.6832e-02, -8.6760e-02],\n",
      "         [ 2.5572e-02, -4.6181e-01, -7.3053e-02],\n",
      "         [-2.6710e-02, -1.4143e-01,  3.1996e-01]],\n",
      "\n",
      "        [[-2.2592e-01,  2.9518e-01,  3.2339e-01],\n",
      "         [-3.5572e-01,  4.2857e-01,  4.4716e-01],\n",
      "         [-5.4249e-02, -3.9402e-01, -4.4152e-02]],\n",
      "\n",
      "        [[-1.2525e-01, -2.2191e-02, -1.1578e-01],\n",
      "         [-9.7026e-02,  1.2904e+00, -5.3054e-02],\n",
      "         [-2.3118e-01,  1.5201e-02, -2.6444e-01]],\n",
      "\n",
      "        [[ 5.9740e-01,  2.3199e-01,  3.0029e-01],\n",
      "         [ 8.8713e-01, -2.2097e+00,  7.4988e-01],\n",
      "         [ 3.7943e-01,  1.0864e+00,  5.0879e-01]],\n",
      "\n",
      "        [[-4.6809e-02, -1.2036e-02,  2.2127e-01],\n",
      "         [-1.2842e-01, -4.0438e-01, -7.0585e-03],\n",
      "         [ 2.7917e-01, -1.4284e-01, -4.4970e-02]],\n",
      "\n",
      "        [[-9.9548e-02, -4.9545e-01,  7.9356e-03],\n",
      "         [-3.2942e-01, -9.4650e-01,  1.2883e+00],\n",
      "         [-1.6432e-01,  1.8039e-01,  2.9617e-01]],\n",
      "\n",
      "        [[-1.5861e-01, -6.2745e-01,  4.4139e-02],\n",
      "         [-4.9120e-01, -1.9121e-01,  5.6333e-01],\n",
      "         [-8.1395e-02,  5.4065e-01,  2.8426e-01]],\n",
      "\n",
      "        [[ 1.0114e-01,  4.5225e-02,  1.3073e-01],\n",
      "         [-6.9287e-02, -1.1333e+00, -1.1934e-01],\n",
      "         [-1.7311e-02, -1.4030e-01, -4.3366e-02]],\n",
      "\n",
      "        [[ 3.6049e-03,  6.5154e-02,  4.1334e-03],\n",
      "         [ 5.6122e-02,  5.3885e-01,  5.8761e-02],\n",
      "         [ 2.5824e-02,  6.3869e-02,  5.4363e-02]],\n",
      "\n",
      "        [[-2.7861e-02, -9.9128e-02,  8.5841e-02],\n",
      "         [-8.4325e-01,  9.8628e-01, -2.6460e-01],\n",
      "         [-2.1722e-01,  2.9190e-01, -1.1528e-02]],\n",
      "\n",
      "        [[ 3.8650e-03, -7.0135e-01, -2.5960e-01],\n",
      "         [ 4.7681e-01, -4.4211e-02, -5.7955e-01],\n",
      "         [ 3.0345e-01,  7.2222e-01,  3.7263e-02]],\n",
      "\n",
      "        [[ 1.3218e-01,  1.1253e-01,  6.5902e-02],\n",
      "         [-1.0735e+00,  8.3313e-01, -9.8176e-01],\n",
      "         [-1.7020e-01,  7.2238e-01, -1.8184e-01]],\n",
      "\n",
      "        [[ 3.7833e-03, -2.9334e-01,  1.4413e-01],\n",
      "         [ 7.5745e-01, -1.1835e+00,  8.1248e-01],\n",
      "         [ 9.5485e-02, -3.6377e-01, -4.3927e-02]],\n",
      "\n",
      "        [[-9.4734e-02, -5.6948e-01, -3.3501e-01],\n",
      "         [-5.8930e-02, -3.0624e-01, -2.8130e-01],\n",
      "         [ 2.3497e-01,  1.0090e+00,  2.9289e-01]],\n",
      "\n",
      "        [[ 7.3008e-02,  9.4027e-01, -1.0514e-01],\n",
      "         [ 1.7673e-01,  1.1322e+00, -8.1000e-01],\n",
      "         [-4.0915e-01, -7.9902e-01, -5.9111e-01]],\n",
      "\n",
      "        [[ 1.7477e-01,  2.0263e-01,  1.5366e-01],\n",
      "         [ 3.3279e-01, -1.1815e+00,  3.6019e-01],\n",
      "         [ 1.5966e-01,  2.5145e-01,  1.7803e-01]],\n",
      "\n",
      "        [[ 4.5718e-02,  2.4334e-01, -9.2681e-02],\n",
      "         [ 1.0865e+00, -1.2603e-01, -9.7116e-01],\n",
      "         [ 4.2411e-01, -2.2329e-01, -2.6398e-01]],\n",
      "\n",
      "        [[ 1.5958e-02,  3.0942e-02,  2.7005e-02],\n",
      "         [ 1.6502e-02,  5.3572e-01,  3.2247e-02],\n",
      "         [ 1.9171e-02, -6.5700e-02, -3.5684e-03]]]) conv_bias: tensor([ 1.0535e+00,  1.3110e-03,  1.5092e-01,  8.0440e-01,  2.2597e+00,\n",
      "         6.4987e-01,  1.8382e+00,  1.0007e+00,  1.0200e+00, -4.7659e-03,\n",
      "         9.5037e-02, -7.0999e-03, -8.8628e-01,  1.2149e-02,  2.2204e+00,\n",
      "        -7.8792e-01, -2.6402e-02, -1.2830e-02, -1.9844e-02, -1.3460e-01,\n",
      "         2.6172e-01, -2.4126e-02, -2.0412e+00,  2.7763e+00, -6.1945e-01,\n",
      "        -7.8019e-01,  1.9993e+00,  9.8040e-01,  5.0816e-02, -1.4029e+00,\n",
      "         6.3786e-02, -5.6096e-03,  4.5979e-01, -7.7177e-01,  1.0260e-01,\n",
      "        -1.0811e-01,  3.8961e-02,  1.5184e+00,  8.9201e-02,  5.7462e-01,\n",
      "        -1.7468e+00, -3.5699e-02, -3.2287e-01, -5.8720e-01, -2.3660e+00,\n",
      "        -5.0110e-03,  2.7254e+00, -1.0547e-02, -3.7222e-02,  1.9442e+00,\n",
      "        -2.4619e-01, -2.7974e-01, -4.3609e-01,  1.6598e+00,  1.1525e-03,\n",
      "         2.0270e+00, -6.6364e-02,  1.5046e-01,  1.4707e-01, -5.4281e-02,\n",
      "         2.6432e-02,  1.5233e-01,  4.5362e+00,  3.4648e-02, -7.2740e-01,\n",
      "        -4.4713e-01, -6.5154e-02,  8.9124e-01,  7.5987e-01, -1.0799e+00,\n",
      "        -1.9051e-03, -7.4195e-02,  1.9346e+00, -1.7444e-01, -1.2915e+00,\n",
      "         2.1908e+00, -2.7048e+00,  1.8913e+00,  5.9696e-01, -9.3740e-02,\n",
      "         1.4813e+00,  1.0339e+00,  6.9822e-01,  2.3367e-01,  2.7588e-02,\n",
      "         2.5208e+00, -8.6612e-01,  1.4087e-01, -4.3718e-03,  3.8327e+00,\n",
      "         1.0364e-01,  1.1481e-01,  8.5430e-01,  1.4039e+00, -2.0206e-01,\n",
      "        -1.9394e-01])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "q_weight: tensor([ -42,  -67,  -24,   -8,  -87,  -12,    4,   12,    1,   80,   13,  -51,\n",
      "          67, -127,  -17,  -49,  -22,   81,    2,   42,    4,  -13,  -63,   -6,\n",
      "           4,   25,    1,  -49,  -74,  -79,  -21,    3,   -3,  -52, -109,  -59,\n",
      "          -6,  -29,  -32,  -16,   78,  -10,  -19,  -19,  -24,  -49,  -10,  -60,\n",
      "         -72,  -71,  -73,  -53,  -38,  -40, -101,    7,   51,  -16,   61,   -1,\n",
      "          49,  -18,  -55,    6, -104,    4,  -34,   31,  -13,  -12,   17,  -14,\n",
      "          58,   22,  -57,   19,   14,   35,   -8,   29,   21,  -10,  -55,  -12,\n",
      "          -7,  -10,  -10,   16,   72,   15,  -28,  -59,   14,   52,  -42,  -78,\n",
      "          23,   85,   27,  -18,   -5,   22,  -71,    1,   71,  -29,   -2,   31,\n",
      "         -18,   37,  -21,  -24,   64,  -25,  -18,   23,   -9,  -11,   -6,   23,\n",
      "         -12,  -55,   69,   -5,  -16,    6,  -16,  -41,   -6,  -13,   60,  -10,\n",
      "         -13,  -21,  -14,    3,    8,    1,    0,   71,    7,   -5,   76,   -6,\n",
      "         -15,   13,   16,  -58,   -9,   66,  -30,  -19,   34,   -3,    7,   -3,\n",
      "         -32,   57,  -30,   -4,   20,   -3,  -19,  -67,  -15,  -11,    6,   16,\n",
      "          10,   62,   17,    9,  -53,    9,   -2,   18,   -8,   -3,   37,   -2,\n",
      "           4,  -22,    5,   34,  -55,   39,    5,  -28,    5,   17,   73,   16,\n",
      "         -23,    8,   24,  -23,  -82,  -10,  -36,   42,   30,   47,    4,   47,\n",
      "          15,   43,   -3,  -24,  -22,   -2,  -20,   80,  -15,   -4,  -27,  -17,\n",
      "         -13,  -26,  -16,  -13,   74,  -17,   -9,   -2,  -12,  -12,  -17,   16,\n",
      "         -16,   54,  -16,   12,   -6,   -9,  -28,  -60,  -30,  -52,   83,  -59,\n",
      "         -30,  -15,  -21,  -22,  -48,  -24,  -37,   92,  -35,  -32,    3,  -39,\n",
      "          19,   -2,   -8,   71,  -60,  -12,   10,  -20,   -4,  -56,   44,   32,\n",
      "          -1,   48,   46,   -5,   10,  -59,    7,  -81,  -14,   73,    0,  -72,\n",
      "          27,   62,  -11,  -36,  -11,   30,  -81,   -4,   91,  -32,    6,   36,\n",
      "          36,  -43,   23, -111,  -58,  -95,  -54,  -35,  -41,   -1,   21,   -3,\n",
      "          25,  -35,   23,   -3,   36,   -1,  -10,   -5,  -12,    1,  -71,   -2,\n",
      "           8,   65,   16,  -35,  -57,    9,  -67,   -3,   69,  -11,   52,   36,\n",
      "           5,   14,  -13,  -18,   44,  -16,    5,  -56,   29,   19,   16,   26,\n",
      "          14, -118,    9,   21,   -8,   29,   15,  -48,  -34,  -66,  -65,   51,\n",
      "           4,  100,   35,  -22,  -54,  -12,   -4,   85,   -5,   -1,  -19,   -9,\n",
      "         -22,  -39,  -24,   36,   67,   38,  -21,  -10,  -20,  -18,   10,   27,\n",
      "         -92,    8,   87,  -34,    4,   12,   -9,    2,   -9,   -8,   70,   -9,\n",
      "          -6,  -11,  -10,   -7,   -3,    0,    7,   51,    7,   -9,  -17,  -16,\n",
      "          22,   20,  -27,  -25,   44,  -17,  -27,   21,   27,   -4,  -28,   -4,\n",
      "          21,   57,   17,   -9,  -41,   -7,    4,  -25,    4,   -4,  -35,   -8,\n",
      "          -3,  -17,   -3,  -47,  101,   13, -127,   23,  103,  -72,   64,   31,\n",
      "          10,  -70,  -51,   59,  -21,  -73,   69,   66,   -4,  -16,   -6,  -15,\n",
      "         -19,   70,  -14,  -11,  -20,  -14,  -11,   19,    2,   13,   65,   13,\n",
      "          -7,   -3,  -11,   10,   57,   30,   43,   36,   67,   16,   44,    2,\n",
      "         -33,  -77,  -33,  -11,   79,  -28,    8,   72,    0,   -2,  -85,   -4,\n",
      "          42,   20,   40,   -7,  -31,   -9,    2,   -2,    5,   57, -127,   30,\n",
      "           7,   -7,    5,    5,  -65,   48,  -64,  -28,  -68,   16,  -56,    4,\n",
      "         -40,   -9,  -13,  -18,  -14,  -32,  106,    0,  -40,  -14,  -46,  -11,\n",
      "           2,   66,   -1,    2,   -4,    2,   -7,  -51,   -7,   -5,   51,    6,\n",
      "           6,   -3,    0,   25,   93,   44,  -12,  -95,   51,  -40,  -50,   -3,\n",
      "          14,   37,   36,   42,  -96,   32,   19,   13,   14,   12,   58,   28,\n",
      "           4,  -23,   -5,   -8,  -59,  -13,   -5,  -17,   -3,  -18,   58,  -21,\n",
      "          -1,  -19,   -2,   12,   55,   16,   -3,  -50,  -12,   -7,   -7,   -6,\n",
      "          11,   26,   21,   27,   73,   31,    8,   34,    7,   30,   70,    3,\n",
      "           3,  -79,   -3,  -10,    4,  -10,   13,  -15,   16,   26, -116,   40,\n",
      "          25,   -5,   33,   -7,  -36,   -7,   42,  -46,   43,   -7,   -4,   -3,\n",
      "         -64,  -50,  -64,  -64,  -88,  -62,   79,  -87,   70,    2,   25,   10,\n",
      "          23,   57,   29,    1,   11,    8,  -16,   -8,   28,  -36,  -32,   73,\n",
      "          -7,  -24,   15,   -9,    5,    6,  -18,  -47,   62,   -7,   -7,   16,\n",
      "         -60,  -41,  -52,   16,   13,    3,  -16,  -85,   -9,  -16,   -5,  -12,\n",
      "         -14,   80,   -4,  -21,   -9,  -18,   -6,   43,   -3,   24,   86,   28,\n",
      "          -4,   44,   -9,  -69,  -62,  -63,  -85,  -83,  -96,  -42,  -98,  -72,\n",
      "         -20,    7,  -16,  -16,   71,   -4,  -16,   13,   -6,   44,    7,  -79,\n",
      "          -2,   31,  -16,  -52,  -22,   38,   34,    3,  -14,    4,  -74,  -12,\n",
      "          -4,  -23,   51,  -41,   53,   58,  -64,   77,   81,  -10,  -71,   -8,\n",
      "          -8,   -1,   -8,   -6,   86,   -4,  -15,    1,  -18,   25,   10,   13,\n",
      "          37,  -93,   32,   16,   46,   21,  -12,   -3,   58,  -33, -105,   -2,\n",
      "          73,  -37,  -12,   -7,  -32,    1,  -22,  -62,   84,  -11,   12,   19,\n",
      "         -21,  -81,    6,  -64,  -25,   73,  -11,   70,   37,    3,    2,    5,\n",
      "          -2,  -39,   -4,   -1,   -5,   -1,    0,    9,    1,    8,   73,    8,\n",
      "           4,    9,    7,   -2,   -7,    6,  -63,   74,  -20,  -16,   22,   -1,\n",
      "           0,  -86,  -32,   59,   -5,  -71,   37,   89,    5,   13,   11,    6,\n",
      "        -102,   79,  -93,  -16,   68,  -17,    0,  -15,    7,   39,  -61,   42,\n",
      "           5,  -19,   -2,   -7,  -43,  -26,   -4,  -23,  -21,   18,   77,   22,\n",
      "           5,   68,   -8,   13,   82,  -58,  -30,  -58,  -43,   16,   19,   14,\n",
      "          31, -109,   33,   15,   23,   16,    3,   18,   -7,   82,  -10,  -74,\n",
      "          32,  -17,  -20,    3,    6,    5,    3,   96,    6,    3,  -12,   -1],\n",
      "       dtype=torch.int32) q_bias: tensor([ 4511,  2199,    76,  3565,  1357,  1682,  3051,   817,  1599,    -3,\n",
      "          109,    -6,  -455,     9,  1530, -1504,   -26,    -9,   -17,   -73,\n",
      "          172,   -27, -2970,  1391,  -580,  -342,  2379,   831,    42, -1941,\n",
      "           87,    -7,  2353,  -672,    73,  -173,    17,  1806,   103,   293,\n",
      "         -590,   -41,  -156,  -432, -1788,    -4,  1372,  -605,   -64,  1270,\n",
      "         -545, -1140,  -604,  1472,   622,  2017,   -97,    80,    68,   -80,\n",
      "           21,   123,  2223,    23, -1346,  -319,   -63,   748,  1558, -1818,\n",
      "           -2,   -45,  2680,  -112, -2429, 23139,  -717,  2578,  1173,  -208,\n",
      "         1213,   535,  2230,   188,    44,  1067, -1448,   130,    -7,  4456,\n",
      "           66,   107,   757,  1586,  -188,  -427], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0003) tensor(0.0216)   bias tensor(-0.0001) tensor(0.0009)\n",
      "features.5.conv.6.weight features.5.conv.8\n",
      "torch.Size([16, 96, 1, 1]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.0649]) torch.Size([1]) \n",
      "wscale= tensor([0.0099, 0.0044, 0.0073, 0.0028, 0.0037, 0.0037, 0.0037, 0.0034, 0.0059,\n",
      "        0.0065, 0.0053, 0.0059, 0.0066, 0.0048, 0.0042, 0.0035]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.0798]) torch.Size([1])\n",
      "###: M= tensor([0.0080, 0.0036, 0.0060, 0.0023, 0.0030, 0.0030, 0.0030, 0.0027, 0.0048,\n",
      "        0.0053, 0.0043, 0.0048, 0.0054, 0.0039, 0.0034, 0.0028])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "conv_weight: tensor([[-3.9816e-01, -7.4674e-04, -3.2768e-02,  ..., -3.4432e-01,\n",
      "          9.6132e-02,  3.1566e-02],\n",
      "        [ 3.8438e-02,  2.4714e-04, -2.8019e-02,  ..., -3.0614e-02,\n",
      "          1.6380e-01, -4.0163e-02],\n",
      "        [-1.6707e-01,  9.5584e-05,  1.5534e-01,  ...,  2.5972e-02,\n",
      "         -6.2129e-03, -3.4818e-01],\n",
      "        ...,\n",
      "        [ 3.3949e-01,  7.8758e-04, -6.2768e-02,  ...,  4.7104e-03,\n",
      "         -1.6643e-01,  1.8074e-01],\n",
      "        [-1.3978e-01, -1.6764e-04,  1.0326e-01,  ..., -1.9054e-01,\n",
      "         -1.9632e-01, -9.2209e-02],\n",
      "        [-1.4901e-01,  2.7604e-04,  1.8327e-02,  ..., -5.0597e-02,\n",
      "         -1.9312e-02, -1.6851e-01]]) conv_bias: tensor([ 5.7184,  0.6781,  0.2668,  0.1782,  0.4345, -2.8473, -0.9731,  0.3751,\n",
      "         1.3749,  4.3067,  5.3195, -2.4926,  1.9649,  2.9373,  0.6198, -1.8536])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "q_weight: tensor([-40,   0,  -3,  ..., -14,  -6, -48], dtype=torch.int32) q_bias: tensor([  8916,   2361,    560,    981,   1796, -11766,  -4015,   1724,   3597,\n",
      "         10209,  15586,  -6469,   4571,   9366,   2294,  -8156],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(2.5236e-05) tensor(0.0047)   bias tensor(1.8112e-05) tensor(0.0003)\n",
      "features.6.conv.0.weight features.6.conv.2\n",
      "torch.Size([96, 16, 1, 1]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.0798]) torch.Size([1]) \n",
      "wscale= tensor([0.0023, 0.0020, 0.0012, 0.0025, 0.0032, 0.0019, 0.0040, 0.0026, 0.0068,\n",
      "        0.0094, 0.0021, 0.0024, 0.0015, 0.0041, 0.0023, 0.0020, 0.0020, 0.0028,\n",
      "        0.0016, 0.0020, 0.0022, 0.0032, 0.0014, 0.0018, 0.0018, 0.0021, 0.0016,\n",
      "        0.0024, 0.0013, 0.0020, 0.0029, 0.0017, 0.0014, 0.0013, 0.0020, 0.0019,\n",
      "        0.0016, 0.0017, 0.0015, 0.0016, 0.0014, 0.0025, 0.0018, 0.0017, 0.0022,\n",
      "        0.0035, 0.0018, 0.0016, 0.0010, 0.0015, 0.0032, 0.0016, 0.0023, 0.0037,\n",
      "        0.0014, 0.0029, 0.0017, 0.0018, 0.0030, 0.0012, 0.0028, 0.0015, 0.0011,\n",
      "        0.0020, 0.0012, 0.0014, 0.0028, 0.0032, 0.0050, 0.0013, 0.0024, 0.0014,\n",
      "        0.0014, 0.0017, 0.0021, 0.0015, 0.0019, 0.0023, 0.0049, 0.0020, 0.0027,\n",
      "        0.0021, 0.0012, 0.0017, 0.0013, 0.0017, 0.0043, 0.0023, 0.0036, 0.0021,\n",
      "        0.0020, 0.0012, 0.0012, 0.0054, 0.0055, 0.0014]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.0928]) torch.Size([1])\n",
      "###: M= tensor([0.0020, 0.0017, 0.0011, 0.0021, 0.0027, 0.0017, 0.0034, 0.0022, 0.0058,\n",
      "        0.0081, 0.0018, 0.0021, 0.0013, 0.0036, 0.0020, 0.0018, 0.0017, 0.0024,\n",
      "        0.0014, 0.0017, 0.0019, 0.0027, 0.0012, 0.0015, 0.0016, 0.0018, 0.0014,\n",
      "        0.0021, 0.0011, 0.0018, 0.0025, 0.0015, 0.0012, 0.0011, 0.0017, 0.0016,\n",
      "        0.0014, 0.0015, 0.0013, 0.0014, 0.0012, 0.0021, 0.0016, 0.0015, 0.0019,\n",
      "        0.0031, 0.0015, 0.0014, 0.0009, 0.0013, 0.0027, 0.0014, 0.0019, 0.0032,\n",
      "        0.0012, 0.0025, 0.0014, 0.0015, 0.0026, 0.0011, 0.0024, 0.0013, 0.0010,\n",
      "        0.0017, 0.0010, 0.0012, 0.0024, 0.0028, 0.0043, 0.0011, 0.0020, 0.0012,\n",
      "        0.0012, 0.0014, 0.0018, 0.0013, 0.0016, 0.0019, 0.0042, 0.0017, 0.0023,\n",
      "        0.0018, 0.0010, 0.0015, 0.0011, 0.0014, 0.0037, 0.0020, 0.0031, 0.0018,\n",
      "        0.0017, 0.0011, 0.0010, 0.0046, 0.0048, 0.0012])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "conv_weight: tensor([[ 0.1201,  0.0250,  0.0743,  ...,  0.2463,  0.0943, -0.0098],\n",
      "        [-0.2346, -0.0020,  0.0445,  ..., -0.1020, -0.0051,  0.0590],\n",
      "        [-0.0412, -0.0445, -0.0325,  ...,  0.0746, -0.1488,  0.0643],\n",
      "        ...,\n",
      "        [ 0.1480, -0.2244, -0.0448,  ...,  0.1652, -0.2743,  0.6767],\n",
      "        [ 0.2119,  0.5361,  0.2769,  ..., -0.1621,  0.5039, -0.3770],\n",
      "        [-0.0464, -0.0066,  0.0250,  ...,  0.0270, -0.0942, -0.1196]]) conv_bias: tensor([ 0.6428,  0.9511,  0.8595,  0.7474,  0.1331,  1.7428, -0.1846, -0.1845,\n",
      "         0.1564, -0.1301, -0.4866,  0.8936,  1.0464,  0.4620,  0.5336,  0.7308,\n",
      "         0.6262,  0.6215,  2.0001,  1.0722,  1.0056, -0.2826,  1.5838,  1.0145,\n",
      "         0.8461, -0.4156,  0.6301, -0.2427,  0.8359, -0.5478,  1.6387, -0.6731,\n",
      "         0.5835,  0.7414,  0.4406,  1.5920,  0.9181,  1.6491,  0.6440,  0.9261,\n",
      "         1.3576,  0.9786, -0.5133, -0.3757,  1.1837,  0.1256,  0.6557,  0.9162,\n",
      "         1.4710,  0.9006, -0.5546, -0.4071,  0.5939, -0.2195,  0.9622,  0.9792,\n",
      "        -0.6470,  0.9001,  0.8879,  1.1274,  0.1612,  0.8755,  0.7537,  0.9852,\n",
      "         2.2542,  2.1243,  0.7161,  0.5834,  0.0751,  0.5446,  1.0923,  1.6055,\n",
      "         0.9019,  1.1499,  0.8059,  1.1494, -0.3033, -0.5135,  0.3768, -0.4937,\n",
      "        -0.5440,  0.7257,  0.7497,  1.8161,  1.6994,  1.3658,  0.6926,  1.3650,\n",
      "        -0.2671,  1.5098,  1.1304,  0.6232,  0.9045, -0.0730, -0.0388,  1.0541])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "q_weight: tensor([ 53,  11,  33,  ...,  19, -65, -83], dtype=torch.int32) q_bias: tensor([ 3533,  6039,  8727,  3786,   524, 11208,  -585,  -891,   288,  -173,\n",
      "        -2877,  4682,  8858,  1401,  2880,  4494,  3963,  2785, 15272,  6709,\n",
      "         5645, -1120, 14479,  7181,  5835, -2506,  4852, -1266,  8071, -3371,\n",
      "         7037, -4988,  5305,  7046,  2755, 10523,  7014, 12107,  5361,  7049,\n",
      "        11814,  4908, -3525, -2692,  6700,   444,  4602,  7061, 18004,  7691,\n",
      "        -2205, -3143,  3294,  -743,  8591,  4275, -4836,  6410,  3668, 11542,\n",
      "          733,  7107,  8334,  6139, 23924, 18854,  3231,  2268,   186,  5110,\n",
      "         5749, 13875,  7871,  8584,  4838,  9477, -2004, -2845,   968, -3097,\n",
      "        -2521,  4308,  8131, 13409, 16487, 10235,  2037,  7421,  -929,  9009,\n",
      "         7125,  6298,  9737,  -171,   -88,  9155], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(2.0441e-05) tensor(0.0046)   bias tensor(-3.8558e-06) tensor(0.0002)\n",
      "features.6.conv.3.weight features.6.conv.5\n",
      "torch.Size([96, 1, 3, 3]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.0897]) torch.Size([1]) \n",
      "wscale= tensor([0.0115, 0.0062, 0.0141, 0.0132, 0.0072, 0.0225, 0.0038, 0.0088, 0.0034,\n",
      "        0.0046, 0.0184, 0.0098, 0.0191, 0.0101, 0.0101, 0.0120, 0.0057, 0.0058,\n",
      "        0.0195, 0.0099, 0.0139, 0.0071, 0.0248, 0.0346, 0.0125, 0.0170, 0.0091,\n",
      "        0.0040, 0.0113, 0.0519, 0.0205, 0.0444, 0.0099, 0.0110, 0.0038, 0.0103,\n",
      "        0.0086, 0.0143, 0.0160, 0.0141, 0.0142, 0.0133, 0.0342, 0.0259, 0.0105,\n",
      "        0.0070, 0.0116, 0.0097, 0.0164, 0.0126, 0.0150, 0.0109, 0.0062, 0.0063,\n",
      "        0.0113, 0.0109, 0.0240, 0.0134, 0.0163, 0.0157, 0.0090, 0.0108, 0.0093,\n",
      "        0.0213, 0.0185, 0.0349, 0.0128, 0.0101, 0.0043, 0.0131, 0.0132, 0.0152,\n",
      "        0.0112, 0.0157, 0.0180, 0.0168, 0.0081, 0.0212, 0.0075, 0.0109, 0.0221,\n",
      "        0.0092, 0.0121, 0.0209, 0.0316, 0.0224, 0.0183, 0.0112, 0.0070, 0.0348,\n",
      "        0.0144, 0.0115, 0.0122, 0.0106, 0.0051, 0.0123]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.0592]) torch.Size([1])\n",
      "###: M= tensor([0.0175, 0.0094, 0.0213, 0.0201, 0.0110, 0.0342, 0.0058, 0.0133, 0.0052,\n",
      "        0.0070, 0.0278, 0.0149, 0.0290, 0.0154, 0.0153, 0.0182, 0.0087, 0.0088,\n",
      "        0.0296, 0.0150, 0.0211, 0.0108, 0.0376, 0.0525, 0.0189, 0.0258, 0.0139,\n",
      "        0.0061, 0.0171, 0.0787, 0.0311, 0.0673, 0.0150, 0.0167, 0.0057, 0.0156,\n",
      "        0.0130, 0.0217, 0.0242, 0.0214, 0.0215, 0.0202, 0.0518, 0.0393, 0.0159,\n",
      "        0.0106, 0.0176, 0.0147, 0.0249, 0.0192, 0.0228, 0.0165, 0.0093, 0.0096,\n",
      "        0.0172, 0.0165, 0.0364, 0.0203, 0.0248, 0.0238, 0.0136, 0.0163, 0.0140,\n",
      "        0.0323, 0.0281, 0.0529, 0.0194, 0.0153, 0.0065, 0.0198, 0.0200, 0.0231,\n",
      "        0.0169, 0.0239, 0.0273, 0.0255, 0.0123, 0.0321, 0.0113, 0.0165, 0.0335,\n",
      "        0.0139, 0.0183, 0.0317, 0.0480, 0.0340, 0.0277, 0.0170, 0.0106, 0.0528,\n",
      "        0.0218, 0.0174, 0.0185, 0.0160, 0.0077, 0.0187])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "conv_weight: tensor([[[-3.8415e-02, -2.4662e-01,  6.4412e-02],\n",
      "         [ 2.1753e-01, -8.1641e-01,  2.7534e-01],\n",
      "         [ 2.3418e-01,  8.9839e-01, -1.4091e-01]],\n",
      "\n",
      "        [[-2.0277e-01, -3.1495e-01, -1.8968e-01],\n",
      "         [-3.9038e-01,  4.1618e-01, -3.6512e-01],\n",
      "         [-2.6900e-01, -4.4157e-01, -3.2733e-01]],\n",
      "\n",
      "        [[-6.4269e-01,  6.1221e-01,  1.8786e-01],\n",
      "         [-6.1072e-01, -1.1990e+00, -1.1888e-01],\n",
      "         [ 4.2800e-01,  7.0089e-01, -1.0865e+00]],\n",
      "\n",
      "        [[-2.3686e-01,  4.0422e-01,  7.7578e-01],\n",
      "         [-4.6494e-01, -2.1678e-01,  3.9409e-01],\n",
      "         [-1.6205e-01, -2.7493e-01, -2.8106e-01]],\n",
      "\n",
      "        [[-1.6909e-01,  5.5428e-01, -7.0064e-02],\n",
      "         [-3.5685e-01,  2.4210e-01, -3.2812e-01],\n",
      "         [-1.8168e-02,  1.5073e-01, -1.6327e-02]],\n",
      "\n",
      "        [[-4.8076e-01,  2.1052e-01,  3.1823e-01],\n",
      "         [ 2.1591e-01,  8.2049e-01,  2.5027e-01],\n",
      "         [ 2.3415e-01,  2.2493e-01, -5.6485e-01]],\n",
      "\n",
      "        [[-1.3485e-01, -3.8736e-01, -1.3497e-01],\n",
      "         [-2.4342e-01,  1.7082e-01, -3.1448e-01],\n",
      "         [-1.0013e-01, -2.8667e-01, -2.1582e-01]],\n",
      "\n",
      "        [[-1.1245e-01, -8.7628e-01, -9.4710e-02],\n",
      "         [ 6.3554e-01,  2.7142e-01,  7.2592e-01],\n",
      "         [-2.5205e-02, -9.1391e-02, -8.8563e-02]],\n",
      "\n",
      "        [[ 1.8137e-01,  4.5625e-02, -2.4343e-01],\n",
      "         [ 4.6423e-02,  6.7062e-03, -1.0928e-01],\n",
      "         [-2.2209e-01, -3.1620e-02,  1.8914e-01]],\n",
      "\n",
      "        [[-2.8955e-02,  4.6495e-02, -1.1579e-02],\n",
      "         [-3.8030e-02,  4.1417e-01, -6.6346e-02],\n",
      "         [-3.1598e-02,  1.0598e-01, -2.1314e-02]],\n",
      "\n",
      "        [[-1.5433e-01,  3.3326e-01, -2.8874e-02],\n",
      "         [ 7.8858e-02,  1.6427e+00,  2.6144e-01],\n",
      "         [-7.7376e-02, -3.9586e-01, -1.4214e-01]],\n",
      "\n",
      "        [[-3.9290e-03, -4.2458e-01, -9.4679e-02],\n",
      "         [-2.1015e-01, -4.5947e-01,  4.7185e-01],\n",
      "         [-1.5520e-01,  1.9396e-01,  6.4120e-01]],\n",
      "\n",
      "        [[ 3.6144e-02,  1.4509e+00,  4.4774e-01],\n",
      "         [-1.6689e-01, -1.1272e+00, -5.0499e-01],\n",
      "         [-8.2577e-03,  3.6797e-01,  3.0030e-02]],\n",
      "\n",
      "        [[-1.0973e-01, -2.4875e-01, -6.0866e-02],\n",
      "         [-2.7880e-01,  4.6481e-01,  6.7614e-01],\n",
      "         [-3.4013e-01, -1.9158e-01,  1.4777e-01]],\n",
      "\n",
      "        [[ 1.6774e-01,  3.1152e-01,  2.6693e-03],\n",
      "         [ 5.7867e-01,  2.4379e-01, -7.6822e-01],\n",
      "         [ 2.5141e-01, -7.9754e-01, -1.2837e-01]],\n",
      "\n",
      "        [[-4.8733e-02,  6.1257e-01,  1.9170e-01],\n",
      "         [-3.7132e-01, -1.1479e+00, -7.9724e-01],\n",
      "         [ 2.7998e-01,  5.2863e-01,  4.2823e-01]],\n",
      "\n",
      "        [[ 1.4703e-01, -1.5151e-01, -2.3576e-01],\n",
      "         [ 5.1592e-01, -2.6190e-01, -6.0589e-01],\n",
      "         [ 4.0668e-01,  2.5295e-01, -8.7387e-02]],\n",
      "\n",
      "        [[-3.6725e-02,  1.8607e-01, -3.8142e-02],\n",
      "         [ 4.3113e-01,  2.6406e-01,  5.5763e-01],\n",
      "         [ 1.5419e-01,  3.0176e-01,  1.0160e-01]],\n",
      "\n",
      "        [[-4.0331e-01, -1.4586e-01,  6.7156e-01],\n",
      "         [-1.4946e-02, -9.3238e-01, -3.4191e-01],\n",
      "         [ 5.5097e-01,  7.6296e-03, -3.3737e-01]],\n",
      "\n",
      "        [[ 2.7918e-01,  7.6962e-01,  4.4438e-01],\n",
      "         [-6.3694e-02, -3.7394e-01,  1.4041e-01],\n",
      "         [-1.8861e-01, -6.0159e-01, -1.6927e-01]],\n",
      "\n",
      "        [[ 1.7127e-01, -8.4853e-02, -2.1473e-01],\n",
      "         [ 5.1444e-01,  4.9170e-01, -1.3194e+00],\n",
      "         [ 2.2972e-01,  3.8706e-01, -3.3414e-01]],\n",
      "\n",
      "        [[-8.0526e-02, -6.7356e-01, -2.5158e-01],\n",
      "         [ 4.2067e-01,  5.8503e-01,  7.5762e-01],\n",
      "         [-1.1926e-01, -5.3897e-01, -2.9516e-01]],\n",
      "\n",
      "        [[ 1.2061e-01, -1.0236e+00,  3.4945e-01],\n",
      "         [ 7.3275e-01, -1.3240e+00,  1.0551e+00],\n",
      "         [ 6.0125e-02,  2.7188e-01,  8.1867e-02]],\n",
      "\n",
      "        [[-3.0668e-01, -2.2569e-01, -4.0054e-01],\n",
      "         [-4.5474e-01,  1.7131e+00, -3.9905e-01],\n",
      "         [-3.2121e-01, -3.4519e-01, -2.6464e-01]],\n",
      "\n",
      "        [[-7.4574e-02, -5.0144e-01, -4.0141e-01],\n",
      "         [ 1.7603e-01, -1.9212e-01, -4.1075e-01],\n",
      "         [ 7.3020e-02,  9.2647e-01,  2.1219e-01]],\n",
      "\n",
      "        [[ 3.2455e-01,  6.0211e-01,  3.7798e-01],\n",
      "         [ 5.2327e-01,  1.0418e+00,  5.3084e-01],\n",
      "         [ 4.2112e-01,  8.5992e-01,  4.0106e-01]],\n",
      "\n",
      "        [[-7.1563e-02, -8.2513e-01,  2.0103e-01],\n",
      "         [ 9.5720e-01, -4.0319e-03, -6.9063e-01],\n",
      "         [ 1.5981e-01,  9.6529e-01, -2.1499e-01]],\n",
      "\n",
      "        [[-3.3596e-01, -7.6626e-02, -4.0012e-01],\n",
      "         [-3.5392e-01,  2.7595e-01, -2.8267e-01],\n",
      "         [-2.1277e-01, -1.5949e-01, -3.2352e-01]],\n",
      "\n",
      "        [[ 7.3135e-02, -6.2163e-01,  2.4162e-01],\n",
      "         [ 6.9762e-01, -8.3182e-01,  7.7091e-01],\n",
      "         [ 2.5235e-01, -6.0262e-01,  3.3088e-01]],\n",
      "\n",
      "        [[ 9.5817e-01,  1.0901e+00,  8.9797e-01],\n",
      "         [ 9.8364e-01,  2.9763e+00,  1.7529e+00],\n",
      "         [-1.8482e-01, -4.0442e-01, -7.8643e-02]],\n",
      "\n",
      "        [[-6.1581e-02, -1.3692e-01, -2.6531e-02],\n",
      "         [ 2.5728e-01, -1.0408e+00, -1.0219e-02],\n",
      "         [ 2.4468e-01,  7.2131e-01,  2.6644e-01]],\n",
      "\n",
      "        [[-1.8449e-01,  6.5638e-01, -6.4216e-02],\n",
      "         [ 9.9878e-01,  8.1939e-01,  1.0229e+00],\n",
      "         [-5.9490e-01,  1.2488e+00, -5.1786e-01]],\n",
      "\n",
      "        [[ 2.2090e-01, -8.2252e-01, -8.2002e-02],\n",
      "         [ 3.8083e-02, -2.4718e-01, -1.0562e-01],\n",
      "         [ 3.8401e-01, -9.9685e-01, -5.4277e-02]],\n",
      "\n",
      "        [[ 3.4684e-01,  1.8038e-01, -1.1233e+00],\n",
      "         [-3.0145e-02, -1.0741e+00, -2.4686e-01],\n",
      "         [-6.2508e-01, -9.0806e-02,  3.7741e-01]],\n",
      "\n",
      "        [[-1.7367e-01, -3.9412e-01, -3.6496e-01],\n",
      "         [-3.6730e-02, -7.5903e-02, -9.5723e-02],\n",
      "         [-1.1758e-01, -1.8928e-01, -1.3760e-01]],\n",
      "\n",
      "        [[ 1.9992e-01,  3.4296e-01,  1.9017e-01],\n",
      "         [ 3.7740e-02, -1.5523e-01, -1.7499e-01],\n",
      "         [-5.9237e-02, -5.9793e-01, -3.2745e-01]],\n",
      "\n",
      "        [[ 3.7919e-01,  4.4184e-02, -3.9418e-01],\n",
      "         [ 5.6248e-01,  1.0552e-01, -7.3537e-01],\n",
      "         [ 3.0302e-01, -1.0367e-01, -3.0684e-01]],\n",
      "\n",
      "        [[-8.8968e-02,  3.8345e-01,  5.8035e-01],\n",
      "         [-5.0882e-01,  6.1063e-01, -5.0069e-01],\n",
      "         [ 4.7796e-01,  5.0438e-01, -2.7848e-01]],\n",
      "\n",
      "        [[ 1.2592e-01,  2.2227e-01,  1.1811e-02],\n",
      "         [-3.2973e-01, -1.2491e+00, -4.2636e-01],\n",
      "         [ 1.6832e-01,  9.3868e-01,  4.0959e-01]],\n",
      "\n",
      "        [[-1.5279e-01,  4.7874e-01, -1.1129e-01],\n",
      "         [ 2.2278e-01, -9.6840e-01, -1.0824e+00],\n",
      "         [-1.0872e+00,  4.7549e-01,  5.4325e-01]],\n",
      "\n",
      "        [[ 6.1960e-01,  8.0760e-01, -8.4493e-01],\n",
      "         [-8.1369e-01,  5.7627e-01, -7.0007e-01],\n",
      "         [-5.1078e-02,  2.3374e-01,  3.3749e-01]],\n",
      "\n",
      "        [[ 7.0223e-02, -3.9424e-02, -8.0761e-02],\n",
      "         [-1.7777e-01, -1.2059e+00, -2.6455e-01],\n",
      "         [ 3.6442e-01,  9.6886e-01,  5.7175e-01]],\n",
      "\n",
      "        [[ 4.6286e-02, -5.3993e-01,  4.3286e-02],\n",
      "         [-6.2979e-01, -5.1620e-01, -5.0791e-01],\n",
      "         [-1.2211e-01,  2.4841e+00,  5.0466e-01]],\n",
      "\n",
      "        [[-3.9306e-01,  1.4793e+00, -1.1275e-01],\n",
      "         [ 3.2002e-02,  6.2842e-01,  3.5975e-01],\n",
      "         [-7.2932e-03,  1.0638e+00, -1.3816e-01]],\n",
      "\n",
      "        [[-5.0974e-01, -4.5313e-01,  6.7892e-01],\n",
      "         [-2.6903e-01,  6.1466e-01,  1.0595e-01],\n",
      "         [ 3.1160e-01,  3.3038e-01, -7.6451e-01]],\n",
      "\n",
      "        [[-6.4011e-02,  5.4051e-01,  1.2851e-01],\n",
      "         [-2.5886e-01, -5.2991e-01, -2.9898e-01],\n",
      "         [ 1.2146e-01,  4.3404e-01, -1.6055e-01]],\n",
      "\n",
      "        [[-2.4844e-02, -1.2091e+00, -1.9899e-03],\n",
      "         [-5.9392e-01,  2.7198e-01, -5.3248e-01],\n",
      "         [-1.7517e-01, -5.3627e-01, -3.1617e-01]],\n",
      "\n",
      "        [[ 4.2746e-01,  4.6357e-01,  9.9759e-02],\n",
      "         [ 5.4139e-01,  1.8472e-01, -5.0048e-01],\n",
      "         [-4.4360e-02, -6.5449e-01, -4.3082e-01]],\n",
      "\n",
      "        [[-5.8642e-02,  7.3948e-02,  2.2213e-02],\n",
      "         [ 1.0032e+00,  6.1494e-01, -1.3206e+00],\n",
      "         [ 2.5181e-01, -1.6186e-01, -6.9045e-01]],\n",
      "\n",
      "        [[ 9.7385e-02,  7.3411e-01,  6.0933e-02],\n",
      "         [ 3.5397e-01,  4.4750e-01, -7.0823e-01],\n",
      "         [ 1.7098e-01, -6.1525e-01, -4.5291e-01]],\n",
      "\n",
      "        [[-1.2662e-01,  2.0616e-02, -6.4902e-02],\n",
      "         [ 1.7552e-01,  1.5694e+00,  3.6237e-01],\n",
      "         [ 1.9110e-02,  4.4101e-01,  1.2835e-01]],\n",
      "\n",
      "        [[-7.6105e-02,  2.5440e-01,  5.0802e-02],\n",
      "         [-6.2740e-01, -8.1230e-01, -8.5729e-01],\n",
      "         [-8.9665e-04,  1.4288e-01,  8.5954e-02]],\n",
      "\n",
      "        [[-2.9096e-02, -2.4600e-01, -1.2130e-01],\n",
      "         [-4.3781e-01, -5.5192e-01,  1.9897e-01],\n",
      "         [ 6.4049e-02,  5.5958e-01,  3.9576e-01]],\n",
      "\n",
      "        [[-6.7409e-02,  1.5643e-01, -1.2407e-02],\n",
      "         [-8.7541e-02,  6.9383e-01,  1.6019e-02],\n",
      "         [-2.2557e-01, -2.7550e-01, -2.6753e-01]],\n",
      "\n",
      "        [[-1.8889e-01,  1.7838e-01,  2.6699e-01],\n",
      "         [-4.0932e-01, -5.1521e-01,  1.0635e+00],\n",
      "         [-2.4954e-01, -4.5294e-01,  2.1341e-01]],\n",
      "\n",
      "        [[ 1.7821e-01, -6.3468e-01, -3.1507e-02],\n",
      "         [-5.0168e-01, -5.0829e-01,  7.4690e-01],\n",
      "         [-1.2074e-01,  4.2596e-01,  4.1740e-01]],\n",
      "\n",
      "        [[ 5.2646e-02,  1.1500e+00,  1.7782e-01],\n",
      "         [-3.4341e-02,  9.5915e-01, -4.0953e-03],\n",
      "         [-2.1863e-02,  1.6078e+00,  2.2245e-01]],\n",
      "\n",
      "        [[ 1.8525e-01,  5.0242e-01,  2.8823e-01],\n",
      "         [-1.5499e-01,  7.3228e-01,  1.9410e-01],\n",
      "         [-1.7478e-01, -1.0676e+00, -5.0006e-01]],\n",
      "\n",
      "        [[-1.3677e-01,  2.7094e-01,  1.9637e-01],\n",
      "         [-4.9634e-01, -8.6506e-02,  8.9124e-01],\n",
      "         [-1.0221e-01, -6.5232e-01,  2.4367e-02]],\n",
      "\n",
      "        [[-7.9558e-01,  3.1886e-01, -5.2772e-04],\n",
      "         [ 5.2226e-01, -1.1591e+00,  4.4484e-01],\n",
      "         [-5.0213e-02,  8.5873e-01, -8.1102e-01]],\n",
      "\n",
      "        [[-1.5021e-01, -2.2504e-01, -1.5968e-01],\n",
      "         [-3.0408e-02,  9.0209e-01,  2.3920e-01],\n",
      "         [-5.0222e-02, -1.9106e-01, -9.5665e-02]],\n",
      "\n",
      "        [[-1.9101e-01,  2.7020e-02, -2.7152e-01],\n",
      "         [-2.8183e-01, -2.1881e-01, -2.9055e-01],\n",
      "         [ 1.7696e-01,  9.2799e-01,  2.2219e-01]],\n",
      "\n",
      "        [[-3.2553e-01, -2.2473e-01,  3.3589e-01],\n",
      "         [-4.8506e-01, -1.5853e-01,  8.6395e-01],\n",
      "         [-2.8413e-01, -2.1249e-01,  4.9164e-01]],\n",
      "\n",
      "        [[ 3.3728e-01,  7.6439e-02,  1.9314e-01],\n",
      "         [-5.5394e-01,  7.3191e-01, -4.9951e-01],\n",
      "         [-7.3342e-02,  4.1142e-01,  2.9811e-02]],\n",
      "\n",
      "        [[ 2.2986e-01, -1.1573e-02, -9.1272e-03],\n",
      "         [-1.0129e-01, -1.0120e+00, -8.6665e-01],\n",
      "         [-3.7926e-01, -6.8188e-01, -7.6858e-01]],\n",
      "\n",
      "        [[ 8.9809e-02,  6.4148e-01,  8.8003e-02],\n",
      "         [-1.2554e-01, -1.5555e+00, -2.6467e-01],\n",
      "         [-1.7960e-02,  8.5531e-01,  8.7160e-02]],\n",
      "\n",
      "        [[ 8.0188e-02,  8.8019e-02,  1.2063e-01],\n",
      "         [-3.3781e-02,  6.1518e-01,  1.9851e-02],\n",
      "         [-1.0452e-01,  6.8149e-01, -3.2689e-02]],\n",
      "\n",
      "        [[ 1.7730e-01, -3.4393e-01,  4.3016e-01],\n",
      "         [-3.9762e-01,  6.8844e-01, -3.9666e-01],\n",
      "         [-1.4650e-01,  3.5706e-01, -3.4643e-01]],\n",
      "\n",
      "        [[ 7.2969e-02,  2.5136e-02, -5.9854e-03],\n",
      "         [ 1.1312e-01,  3.3737e-01,  2.1835e-01],\n",
      "         [-2.3789e-02,  4.3437e-02,  5.9228e-03]],\n",
      "\n",
      "        [[ 4.1023e-01, -5.4319e-01, -3.2328e-01],\n",
      "         [-2.8909e-01, -7.9568e-01,  9.3822e-01],\n",
      "         [-3.8802e-01,  1.0918e+00,  2.0111e-01]],\n",
      "\n",
      "        [[ 8.4835e-02, -3.2320e-01, -1.2850e-02],\n",
      "         [-2.2703e-01, -7.7995e-01,  4.4330e-01],\n",
      "         [-5.6699e-02,  4.3429e-01,  4.6529e-01]],\n",
      "\n",
      "        [[-8.5389e-01,  1.2397e-01,  9.0081e-01],\n",
      "         [-3.2489e-01,  6.3245e-01, -5.7908e-01],\n",
      "         [ 3.9337e-01,  1.4653e-01, -5.1517e-01]],\n",
      "\n",
      "        [[ 6.6753e-01,  3.4082e-01, -2.3393e-01],\n",
      "         [ 7.5320e-01,  8.8928e-02, -6.5268e-01],\n",
      "         [-5.7016e-02, -1.7775e-01, -4.5090e-01]],\n",
      "\n",
      "        [[-2.8428e-02, -1.6174e-01, -1.7824e-01],\n",
      "         [-2.1398e-01, -9.7905e-01, -3.3248e-01],\n",
      "         [-1.1689e-01, -1.4152e-01, -7.2783e-02]],\n",
      "\n",
      "        [[-1.7191e-01,  3.9576e-01,  6.4018e-01],\n",
      "         [-2.0558e-01, -9.4890e-01,  6.5760e-01],\n",
      "         [ 3.9515e-01, -4.8380e-01, -3.0151e-01]],\n",
      "\n",
      "        [[ 5.2415e-01,  6.3651e-01,  4.6165e-01],\n",
      "         [-2.1265e-01, -1.2452e+00, -1.6515e-01],\n",
      "         [ 2.1229e-01,  2.9637e-01,  2.6688e-01]],\n",
      "\n",
      "        [[ 4.8844e-01, -1.5775e-01,  4.8454e-01],\n",
      "         [ 2.8522e-01, -7.1156e-01,  3.7728e-01],\n",
      "         [ 1.1438e-01, -1.0309e-01,  6.5087e-02]],\n",
      "\n",
      "        [[ 4.9857e-01, -1.2287e+00, -1.2038e+00],\n",
      "         [ 2.0400e+00, -1.1364e+00, -4.7488e-01],\n",
      "         [ 7.0709e-02, -3.8142e-01,  1.8493e-01]],\n",
      "\n",
      "        [[ 1.5995e-02,  6.2747e-01,  2.4312e-02],\n",
      "         [ 7.9012e-02, -1.8250e-02,  2.4583e-02],\n",
      "         [-5.7754e-02,  6.8983e-02, -4.9315e-02]],\n",
      "\n",
      "        [[ 1.2162e-01,  2.7957e-01, -2.2273e-01],\n",
      "         [ 6.0607e-01,  8.2598e-01,  1.6002e-01],\n",
      "         [-1.0677e-01, -1.7605e-01,  2.1020e-01]],\n",
      "\n",
      "        [[ 3.4646e-01, -3.4913e-01,  1.4221e-01],\n",
      "         [ 1.5150e-01,  1.6129e+00,  4.1756e-01],\n",
      "         [ 3.1575e-01,  2.1486e-01,  2.6606e-01]],\n",
      "\n",
      "        [[-1.0874e-02, -4.3216e-01, -6.0353e-02],\n",
      "         [-3.0662e-01, -7.5899e-01,  7.9463e-01],\n",
      "         [-1.8357e-01,  4.5781e-01,  3.8014e-01]],\n",
      "\n",
      "        [[-1.0807e-02, -6.9903e-01,  8.0006e-01],\n",
      "         [ 4.0055e-01, -3.7754e-01, -3.0813e-01],\n",
      "         [ 2.5710e-02,  5.1925e-01, -1.3632e+00]],\n",
      "\n",
      "        [[ 4.0240e-01,  1.0020e-01, -6.6800e-01],\n",
      "         [-2.1214e-02,  8.4935e-01, -1.7723e-01],\n",
      "         [-9.7031e-01, -1.1726e-01,  7.0803e-01]],\n",
      "\n",
      "        [[ 1.0463e-01, -4.4783e-01,  1.1492e-01],\n",
      "         [ 3.9351e-01, -1.3544e+00,  7.1029e-01],\n",
      "         [ 4.6635e-02,  8.3120e-03,  2.0420e-01]],\n",
      "\n",
      "        [[-6.8407e-01,  3.9287e-01,  7.4082e-01],\n",
      "         [ 6.0026e-01, -1.4634e+00,  2.9587e-01],\n",
      "         [ 4.2088e-01,  2.9707e-01, -8.3392e-01]],\n",
      "\n",
      "        [[-1.0512e-01, -1.0989e-01, -1.4421e-01],\n",
      "         [-3.8395e-02,  8.6292e-01,  1.7595e-01],\n",
      "         [-1.1401e-01,  4.9558e-02, -5.1543e-02]],\n",
      "\n",
      "        [[ 2.1959e-01, -6.2074e-01, -1.6214e-01],\n",
      "         [-4.5042e-01, -5.8052e-01,  6.5135e-01],\n",
      "         [ 1.4122e-02,  3.8815e-01,  3.8026e-01]],\n",
      "\n",
      "        [[ 1.0012e-01,  5.8206e-02, -3.7681e-03],\n",
      "         [ 8.4308e-02,  5.9760e-01,  4.4736e-01],\n",
      "         [ 5.8406e-02,  2.0194e-01,  8.2240e-02]],\n",
      "\n",
      "        [[-7.1900e-02, -4.0282e-01, -1.0220e-01],\n",
      "         [-2.3029e-01,  2.1242e+00, -4.0819e-01],\n",
      "         [-1.2084e-01, -4.7202e-01, -3.0116e-01]],\n",
      "\n",
      "        [[ 1.3973e-01, -1.1212e+00,  1.6926e-01],\n",
      "         [-2.6838e-01,  1.0382e+00, -6.9149e-01],\n",
      "         [-3.1189e-02,  4.7449e-01, -8.2768e-03]],\n",
      "\n",
      "        [[ 5.8346e-02,  7.8100e-01,  4.3888e-02],\n",
      "         [ 7.4110e-01, -5.5433e-02, -1.0375e+00],\n",
      "         [ 5.6645e-02, -6.6022e-01,  1.6195e-01]],\n",
      "\n",
      "        [[ 1.6347e-01,  1.0683e+00,  3.5397e-01],\n",
      "         [-5.5334e-02, -5.3723e-01, -2.8007e-01],\n",
      "         [-3.1632e-03, -5.6340e-01, -2.3294e-01]],\n",
      "\n",
      "        [[ 5.9439e-02,  1.0233e-01,  1.7953e-01],\n",
      "         [ 1.9302e-01,  6.5844e-01,  1.3089e-01],\n",
      "         [ 1.5549e-02,  1.1047e-01,  1.4125e-01]],\n",
      "\n",
      "        [[-2.3074e-01, -9.2985e-03,  2.8251e-01],\n",
      "         [-1.3155e-01, -3.4972e-03,  3.2640e-02],\n",
      "         [ 1.6037e-01,  4.2437e-02, -2.6654e-01]],\n",
      "\n",
      "        [[ 4.9045e-01,  1.1248e-01, -4.3657e-01],\n",
      "         [ 7.4618e-01,  3.2171e-01, -1.0987e+00],\n",
      "         [ 1.7757e-01, -9.7536e-02, -4.5803e-01]]]) conv_bias: tensor([-5.4158e-01,  2.4444e+00,  5.0029e-02, -2.3850e-01,  1.4984e+00,\n",
      "        -2.4578e+00,  3.6376e+00,  2.0452e+00,  2.8334e+00, -1.2280e-01,\n",
      "        -1.4772e-01,  1.1549e-01, -8.9618e-01, -7.6013e-01, -2.7394e-02,\n",
      "        -2.0501e-01, -9.1596e-02, -1.5775e+00,  1.5169e+00, -4.4413e-01,\n",
      "        -1.7917e-02,  1.3582e+00, -8.3348e-01,  9.8059e-01,  3.2326e-02,\n",
      "        -7.6078e-01, -5.3787e-01,  2.4794e+00, -4.7724e-01, -3.0843e-01,\n",
      "        -2.5084e-02,  5.8667e-01,  1.0033e+00,  9.3475e-01,  1.0337e+00,\n",
      "         1.0954e+00, -2.0347e-03, -2.8499e+00,  4.9878e-02,  4.2535e-01,\n",
      "        -6.3418e-01, -3.6974e-01,  5.6334e-03, -3.6727e-01, -2.5639e-01,\n",
      "        -2.6566e-01,  1.6024e+00, -4.8455e-01,  3.1155e-01, -1.4892e-01,\n",
      "        -3.8398e-01,  1.2203e+00,  2.1743e-02, -5.2041e-01, -6.3077e-02,\n",
      "        -1.8219e-02, -3.1015e-02, -3.8453e-01, -9.7865e-02,  5.7572e-01,\n",
      "         1.7903e+00,  1.9728e-01, -1.6824e-01, -1.4447e+00,  7.5329e+00,\n",
      "         5.5373e-01, -1.6123e+00, -5.4020e-01, -7.4344e-01, -4.1325e-01,\n",
      "        -1.3315e-01, -3.6965e-01, -3.8329e-01,  1.9006e+00, -9.6823e-02,\n",
      "         1.6590e+00,  1.7176e-01,  5.1867e-03, -2.8121e-01, -1.6695e-01,\n",
      "        -3.6211e-01,  4.0122e-02,  8.0200e-02, -3.3233e-01,  8.0137e-01,\n",
      "         1.0184e-01, -1.5322e+00,  2.2432e-01, -9.5257e-01, -5.8330e-01,\n",
      "         3.3789e-01, -1.1048e-01,  4.5245e-02, -1.1465e+00,  2.4362e+00,\n",
      "         1.9616e-01])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "q_weight: tensor([  -3,  -21,    6,   19,  -71,   24,   20,   78,  -12,  -33,  -51,  -30,\n",
      "         -63,   67,  -59,  -43,  -71,  -53,  -46,   44,   13,  -43,  -85,   -8,\n",
      "          30,   50,  -77,  -18,   31,   59,  -35,  -16,   30,  -12,  -21,  -21,\n",
      "         -23,   77,  -10,  -49,   33,  -45,   -3,   21,   -2,  -21,    9,   14,\n",
      "          10,   36,   11,   10,   10,  -25,  -35, -101,  -35,  -64,   45,  -82,\n",
      "         -26,  -75,  -56,  -13, -100,  -11,   72,   31,   83,   -3,  -10,  -10,\n",
      "          53,   13,  -72,   14,    2,  -32,  -65,   -9,   56,   -6,   10,   -3,\n",
      "          -8,   90,  -14,   -7,   23,   -5,   -8,   18,   -2,    4,   89,   14,\n",
      "          -4,  -22,   -8,    0,  -43,  -10,  -21,  -47,   48,  -16,   20,   65,\n",
      "           2,   76,   23,   -9,  -59,  -26,    0,   19,    2,  -11,  -25,   -6,\n",
      "         -28,   46,   67,  -34,  -19,   15,   17,   31,    0,   57,   24,  -76,\n",
      "          25,  -79,  -13,   -4,   51,   16,  -31,  -96,  -66,   23,   44,   36,\n",
      "          26,  -27,  -41,   90,  -46, -106,   71,   44,  -15,   -6,   32,   -7,\n",
      "          74,   46,   96,   27,   52,   18,  -21,   -7,   34,   -1,  -48,  -18,\n",
      "          28,    0,  -17,   28,   78,   45,   -6,  -38,   14,  -19,  -61,  -17,\n",
      "          12,   -6,  -15,   37,   35,  -95,   16,   28,  -24,  -11,  -94,  -35,\n",
      "          59,   82,  106,  -17,  -76,  -41,    5,  -41,   14,   30,  -53,   43,\n",
      "           2,   11,    3,   -9,   -7,  -12,  -13,   50,  -12,   -9,  -10,   -8,\n",
      "          -6,  -40,  -32,   14,  -15,  -33,    6,   74,   17,   19,   35,   22,\n",
      "          31,   61,   31,   25,   51,   24,   -8,  -90,   22,  105,    0,  -75,\n",
      "          17,  106,  -23,  -84,  -19, -100,  -89,   69,  -71,  -53,  -40,  -81,\n",
      "           6,  -55,   21,   62,  -74,   68,   22,  -53,   29,   18,   21,   17,\n",
      "          19,   57,   34,   -4,   -8,   -2,   -3,   -7,   -1,   13,  -51,    0,\n",
      "          12,   35,   13,   -4,   15,   -1,   22,   18,   23,  -13,   28,  -12,\n",
      "          22,  -83,   -8,    4,  -25,  -11,   39, -100,   -5,   32,   16, -102,\n",
      "          -3,  -98,  -22,  -57,   -8,   34,  -46, -105,  -97,  -10,  -20,  -25,\n",
      "         -31,  -50,  -37,   19,   33,   19,    4,  -15,  -17,   -6,  -58,  -32,\n",
      "          44,    5,  -46,   65,   12,  -86,   35,  -12,  -36,   -6,   27,   41,\n",
      "         -36,   43,  -35,   33,   35,  -19,    8,   14,    1,  -21,  -78,  -27,\n",
      "          11,   59,   26,  -11,   34,   -8,   16,  -69,  -77,  -77,   34,   38,\n",
      "          44,   57,  -60,  -57,   41,  -49,   -4,   16,   24,    5,   -3,   -6,\n",
      "         -13,  -91,  -20,   27,   73,   43,    1,  -16,    1,  -18,  -15,  -15,\n",
      "          -4,   73,   15,  -15,   57,   -4,    1,   24,   14,    0,   41,   -5,\n",
      "         -49,  -43,   65,  -26,   59,   10,   30,   31,  -73,   -9,   77,   18,\n",
      "         -37,  -76,  -43,   17,   62,  -23,   -2, -104,    0,  -51,   23,  -46,\n",
      "         -15,  -46,  -27,   44,   48,   10,   56,   19,  -52,   -5,  -67,  -44,\n",
      "          -4,    4,    1,   61,   37,  -80,   15,  -10,  -42,    8,   58,    5,\n",
      "          28,   35,  -56,   14,  -49,  -36,   -8,    1,   -4,   12,  104,   24,\n",
      "           1,   29,    9,   -7,   23,    5,  -58,  -75,  -79,    0,   13,    8,\n",
      "          -5,  -40,  -20,  -71,  -90,   32,   10,   91,   64,  -11,   25,   -2,\n",
      "         -14,  109,    3,  -36,  -43,  -42,  -17,   16,   24,  -36,  -46,   94,\n",
      "         -22,  -40,   19,   16,  -58,   -3,  -46,  -47,   69,  -11,   39,   38,\n",
      "           2,   48,    7,   -1,   40,    0,   -1,   67,    9,   14,   38,   22,\n",
      "         -12,   55,   15,  -13,  -80,  -37,   -8,   17,   12,  -30,   -5,   55,\n",
      "          -6,  -40,    1,  -51,   20,    0,   33,  -74,   28,   -3,   55,  -52,\n",
      "         -17,  -25,  -18,   -3,  101,   27,   -6,  -21,  -11,  -18,    3,  -25,\n",
      "         -26,  -20,  -27,   16,   86,   21,  -35,  -24,   36,  -52,  -17,   93,\n",
      "         -31,  -23,   53,   16,    4,    9,  -26,   34,  -23,   -3,   19,    1,\n",
      "          12,   -1,    0,   -5,  -55,  -47,  -20,  -37,  -41,    3,   18,    3,\n",
      "          -4,  -45,   -8,   -1,   25,    2,    6,    7,    9,   -3,   48,    2,\n",
      "          -8,   53,   -3,   18,  -34,   43,  -39,   68,  -39,  -15,   35,  -34,\n",
      "          17,    6,   -1,   26,   78,   51,   -6,   10,    1,   31,  -42,  -25,\n",
      "         -22,  -61,   72,  -30,   83,   15,    6,  -25,   -1,  -17,  -59,   34,\n",
      "          -4,   33,   35,  -56,    8,   59,  -21,   42,  -38,   26,   10,  -34,\n",
      "          60,   30,  -21,   67,    8,  -58,   -5,  -16,  -40,   -2,  -10,  -11,\n",
      "         -14,  -62,  -21,   -7,   -9,   -5,  -10,   22,   36,  -11,  -53,   37,\n",
      "          22,  -27,  -17,   31,   38,   27,  -13,  -74,  -10,   13,   18,   16,\n",
      "          60,  -19,   60,   35,  -88,   46,   14,  -13,    8,   24,  -58,  -57,\n",
      "          96,  -54,  -22,    3,  -18,    9,    2,   84,    3,   11,   -2,    3,\n",
      "          -8,    9,   -7,   11,   26,  -20,   56,   76,   15,  -10,  -16,   19,\n",
      "          16,  -16,    6,    7,   73,   19,   14,   10,   12,   -1,  -47,   -7,\n",
      "         -33,  -83,   87,  -20,   50,   41,   -1,  -58,   66,   33,  -31,  -26,\n",
      "           2,   43, -113,   19,    5,  -32,   -1,   41,   -8,  -46,   -6,   34,\n",
      "           3,  -14,    4,   12,  -43,   22,    1,    0,    6,  -30,   18,   33,\n",
      "          27,  -65,   13,   19,   13,  -37,   -6,   -6,   -8,   -2,   47,   10,\n",
      "          -6,    3,   -3,   20,  -55,  -14,  -40,  -52,   58,    1,   35,   34,\n",
      "          14,    8,   -1,   12,   86,   64,    8,   29,   12,   -2,  -12,   -3,\n",
      "          -7,   61,  -12,   -3,  -14,   -9,   10,  -78,   12,  -19,   72,  -48,\n",
      "          -2,   33,   -1,    5,   68,    4,   65,   -5,  -90,    5,  -57,   14,\n",
      "          13,   88,   29,   -5,  -44,  -23,    0,  -46,  -19,    6,   10,   17,\n",
      "          18,   62,   12,    1,   10,   13,  -46,   -2,   56,  -26,   -1,    6,\n",
      "          32,    8,  -53,   40,    9,  -35,   61,   26,  -89,   14,   -8,  -37],\n",
      "       dtype=torch.int32) q_bias: tensor([ -524,  4377,    40,  -201,  2309, -1215, 10610,  2598,  9284,  -297,\n",
      "          -90,   131,  -523,  -837,   -30,  -190,  -179, -3033,   867,  -499,\n",
      "          -14,  2121,  -374,   316,    29,  -498,  -655,  6921,  -471,   -66,\n",
      "          -14,   147,  1127,   947,  3062,  1188,    -3, -2222,    35,   336,\n",
      "         -498,  -309,     2,  -158,  -272,  -424,  1540,  -556,   211,  -131,\n",
      "         -285,  1248,    39,  -915,   -62,   -19,   -14,  -321,   -67,   408,\n",
      "         2224,   204,  -203,  -755,  4533,   177, -1407,  -597, -1926,  -352,\n",
      "         -113,  -271,  -382,  1345,   -60,  1100,   236,     3,  -419,  -171,\n",
      "         -183,    49,    74,  -177,   282,    51,  -935,   223, -1522,  -187,\n",
      "          262,  -107,    41, -1210,  5354,   177], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0003) tensor(0.0252)   bias tensor(-4.1135e-05) tensor(0.0012)\n",
      "features.6.conv.6.weight features.6.conv.8\n",
      "torch.Size([16, 96, 1, 1]) conv_bias= torch.Size([16]) \n",
      "ascale= tensor([0.0575]) torch.Size([1]) \n",
      "wscale= tensor([0.0049, 0.0049, 0.0058, 0.0034, 0.0040, 0.0053, 0.0040, 0.0049, 0.0055,\n",
      "        0.0088, 0.0054, 0.0067, 0.0085, 0.0048, 0.0049, 0.0087]) torch.Size([16, 1, 1, 1]) \n",
      "oscale= tensor([0.1163]) torch.Size([1])\n",
      "###: M= tensor([0.0024, 0.0024, 0.0029, 0.0017, 0.0020, 0.0026, 0.0020, 0.0024, 0.0027,\n",
      "        0.0043, 0.0027, 0.0033, 0.0042, 0.0024, 0.0024, 0.0043])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "conv_weight: tensor([[ 0.1325,  0.4797, -0.3838,  ..., -0.3445,  0.2559,  0.3053],\n",
      "        [ 0.0970, -0.2161,  0.4229,  ...,  0.0415, -0.1936, -0.2609],\n",
      "        [ 0.1209,  0.0151, -0.2023,  ..., -0.2427, -0.2611,  0.0708],\n",
      "        ...,\n",
      "        [ 0.0011,  0.2000, -0.3459,  ..., -0.2912,  0.1980,  0.2193],\n",
      "        [ 0.3708, -0.1273,  0.2765,  ..., -0.1775, -0.1172, -0.2843],\n",
      "        [-0.1049, -0.0498, -0.4343,  ..., -0.0939, -0.1182,  0.0996]]) conv_bias: tensor([-2.6719,  1.5552,  0.7363,  0.2504, -1.7271,  1.9050,  1.4660, -1.0151,\n",
      "         0.5940,  0.7231,  1.9815, -4.4429,  7.8451,  0.9582,  1.7263,  2.2550])\n",
      "torch.Size([16, 96, 1, 1]) torch.Size([16])\n",
      "q_weight: tensor([ 27,  98, -78,  ..., -11, -14,  12], dtype=torch.int32) q_bias: tensor([ -9501,   5560,   2214,   1290,  -7559,   6306,   6312,  -3598,   1891,\n",
      "          1432,   6324, -11554,  16127,   3493,   6083,   4534],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-2.2858e-05) tensor(0.0044)   bias tensor(-5.5801e-05) tensor(0.0001)\n",
      "features.7.conv.0.weight features.7.conv.2\n",
      "torch.Size([96, 16, 1, 1]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.1163]) torch.Size([1]) \n",
      "wscale= tensor([0.0043, 0.0018, 0.0041, 0.0040, 0.0023, 0.0022, 0.0018, 0.0017, 0.0030,\n",
      "        0.0018, 0.0031, 0.0055, 0.0029, 0.0037, 0.0029, 0.0012, 0.0023, 0.0042,\n",
      "        0.0008, 0.0089, 0.0076, 0.0013, 0.0042, 0.0042, 0.0036, 0.0022, 0.0018,\n",
      "        0.0027, 0.0012, 0.0025, 0.0014, 0.0043, 0.0027, 0.0016, 0.0023, 0.0030,\n",
      "        0.0014, 0.0037, 0.0032, 0.0007, 0.0045, 0.0018, 0.0037, 0.0021, 0.0023,\n",
      "        0.0032, 0.0025, 0.0022, 0.0042, 0.0023, 0.0035, 0.0017, 0.0034, 0.0018,\n",
      "        0.0035, 0.0041, 0.0018, 0.0031, 0.0055, 0.0037, 0.0009, 0.0029, 0.0046,\n",
      "        0.0013, 0.0016, 0.0037, 0.0023, 0.0056, 0.0031, 0.0011, 0.0035, 0.0027,\n",
      "        0.0036, 0.0036, 0.0016, 0.0019, 0.0042, 0.0016, 0.0010, 0.0017, 0.0037,\n",
      "        0.0009, 0.0010, 0.0044, 0.0024, 0.0049, 0.0017, 0.0036, 0.0020, 0.0038,\n",
      "        0.0026, 0.0056, 0.0056, 0.0046, 0.0019, 0.0016]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.1325]) torch.Size([1])\n",
      "###: M= tensor([0.0038, 0.0015, 0.0036, 0.0035, 0.0020, 0.0019, 0.0015, 0.0015, 0.0026,\n",
      "        0.0016, 0.0027, 0.0049, 0.0026, 0.0033, 0.0025, 0.0010, 0.0020, 0.0037,\n",
      "        0.0007, 0.0078, 0.0067, 0.0011, 0.0037, 0.0037, 0.0032, 0.0019, 0.0015,\n",
      "        0.0024, 0.0010, 0.0022, 0.0012, 0.0038, 0.0024, 0.0014, 0.0020, 0.0026,\n",
      "        0.0013, 0.0032, 0.0028, 0.0006, 0.0039, 0.0015, 0.0032, 0.0019, 0.0020,\n",
      "        0.0028, 0.0022, 0.0019, 0.0037, 0.0020, 0.0031, 0.0015, 0.0030, 0.0016,\n",
      "        0.0031, 0.0036, 0.0016, 0.0028, 0.0048, 0.0032, 0.0008, 0.0025, 0.0040,\n",
      "        0.0012, 0.0014, 0.0032, 0.0020, 0.0050, 0.0027, 0.0010, 0.0030, 0.0023,\n",
      "        0.0032, 0.0031, 0.0014, 0.0017, 0.0037, 0.0014, 0.0009, 0.0015, 0.0032,\n",
      "        0.0008, 0.0009, 0.0039, 0.0021, 0.0043, 0.0015, 0.0032, 0.0018, 0.0034,\n",
      "        0.0022, 0.0050, 0.0049, 0.0040, 0.0016, 0.0014])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "conv_weight: tensor([[-0.2033, -0.1784,  0.1064,  ..., -0.0839,  0.4914,  0.0882],\n",
      "        [-0.0948, -0.0374,  0.0892,  ...,  0.0510,  0.0040,  0.0473],\n",
      "        [ 0.0103, -0.2216,  0.0602,  ..., -0.1016,  0.3220,  0.0099],\n",
      "        ...,\n",
      "        [ 0.2109,  0.2043,  0.5771,  ...,  0.3587,  0.3299,  0.1477],\n",
      "        [ 0.1052, -0.0287, -0.0500,  ..., -0.1416, -0.1082,  0.2268],\n",
      "        [ 0.0828,  0.1431,  0.0598,  ..., -0.1528,  0.0901, -0.2002]]) conv_bias: tensor([-0.2238,  0.5337,  0.9167, -0.3575, -0.1650,  1.6202,  0.6828,  0.7119,\n",
      "         0.6743,  1.2532, -0.6999,  0.3120, -0.3038, -0.3723,  1.7090, -0.8182,\n",
      "         0.7321,  0.1086, -0.9015,  0.8533,  0.0640, -0.8783, -0.0469,  0.2584,\n",
      "         0.4977,  0.7457,  0.6234,  1.1265, -0.6101,  0.3397,  1.3178,  0.9255,\n",
      "         0.4436, -1.0630,  0.6111,  0.4667, -0.8695, -0.1477,  0.5194,  3.1783,\n",
      "         0.2534,  0.8832,  0.6201,  0.4450,  0.6542, -0.3839,  0.8053, -0.3421,\n",
      "         0.6563, -0.5710, -0.0594, -0.7135,  0.6993, -0.6061, -0.5829,  0.8068,\n",
      "        -0.6936, -0.1041,  0.4125, -0.3254, -0.9589, -0.3197,  0.8085, -0.7558,\n",
      "        -0.7458,  0.2714, -0.0120,  0.1196,  1.6031,  0.7211,  0.9957,  0.7666,\n",
      "         0.2240,  0.0398, -0.7933, -0.5840,  0.1735,  1.0271, -0.8664, -0.9753,\n",
      "        -0.1675,  1.4795, -0.8608, -0.3045,  1.0744, -0.1081, -1.1504, -0.3948,\n",
      "         0.6551, -0.3336,  0.7765, -0.0970,  0.3834,  0.1886,  1.4475,  1.1714])\n",
      "torch.Size([96, 16, 1, 1]) torch.Size([96])\n",
      "q_weight: tensor([ -47,  -41,   25,  ...,  -96,   57, -126], dtype=torch.int32) q_bias: tensor([ -445,  2609,  1922,  -772,  -620,  6308,  3332,  3576,  1950,  5888,\n",
      "        -1930,   484,  -899,  -859,  5100, -5905,  2750,   224, -9532,   821,\n",
      "           72, -5827,   -96,   527,  1187,  2946,  3059,  3613, -4471,  1186,\n",
      "         8033,  1853,  1414, -5717,  2281,  1341, -5238,  -346,  1415, 40551,\n",
      "          486,  4325,  1440,  1796,  2435, -1035,  2757, -1335,  1337, -2175,\n",
      "         -146, -3569,  1787, -2840, -1434,  1711, -3251,  -285,   643,  -763,\n",
      "        -8894,  -964,  1527, -4848, -3953,   631,   -46,   182,  4488,  5690,\n",
      "         2479,  2487,   530,    96, -4174, -2622,   353,  5571, -7604, -4901,\n",
      "         -389, 13836, -7470,  -593,  3929,  -189, -5707,  -933,  2789,  -746,\n",
      "         2617,  -148,   589,   353,  6679,  6322], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(1.7595e-05) tensor(0.0044)   bias tensor(4.4871e-06) tensor(0.0004)\n",
      "features.7.conv.3.weight features.7.conv.5\n",
      "torch.Size([96, 1, 3, 3]) conv_bias= torch.Size([96]) \n",
      "ascale= tensor([0.1305]) torch.Size([1]) \n",
      "wscale= tensor([0.0048, 0.0051, 0.0030, 0.0065, 0.0093, 0.0053, 0.0057, 0.0066, 0.0046,\n",
      "        0.0070, 0.0098, 0.0028, 0.0038, 0.0047, 0.0074, 0.0426, 0.0090, 0.0028,\n",
      "        0.0344, 0.0021, 0.0020, 0.0218, 0.0033, 0.0086, 0.0059, 0.0057, 0.0051,\n",
      "        0.0048, 0.0223, 0.0053, 0.0065, 0.0040, 0.0042, 0.0469, 0.0045, 0.0092,\n",
      "        0.0221, 0.0062, 0.0038, 0.0247, 0.0036, 0.0055, 0.0030, 0.0036, 0.0082,\n",
      "        0.0042, 0.0039, 0.0065, 0.0035, 0.0101, 0.0048, 0.0163, 0.0028, 0.0095,\n",
      "        0.0042, 0.0027, 0.0162, 0.0062, 0.0025, 0.0057, 0.0812, 0.0056, 0.0047,\n",
      "        0.0186, 0.0160, 0.0048, 0.0055, 0.0020, 0.0051, 0.0062, 0.0038, 0.0066,\n",
      "        0.0034, 0.0025, 0.0153, 0.0126, 0.0044, 0.0076, 0.0555, 0.0233, 0.0025,\n",
      "        0.0102, 0.1201, 0.0033, 0.0055, 0.0026, 0.0343, 0.0055, 0.0045, 0.0049,\n",
      "        0.0036, 0.0034, 0.0032, 0.0037, 0.0086, 0.0067]) torch.Size([96, 1, 1, 1]) \n",
      "oscale= tensor([0.1453]) torch.Size([1])\n",
      "###: M= tensor([0.0043, 0.0046, 0.0027, 0.0058, 0.0084, 0.0048, 0.0051, 0.0059, 0.0041,\n",
      "        0.0063, 0.0088, 0.0025, 0.0034, 0.0043, 0.0066, 0.0383, 0.0080, 0.0026,\n",
      "        0.0309, 0.0019, 0.0018, 0.0196, 0.0030, 0.0077, 0.0053, 0.0051, 0.0046,\n",
      "        0.0043, 0.0200, 0.0048, 0.0058, 0.0036, 0.0038, 0.0421, 0.0040, 0.0083,\n",
      "        0.0198, 0.0055, 0.0034, 0.0222, 0.0032, 0.0049, 0.0027, 0.0033, 0.0073,\n",
      "        0.0038, 0.0035, 0.0058, 0.0031, 0.0091, 0.0043, 0.0147, 0.0025, 0.0085,\n",
      "        0.0037, 0.0024, 0.0145, 0.0055, 0.0022, 0.0051, 0.0729, 0.0050, 0.0042,\n",
      "        0.0167, 0.0143, 0.0043, 0.0050, 0.0018, 0.0046, 0.0056, 0.0034, 0.0060,\n",
      "        0.0031, 0.0023, 0.0138, 0.0113, 0.0040, 0.0068, 0.0498, 0.0209, 0.0022,\n",
      "        0.0091, 0.1078, 0.0030, 0.0050, 0.0024, 0.0308, 0.0049, 0.0040, 0.0044,\n",
      "        0.0032, 0.0030, 0.0028, 0.0034, 0.0077, 0.0060])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "conv_weight: tensor([[[ 2.8436e-01,  3.7683e-01,  3.1711e-01],\n",
      "         [ 3.6250e-01,  5.5184e-01,  4.4472e-01],\n",
      "         [ 2.3327e-01,  3.3646e-01,  2.8523e-01]],\n",
      "\n",
      "        [[-1.4697e-01, -2.5185e-01, -2.3336e-01],\n",
      "         [-3.3943e-01, -5.1088e-01, -3.3562e-01],\n",
      "         [-1.8108e-01, -3.1141e-01, -2.9210e-01]],\n",
      "\n",
      "        [[-1.9463e-01, -2.2510e-01, -2.8336e-01],\n",
      "         [-2.5034e-01, -1.2475e-01, -3.1583e-01],\n",
      "         [-2.3426e-01, -1.9692e-01, -3.4514e-01]],\n",
      "\n",
      "        [[ 2.2807e-01,  3.5163e-01,  3.1642e-01],\n",
      "         [ 4.3835e-01,  6.4525e-01,  5.3683e-01],\n",
      "         [ 3.1263e-01,  3.5043e-01,  3.4174e-01]],\n",
      "\n",
      "        [[-2.6088e-01, -5.2405e-01, -3.3918e-01],\n",
      "         [-4.2265e-01, -7.7582e-01, -6.0355e-01],\n",
      "         [-2.8844e-01, -4.7878e-01, -3.3241e-01]],\n",
      "\n",
      "        [[ 9.5406e-02,  1.2550e-01,  1.2490e-01],\n",
      "         [ 2.0589e-01,  3.5629e-01,  2.6983e-01],\n",
      "         [ 1.6787e-01,  3.0177e-01,  2.2976e-01]],\n",
      "\n",
      "        [[-1.0136e-01, -2.7190e-01, -2.2928e-01],\n",
      "         [-2.3778e-01, -5.0670e-01, -3.5886e-01],\n",
      "         [-6.7860e-02, -3.1240e-01, -1.8032e-01]],\n",
      "\n",
      "        [[-1.5680e-01, -2.7761e-01, -2.2867e-01],\n",
      "         [ 2.9874e-01,  5.4781e-01,  3.3801e-01],\n",
      "         [-1.2171e-01, -3.2167e-01, -1.3328e-01]],\n",
      "\n",
      "        [[-1.1130e-01, -2.2835e-01, -1.7066e-01],\n",
      "         [-2.2770e-01, -4.5499e-01, -2.9780e-01],\n",
      "         [-1.7017e-01, -2.7931e-01, -2.0636e-01]],\n",
      "\n",
      "        [[-2.4717e-01, -4.5616e-01, -2.1182e-01],\n",
      "         [-3.7927e-01, -7.1490e-01, -3.4840e-01],\n",
      "         [-2.5071e-01, -4.5720e-01, -2.3716e-01]],\n",
      "\n",
      "        [[ 2.7561e-01,  4.7290e-01,  3.8142e-01],\n",
      "         [ 4.2792e-01,  9.2126e-01,  6.2448e-01],\n",
      "         [ 4.2179e-01,  7.2002e-01,  5.5717e-01]],\n",
      "\n",
      "        [[ 1.0714e-01,  1.6703e-01,  1.3258e-01],\n",
      "         [ 1.8590e-01,  3.2129e-01,  2.1339e-01],\n",
      "         [ 1.3791e-01,  1.8361e-01,  1.3594e-01]],\n",
      "\n",
      "        [[-2.0113e-01, -3.0967e-01, -1.8518e-01],\n",
      "         [-2.8005e-01, -3.6009e-01, -3.2455e-01],\n",
      "         [-1.5579e-01, -3.5412e-01, -1.9849e-01]],\n",
      "\n",
      "        [[ 1.4999e-01,  2.3680e-01,  1.8035e-01],\n",
      "         [ 2.8707e-01,  5.1387e-01,  3.8783e-01],\n",
      "         [ 1.3441e-01,  2.6046e-01,  2.0099e-01]],\n",
      "\n",
      "        [[ 1.2669e-01,  1.8412e-01,  1.5194e-01],\n",
      "         [ 2.6842e-01,  5.3996e-01,  3.6207e-01],\n",
      "         [ 1.4471e-01,  2.7158e-01,  1.7873e-01]],\n",
      "\n",
      "        [[-1.6837e+00, -1.8732e+00, -1.8217e+00],\n",
      "         [-8.9368e-01, -1.8693e+00, -1.1950e+00],\n",
      "         [ 2.2403e+00,  3.6841e+00,  3.0221e+00]],\n",
      "\n",
      "        [[-2.3411e-01, -2.5802e-01,  3.2312e-01],\n",
      "         [-1.4414e-01, -3.9314e-01,  6.8499e-01],\n",
      "         [-2.2746e-01, -3.3147e-01,  4.1047e-01]],\n",
      "\n",
      "        [[ 8.8403e-02,  1.8508e-01,  1.0535e-01],\n",
      "         [ 1.5221e-01,  3.2613e-01,  1.9093e-01],\n",
      "         [ 8.3192e-02,  1.3360e-01,  8.2347e-02]],\n",
      "\n",
      "        [[-1.1353e+00, -1.4702e+00, -1.2298e+00],\n",
      "         [-1.7542e+00, -2.2590e+00, -2.0541e+00],\n",
      "         [-1.5206e+00, -1.7842e+00, -1.7103e+00]],\n",
      "\n",
      "        [[ 4.5597e-02,  1.1289e-01,  7.6329e-02],\n",
      "         [ 8.9574e-02,  2.3298e-01,  1.1896e-01],\n",
      "         [ 6.5157e-02,  1.3220e-01,  6.6953e-02]],\n",
      "\n",
      "        [[ 8.6823e-02,  1.7266e-01,  1.1723e-01],\n",
      "         [ 1.2362e-01,  2.1957e-01,  1.5611e-01],\n",
      "         [ 8.4448e-02,  1.3402e-01,  1.0054e-01]],\n",
      "\n",
      "        [[-9.9013e-01, -1.2269e+00, -1.1931e+00],\n",
      "         [-1.3744e+00, -1.5042e+00, -1.5374e+00],\n",
      "         [-1.0853e+00, -1.4930e+00, -1.5325e+00]],\n",
      "\n",
      "        [[ 9.3824e-02,  1.9148e-01,  1.1879e-01],\n",
      "         [ 1.6084e-01,  3.2264e-01,  1.8355e-01],\n",
      "         [ 1.0353e-01,  1.7704e-01,  1.0188e-01]],\n",
      "\n",
      "        [[-1.4730e-01, -2.2649e-01, -1.5790e-01],\n",
      "         [-4.4873e-03,  6.1739e-02,  4.1191e-03],\n",
      "         [ 1.9351e-01,  3.7984e-01,  2.5376e-01]],\n",
      "\n",
      "        [[ 2.4059e-01,  4.2667e-01,  2.6058e-01],\n",
      "         [ 1.0398e-02,  6.8331e-02, -1.0154e-02],\n",
      "         [-2.4670e-01, -3.4947e-01, -2.8435e-01]],\n",
      "\n",
      "        [[-1.3838e-01, -4.8809e-02,  2.7441e-01],\n",
      "         [-2.4763e-01, -3.1021e-02,  5.7817e-01],\n",
      "         [-1.5895e-01, -4.2953e-02,  3.5293e-01]],\n",
      "\n",
      "        [[ 3.2528e-01,  5.1082e-02, -4.1277e-01],\n",
      "         [ 4.5314e-01,  1.9516e-02, -4.8186e-01],\n",
      "         [ 2.8447e-01,  6.3435e-02, -3.2094e-01]],\n",
      "\n",
      "        [[ 1.0347e-01,  1.6894e-01,  1.2958e-01],\n",
      "         [ 2.4420e-01,  4.2332e-01,  2.9786e-01],\n",
      "         [ 1.6588e-01,  2.4901e-01,  1.8797e-01]],\n",
      "\n",
      "        [[-1.0400e+00, -1.1066e+00, -1.2850e+00],\n",
      "         [-1.7377e+00, -1.8470e+00, -2.1443e+00],\n",
      "         [-1.4580e+00, -1.7643e+00, -1.8306e+00]],\n",
      "\n",
      "        [[-1.7086e-01, -2.0604e-01, -1.6466e-01],\n",
      "         [-1.0956e-01, -9.4150e-02, -7.9057e-02],\n",
      "         [ 2.8238e-01,  4.9223e-01,  3.6050e-01]],\n",
      "\n",
      "        [[-3.1992e-01, -5.5332e-01, -4.1976e-01],\n",
      "         [ 2.4233e-02,  7.4802e-02,  6.7553e-02],\n",
      "         [ 2.1429e-01,  5.3752e-01,  3.6754e-01]],\n",
      "\n",
      "        [[ 1.2742e-01,  2.4288e-01,  1.5435e-01],\n",
      "         [ 2.2494e-01,  4.2304e-01,  2.7380e-01],\n",
      "         [ 1.3248e-01,  2.5414e-01,  1.7851e-01]],\n",
      "\n",
      "        [[-1.4414e-01, -2.5720e-01, -1.7187e-01],\n",
      "         [-2.7872e-01, -2.1741e-01, -3.2654e-01],\n",
      "         [-2.0506e-01, -4.0751e-01, -2.9528e-01]],\n",
      "\n",
      "        [[ 1.4978e+00,  1.9106e+00,  1.7100e+00],\n",
      "         [ 3.2435e+00,  4.1192e+00,  3.5141e+00],\n",
      "         [ 2.7274e+00,  3.1329e+00,  2.8800e+00]],\n",
      "\n",
      "        [[ 2.2242e-01,  2.9463e-01,  2.8455e-01],\n",
      "         [ 2.3435e-01,  4.5031e-01,  2.5189e-01],\n",
      "         [ 1.9105e-01,  3.0115e-01,  2.0599e-01]],\n",
      "\n",
      "        [[-2.6474e-01, -1.8654e-01,  2.9432e-01],\n",
      "         [-2.8975e-01, -2.6607e-01,  5.8741e-01],\n",
      "         [-2.0989e-01, -2.1585e-01,  4.0433e-01]],\n",
      "\n",
      "        [[ 6.5749e-01,  1.3113e+00,  1.1107e+00],\n",
      "         [ 1.0666e+00,  2.0313e+00,  1.7339e+00],\n",
      "         [ 9.5556e-01,  1.6245e+00,  1.4099e+00]],\n",
      "\n",
      "        [[ 2.0630e-01,  3.8983e-01,  2.5003e-01],\n",
      "         [ 3.0840e-01,  6.2537e-01,  4.1767e-01],\n",
      "         [ 1.7792e-01,  3.4859e-01,  2.3382e-01]],\n",
      "\n",
      "        [[ 2.0081e-01,  4.4050e-01,  2.9432e-01],\n",
      "         [ 2.1075e-02,  1.9865e-01,  1.3067e-01],\n",
      "         [-2.2175e-01, -3.7845e-01, -2.9021e-01]],\n",
      "\n",
      "        [[-8.1891e-01,  2.6145e-01, -1.1277e+00],\n",
      "         [ 1.0579e-01,  1.0286e+00, -3.5499e-01],\n",
      "         [-9.5722e-01, -3.5945e-02, -1.6296e+00]],\n",
      "\n",
      "        [[ 1.2034e-01,  1.6329e-01,  1.6297e-01],\n",
      "         [ 2.0791e-01,  3.6690e-01,  2.9513e-01],\n",
      "         [ 8.5761e-02,  1.6046e-01,  1.1998e-01]],\n",
      "\n",
      "        [[-1.6014e-01, -4.3353e-01, -3.2406e-01],\n",
      "         [-3.0225e-01, -5.8496e-01, -3.8957e-01],\n",
      "         [-2.4999e-01, -4.2756e-01, -2.0015e-01]],\n",
      "\n",
      "        [[ 4.5571e-02,  1.3211e-01,  4.6899e-02],\n",
      "         [ 8.3434e-02,  3.7243e-01,  1.2625e-01],\n",
      "         [ 6.9562e-02,  2.4768e-01,  1.0482e-01]],\n",
      "\n",
      "        [[-2.0260e-01, -3.3099e-01, -2.6766e-01],\n",
      "         [-2.6171e-01, -3.2788e-01, -3.9207e-01],\n",
      "         [-1.7641e-01, -3.4916e-01, -2.6471e-01]],\n",
      "\n",
      "        [[ 3.2085e-01, -1.7658e-01, -3.3653e-01],\n",
      "         [ 6.2403e-01, -1.4688e-01, -3.5551e-01],\n",
      "         [ 3.6972e-01, -1.9044e-01, -2.7568e-01]],\n",
      "\n",
      "        [[ 1.8898e-01,  4.3407e-01,  2.9251e-01],\n",
      "         [ 2.4450e-01,  5.1563e-01,  3.1258e-01],\n",
      "         [ 1.1341e-01,  1.9921e-01,  1.0885e-01]],\n",
      "\n",
      "        [[ 2.4733e-01,  4.1182e-01,  1.8633e-01],\n",
      "         [ 6.8244e-03, -1.2276e-01, -1.7106e-01],\n",
      "         [-2.1269e-01, -4.0486e-01, -3.5493e-01]],\n",
      "\n",
      "        [[ 2.2857e-01,  4.0681e-01,  2.6748e-01],\n",
      "         [ 4.7551e-01,  7.2528e-01,  4.7158e-01],\n",
      "         [ 3.6765e-01,  5.3698e-01,  3.8292e-01]],\n",
      "\n",
      "        [[ 7.7298e-02,  2.1097e-01,  1.5320e-01],\n",
      "         [ 1.5072e-01,  3.6276e-01,  2.7510e-01],\n",
      "         [ 1.2648e-01,  2.5363e-01,  1.9550e-01]],\n",
      "\n",
      "        [[ 3.0160e-01,  5.3666e-01,  3.6120e-01],\n",
      "         [ 5.4161e-01,  1.0099e+00,  7.1338e-01],\n",
      "         [ 4.4397e-01,  7.9727e-01,  6.1471e-01]],\n",
      "\n",
      "        [[-3.6742e-01, -2.7003e-01, -3.8921e-01],\n",
      "         [-3.6677e-01, -2.8369e-01, -4.7525e-01],\n",
      "         [-3.1633e-01, -3.4055e-01, -5.3645e-01]],\n",
      "\n",
      "        [[ 5.1027e-01,  9.6363e-01,  5.8431e-01],\n",
      "         [ 9.0241e-01,  1.6411e+00,  1.0302e+00],\n",
      "         [ 5.2644e-01,  9.0861e-01,  5.9657e-01]],\n",
      "\n",
      "        [[-9.0798e-02, -1.8239e-01, -2.1544e-01],\n",
      "         [-2.0051e-01, -2.1720e-01, -2.8198e-01],\n",
      "         [-1.3866e-01, -1.7832e-01, -1.8550e-01]],\n",
      "\n",
      "        [[ 2.6451e-01,  5.0334e-01,  3.9378e-01],\n",
      "         [ 4.7971e-01,  9.2779e-01,  6.8330e-01],\n",
      "         [ 3.3150e-01,  6.3521e-01,  4.2715e-01]],\n",
      "\n",
      "        [[ 2.0845e-01,  3.7025e-01,  2.6450e-01],\n",
      "         [ 2.5109e-01,  4.8951e-01,  3.6971e-01],\n",
      "         [ 6.5445e-02,  1.5348e-01,  1.0273e-01]],\n",
      "\n",
      "        [[-1.7211e-01, -1.8417e-01, -2.1571e-01],\n",
      "         [-1.9762e-01, -1.5805e-01, -2.9684e-01],\n",
      "         [-1.5060e-01, -1.4128e-01, -1.8403e-01]],\n",
      "\n",
      "        [[ 8.7272e-01,  1.2376e+00,  1.1556e+00],\n",
      "         [ 9.2474e-01,  1.5156e+00,  1.3597e+00],\n",
      "         [ 4.1450e-01,  6.9201e-01,  5.4225e-01]],\n",
      "\n",
      "        [[-2.5754e-01, -4.3446e-01, -3.7033e-01],\n",
      "         [-3.7719e-01, -6.9398e-01, -5.0036e-01],\n",
      "         [-8.9723e-02, -2.2624e-01, -1.5193e-01]],\n",
      "\n",
      "        [[ 6.1828e-02,  1.0206e-01,  7.7559e-02],\n",
      "         [ 1.5963e-01,  2.8707e-01,  1.8583e-01],\n",
      "         [ 1.0537e-01,  2.0564e-01,  1.2821e-01]],\n",
      "\n",
      "        [[-2.7601e-01, -3.9789e-01, -3.7637e-01],\n",
      "         [-4.6113e-01, -5.7116e-01, -5.6589e-01],\n",
      "         [-3.1711e-01, -5.5718e-01, -3.8284e-01]],\n",
      "\n",
      "        [[ 2.2186e+00,  2.6487e+00,  2.3744e+00],\n",
      "         [ 2.8563e+00,  4.5463e+00,  4.0641e+00],\n",
      "         [ 2.1959e+00,  4.3798e+00,  3.6447e+00]],\n",
      "\n",
      "        [[ 2.8486e-01,  4.0522e-01,  3.3527e-01],\n",
      "         [ 3.2712e-01,  6.1747e-01,  3.9522e-01],\n",
      "         [ 2.1223e-01,  2.9444e-01,  1.8221e-01]],\n",
      "\n",
      "        [[ 1.6156e-01,  1.8898e-01,  1.3960e-01],\n",
      "         [ 2.6019e-01,  3.9963e-01,  2.5667e-01],\n",
      "         [ 1.0735e-01,  1.2805e-01,  9.6652e-02]],\n",
      "\n",
      "        [[-4.6779e-01, -8.9275e-01, -5.0187e-01],\n",
      "         [-7.0191e-01, -1.3915e+00, -9.5358e-01],\n",
      "         [-3.3943e-01, -7.8051e-01, -5.5100e-01]],\n",
      "\n",
      "        [[ 6.8357e-01,  9.2558e-01,  8.0689e-01],\n",
      "         [ 1.0167e+00,  1.5339e+00,  1.3258e+00],\n",
      "         [ 8.2251e-01,  1.2787e+00,  1.0076e+00]],\n",
      "\n",
      "        [[-1.4911e-01, -2.6108e-01, -2.0313e-01],\n",
      "         [-2.6612e-01, -4.5652e-01, -3.4109e-01],\n",
      "         [-1.5485e-01, -2.7717e-01, -2.1474e-01]],\n",
      "\n",
      "        [[ 1.4115e-01,  2.1452e-01,  1.6551e-01],\n",
      "         [ 3.4891e-01,  6.0042e-01,  4.7773e-01],\n",
      "         [ 1.2830e-01,  2.7086e-01,  2.0941e-01]],\n",
      "\n",
      "        [[ 7.4759e-02,  1.2544e-01,  1.0670e-01],\n",
      "         [ 1.2124e-01,  2.2516e-01,  1.7763e-01],\n",
      "         [ 8.1250e-02,  1.3270e-01,  1.1998e-01]],\n",
      "\n",
      "        [[-8.1312e-02, -1.5577e-01, -1.2401e-01],\n",
      "         [-1.8102e-01, -4.4455e-01, -2.9142e-01],\n",
      "         [-1.1075e-01, -2.8295e-01, -1.9545e-01]],\n",
      "\n",
      "        [[-4.1803e-01, -1.3679e-02,  4.7865e-01],\n",
      "         [-7.0322e-01, -1.7733e-02,  6.8298e-01],\n",
      "         [-4.0029e-01, -3.0048e-02,  5.1205e-01]],\n",
      "\n",
      "        [[ 1.0983e-01,  2.1534e-01,  1.8165e-01],\n",
      "         [ 1.9189e-01,  4.0680e-01,  3.1220e-01],\n",
      "         [ 1.2994e-01,  2.4043e-01,  1.8894e-01]],\n",
      "\n",
      "        [[ 2.4771e-01,  4.4819e-01,  3.4959e-01],\n",
      "         [ 3.3838e-02,  2.2511e-02,  1.4724e-02],\n",
      "         [-2.5429e-01, -5.4315e-01, -3.8433e-01]],\n",
      "\n",
      "        [[ 1.2777e-01,  1.9572e-01,  1.5484e-01],\n",
      "         [ 1.9125e-01,  3.7964e-01,  2.5054e-01],\n",
      "         [ 1.1457e-01,  1.8537e-01,  1.1610e-01]],\n",
      "\n",
      "        [[-3.1989e-02, -9.4866e-02, -5.1861e-02],\n",
      "         [-1.2250e-01, -2.5892e-01, -1.8803e-01],\n",
      "         [-1.1800e-01, -1.8611e-01, -1.4983e-01]],\n",
      "\n",
      "        [[ 5.2145e-01,  6.1959e-01,  5.2440e-01],\n",
      "         [ 7.9946e-01,  1.3654e+00,  7.8141e-01],\n",
      "         [ 6.7688e-01,  8.5215e-01,  6.0291e-01]],\n",
      "\n",
      "        [[ 1.0379e-01,  3.8253e-01,  2.4853e-01],\n",
      "         [ 5.8662e-01,  1.2016e+00,  8.0238e-01],\n",
      "         [ 3.6297e-01,  7.8931e-01,  6.4504e-01]],\n",
      "\n",
      "        [[ 1.9901e-01,  3.1926e-01,  2.1656e-01],\n",
      "         [ 2.8360e-01,  5.2073e-01,  3.3693e-01],\n",
      "         [ 1.7444e-01,  3.1529e-01,  2.3384e-01]],\n",
      "\n",
      "        [[ 2.9192e-01,  5.4825e-01,  3.5442e-01],\n",
      "         [ 5.0679e-03,  1.2940e-01,  4.6757e-02],\n",
      "         [-2.9397e-01, -5.9961e-01, -4.0925e-01]],\n",
      "\n",
      "        [[-1.7577e+00, -2.4201e+00, -2.3570e+00],\n",
      "         [-3.1519e+00, -3.6775e+00, -3.5065e+00],\n",
      "         [-2.2850e+00, -3.2405e+00, -2.3479e+00]],\n",
      "\n",
      "        [[ 6.7307e-01,  1.1665e+00,  7.8430e-01],\n",
      "         [ 1.0731e+00,  1.8146e+00,  1.3480e+00],\n",
      "         [ 5.9505e-01,  1.1346e+00,  8.9172e-01]],\n",
      "\n",
      "        [[-1.7307e-01, -2.3161e-01, -1.8844e-01],\n",
      "         [-2.2713e-01, -2.3951e-01, -2.7552e-01],\n",
      "         [-1.6053e-01, -2.0188e-01, -2.1637e-01]],\n",
      "\n",
      "        [[ 3.2058e-01,  7.6391e-01,  6.3170e-01],\n",
      "         [-2.4300e-01, -1.2126e-01,  3.5634e-01],\n",
      "         [-5.0013e-01, -1.0739e+00, -2.0966e-01]],\n",
      "\n",
      "        [[ 3.2788e+00,  3.7947e+00,  3.0146e+00],\n",
      "         [ 4.1533e+00,  5.4133e+00,  3.9825e+00],\n",
      "         [ 2.2937e+00,  3.6725e+00,  3.1008e+00]],\n",
      "\n",
      "        [[-1.4033e-01, -2.2687e-01, -1.7092e-01],\n",
      "         [-2.3085e-01, -3.8845e-01, -2.8205e-01],\n",
      "         [-1.3171e-01, -2.6544e-01, -1.6716e-01]],\n",
      "\n",
      "        [[-1.9607e-01, -3.9254e-01, -2.5663e-01],\n",
      "         [ 2.0669e-02, -2.2681e-02,  3.2911e-02],\n",
      "         [ 2.2386e-01,  4.8530e-01,  3.3303e-01]],\n",
      "\n",
      "        [[ 9.4491e-02,  1.5368e-01,  7.4843e-02],\n",
      "         [ 1.4640e-01,  3.1783e-01,  1.6283e-01],\n",
      "         [ 8.5138e-02,  1.9261e-01,  1.0943e-01]],\n",
      "\n",
      "        [[ 1.0293e+00,  1.3119e+00,  1.2142e+00],\n",
      "         [ 1.5059e+00,  1.8536e+00,  1.6652e+00],\n",
      "         [ 1.1853e+00,  1.6404e+00,  1.7797e+00]],\n",
      "\n",
      "        [[-2.3851e-01, -3.3724e-01, -2.6656e-01],\n",
      "         [-3.8328e-01, -5.6267e-01, -4.4083e-01],\n",
      "         [-2.8508e-01, -4.4895e-01, -2.9918e-01]],\n",
      "\n",
      "        [[-2.1921e-01, -3.5443e-01, -1.8204e-01],\n",
      "         [-3.4490e-01, -3.5680e-01, -4.1470e-01],\n",
      "         [-3.9094e-01, -4.9040e-01, -3.9725e-01]],\n",
      "\n",
      "        [[ 1.5835e-01,  3.3292e-01,  1.9874e-01],\n",
      "         [ 2.8040e-01,  5.5566e-01,  3.5029e-01],\n",
      "         [ 1.5976e-01,  2.8669e-01,  1.8287e-01]],\n",
      "\n",
      "        [[-1.5002e-01, -2.2742e-01, -2.6062e-01],\n",
      "         [-3.2750e-01, -3.5064e-01, -3.7187e-01],\n",
      "         [-2.2323e-01, -4.1461e-01, -3.1666e-01]],\n",
      "\n",
      "        [[ 1.3760e-01,  1.8734e-01,  1.6112e-01],\n",
      "         [ 2.2490e-01,  3.6782e-01,  2.7096e-01],\n",
      "         [ 1.6961e-01,  2.3951e-01,  2.0373e-01]],\n",
      "\n",
      "        [[-6.3881e-02, -1.3918e-01, -1.3546e-01],\n",
      "         [-1.2322e-01, -2.7543e-01, -2.1383e-01],\n",
      "         [-5.6307e-02, -1.5217e-01, -9.0247e-02]],\n",
      "\n",
      "        [[ 9.4614e-02,  1.7148e-01,  1.2376e-01],\n",
      "         [ 1.5591e-01,  2.8256e-01,  2.1796e-01],\n",
      "         [ 7.2704e-02,  1.5991e-01,  1.1171e-01]],\n",
      "\n",
      "        [[ 2.6260e-01, -1.2884e-01, -3.6156e-01],\n",
      "         [ 5.1695e-01,  1.0835e-01, -6.4415e-01],\n",
      "         [ 3.5823e-01,  3.2781e-01, -2.9842e-01]],\n",
      "\n",
      "        [[-1.5330e-01, -2.3021e-01,  2.7147e-01],\n",
      "         [-4.5889e-01, -6.2514e-02,  6.2814e-01],\n",
      "         [-3.0768e-01,  2.7596e-01,  4.7893e-01]]]) conv_bias: tensor([ 1.2300e-01,  1.3247e+00,  1.1235e+00,  1.5955e-01,  1.8030e+00,\n",
      "        -4.1365e-01,  1.8939e+00, -3.5551e-02,  5.2475e+00,  4.0115e+00,\n",
      "         1.0986e-01,  9.2991e-02,  1.4425e+00,  1.1674e-01, -1.4947e+00,\n",
      "         8.5195e-01, -3.4526e-01,  1.0068e-01,  2.1548e+00,  3.3324e-02,\n",
      "         1.0482e-01,  2.5535e+00,  7.2500e-02, -2.4327e-01,  5.5806e-01,\n",
      "         2.1340e+00, -1.6768e-01,  9.7804e-03,  1.3609e+00, -1.3756e-01,\n",
      "         1.0165e+00,  8.9900e-02,  1.5884e+00,  3.6393e-01, -1.5423e+00,\n",
      "        -2.0420e-01,  5.9263e-02,  5.5439e-02,  8.1669e-01,  1.0842e+01,\n",
      "         1.0418e-01,  2.9996e+00,  2.2051e-03,  1.8028e+00, -4.5777e-01,\n",
      "         1.0476e-01,  2.5502e+00,  1.3969e-01,  1.8141e-02,  1.1589e-01,\n",
      "         1.0647e+00,  6.1506e-02,  1.4697e+00,  6.4487e-02,  5.7282e-02,\n",
      "         1.0220e+00,  5.6169e-02,  3.6764e+00, -3.6536e-01,  1.1900e+00,\n",
      "         1.1418e-01,  9.9102e-02,  1.4507e-01,  4.2960e+00,  5.8495e-02,\n",
      "         3.7024e+00,  1.0622e-01, -1.6901e-02,  6.1806e+00, -2.2141e-01,\n",
      "         1.2272e-01,  3.5387e+00,  1.2122e-01,  1.4714e+00,  1.1583e-01,\n",
      "        -1.5689e-01,  1.1312e-01,  3.3901e-01,  3.5550e+00,  2.9090e-02,\n",
      "         2.0127e+00, -1.6843e-01,  1.7983e-01,  1.7256e+00,  2.3429e+00,\n",
      "         1.6424e-02, -1.7602e-01,  2.6798e+00,  1.2568e+00,  6.6622e-02,\n",
      "         1.8662e+00,  3.3176e-02,  4.2378e+00,  3.3481e-02,  3.3355e+00,\n",
      "         1.8081e+00])\n",
      "torch.Size([96, 1, 3, 3]) torch.Size([96])\n",
      "q_weight: tensor([  59,   78,   65,   75,  114,   92,   48,   69,   59,  -29,  -49,  -46,\n",
      "         -66, -100,  -66,  -35,  -61,  -57,  -64,  -74,  -94,  -83,  -41, -104,\n",
      "         -77,  -65, -114,   35,   54,   49,   67,   99,   82,   48,   54,   52,\n",
      "         -28,  -56,  -36,  -45,  -83,  -65,  -31,  -51,  -36,   18,   24,   24,\n",
      "          39,   67,   51,   32,   57,   43,  -18,  -48,  -41,  -42,  -90,  -63,\n",
      "         -12,  -55,  -32,  -24,  -42,  -35,   45,   83,   51,  -18,  -49,  -20,\n",
      "         -24,  -50,  -37,  -50, -100,  -65,  -37,  -61,  -45,  -35,  -65,  -30,\n",
      "         -54, -102,  -50,  -36,  -65,  -34,   28,   48,   39,   44,   94,   64,\n",
      "          43,   74,   57,   38,   60,   47,   66,  115,   76,   49,   65,   48,\n",
      "         -53,  -81,  -48,  -73,  -94,  -85,  -41,  -93,  -52,   32,   50,   38,\n",
      "          60,  108,   82,   28,   55,   42,   17,   25,   21,   36,   73,   49,\n",
      "          20,   37,   24,  -40,  -44,  -43,  -21,  -44,  -28,   53,   86,   71,\n",
      "         -26,  -29,   36,  -16,  -44,   76,  -25,  -37,   46,   31,   65,   37,\n",
      "          54,  115,   67,   29,   47,   29,  -33,  -43,  -36,  -51,  -66,  -60,\n",
      "         -44,  -52,  -50,   22,   54,   36,   43,  111,   57,   31,   63,   32,\n",
      "          44,   88,   60,   63,  112,   80,   43,   68,   51,  -45,  -56,  -55,\n",
      "         -63,  -69,  -70,  -50,  -68,  -70,   29,   58,   36,   49,   98,   56,\n",
      "          32,   54,   31,  -17,  -26,  -18,   -1,    7,    0,   23,   44,   30,\n",
      "          41,   72,   44,    2,   12,   -2,  -42,  -59,  -48,  -24,   -9,   48,\n",
      "         -43,   -5,  101,  -28,   -8,   62,   64,   10,  -81,   89,    4,  -94,\n",
      "          56,   12,  -63,   22,   35,   27,   51,   88,   62,   34,   52,   39,\n",
      "         -47,  -50,  -58,  -78,  -83,  -96,  -65,  -79,  -82,  -32,  -39,  -31,\n",
      "         -21,  -18,  -15,   53,   93,   68,  -49,  -85,  -65,    4,   12,   10,\n",
      "          33,   83,   57,   32,   61,   39,   57,  107,   69,   33,   64,   45,\n",
      "         -34,  -61,  -41,  -66,  -52,  -78,  -49,  -97,  -70,   32,   41,   36,\n",
      "          69,   88,   75,   58,   67,   61,   50,   66,   64,   52,  101,   56,\n",
      "          43,   67,   46,  -29,  -20,   32,  -32,  -29,   64,  -23,  -23,   44,\n",
      "          30,   59,   50,   48,   92,   78,   43,   74,   64,   33,   63,   41,\n",
      "          50,  102,   68,   29,   57,   38,   53,  115,   77,    6,   52,   34,\n",
      "         -58,  -99,  -76,  -33,   11,  -46,    4,   42,  -14,  -39,   -1,  -66,\n",
      "          34,   46,   45,   58,  102,   82,   24,   45,   33,  -29,  -80,  -59,\n",
      "         -55, -107,  -71,  -46,  -78,  -37,   15,   44,   16,   28,  123,   42,\n",
      "          23,   82,   35,  -56,  -91,  -73,  -72,  -90, -107,  -48,  -96,  -73,\n",
      "          39,  -22,  -41,   77,  -18,  -44,   45,  -23,  -34,   45,  104,   70,\n",
      "          58,  123,   75,   27,   48,   26,   63,  105,   48,    2,  -31,  -44,\n",
      "         -54, -103,  -91,   35,   63,   41,   73,  112,   73,   57,   83,   59,\n",
      "          22,   61,   44,   43,  105,   79,   36,   73,   56,   30,   53,   36,\n",
      "          54,  100,   71,   44,   79,   61,  -77,  -57,  -82,  -77,  -60, -100,\n",
      "         -66,  -71, -113,   31,   59,   36,   55,  100,   63,   32,   56,   37,\n",
      "         -32,  -65,  -76,  -71,  -77, -100,  -49,  -63,  -66,   28,   53,   42,\n",
      "          51,   98,   72,   35,   67,   45,   50,   89,   64,   60,  118,   89,\n",
      "          16,   37,   25,  -63,  -68,  -79,  -73,  -58, -109,  -55,  -52,  -68,\n",
      "          54,   77,   71,   57,   94,   84,   26,   43,   34,  -42,  -71,  -60,\n",
      "         -61, -113,  -81,  -15,  -37,  -25,   25,   42,   32,   65,  117,   76,\n",
      "          43,   84,   52,  -49,  -70,  -66,  -81, -101, -100,  -56,  -98,  -67,\n",
      "          27,   33,   29,   35,   56,   50,   27,   54,   45,   51,   72,   60,\n",
      "          58,  110,   71,   38,   53,   33,   34,   40,   30,   55,   85,   54,\n",
      "          23,   27,   20,  -25,  -48,  -27,  -38,  -75,  -51,  -18,  -42,  -30,\n",
      "          43,   58,   51,   64,   96,   83,   52,   80,   63,  -31,  -55,  -43,\n",
      "         -56,  -96,  -72,  -32,  -58,  -45,   26,   39,   30,   63,  109,   86,\n",
      "          23,   49,   38,   37,   63,   53,   61,  112,   89,   41,   66,   60,\n",
      "         -16,  -30,  -24,  -35,  -87,  -57,  -22,  -55,  -38,  -67,   -2,   77,\n",
      "        -113,   -3,  110,  -64,   -5,   82,   29,   57,   48,   50,  107,   82,\n",
      "          34,   63,   50,   37,   67,   53,    5,    3,    2,  -38,  -82,  -58,\n",
      "          38,   58,   46,   56,  112,   74,   34,   55,   34,  -13,  -38,  -21,\n",
      "         -49, -103,  -75,  -47,  -74,  -59,   34,   40,   34,   52,   89,   51,\n",
      "          44,   56,   39,    8,   30,   20,   46,   95,   64,   29,   62,   51,\n",
      "          45,   72,   49,   64,  118,   76,   40,   71,   53,   39,   72,   47,\n",
      "           1,   17,    6,  -39,  -79,  -54,  -32,  -44,  -42,  -57,  -66,  -63,\n",
      "         -41,  -58,  -42,   29,   50,   34,   46,   78,   58,   26,   49,   38,\n",
      "         -70,  -94,  -76,  -92,  -97, -112,  -65,  -82,  -88,   32,   75,   62,\n",
      "         -24,  -12,   35,  -49, -106,  -21,   27,   32,   25,   35,   45,   33,\n",
      "          19,   31,   26,  -42,  -69,  -52,  -70, -118,  -85,  -40,  -80,  -51,\n",
      "         -35,  -71,  -46,    4,   -4,    6,   40,   87,   60,   36,   58,   28,\n",
      "          56,  121,   62,   32,   73,   41,   30,   38,   35,   44,   54,   49,\n",
      "          35,   48,   52,  -43,  -61,  -48,  -70, -102,  -80,  -52,  -82,  -54,\n",
      "         -49,  -79,  -41,  -77,  -80,  -93,  -87, -110,  -89,   32,   67,   40,\n",
      "          57,  113,   71,   32,   58,   37,  -41,  -63,  -72,  -91,  -97, -103,\n",
      "         -62, -115,  -88,   41,   56,   48,   67,  110,   81,   50,   71,   61,\n",
      "         -20,  -44,  -43,  -39,  -87,  -68,  -18,  -48,  -29,   25,   46,   33,\n",
      "          42,   75,   58,   19,   43,   30,   31,  -15,  -42,   60,   13,  -75,\n",
      "          42,   38,  -35,  -23,  -35,   41,  -69,   -9,   94,  -46,   41,   72],\n",
      "       dtype=torch.int32) q_bias: tensor([  195,  1981,  2847,   188,  1480,  -597,  2565,   -41,  8830,  4389,\n",
      "           86,   254,  2888,   188, -1547,   153,  -295,   271,   480,   121,\n",
      "          409,   896,   169,  -218,   720,  2856,  -252,    16,   467,  -198,\n",
      "         1203,   174,  2893,    59, -2641,  -170,    21,    69,  1638,  3357,\n",
      "          223,  4216,     6,  3786,  -430,   192,  4987,   165,    40,    88,\n",
      "         1712,    29,  3997,    52,   105,  2884,    27,  4573, -1140,  1607,\n",
      "           11,   136,   236,  1767,    28,  5949,   147,   -65,  9227,  -273,\n",
      "          247,  4078,   273,  4477,    58,   -95,   196,   343,   491,    10,\n",
      "         6261,  -127,    11,  4000,  3235,    48,   -39,  3734,  2152,   103,\n",
      "         3955,    76, 10262,    68,  2977,  2081], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0001) tensor(0.0367)   bias tensor(2.5769e-05) tensor(0.0075)\n",
      "features.7.conv.6.weight features.7.conv.8\n",
      "torch.Size([32, 96, 1, 1]) conv_bias= torch.Size([32]) \n",
      "ascale= tensor([0.1375]) torch.Size([1]) \n",
      "wscale= tensor([0.0042, 0.0035, 0.0027, 0.0037, 0.0028, 0.0036, 0.0036, 0.0041, 0.0046,\n",
      "        0.0036, 0.0038, 0.0039, 0.0034, 0.0020, 0.0034, 0.0040, 0.0028, 0.0041,\n",
      "        0.0037, 0.0036, 0.0036, 0.0031, 0.0044, 0.0043, 0.0034, 0.0034, 0.0045,\n",
      "        0.0032, 0.0040, 0.0049, 0.0042, 0.0041]) torch.Size([32, 1, 1, 1]) \n",
      "oscale= tensor([0.0756]) torch.Size([1])\n",
      "###: M= tensor([0.0076, 0.0064, 0.0050, 0.0068, 0.0050, 0.0065, 0.0065, 0.0075, 0.0084,\n",
      "        0.0066, 0.0069, 0.0071, 0.0062, 0.0037, 0.0062, 0.0072, 0.0051, 0.0074,\n",
      "        0.0067, 0.0065, 0.0065, 0.0057, 0.0080, 0.0079, 0.0062, 0.0062, 0.0082,\n",
      "        0.0059, 0.0073, 0.0089, 0.0076, 0.0075])\n",
      "torch.Size([32, 96, 1, 1]) torch.Size([32])\n",
      "conv_weight: tensor([[ 0.0595,  0.0406, -0.0158,  ...,  0.1070,  0.0780, -0.0996],\n",
      "        [ 0.1122,  0.0325, -0.1820,  ...,  0.1799,  0.0181,  0.0336],\n",
      "        [ 0.0871,  0.1423, -0.0503,  ...,  0.1409, -0.1152, -0.0809],\n",
      "        ...,\n",
      "        [ 0.0557, -0.0149, -0.0725,  ..., -0.0129, -0.0314,  0.0101],\n",
      "        [ 0.0104,  0.0722,  0.0574,  ..., -0.0867, -0.1636, -0.1605],\n",
      "        [ 0.0574,  0.0791, -0.0344,  ...,  0.0316,  0.0026, -0.0449]]) conv_bias: tensor([-0.5777, -1.0392,  1.9721,  2.2052, -1.1744, -2.0495, -2.5472, -0.2167,\n",
      "        -1.4256,  0.1894,  1.2169,  0.3531, -1.1309,  0.0679,  1.6199,  0.8189,\n",
      "         0.4455, -0.6788,  2.1807,  2.8870, -0.5658, -0.7143, -1.4554,  0.7240,\n",
      "         0.3851, -1.8316, -2.1934,  4.3387, -3.8285,  0.4399,  0.7107,  0.3483])\n",
      "torch.Size([32, 96, 1, 1]) torch.Size([32])\n",
      "q_weight: tensor([ 14,  10,  -4,  ...,   8,   1, -11], dtype=torch.int32) q_bias: tensor([-1003, -2148,  5263,  4298, -3084, -4158, -5167,  -384, -2255,   380,\n",
      "         2348,   660, -2423,   245,  3454,  1502,  1156, -1217,  4322,  5905,\n",
      "        -1153, -1654, -2400,  1217,   824, -3902, -3558,  9777, -6920,   655,\n",
      "         1233,   615], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-8.9188e-07) tensor(0.0024)   bias tensor(3.3757e-05) tensor(0.0003)\n",
      "features.8.conv.0.weight features.8.conv.2\n",
      "torch.Size([192, 32, 1, 1]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.0756]) torch.Size([1]) \n",
      "wscale= tensor([1.9507e-03, 5.0905e-03, 3.4475e-03, 2.5965e-03, 3.2100e-03, 1.5862e-03,\n",
      "        2.2680e-03, 1.9651e-03, 2.5443e-03, 5.6661e-03, 2.7493e-03, 4.8285e-03,\n",
      "        5.8041e-07, 4.0169e-03, 1.6936e-03, 4.0619e-03, 2.3623e-03, 1.4162e-03,\n",
      "        2.2130e-03, 1.9366e-03, 6.8256e-03, 1.7598e-03, 3.0398e-03, 2.1040e-03,\n",
      "        3.7166e-03, 2.9135e-03, 2.0790e-03, 2.1163e-03, 1.8586e-03, 4.4026e-03,\n",
      "        1.5465e-03, 2.0002e-03, 8.6059e-03, 1.7841e-03, 2.7641e-03, 2.7417e-03,\n",
      "        1.3020e-03, 1.7158e-03, 2.1133e-03, 1.1931e-03, 2.5751e-03, 1.9203e-03,\n",
      "        2.1496e-03, 2.3325e-03, 3.1463e-03, 2.8126e-03, 1.1382e-03, 3.0676e-03,\n",
      "        2.4373e-03, 2.0093e-03, 1.5855e-03, 1.4264e-03, 3.0139e-03, 1.9335e-03,\n",
      "        2.8134e-03, 1.2861e-03, 1.6069e-03, 3.6032e-03, 1.1921e-07, 7.5455e-03,\n",
      "        1.5446e-03, 2.8966e-03, 1.8306e-03, 3.8670e-03, 2.2695e-03, 1.7681e-03,\n",
      "        1.7301e-03, 2.4911e-03, 2.1600e-03, 3.3455e-03, 3.9295e-03, 4.6661e-03,\n",
      "        2.0683e-03, 1.9012e-03, 4.8505e-03, 4.9097e-03, 2.1396e-03, 2.0255e-03,\n",
      "        2.4789e-03, 1.9543e-03, 1.0464e-03, 1.9318e-03, 3.6854e-03, 2.7160e-03,\n",
      "        2.4640e-03, 1.8132e-03, 1.7269e-03, 3.5209e-03, 1.5585e-03, 2.9007e-03,\n",
      "        2.1123e-03, 1.8746e-03, 6.2305e-03, 2.2990e-03, 2.2983e-03, 1.4143e-03,\n",
      "        1.7808e-03, 2.2599e-06, 6.8038e-03, 2.0515e-03, 2.7188e-03, 1.6350e-03,\n",
      "        1.8519e-03, 2.5208e-03, 3.6592e-03, 2.2651e-03, 2.3089e-03, 3.4291e-03,\n",
      "        4.4222e-03, 3.8303e-03, 5.5000e-03, 1.5350e-03, 2.7149e-03, 1.5286e-03,\n",
      "        5.0986e-03, 4.7002e-03, 1.2575e-03, 4.2231e-06, 3.4205e-03, 1.8138e-03,\n",
      "        2.8352e-03, 3.8383e-03, 2.2936e-03, 1.3627e-02, 2.8107e-03, 2.5511e-07,\n",
      "        3.4515e-03, 1.9670e-03, 4.0120e-03, 1.7096e-03, 2.3894e-03, 2.6896e-03,\n",
      "        1.3594e-03, 1.1491e-03, 3.8981e-03, 1.7303e-03, 3.2275e-03, 4.5609e-03,\n",
      "        1.9117e-03, 2.8571e-03, 2.0527e-03, 1.2070e-06, 2.6374e-03, 2.2459e-03,\n",
      "        1.4059e-03, 3.4383e-03, 2.4395e-03, 2.4190e-03, 2.3181e-03, 2.2252e-03,\n",
      "        2.1138e-03, 1.7482e-03, 3.7373e-03, 1.4288e-03, 2.6137e-03, 1.9151e-03,\n",
      "        5.5333e-03, 2.6013e-03, 2.7892e-03, 1.9729e-03, 1.3417e-03, 1.6585e-06,\n",
      "        2.0361e-03, 3.7953e-03, 1.5149e-06, 5.7896e-03, 5.6888e-03, 2.6859e-03,\n",
      "        2.8880e-03, 1.2910e-03, 2.5887e-03, 2.5256e-03, 2.2007e-03, 7.0066e-03,\n",
      "        2.0093e-03, 2.8186e-03, 4.3690e-03, 1.0653e-03, 2.5243e-03, 2.6568e-03,\n",
      "        2.3357e-03, 1.8958e-03, 6.2058e-03, 3.1076e-03, 1.6255e-03, 2.0230e-03,\n",
      "        2.7790e-03, 1.6449e-03, 1.4181e-03, 2.1848e-03, 5.1217e-03, 4.3782e-03]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0861]) torch.Size([1])\n",
      "###: M= tensor([1.7134e-03, 4.4714e-03, 3.0283e-03, 2.2808e-03, 2.8196e-03, 1.3933e-03,\n",
      "        1.9922e-03, 1.7262e-03, 2.2349e-03, 4.9770e-03, 2.4149e-03, 4.2413e-03,\n",
      "        5.0982e-07, 3.5284e-03, 1.4876e-03, 3.5679e-03, 2.0750e-03, 1.2439e-03,\n",
      "        1.9439e-03, 1.7011e-03, 5.9955e-03, 1.5458e-03, 2.6701e-03, 1.8482e-03,\n",
      "        3.2646e-03, 2.5592e-03, 1.8262e-03, 1.8589e-03, 1.6325e-03, 3.8672e-03,\n",
      "        1.3584e-03, 1.7570e-03, 7.5593e-03, 1.5672e-03, 2.4280e-03, 2.4082e-03,\n",
      "        1.1437e-03, 1.5071e-03, 1.8563e-03, 1.0480e-03, 2.2619e-03, 1.6868e-03,\n",
      "        1.8882e-03, 2.0488e-03, 2.7637e-03, 2.4705e-03, 9.9979e-04, 2.6945e-03,\n",
      "        2.1408e-03, 1.7650e-03, 1.3927e-03, 1.2529e-03, 2.6473e-03, 1.6983e-03,\n",
      "        2.4713e-03, 1.1297e-03, 1.4115e-03, 3.1650e-03, 1.0471e-07, 6.6278e-03,\n",
      "        1.3567e-03, 2.5444e-03, 1.6079e-03, 3.3967e-03, 1.9935e-03, 1.5531e-03,\n",
      "        1.5197e-03, 2.1882e-03, 1.8973e-03, 2.9386e-03, 3.4517e-03, 4.0986e-03,\n",
      "        1.8168e-03, 1.6700e-03, 4.2606e-03, 4.3126e-03, 1.8794e-03, 1.7792e-03,\n",
      "        2.1774e-03, 1.7167e-03, 9.1915e-04, 1.6968e-03, 3.2372e-03, 2.3857e-03,\n",
      "        2.1644e-03, 1.5927e-03, 1.5169e-03, 3.0927e-03, 1.3690e-03, 2.5479e-03,\n",
      "        1.8554e-03, 1.6467e-03, 5.4727e-03, 2.0194e-03, 2.0187e-03, 1.2423e-03,\n",
      "        1.5642e-03, 1.9850e-06, 5.9763e-03, 1.8020e-03, 2.3882e-03, 1.4361e-03,\n",
      "        1.6267e-03, 2.2143e-03, 3.2142e-03, 1.9896e-03, 2.0281e-03, 3.0121e-03,\n",
      "        3.8844e-03, 3.3645e-03, 4.8311e-03, 1.3483e-03, 2.3847e-03, 1.3427e-03,\n",
      "        4.4785e-03, 4.1286e-03, 1.1045e-03, 3.7095e-06, 3.0045e-03, 1.5933e-03,\n",
      "        2.4904e-03, 3.3715e-03, 2.0146e-03, 1.1970e-02, 2.4689e-03, 2.2409e-07,\n",
      "        3.0318e-03, 1.7278e-03, 3.5241e-03, 1.5017e-03, 2.0988e-03, 2.3625e-03,\n",
      "        1.1941e-03, 1.0093e-03, 3.4240e-03, 1.5199e-03, 2.8350e-03, 4.0062e-03,\n",
      "        1.6792e-03, 2.5097e-03, 1.8030e-03, 1.0602e-06, 2.3166e-03, 1.9728e-03,\n",
      "        1.2349e-03, 3.0202e-03, 2.1428e-03, 2.1248e-03, 2.0362e-03, 1.9545e-03,\n",
      "        1.8567e-03, 1.5356e-03, 3.2828e-03, 1.2550e-03, 2.2958e-03, 1.6822e-03,\n",
      "        4.8604e-03, 2.2849e-03, 2.4500e-03, 1.7330e-03, 1.1785e-03, 1.4568e-06,\n",
      "        1.7885e-03, 3.3337e-03, 1.3306e-06, 5.0855e-03, 4.9970e-03, 2.3593e-03,\n",
      "        2.5368e-03, 1.1340e-03, 2.2739e-03, 2.2185e-03, 1.9330e-03, 6.1545e-03,\n",
      "        1.7649e-03, 2.4758e-03, 3.8376e-03, 9.3574e-04, 2.2173e-03, 2.3337e-03,\n",
      "        2.0517e-03, 1.6653e-03, 5.4511e-03, 2.7297e-03, 1.4278e-03, 1.7770e-03,\n",
      "        2.4410e-03, 1.4448e-03, 1.2456e-03, 1.9191e-03, 4.4988e-03, 3.8457e-03])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "conv_weight: tensor([[ 0.0276, -0.0601,  0.1901,  ...,  0.0401, -0.1216,  0.0208],\n",
      "        [-0.0508, -0.0716, -0.0290,  ..., -0.2385, -0.2218, -0.0086],\n",
      "        [ 0.0410, -0.0544,  0.3834,  ..., -0.0808,  0.0892, -0.0037],\n",
      "        ...,\n",
      "        [-0.0961,  0.0191,  0.0699,  ..., -0.1545,  0.1467,  0.1342],\n",
      "        [ 0.1921,  0.3698,  0.2264,  ...,  0.3649, -0.1411,  0.2811],\n",
      "        [ 0.0157, -0.1277, -0.2840,  ...,  0.0106, -0.1171, -0.3330]]) conv_bias: tensor([ 1.0430e+00,  3.1641e-01,  4.7539e-01,  9.0404e-01,  1.3380e+00,\n",
      "         9.3013e-01,  6.9311e-01,  8.8245e-01,  1.0292e+00, -3.7791e-01,\n",
      "         2.0621e-01, -3.6725e-02, -1.2811e-03, -4.2746e-01,  5.8879e-01,\n",
      "        -7.0887e-02,  1.0421e+00,  1.1473e+00,  4.8530e-01,  9.2269e-01,\n",
      "        -2.5891e-01,  1.2706e+00,  4.7024e-01,  6.5160e-01, -3.3582e-01,\n",
      "         2.8056e-01,  8.8247e-01, -6.2387e-01,  5.8011e-01,  8.9913e-03,\n",
      "         8.8723e-01,  8.4589e-01,  5.9247e-01,  1.8140e+00, -4.2250e-01,\n",
      "        -1.4144e-01,  7.5216e-01,  6.2593e-01,  5.9099e-01,  1.1011e+00,\n",
      "         1.3684e+00,  4.3691e-01,  6.0899e-01,  5.3300e-01,  8.8856e-01,\n",
      "         9.0708e-01,  1.1769e+00, -3.0598e-01,  4.7707e-01,  1.0899e+00,\n",
      "         8.2352e-01,  1.0134e+00,  1.0503e+00,  6.9228e-01,  9.8400e-01,\n",
      "         8.0467e-01,  7.9181e-01,  2.4435e-01, -5.8495e-04,  7.9886e-02,\n",
      "         6.3517e-01,  7.6865e-01,  9.5652e-01,  8.7161e-01,  7.4900e-01,\n",
      "         9.7290e-01,  3.5349e-01,  4.3184e-01,  8.4326e-01,  4.5363e-01,\n",
      "        -1.0362e-01, -2.0470e-01,  1.2098e+00,  7.2222e-01,  5.8826e-02,\n",
      "         1.2462e+00,  1.0395e+00,  8.9190e-01,  1.0739e+00,  4.2501e-01,\n",
      "         9.1570e-01,  5.1089e-01,  9.7138e-02,  3.7120e-01,  5.7283e-01,\n",
      "         8.2536e-01,  7.4014e-01,  5.8180e-01,  7.2989e-01,  8.0580e-01,\n",
      "         7.6312e-01, -4.1000e-01, -1.1536e-01,  7.7349e-01,  1.4043e+00,\n",
      "         9.0427e-01,  8.5162e-01, -3.5906e-03, -1.0089e-01,  9.6818e-01,\n",
      "         7.6624e-01,  9.3359e-01,  1.1186e+00,  8.9899e-01,  1.0396e-01,\n",
      "         8.3594e-01,  7.7377e-01,  4.8322e-01,  2.8460e-01, -4.6920e-01,\n",
      "         5.4895e-02,  1.3491e+00,  8.3845e-01,  7.3297e-01,  3.1538e-01,\n",
      "         3.4825e-01,  7.4619e-01, -4.6424e-03,  4.9621e-01,  7.2701e-01,\n",
      "         8.1145e-01,  2.7706e-01,  5.7557e-01,  4.5483e-01,  1.0130e+00,\n",
      "        -8.6744e-04,  8.7587e-01,  1.3769e+00,  7.9182e-01,  7.4128e-01,\n",
      "         9.7551e-01,  8.4641e-01,  1.1090e+00,  7.3086e-01, -3.4090e-01,\n",
      "         9.2038e-01, -3.8579e-01,  1.5233e-01,  6.8030e-01,  4.3692e-01,\n",
      "         5.5078e-01, -1.6282e-03,  5.5965e-01,  1.1881e+00,  7.6792e-01,\n",
      "         1.1336e+00,  2.7805e-01,  2.5690e-01,  1.1023e+00,  2.2979e-01,\n",
      "         9.1723e-01, -6.3418e-01,  1.0027e+00,  1.8129e+00,  1.0138e+00,\n",
      "         8.6676e-01,  1.5574e-01,  7.8523e-01,  9.1948e-01,  9.0372e-01,\n",
      "         9.8445e-01, -2.3226e-03,  1.1648e+00, -1.4081e-01, -2.4539e-03,\n",
      "        -6.0301e-02, -3.7394e-02,  1.3397e+00,  9.0509e-01,  9.1307e-01,\n",
      "         6.8260e-01,  1.3486e+00,  1.0251e+00,  1.2901e-01,  5.9743e-01,\n",
      "         1.0098e+00,  1.9693e-01,  1.2977e+00, -6.6313e-01, -4.9207e-01,\n",
      "         4.2700e-01,  6.2004e-01, -4.0189e-01,  2.4981e-01,  6.2698e-01,\n",
      "         8.0413e-01,  5.4543e-01,  9.3186e-01,  7.4544e-01,  7.0976e-01,\n",
      "        -7.6508e-02, -2.3435e-01])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "q_weight: tensor([ 14, -31,  97,  ...,   2, -27, -76], dtype=torch.int32) q_bias: tensor([  7073,    822,   1824,   4606,   5514,   7757,   4043,   5940,   5351,\n",
      "          -882,    992,   -101, -29197,  -1408,   4599,   -231,   5836,  10716,\n",
      "          2901,   6303,   -502,   9551,   2046,   4097,  -1195,   1274,   5615,\n",
      "         -3900,   4129,     27,   7589,   5594,    911,  13449,  -2022,   -682,\n",
      "          7642,   4826,   3699,  12208,   7029,   3010,   3748,   3023,   3736,\n",
      "          4266,  13678,  -1319,   2589,   7175,   6871,   9398,   4610,   4736,\n",
      "          4627,   8277,   6518,    897, -64911,    140,   5440,   3510,   6912,\n",
      "          2982,   4366,   7279,   2703,   2293,   5164,   1794,   -349,   -580,\n",
      "          7738,   5025,    160,   3358,   6427,   5825,   5731,   2877,  11576,\n",
      "          3498,    349,   1808,   3075,   6022,   5670,   2186,   6195,   3675,\n",
      "          4779,  -2893,   -245,   4451,   8083,   8458,   6326, -21018,   -196,\n",
      "          6243,   3728,   7553,   7990,   4718,    376,   4882,   4433,   1864,\n",
      "           851,  -1620,    132,  11626,   4085,   6343,    818,    980,   7850,\n",
      "        -14542,   1919,   5302,   3786,    955,   3320,    442,   4768, -44979,\n",
      "          3357,   9260,   2611,   5736,   5401,   4163,  10792,   8414,  -1157,\n",
      "          7036,  -1581,    442,   4707,   2023,   3549, -17845,   2807,   6998,\n",
      "          7225,   4361,   1508,   1405,   6290,   1366,   5740,  -4799,   3549,\n",
      "         16785,   5131,   5987,    372,   3993,   4361,   6059,   9706, -18525,\n",
      "          7568,   -491, -21429,   -138,    -87,   6598,   4146,   9356,   3488,\n",
      "          7064,   6162,    244,   3933,   4739,    596,  16115,  -3475,  -2450,\n",
      "          2418,   4326,   -857,   1063,   5102,   5258,   2596,   7494,   6954,\n",
      "          4297,   -198,   -708], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-6.1781e-06) tensor(0.0064)   bias tensor(-2.4102e-06) tensor(0.0002)\n",
      "features.8.conv.3.weight features.8.conv.5\n",
      "torch.Size([192, 1, 3, 3]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.0695]) torch.Size([1]) \n",
      "wscale= tensor([1.1576e-02, 1.1035e-02, 1.1249e-02, 1.3613e-02, 1.4405e-02, 9.7235e-03,\n",
      "        1.0886e-02, 1.0091e-02, 1.2783e-02, 9.0721e-03, 5.1163e-03, 6.3032e-03,\n",
      "        2.2430e-06, 1.0610e-02, 1.1180e-02, 3.8940e-03, 1.2226e-02, 1.5162e-02,\n",
      "        7.6703e-03, 1.2571e-02, 2.7335e-03, 1.4225e-02, 9.8334e-03, 1.0053e-02,\n",
      "        3.9753e-03, 3.5370e-03, 6.3609e-03, 3.3562e-02, 7.9929e-03, 1.7664e-03,\n",
      "        8.3388e-03, 9.4107e-03, 3.2866e-02, 3.7654e-02, 6.4538e-03, 4.8181e-03,\n",
      "        1.1461e-02, 6.4898e-03, 5.3472e-03, 1.2423e-02, 2.4143e-02, 8.1317e-03,\n",
      "        1.3022e-02, 1.2242e-02, 1.3262e-02, 1.1742e-02, 1.3375e-02, 1.8947e-02,\n",
      "        9.0936e-03, 1.1726e-02, 1.0476e-02, 9.5578e-03, 1.4981e-02, 5.2306e-03,\n",
      "        1.7931e-02, 8.9030e-03, 1.1720e-02, 8.6464e-03, 4.8303e-07, 5.4353e-03,\n",
      "        9.0920e-03, 1.0880e-02, 1.1123e-02, 1.2813e-02, 8.1005e-03, 1.1387e-02,\n",
      "        6.7513e-03, 7.0631e-03, 7.7178e-03, 5.0823e-03, 5.5001e-03, 4.0940e-03,\n",
      "        1.9307e-02, 9.8746e-03, 3.5150e-03, 1.9275e-02, 1.3370e-02, 1.2447e-02,\n",
      "        1.9928e-02, 1.4676e-02, 7.7193e-03, 5.3015e-03, 5.0061e-03, 9.4507e-03,\n",
      "        1.0997e-02, 1.1616e-02, 1.0156e-02, 5.8165e-03, 9.3510e-03, 1.3730e-02,\n",
      "        9.6774e-03, 3.6305e-02, 2.0573e-03, 1.2883e-02, 2.4530e-02, 8.8547e-03,\n",
      "        1.3344e-02, 3.5847e-05, 4.7954e-03, 1.1792e-02, 1.1421e-02, 1.3610e-02,\n",
      "        1.5333e-02, 1.5044e-02, 7.8206e-03, 1.2761e-02, 1.1406e-02, 1.0763e-02,\n",
      "        6.1197e-03, 1.2401e-02, 3.6340e-03, 2.8681e-02, 1.4256e-02, 1.1949e-02,\n",
      "        3.9043e-03, 6.6922e-03, 1.0652e-02, 2.8557e-05, 9.6901e-03, 1.1226e-02,\n",
      "        1.1419e-02, 7.1578e-03, 7.2537e-03, 5.7890e-03, 1.4730e-02, 1.7551e-06,\n",
      "        9.4938e-03, 1.2438e-02, 1.1293e-02, 7.5997e-03, 1.1626e-02, 1.3196e-02,\n",
      "        1.1010e-02, 6.1208e-03, 8.3496e-03, 9.9150e-03, 1.6833e-02, 1.3826e-02,\n",
      "        1.4901e-02, 4.9124e-03, 1.0721e-02, 8.6578e-06, 1.0552e-02, 1.3379e-02,\n",
      "        1.1286e-02, 2.6541e-02, 8.4039e-03, 1.0896e-02, 1.2433e-02, 3.2026e-03,\n",
      "        1.4981e-02, 3.1193e-02, 1.5345e-02, 1.9571e-02, 1.5267e-02, 9.8337e-03,\n",
      "        2.7160e-03, 1.0654e-02, 1.5008e-02, 1.3785e-02, 9.9671e-03, 1.7593e-05,\n",
      "        1.0943e-02, 9.5303e-03, 7.6004e-06, 8.9232e-03, 2.4147e-03, 2.0520e-02,\n",
      "        1.3344e-02, 9.8673e-03, 1.0623e-02, 2.0246e-02, 1.2522e-02, 1.4313e-03,\n",
      "        7.4590e-03, 1.1724e-02, 1.0181e-02, 2.3615e-02, 2.6304e-02, 8.2301e-03,\n",
      "        2.1346e-02, 3.8923e-03, 4.2412e-03, 3.7506e-03, 1.0394e-02, 1.2813e-02,\n",
      "        8.3651e-03, 1.0420e-02, 8.9653e-03, 1.3965e-02, 2.3251e-03, 1.4114e-02]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0635]) torch.Size([1])\n",
      "###: M= tensor([1.2670e-02, 1.2078e-02, 1.2312e-02, 1.4899e-02, 1.5766e-02, 1.0642e-02,\n",
      "        1.1914e-02, 1.1045e-02, 1.3990e-02, 9.9291e-03, 5.5997e-03, 6.8986e-03,\n",
      "        2.4549e-06, 1.1612e-02, 1.2236e-02, 4.2619e-03, 1.3381e-02, 1.6594e-02,\n",
      "        8.3949e-03, 1.3759e-02, 2.9917e-03, 1.5569e-02, 1.0762e-02, 1.1002e-02,\n",
      "        4.3508e-03, 3.8712e-03, 6.9619e-03, 3.6733e-02, 8.7479e-03, 1.9333e-03,\n",
      "        9.1266e-03, 1.0300e-02, 3.5971e-02, 4.1212e-02, 7.0635e-03, 5.2733e-03,\n",
      "        1.2544e-02, 7.1029e-03, 5.8524e-03, 1.3597e-02, 2.6424e-02, 8.8999e-03,\n",
      "        1.4252e-02, 1.3398e-02, 1.4515e-02, 1.2851e-02, 1.4638e-02, 2.0737e-02,\n",
      "        9.9527e-03, 1.2834e-02, 1.1466e-02, 1.0461e-02, 1.6396e-02, 5.7248e-03,\n",
      "        1.9624e-02, 9.7441e-03, 1.2827e-02, 9.4632e-03, 5.2867e-07, 5.9488e-03,\n",
      "        9.9509e-03, 1.1908e-02, 1.2174e-02, 1.4023e-02, 8.8658e-03, 1.2463e-02,\n",
      "        7.3892e-03, 7.7303e-03, 8.4470e-03, 5.5624e-03, 6.0197e-03, 4.4807e-03,\n",
      "        2.1131e-02, 1.0807e-02, 3.8470e-03, 2.1096e-02, 1.4633e-02, 1.3623e-02,\n",
      "        2.1811e-02, 1.6062e-02, 8.4485e-03, 5.8024e-03, 5.4790e-03, 1.0344e-02,\n",
      "        1.2036e-02, 1.2713e-02, 1.1115e-02, 6.3660e-03, 1.0234e-02, 1.5027e-02,\n",
      "        1.0592e-02, 3.9735e-02, 2.2516e-03, 1.4100e-02, 2.6847e-02, 9.6913e-03,\n",
      "        1.4605e-02, 3.9233e-05, 5.2485e-03, 1.2906e-02, 1.2500e-02, 1.4895e-02,\n",
      "        1.6782e-02, 1.6465e-02, 8.5595e-03, 1.3967e-02, 1.2483e-02, 1.1779e-02,\n",
      "        6.6978e-03, 1.3572e-02, 3.9773e-03, 3.1390e-02, 1.5603e-02, 1.3078e-02,\n",
      "        4.2731e-03, 7.3244e-03, 1.1658e-02, 3.1255e-05, 1.0605e-02, 1.2286e-02,\n",
      "        1.2498e-02, 7.8340e-03, 7.9389e-03, 6.3359e-03, 1.6122e-02, 1.9209e-06,\n",
      "        1.0391e-02, 1.3613e-02, 1.2359e-02, 8.3176e-03, 1.2724e-02, 1.4442e-02,\n",
      "        1.2050e-02, 6.6990e-03, 9.1384e-03, 1.0852e-02, 1.8423e-02, 1.5132e-02,\n",
      "        1.6309e-02, 5.3765e-03, 1.1734e-02, 9.4757e-06, 1.1549e-02, 1.4643e-02,\n",
      "        1.2353e-02, 2.9049e-02, 9.1978e-03, 1.1925e-02, 1.3607e-02, 3.5052e-03,\n",
      "        1.6396e-02, 3.4139e-02, 1.6794e-02, 2.1420e-02, 1.6709e-02, 1.0763e-02,\n",
      "        2.9726e-03, 1.1661e-02, 1.6425e-02, 1.5088e-02, 1.0909e-02, 1.9255e-05,\n",
      "        1.1977e-02, 1.0431e-02, 8.3184e-06, 9.7662e-03, 2.6429e-03, 2.2459e-02,\n",
      "        1.4605e-02, 1.0800e-02, 1.1626e-02, 2.2159e-02, 1.3705e-02, 1.5665e-03,\n",
      "        8.1636e-03, 1.2832e-02, 1.1143e-02, 2.5846e-02, 2.8789e-02, 9.0077e-03,\n",
      "        2.3363e-02, 4.2600e-03, 4.6419e-03, 4.1049e-03, 1.1376e-02, 1.4024e-02,\n",
      "        9.1553e-03, 1.1404e-02, 9.8123e-03, 1.5284e-02, 2.5448e-03, 1.5447e-02])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "conv_weight: tensor([[[ 0.2797, -0.0517, -0.0859],\n",
      "         [ 0.6991,  0.1335, -0.9847],\n",
      "         [ 0.1676,  0.1697, -0.2422]],\n",
      "\n",
      "        [[-0.1017, -0.1036, -0.1082],\n",
      "         [-0.1409,  0.6924, -0.1726],\n",
      "         [-0.0851, -0.1145, -0.0937]],\n",
      "\n",
      "        [[-0.1861, -0.3615, -0.2096],\n",
      "         [ 0.1491, -0.9500,  0.1295],\n",
      "         [ 0.3395,  0.5709,  0.3870]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0437,  0.1587,  0.1884],\n",
      "         [-0.0864, -0.5652,  0.7526],\n",
      "         [-0.1572, -0.0311, -0.2174]],\n",
      "\n",
      "        [[-0.0109, -0.0530, -0.0450],\n",
      "         [-0.0851, -0.1893, -0.1196],\n",
      "         [-0.0807, -0.1227, -0.0439]],\n",
      "\n",
      "        [[-0.0368,  0.1646, -0.0383],\n",
      "         [ 0.1189,  0.7093,  0.1724],\n",
      "         [ 0.0731,  0.3309,  0.1011]]]) conv_bias: tensor([-1.9740e-01,  1.8330e+00, -5.5699e-02, -5.3005e-02,  2.1064e-01,\n",
      "        -3.9984e-02, -2.9053e-01, -5.2369e-02, -3.4391e-01, -2.4612e-01,\n",
      "        -6.3820e-02, -1.6730e-01, -9.2101e-04,  2.5942e+00,  1.8741e-02,\n",
      "         8.4551e-01,  3.0366e-02,  2.5070e-01, -2.7977e-01,  2.1268e-01,\n",
      "         1.6624e+00,  6.3040e-01,  1.4651e-02, -2.8983e-01,  1.2852e+00,\n",
      "         1.0621e+00,  1.7310e+00,  1.2475e+00, -5.8533e-02,  1.0521e+00,\n",
      "         2.2574e+00, -3.3966e-02,  2.0920e+00,  4.3766e+00,  1.5005e+00,\n",
      "        -1.7028e-01, -6.7729e-01,  4.3898e-02,  1.3429e+00,  2.2151e+00,\n",
      "         3.7977e+00, -5.1201e-02,  1.1880e-03,  1.8868e-01,  3.9945e-02,\n",
      "        -6.4261e-03, -1.6930e+00, -4.0516e-01, -9.2489e-02,  4.2057e-02,\n",
      "         2.0986e+00,  2.2156e+00,  2.3971e+00,  8.4800e-02,  2.0746e+00,\n",
      "        -5.3544e-01, -2.3684e-01, -2.3125e-02, -4.2298e-04, -1.3629e-01,\n",
      "         1.2787e+00, -9.8004e-02, -7.0284e-02, -7.2838e-02, -6.0594e-04,\n",
      "         3.2405e-03,  7.9040e-01, -1.5237e-01, -1.3760e-01,  8.4120e-01,\n",
      "         1.3153e-01,  8.5856e-01,  2.8081e+00, -4.4572e-02,  1.5586e+00,\n",
      "         5.0417e-01, -2.5995e-01, -6.5582e-02, -2.9163e+00, -5.2509e-01,\n",
      "         2.0067e+00, -3.1066e-01, -1.7274e-01, -4.1365e-01, -1.0202e+00,\n",
      "        -1.6522e-01,  8.1988e-02,  3.1909e-01,  1.9598e+00, -3.9820e-01,\n",
      "        -9.1139e-03,  1.4215e-01, -8.8666e-01, -1.8547e-01,  3.4781e+00,\n",
      "        -1.1417e-01, -6.9171e-02,  4.8875e-03, -6.9433e-01,  6.4624e-02,\n",
      "        -4.8067e-02,  3.8866e-01, -2.3044e-01,  4.3585e-01, -1.6230e-01,\n",
      "        -1.1568e-01,  9.1358e-01,  2.6297e-02,  9.0972e-01,  1.3525e-03,\n",
      "         1.5480e+00,  1.5556e+00,  5.1305e-02, -1.7826e-01,  8.7818e-01,\n",
      "        -5.1828e-03,  1.3190e+00, -3.1604e-04, -1.8097e-01, -3.0758e-02,\n",
      "        -7.2424e-02,  1.6206e-01, -1.7678e-01, -1.0520e+00,  2.8241e+00,\n",
      "        -3.5659e-04, -9.8212e-02,  2.7737e+00, -1.2789e-02,  8.0310e-01,\n",
      "         1.4200e-01, -6.3476e-02,  2.7049e+00, -6.0749e-02, -5.1494e-01,\n",
      "        -3.2139e-01, -5.4049e-01,  1.0742e-02,  5.5362e-01,  2.7042e-01,\n",
      "        -5.9692e-01, -3.6023e-04, -2.2834e-01, -4.6494e-02,  1.5113e-01,\n",
      "         8.7200e-01,  1.7889e+00,  1.0974e-02,  2.7606e+00,  9.0989e-01,\n",
      "        -4.1109e-02,  7.5285e-01, -1.8267e-01,  3.0479e+00,  2.1829e-01,\n",
      "         1.1569e-02,  8.0498e-01, -1.5335e-02, -2.9969e-02,  7.1264e-01,\n",
      "        -3.5748e-01, -3.3562e-03,  2.6087e+00, -1.1148e+00, -1.2674e-03,\n",
      "         3.1996e-02,  2.5887e+00,  4.2955e+00, -4.5598e-02, -1.2276e-01,\n",
      "        -1.6989e-02,  3.2250e+00,  8.6247e-02,  1.4234e+00, -8.7464e-01,\n",
      "         9.1154e-03,  1.2152e+00,  2.5651e+00,  1.0412e+00,  2.3054e+00,\n",
      "        -8.8311e-01,  1.3855e+00, -4.5114e-01,  9.5758e-01, -4.6559e-02,\n",
      "         5.2862e-03, -5.6163e-02, -2.3125e-01, -3.5385e-02,  1.6428e-01,\n",
      "         8.0380e-01, -7.5111e-01])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "q_weight: tensor([24, -4, -7,  ...,  5, 23,  7], dtype=torch.int32) q_bias: tensor([  -245,   2389,    -71,    -56,    210,    -59,   -384,    -75,   -387,\n",
      "          -390,   -179,   -382,  -5906,   3517,     24,   3123,     36,    238,\n",
      "          -525,    243,   8747,    637,     21,   -415,   4650,   4319,   3914,\n",
      "           535,   -105,   8567,   3894,    -52,    916,   1672,   3344,   -508,\n",
      "          -850,     97,   3612,   2565,   2263,    -91,      1,    222,     43,\n",
      "            -8,  -1821,   -308,   -146,     52,   2881,   3334,   2301,    233,\n",
      "          1664,   -865,   -291,    -38, -12595,   -361,   2023,   -130,    -91,\n",
      "           -82,     -1,      4,   1684,   -310,   -256,   2381,    344,   3016,\n",
      "          2092,    -65,   6378,    376,   -280,    -76,  -2105,   -515,   3739,\n",
      "          -843,   -496,   -630,  -1334,   -205,    116,    789,   3015,   -417,\n",
      "           -14,     56,  -6199,   -207,   2039,   -185,    -75,   1961,  -2083,\n",
      "            79,    -61,    411,   -216,    417,   -298,   -130,   1152,     35,\n",
      "          2138,      2,   6127,    780,     52,   -215,   3235,    -11,   1781,\n",
      "          -159,   -269,    -39,    -91,    326,   -351,  -2614,   2758,  -2922,\n",
      "          -149,   3208,    -16,   1520,    176,    -69,   3534,   -143,   -887,\n",
      "          -466,   -462,     11,    534,    792,   -801,   -598,   -311,    -50,\n",
      "           193,    473,   3062,     14,   3194,   4086,    -39,    347,   -171,\n",
      "          2240,    206,     17,   4263,    -21,    -29,    744,   -516,  -2744,\n",
      "          3429,  -1682,  -2399,     52,  15419,   3011,    -49,   -179,    -23,\n",
      "          2291,     99,  14304,  -1687,     11,   1717,   1562,    569,   4029,\n",
      "          -595,   5120,  -1530,   3672,    -64,      6,    -97,   -319,    -57,\n",
      "           169,   4972,   -765], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(5.9633e-05) tensor(0.0174)   bias tensor(-5.9554e-06) tensor(0.0008)\n",
      "features.8.conv.6.weight features.8.conv.8\n",
      "torch.Size([32, 192, 1, 1]) conv_bias= torch.Size([32]) \n",
      "ascale= tensor([0.0597]) torch.Size([1]) \n",
      "wscale= tensor([0.0029, 0.0035, 0.0034, 0.0030, 0.0055, 0.0025, 0.0027, 0.0036, 0.0031,\n",
      "        0.0037, 0.0027, 0.0029, 0.0036, 0.0044, 0.0031, 0.0037, 0.0029, 0.0026,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0020, 0.0039, 0.0047, 0.0027, 0.0021,\n",
      "        0.0039, 0.0026, 0.0066, 0.0048, 0.0027]) torch.Size([32, 1, 1, 1]) \n",
      "oscale= tensor([0.0789]) torch.Size([1])\n",
      "###: M= tensor([0.0022, 0.0027, 0.0026, 0.0022, 0.0042, 0.0019, 0.0020, 0.0027, 0.0023,\n",
      "        0.0028, 0.0020, 0.0022, 0.0027, 0.0033, 0.0024, 0.0028, 0.0022, 0.0019,\n",
      "        0.0022, 0.0022, 0.0022, 0.0022, 0.0015, 0.0030, 0.0035, 0.0020, 0.0016,\n",
      "        0.0030, 0.0020, 0.0050, 0.0037, 0.0021])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "conv_weight: tensor([[-0.0860, -0.1187, -0.0638,  ...,  0.1217, -0.0279, -0.0754],\n",
      "        [ 0.0501, -0.0011,  0.0007,  ..., -0.1082, -0.0315,  0.1906],\n",
      "        [-0.0435, -0.1410,  0.0867,  ..., -0.1999, -0.0801,  0.0893],\n",
      "        ...,\n",
      "        [-0.1353,  0.0900, -0.0927,  ...,  0.0045,  0.0237, -0.0203],\n",
      "        [-0.1305, -0.0874,  0.0074,  ..., -0.0952, -0.0038, -0.0387],\n",
      "        [ 0.1738,  0.0413, -0.0507,  ..., -0.0153,  0.1092,  0.1561]]) conv_bias: tensor([-0.0571,  0.7820,  1.9549,  0.4759,  1.3792,  0.5935,  0.1451, -0.4171,\n",
      "        -1.3589,  1.0194,  0.1890,  0.3245, -0.6421, -0.2356,  0.2778,  0.9780,\n",
      "         2.2494,  0.9279, -0.2992,  1.2827, -0.6959,  2.0775,  1.2011,  0.7934,\n",
      "         2.1136,  1.1865, -0.0893, -0.8134, -0.0805, -2.8030, -1.0666, -0.8527])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "q_weight: tensor([-30, -41, -22,  ...,  -6,  40,  57], dtype=torch.int32) q_bias: tensor([ -331,  3694,  9636,  2688,  4198,  3963,   912, -1933, -7386,  4649,\n",
      "         1186,  1903, -2997,  -893,  1479,  4415, 12792,  6076, -1733,  7463,\n",
      "        -3955, 12041, 10035,  3391,  7548,  7472,  -722, -3452,  -518, -7084,\n",
      "        -3696, -5221], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-8.7258e-06) tensor(0.0032)   bias tensor(1.8460e-05) tensor(0.0001)\n",
      "features.9.conv.0.weight features.9.conv.2\n",
      "torch.Size([192, 32, 1, 1]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.0789]) torch.Size([1]) \n",
      "wscale= tensor([2.5035e-03, 2.3835e-03, 1.7564e-03, 4.1068e-03, 5.7520e-06, 3.4124e-03,\n",
      "        1.5311e-03, 2.7222e-03, 2.3808e-03, 4.3093e-03, 4.0599e-03, 1.3630e-03,\n",
      "        1.7320e-03, 1.2624e-03, 3.3816e-03, 2.4857e-03, 8.1208e-04, 1.5922e-03,\n",
      "        2.0931e-03, 2.7624e-03, 1.7992e-03, 5.2897e-03, 4.0922e-03, 4.3882e-03,\n",
      "        2.5969e-03, 1.4916e-03, 2.1853e-03, 1.5392e-03, 2.3744e-03, 2.4124e-03,\n",
      "        1.3827e-03, 1.7117e-03, 1.3044e-03, 1.5933e-03, 3.2090e-03, 5.1325e-03,\n",
      "        8.0374e-06, 2.2635e-03, 2.0110e-06, 3.8229e-03, 1.9637e-03, 1.5576e-03,\n",
      "        4.8004e-03, 3.2829e-03, 3.2778e-03, 3.1889e-03, 1.9166e-03, 1.8157e-03,\n",
      "        2.0839e-03, 1.5397e-03, 1.6968e-03, 2.0395e-03, 1.4537e-03, 1.6604e-03,\n",
      "        1.4591e-03, 5.1115e-03, 2.2493e-03, 1.3417e-03, 1.8409e-03, 1.7264e-03,\n",
      "        4.0126e-03, 1.3998e-03, 2.0935e-03, 1.3978e-03, 1.8258e-03, 1.4440e-03,\n",
      "        4.5509e-03, 1.8356e-03, 2.1308e-03, 4.0588e-03, 3.6600e-03, 1.3916e-03,\n",
      "        1.5665e-03, 3.6065e-03, 5.6995e-03, 2.7612e-03, 1.6623e-03, 2.5157e-03,\n",
      "        2.0223e-03, 2.0540e-03, 2.8168e-03, 2.2572e-03, 4.8127e-03, 1.8965e-03,\n",
      "        3.4333e-03, 2.3587e-03, 1.4010e-03, 1.0145e-03, 4.1779e-03, 3.3542e-03,\n",
      "        1.2468e-03, 1.3092e-03, 1.6547e-03, 5.0238e-03, 6.4877e-03, 2.9093e-03,\n",
      "        2.2040e-03, 3.8144e-03, 1.9783e-03, 4.1766e-03, 4.3607e-03, 2.1341e-03,\n",
      "        2.0545e-03, 1.5688e-03, 2.0128e-03, 3.2302e-03, 1.8448e-03, 1.3622e-05,\n",
      "        2.5139e-03, 3.1776e-03, 4.3036e-03, 3.1097e-03, 2.3945e-03, 1.7040e-03,\n",
      "        7.1729e-07, 1.4934e-03, 2.6263e-03, 1.7030e-03, 1.6656e-03, 1.2365e-03,\n",
      "        3.7229e-03, 4.8769e-03, 4.8869e-03, 3.5660e-03, 2.9294e-07, 4.0374e-03,\n",
      "        1.5393e-03, 2.1714e-03, 1.4920e-03, 1.6182e-03, 1.5830e-03, 4.1040e-03,\n",
      "        7.5884e-06, 2.7135e-03, 4.1573e-03, 1.4577e-03, 4.2464e-03, 1.9336e-03,\n",
      "        3.1315e-03, 2.9192e-03, 1.5127e-03, 1.8344e-03, 4.0724e-03, 1.8807e-03,\n",
      "        2.2748e-03, 2.5373e-03, 1.6732e-03, 1.4064e-03, 7.9521e-03, 1.8139e-03,\n",
      "        1.1904e-03, 3.9875e-03, 2.8364e-03, 2.1235e-03, 2.1521e-03, 1.3821e-03,\n",
      "        1.5200e-05, 3.6159e-03, 1.8789e-03, 6.4048e-03, 2.2210e-03, 1.2227e-03,\n",
      "        2.5381e-03, 4.4691e-03, 1.3299e-03, 1.8890e-03, 2.2593e-03, 1.7817e-03,\n",
      "        3.0481e-03, 1.7171e-03, 2.2680e-06, 1.9691e-03, 4.5160e-03, 4.0835e-03,\n",
      "        1.7708e-06, 1.2733e-03, 3.5287e-03, 4.0669e-03, 2.9045e-03, 2.5283e-03,\n",
      "        2.1080e-03, 3.2859e-03, 2.5343e-03, 5.7031e-03, 2.3355e-03, 2.2395e-03,\n",
      "        3.3850e-03, 2.4231e-03, 1.4132e-03, 1.5872e-03, 1.4759e-03, 3.3425e-03]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.1342]) torch.Size([1])\n",
      "###: M= tensor([1.4725e-03, 1.4019e-03, 1.0331e-03, 2.4155e-03, 3.3831e-06, 2.0070e-03,\n",
      "        9.0053e-04, 1.6011e-03, 1.4003e-03, 2.5346e-03, 2.3879e-03, 8.0167e-04,\n",
      "        1.0187e-03, 7.4248e-04, 1.9889e-03, 1.4620e-03, 4.7763e-04, 9.3645e-04,\n",
      "        1.2311e-03, 1.6247e-03, 1.0582e-03, 3.1112e-03, 2.4068e-03, 2.5810e-03,\n",
      "        1.5274e-03, 8.7727e-04, 1.2853e-03, 9.0531e-04, 1.3965e-03, 1.4189e-03,\n",
      "        8.1324e-04, 1.0067e-03, 7.6717e-04, 9.3711e-04, 1.8874e-03, 3.0187e-03,\n",
      "        4.7273e-06, 1.3313e-03, 1.1828e-06, 2.2485e-03, 1.1550e-03, 9.1614e-04,\n",
      "        2.8234e-03, 1.9309e-03, 1.9279e-03, 1.8756e-03, 1.1273e-03, 1.0679e-03,\n",
      "        1.2257e-03, 9.0560e-04, 9.9800e-04, 1.1995e-03, 8.5498e-04, 9.7657e-04,\n",
      "        8.5818e-04, 3.0064e-03, 1.3229e-03, 7.8915e-04, 1.0827e-03, 1.0154e-03,\n",
      "        2.3601e-03, 8.2328e-04, 1.2313e-03, 8.2214e-04, 1.0739e-03, 8.4930e-04,\n",
      "        2.6767e-03, 1.0796e-03, 1.2532e-03, 2.3872e-03, 2.1527e-03, 8.1848e-04,\n",
      "        9.2137e-04, 2.1212e-03, 3.3522e-03, 1.6240e-03, 9.7768e-04, 1.4796e-03,\n",
      "        1.1894e-03, 1.2081e-03, 1.6568e-03, 1.3276e-03, 2.8307e-03, 1.1154e-03,\n",
      "        2.0193e-03, 1.3873e-03, 8.2400e-04, 5.9667e-04, 2.4573e-03, 1.9728e-03,\n",
      "        7.3330e-04, 7.7000e-04, 9.7325e-04, 2.9548e-03, 3.8158e-03, 1.7111e-03,\n",
      "        1.2963e-03, 2.2435e-03, 1.1636e-03, 2.4565e-03, 2.5648e-03, 1.2552e-03,\n",
      "        1.2084e-03, 9.2272e-04, 1.1838e-03, 1.8999e-03, 1.0850e-03, 8.0120e-06,\n",
      "        1.4786e-03, 1.8689e-03, 2.5312e-03, 1.8290e-03, 1.4084e-03, 1.0022e-03,\n",
      "        4.2188e-07, 8.7837e-04, 1.5447e-03, 1.0016e-03, 9.7966e-04, 7.2726e-04,\n",
      "        2.1897e-03, 2.8684e-03, 2.8743e-03, 2.0974e-03, 1.7229e-07, 2.3746e-03,\n",
      "        9.0538e-04, 1.2772e-03, 8.7752e-04, 9.5174e-04, 9.3105e-04, 2.4138e-03,\n",
      "        4.4632e-06, 1.5960e-03, 2.4452e-03, 8.5733e-04, 2.4976e-03, 1.1372e-03,\n",
      "        1.8418e-03, 1.7169e-03, 8.8974e-04, 1.0789e-03, 2.3952e-03, 1.1062e-03,\n",
      "        1.3380e-03, 1.4923e-03, 9.8408e-04, 8.2717e-04, 4.6771e-03, 1.0669e-03,\n",
      "        7.0016e-04, 2.3453e-03, 1.6682e-03, 1.2490e-03, 1.2658e-03, 8.1288e-04,\n",
      "        8.9402e-06, 2.1267e-03, 1.1051e-03, 3.7671e-03, 1.3063e-03, 7.1916e-04,\n",
      "        1.4928e-03, 2.6286e-03, 7.8222e-04, 1.1110e-03, 1.3288e-03, 1.0479e-03,\n",
      "        1.7928e-03, 1.0099e-03, 1.3339e-06, 1.1582e-03, 2.6561e-03, 2.4017e-03,\n",
      "        1.0415e-06, 7.4890e-04, 2.0754e-03, 2.3920e-03, 1.7083e-03, 1.4871e-03,\n",
      "        1.2398e-03, 1.9326e-03, 1.4906e-03, 3.3543e-03, 1.3737e-03, 1.3172e-03,\n",
      "        1.9909e-03, 1.4251e-03, 8.3121e-04, 9.3352e-04, 8.6807e-04, 1.9659e-03])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "conv_weight: tensor([[-0.0211,  0.0233, -0.0299,  ..., -0.1874,  0.2807,  0.0710],\n",
      "        [-0.0318, -0.0114, -0.0861,  ..., -0.0784, -0.0159,  0.0136],\n",
      "        [-0.1763,  0.1217,  0.0044,  ...,  0.0569, -0.0409,  0.0387],\n",
      "        ...,\n",
      "        [-0.1454, -0.0876, -0.0367,  ...,  0.0115,  0.1736,  0.0828],\n",
      "        [-0.0650,  0.1279,  0.0715,  ..., -0.0464,  0.1125,  0.1022],\n",
      "        [-0.1210,  0.1731,  0.0316,  ..., -0.1535,  0.3767,  0.1565]]) conv_bias: tensor([ 8.3893e-01,  8.0203e-01,  9.1162e-01,  4.4649e-01, -5.8235e-03,\n",
      "        -2.4677e-01,  4.6800e-01,  3.7381e-01, -4.9594e-01, -3.0172e-01,\n",
      "         7.2649e-03,  1.0708e+00, -5.4436e-01,  9.2558e-01, -7.7386e-02,\n",
      "         9.8822e-01,  1.2662e+00, -3.1228e-01,  9.0778e-01,  6.4865e-01,\n",
      "         6.6010e-01,  1.5697e-01,  6.1965e-01, -3.2670e-01, -6.1258e-01,\n",
      "         1.0192e+00,  1.2129e+00,  6.1709e-01,  3.9228e-01, -3.6408e-01,\n",
      "         9.2372e-01, -5.0983e-01,  1.3160e+00,  7.9749e-01,  9.1804e-01,\n",
      "        -4.8597e-01, -1.4166e-02,  1.1810e+00, -3.4060e-03,  4.1216e-01,\n",
      "        -6.1883e-01,  8.6758e-01, -3.9055e-01,  5.8794e-01,  6.1862e-01,\n",
      "         4.1643e-01,  5.6954e-01,  1.4558e+00,  9.8737e-01,  3.8471e-01,\n",
      "         8.3817e-01,  5.6807e-01,  8.3846e-01,  5.7600e-01,  7.0511e-01,\n",
      "        -5.8221e-02,  1.2481e+00,  6.3468e-01,  3.7879e-01, -5.6501e-01,\n",
      "        -1.9751e-01, -4.4607e-01,  1.0907e+00, -5.3729e-01,  1.6514e+00,\n",
      "         1.1119e+00,  3.2676e-01,  7.1235e-01,  4.9151e-01, -1.8249e-01,\n",
      "        -3.5005e-01,  6.2493e-01, -4.9973e-01, -3.0964e-01, -2.8930e-01,\n",
      "         1.1289e-01,  8.0144e-01, -4.0693e-01,  1.0067e+00,  5.4193e-01,\n",
      "         8.2080e-01,  3.3027e-01, -5.3359e-02,  9.3903e-01,  3.8756e-01,\n",
      "        -6.8017e-01, -5.8444e-01,  9.7554e-01, -7.4186e-02, -2.0541e-01,\n",
      "         1.0644e+00,  1.1126e+00,  6.3317e-01,  3.8037e-01,  3.7737e-01,\n",
      "         1.3043e+00,  7.1297e-01,  1.2597e-02,  6.3792e-01, -2.6960e-01,\n",
      "        -2.5010e-01,  6.4263e-01, -3.0662e-01,  6.7139e-01,  1.5085e+00,\n",
      "        -1.6461e-01,  5.0731e-01, -2.3902e-02, -1.6648e-01,  2.3238e-01,\n",
      "        -1.3683e-03, -4.2465e-01,  1.0328e+00, -4.3798e-01, -2.6129e-03,\n",
      "        -3.5941e-01, -3.2792e-01,  6.7090e-01, -3.3676e-01,  9.0239e-01,\n",
      "         1.7136e+00,  2.8706e-01,  3.1442e-01,  8.5736e-02, -8.7621e-04,\n",
      "        -5.1678e-01,  1.0274e+00, -3.7074e-01, -4.5326e-01,  4.8680e-01,\n",
      "         8.4377e-01, -3.0185e-01, -1.0581e-02,  1.0252e+00,  5.0732e-01,\n",
      "         8.0858e-01,  1.9965e+00,  5.0958e-01,  7.7704e-03,  1.0278e+00,\n",
      "         8.1045e-01,  7.8914e-01,  4.5969e-01,  8.3239e-01,  7.1794e-01,\n",
      "         1.2635e+00,  1.0945e+00, -6.5519e-01, -3.0286e-01,  6.6109e-01,\n",
      "        -7.6061e-01, -2.8726e-01, -4.1743e-01, -4.5150e-01, -3.8937e-01,\n",
      "         8.0598e-01, -2.7408e-02,  3.8222e-01,  8.9694e-01, -5.1523e-01,\n",
      "         6.3762e-01,  8.5239e-01,  8.3150e-01, -3.5829e-01,  1.0074e+00,\n",
      "         6.3893e-01, -5.1717e-01, -4.7499e-01,  1.5786e+00,  5.5540e-01,\n",
      "        -3.2780e-03,  8.1771e-01,  4.0844e-01,  4.2803e-01, -2.6545e-03,\n",
      "        -5.9245e-01,  1.8368e+00, -2.0136e-01,  2.0220e-01,  2.6231e-01,\n",
      "         6.9835e-01, -2.8365e-01, -4.0989e-01, -3.7503e-01, -4.2088e-01,\n",
      "         9.1420e-01, -6.2485e-02,  1.2435e+00, -6.0078e-01, -4.3085e-01,\n",
      "         4.2476e-01, -1.7176e-01])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "q_weight: tensor([ -8,   9, -12,  ..., -46, 113,  47], dtype=torch.int32) q_bias: tensor([  4246,   4264,   6577,   1378, -12830,   -916,   3873,   1740,  -2640,\n",
      "          -887,     23,   9955,  -3983,   9291,   -290,   5038,  19759,  -2485,\n",
      "          5496,   2976,   4649,    376,   1919,   -943,  -2989,   8659,   7033,\n",
      "          5080,   2094,  -1912,   8466,  -3774,  12786,   6343,   3625,  -1200,\n",
      "        -22334,   6611, -21463,   1366,  -3993,   7058,  -1031,   2270,   2392,\n",
      "          1655,   3766,  10160,   6004,   3166,   6260,   3530,   7309,   4396,\n",
      "          6124,   -144,   7032,   5994,   2608,  -4147,   -624,  -4038,   6602,\n",
      "         -4871,  11462,   9758,    910,   4918,   2923,   -570,  -1212,   5691,\n",
      "         -4043,  -1088,   -643,    518,   6110,  -2050,   6308,   3344,   3693,\n",
      "          1854,   -140,   6275,   1430,  -3654,  -5286,  12186,   -225,   -776,\n",
      "         10819,  10770,   4849,    959,    737,   5681,   4099,     42,   4086,\n",
      "          -818,   -727,   3816,  -1891,   5423,   9497,   -646,   3485, -22235,\n",
      "          -839,    927,     -4,  -1730,   5466,  -3257, -46162,  -3050,  -1582,\n",
      "          4992,  -2562,   9248,   5833,    746,    815,    305, -37904,  -1622,\n",
      "          8458,  -2164,  -3850,   3812,   6755,   -932, -17669,   4787,   1546,\n",
      "          7029,   5958,   3340,     31,   4462,   6789,   5451,   1430,   5609,\n",
      "          3999,   6310,   8290,  -5904,   -483,   4618,  -8097,   -913,  -1865,\n",
      "         -2694,  -2293,   7390, -22850,   1340,   6049,  -1019,   3638,   8834,\n",
      "          4152,  -1016,   9599,   4286,  -2901,  -3378,   6563,   4099, -18315,\n",
      "          5262,   1146,   1328, -18996,  -5896,   6596,   -627,    882,   1315,\n",
      "          4198,  -1094,  -2050,   -833,  -2284,   5173,   -234,   6503,  -5387,\n",
      "         -3440,   3647,   -651], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-2.9433e-06) tensor(0.0039)   bias tensor(-1.0376e-06) tensor(0.0002)\n",
      "features.9.conv.3.weight features.9.conv.5\n",
      "torch.Size([192, 1, 3, 3]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.1304]) torch.Size([1]) \n",
      "wscale= tensor([1.8001e-02, 1.0626e-02, 1.4267e-02, 1.0777e-02, 6.5296e-05, 6.1147e-03,\n",
      "        8.2484e-03, 7.4554e-03, 1.3016e-02, 4.7021e-03, 3.9088e-03, 1.0511e-02,\n",
      "        1.3479e-02, 1.3409e-02, 4.4784e-03, 2.5365e-02, 1.3976e-02, 1.1713e-02,\n",
      "        1.0593e-02, 9.3852e-03, 8.2968e-03, 1.5053e-03, 3.8366e-03, 4.3951e-03,\n",
      "        1.0868e-02, 9.8247e-03, 2.0824e-02, 1.0317e-02, 6.1120e-03, 2.4927e-02,\n",
      "        9.5766e-03, 3.1403e-02, 1.9242e-02, 8.6945e-03, 9.1837e-03, 5.7192e-03,\n",
      "        4.0023e-04, 1.2888e-02, 2.6400e-05, 1.1907e-02, 4.5742e-02, 5.1690e-03,\n",
      "        8.0646e-03, 5.3530e-03, 3.3031e-03, 1.1075e-02, 8.7193e-03, 2.1383e-02,\n",
      "        1.1917e-02, 1.2793e-02, 1.3558e-02, 7.9441e-03, 1.2085e-02, 9.8128e-03,\n",
      "        1.0413e-02, 2.0248e-03, 1.5226e-02, 9.6698e-03, 7.4698e-03, 2.6553e-02,\n",
      "        6.0305e-03, 2.2230e-02, 1.3313e-02, 3.4448e-02, 1.5626e-02, 1.3669e-02,\n",
      "        3.6690e-03, 1.1351e-02, 6.5940e-03, 3.3464e-03, 3.3022e-03, 5.9421e-03,\n",
      "        1.2703e-02, 5.9572e-03, 3.7945e-03, 5.3845e-03, 8.3893e-03, 3.7512e-03,\n",
      "        1.1344e-02, 5.0563e-03, 1.0111e-02, 9.4138e-03, 3.5735e-03, 1.5793e-02,\n",
      "        4.5402e-03, 2.8876e-02, 4.9500e-02, 1.1243e-02, 4.6072e-03, 4.0773e-03,\n",
      "        6.0894e-03, 1.3239e-02, 9.8124e-03, 4.8211e-03, 6.2751e-03, 2.3467e-02,\n",
      "        1.3666e-02, 5.1250e-03, 5.6558e-03, 2.7681e-03, 3.4960e-03, 1.2010e-02,\n",
      "        1.0965e-02, 1.0522e-02, 2.2476e-02, 6.5840e-03, 1.1853e-02, 1.0445e-03,\n",
      "        6.5313e-03, 1.0095e-02, 3.6129e-03, 1.8648e-02, 1.1299e-02, 1.4703e-02,\n",
      "        1.4752e-05, 1.6149e-02, 6.6908e-03, 1.1250e-02, 6.3290e-03, 2.1693e-02,\n",
      "        2.5295e-02, 7.2525e-03, 4.9115e-03, 4.6735e-03, 2.3389e-06, 5.6982e-03,\n",
      "        1.2054e-02, 2.0002e-02, 1.1151e-02, 1.0638e-02, 1.1787e-02, 1.4276e-02,\n",
      "        2.8182e-04, 1.2206e-02, 6.0596e-03, 1.1562e-02, 5.9919e-02, 7.1329e-03,\n",
      "        4.9625e-03, 1.5424e-02, 1.9258e-02, 1.2815e-02, 5.2530e-03, 1.2916e-02,\n",
      "        1.1671e-02, 2.1901e-02, 1.4930e-02, 1.2982e-02, 8.0463e-03, 9.4848e-03,\n",
      "        7.8090e-02, 2.1020e-03, 8.7189e-03, 2.2825e-02, 1.5535e-02, 1.3211e-02,\n",
      "        2.2968e-03, 7.9502e-03, 2.1320e-02, 4.9695e-03, 1.4399e-02, 1.8313e-02,\n",
      "        1.5304e-02, 9.7553e-03, 1.3249e-02, 9.7183e-03, 1.7197e-02, 9.1080e-03,\n",
      "        1.4816e-02, 7.5732e-03, 1.7352e-05, 9.2200e-03, 5.6653e-03, 2.6239e-03,\n",
      "        2.0325e-05, 1.6693e-02, 1.9698e-02, 3.4482e-03, 5.2063e-03, 5.0983e-03,\n",
      "        1.1358e-02, 1.5709e-02, 7.6036e-03, 5.6543e-03, 9.6132e-03, 1.1549e-02,\n",
      "        5.3835e-03, 1.4716e-02, 9.1009e-03, 1.4744e-02, 9.4126e-03, 1.2784e-02]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0755]) torch.Size([1])\n",
      "###: M= tensor([3.1113e-02, 1.8367e-02, 2.4660e-02, 1.8628e-02, 1.1286e-04, 1.0569e-02,\n",
      "        1.4257e-02, 1.2886e-02, 2.2498e-02, 8.1273e-03, 6.7562e-03, 1.8168e-02,\n",
      "        2.3298e-02, 2.3177e-02, 7.7408e-03, 4.3843e-02, 2.4157e-02, 2.0246e-02,\n",
      "        1.8310e-02, 1.6222e-02, 1.4341e-02, 2.6019e-03, 6.6315e-03, 7.5967e-03,\n",
      "        1.8785e-02, 1.6982e-02, 3.5994e-02, 1.7833e-02, 1.0564e-02, 4.3085e-02,\n",
      "        1.6553e-02, 5.4279e-02, 3.3259e-02, 1.5028e-02, 1.5874e-02, 9.8853e-03,\n",
      "        6.9178e-04, 2.2276e-02, 4.5632e-05, 2.0580e-02, 7.9063e-02, 8.9343e-03,\n",
      "        1.3939e-02, 9.2525e-03, 5.7093e-03, 1.9142e-02, 1.5071e-02, 3.6960e-02,\n",
      "        2.0598e-02, 2.2113e-02, 2.3434e-02, 1.3731e-02, 2.0888e-02, 1.6961e-02,\n",
      "        1.7998e-02, 3.4998e-03, 2.6317e-02, 1.6714e-02, 1.2911e-02, 4.5895e-02,\n",
      "        1.0423e-02, 3.8423e-02, 2.3011e-02, 5.9542e-02, 2.7010e-02, 2.3627e-02,\n",
      "        6.3417e-03, 1.9619e-02, 1.1397e-02, 5.7841e-03, 5.7077e-03, 1.0271e-02,\n",
      "        2.1956e-02, 1.0297e-02, 6.5587e-03, 9.3069e-03, 1.4501e-02, 6.4837e-03,\n",
      "        1.9608e-02, 8.7396e-03, 1.7477e-02, 1.6271e-02, 6.1767e-03, 2.7298e-02,\n",
      "        7.8475e-03, 4.9911e-02, 8.5559e-02, 1.9433e-02, 7.9633e-03, 7.0474e-03,\n",
      "        1.0525e-02, 2.2882e-02, 1.6960e-02, 8.3331e-03, 1.0846e-02, 4.0562e-02,\n",
      "        2.3621e-02, 8.8583e-03, 9.7758e-03, 4.7845e-03, 6.0428e-03, 2.0759e-02,\n",
      "        1.8952e-02, 1.8188e-02, 3.8850e-02, 1.1380e-02, 2.0488e-02, 1.8054e-03,\n",
      "        1.1289e-02, 1.7449e-02, 6.2447e-03, 3.2232e-02, 1.9530e-02, 2.5413e-02,\n",
      "        2.5497e-05, 2.7913e-02, 1.1565e-02, 1.9445e-02, 1.0939e-02, 3.7495e-02,\n",
      "        4.3721e-02, 1.2536e-02, 8.4893e-03, 8.0780e-03, 4.0426e-06, 9.8492e-03,\n",
      "        2.0835e-02, 3.4572e-02, 1.9274e-02, 1.8387e-02, 2.0373e-02, 2.4676e-02,\n",
      "        4.8712e-04, 2.1097e-02, 1.0474e-02, 1.9984e-02, 1.0357e-01, 1.2329e-02,\n",
      "        8.5774e-03, 2.6659e-02, 3.3287e-02, 2.2150e-02, 9.0796e-03, 2.2324e-02,\n",
      "        2.0173e-02, 3.7855e-02, 2.5806e-02, 2.2438e-02, 1.3908e-02, 1.6394e-02,\n",
      "        1.3498e-01, 3.6332e-03, 1.5070e-02, 3.9452e-02, 2.6852e-02, 2.2835e-02,\n",
      "        3.9699e-03, 1.3741e-02, 3.6850e-02, 8.5895e-03, 2.4888e-02, 3.1653e-02,\n",
      "        2.6453e-02, 1.6862e-02, 2.2900e-02, 1.6798e-02, 2.9724e-02, 1.5743e-02,\n",
      "        2.5608e-02, 1.3090e-02, 2.9992e-05, 1.5936e-02, 9.7922e-03, 4.5352e-03,\n",
      "        3.5132e-05, 2.8853e-02, 3.4048e-02, 5.9600e-03, 8.9989e-03, 8.8122e-03,\n",
      "        1.9632e-02, 2.7152e-02, 1.3143e-02, 9.7733e-03, 1.6616e-02, 1.9963e-02,\n",
      "        9.3051e-03, 2.5436e-02, 1.5730e-02, 2.5484e-02, 1.6269e-02, 2.2096e-02])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "conv_weight: tensor([[[ 0.2552,  0.0271, -0.2156],\n",
      "         [-0.1128,  0.6607, -0.1667],\n",
      "         [-0.0449, -0.0933,  0.1219]],\n",
      "\n",
      "        [[ 0.0807,  0.8001,  0.1115],\n",
      "         [ 0.0072, -0.3886, -0.0811],\n",
      "         [-0.0780, -0.2823, -0.0704]],\n",
      "\n",
      "        [[-0.1418,  0.0635,  0.0450],\n",
      "         [-0.9471,  0.9118, -0.0797],\n",
      "         [-0.2776,  0.2223,  0.1315]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6536,  0.2965, -0.3563],\n",
      "         [ 0.2056,  0.9384,  0.2559],\n",
      "         [-0.3283,  0.1958,  0.9471]],\n",
      "\n",
      "        [[ 0.1600, -0.5214, -0.5053],\n",
      "         [-0.4431, -0.9079, -0.1466],\n",
      "         [-0.4043, -0.2533,  0.1443]],\n",
      "\n",
      "        [[ 0.1417,  0.1270,  0.1661],\n",
      "         [ 0.0861,  0.8174,  0.1067],\n",
      "         [ 0.0511, -0.0344,  0.0039]]]) conv_bias: tensor([-3.7611e-01, -3.6019e-01, -1.6878e-01, -7.6933e-01, -3.4486e-03,\n",
      "         1.6198e+00,  8.9078e-01, -2.5589e-01, -2.6774e-01,  8.2414e-01,\n",
      "        -3.8028e-01,  2.8351e+00,  1.3228e+00, -1.1261e-01, -6.7186e-01,\n",
      "         7.9668e-01,  2.8764e+00,  7.4333e-02, -1.3546e-01, -1.7648e-01,\n",
      "         2.3778e+00,  1.0354e+00,  9.3890e-01, -1.1204e+00,  2.1781e+00,\n",
      "         2.0179e+00,  1.4433e+00, -1.2708e+00,  7.9365e-02, -2.1841e-01,\n",
      "         2.0285e+00,  2.5147e-01,  6.9494e-01,  3.5410e-03, -1.8063e+00,\n",
      "         7.0744e-02, -5.0198e-03,  8.2151e-01,  1.3486e-03, -1.3284e-01,\n",
      "         1.0879e+00,  2.4434e+00,  2.9729e-02,  1.1481e+00,  1.0347e+00,\n",
      "        -4.4416e-01, -4.1640e-01,  2.0683e+00, -1.6126e-01, -2.1299e-01,\n",
      "         2.0731e+00,  1.6579e-02, -3.5604e-01, -8.9065e-01,  1.3200e+00,\n",
      "         8.8373e-01, -3.3480e-03, -4.0978e-01, -5.1190e-02, -1.0315e-01,\n",
      "         1.9169e+00, -2.2144e-01, -2.3342e-01, -1.9299e-01,  6.8175e-01,\n",
      "        -4.2417e-01, -6.0233e-01, -7.1601e-01, -9.9703e-02,  1.0265e+00,\n",
      "         6.1489e-01,  1.4692e+00,  8.3370e-01, -5.5604e-01, -1.2924e+00,\n",
      "         1.7823e+00, -6.0751e-01, -8.7078e-01, -4.9687e-01,  8.7670e-01,\n",
      "        -4.4945e-02, -1.9953e-01,  8.6057e-01, -2.4996e-01,  3.5495e-01,\n",
      "         8.1319e-01, -2.2952e-01,  1.6058e+00,  1.0529e-01, -3.5700e-01,\n",
      "         3.2334e+00,  1.2523e+00, -1.1032e+00, -1.4897e+00, -1.9658e+00,\n",
      "        -4.5682e-01, -5.1871e-03, -3.7953e-01, -3.9204e-01,  8.1674e-01,\n",
      "         1.3036e+00, -1.8957e-01, -3.6643e-01, -1.5031e-02,  2.4578e+00,\n",
      "         2.1575e+00, -7.3888e-03, -1.3005e-02,  1.9593e+00,  3.0062e+00,\n",
      "        -5.1714e-01,  1.7253e+00, -3.0924e-02, -2.7424e-01, -2.2131e-03,\n",
      "        -6.9804e-01,  8.0817e-01,  3.0362e-01,  9.4869e-01, -2.7390e-01,\n",
      "        -2.5358e+00, -2.1534e-02, -1.5636e+00,  1.4771e+00, -3.5985e-04,\n",
      "        -1.3191e+00,  2.2731e+00,  9.4761e-01,  1.7352e+00, -6.4550e-01,\n",
      "         7.0078e-01, -4.8181e-01, -5.7066e-03, -4.6516e-01,  2.4940e+00,\n",
      "        -6.2855e-01,  3.3550e+00, -2.4209e-01,  2.1690e-01,  4.6626e-01,\n",
      "        -7.8413e-02, -1.2228e-01, -6.2055e-01,  1.7518e+00,  9.0255e-01,\n",
      "         4.6577e-01, -1.2771e-01, -9.2350e-02, -3.9053e-01, -7.2800e-01,\n",
      "         5.4792e-01,  2.6608e+00, -2.4323e-01, -1.8945e+00, -9.9936e-01,\n",
      "        -2.7727e-01, -1.7547e-02, -4.4376e-01,  2.9541e-01, -1.2611e+00,\n",
      "         1.3975e+00, -3.8085e-01,  1.7063e+00, -1.0732e+00, -5.2481e-01,\n",
      "        -5.4409e-01,  2.2174e+00,  1.2229e+00, -2.5445e+00, -6.7820e-01,\n",
      "        -1.0368e-03, -4.4726e-02,  7.2935e-02,  4.5926e-01, -2.6690e-03,\n",
      "         2.1630e+00,  7.7415e-01,  1.0224e+00,  1.0440e+00,  1.0943e+00,\n",
      "        -3.6868e-01, -1.0515e+00, -3.3429e-01, -1.1969e+00,  1.3221e+00,\n",
      "         1.2608e+00, -3.1987e-01,  2.6129e+00,  3.2965e-03, -7.9518e-01,\n",
      "         8.8151e-01, -7.5249e-01])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "q_weight: tensor([ 14,   2, -12,  ...,   4,  -3,   0], dtype=torch.int32) q_bias: tensor([ -160,  -260,   -91,  -547,  -405,  2031,   828,  -263,  -158,  1344,\n",
      "         -746,  2068,   752,   -64, -1150,   241,  1578,    49,   -98,  -144,\n",
      "         2197,  5273,  1876, -1954,  1537,  1575,   531,  -944,   100,   -67,\n",
      "         1624,    61,   277,     3, -1508,    95,   -96,   489,   392,   -86,\n",
      "          182,  3624,    28,  1644,  2401,  -307,  -366,   742,  -104,  -128,\n",
      "         1172,    16,  -226,  -696,   972,  3346,    -2,  -325,   -53,   -30,\n",
      "         2437,   -76,  -134,   -43,   334,  -238, -1259,  -484,  -116,  2352,\n",
      "         1428,  1896,   503,  -716, -2611,  2538,  -555, -1780,  -336,  1329,\n",
      "          -34,  -162,  1846,  -121,   599,   216,   -36,  1095,   175,  -671,\n",
      "         4071,   725,  -862, -2369, -2402,  -149,    -3,  -568,  -531,  2262,\n",
      "         2859,  -121,  -256,   -11,   838,  2512,    -5,   -95,  2300,  2283,\n",
      "        -1097,   709,   -21,  -143, -1150,  -331,   926,   207,  1149,   -97,\n",
      "         -769,   -23, -2441,  2423, -1180, -1775,  1446,   363,  1193,  -465,\n",
      "          456,  -259,  -155,  -292,  3155,  -417,   429,  -260,   335,   232,\n",
      "          -31,   -73,  -906,  1040,   593,   163,   -66,   -55,  -372,  -588,\n",
      "           54,  9705,  -214,  -636,  -493,  -161,   -59,  -428,   106, -1945,\n",
      "          744,  -159,   855,  -843,  -304,  -429,   989,  1029, -1317,  -687,\n",
      "         -458,   -37,    99,  1342, -1007,   993,   301,  2273,  1537,  1646,\n",
      "         -249,  -513,  -337, -1623,  1054,   837,  -456,  1361,     3,  -413,\n",
      "          718,  -451], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-3.3417e-05) tensor(0.0318)   bias tensor(2.9940e-05) tensor(0.0029)\n",
      "features.9.conv.6.weight features.9.conv.8\n",
      "torch.Size([32, 192, 1, 1]) conv_bias= torch.Size([32]) \n",
      "ascale= tensor([0.0749]) torch.Size([1]) \n",
      "wscale= tensor([0.0037, 0.0037, 0.0044, 0.0037, 0.0049, 0.0032, 0.0028, 0.0031, 0.0035,\n",
      "        0.0033, 0.0043, 0.0028, 0.0029, 0.0053, 0.0039, 0.0025, 0.0044, 0.0029,\n",
      "        0.0027, 0.0033, 0.0053, 0.0029, 0.0029, 0.0042, 0.0051, 0.0039, 0.0028,\n",
      "        0.0042, 0.0035, 0.0077, 0.0047, 0.0031]) torch.Size([32, 1, 1, 1]) \n",
      "oscale= tensor([0.0803]) torch.Size([1])\n",
      "###: M= tensor([0.0035, 0.0034, 0.0041, 0.0035, 0.0046, 0.0030, 0.0027, 0.0029, 0.0032,\n",
      "        0.0031, 0.0040, 0.0026, 0.0027, 0.0049, 0.0037, 0.0023, 0.0041, 0.0027,\n",
      "        0.0025, 0.0031, 0.0049, 0.0027, 0.0027, 0.0039, 0.0048, 0.0036, 0.0026,\n",
      "        0.0039, 0.0033, 0.0072, 0.0044, 0.0029])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "conv_weight: tensor([[-0.1053, -0.0146,  0.0370,  ...,  0.0275,  0.1808,  0.0329],\n",
      "        [ 0.0757,  0.0256,  0.1216,  ...,  0.2535, -0.0235,  0.1042],\n",
      "        [ 0.0160, -0.0474, -0.3662,  ..., -0.2292, -0.0225, -0.0839],\n",
      "        ...,\n",
      "        [-0.1454, -0.0766, -0.1109,  ...,  0.0468,  0.1627,  0.0020],\n",
      "        [ 0.0617, -0.1973,  0.2367,  ..., -0.1237, -0.1957,  0.0762],\n",
      "        [ 0.1078,  0.1324, -0.1546,  ...,  0.1677, -0.0400,  0.2958]]) conv_bias: tensor([-0.0336, -0.1416, -0.5649,  0.1577, -0.5567,  0.9955, -1.4457,  0.9616,\n",
      "        -1.1085, -2.3647, -1.7883,  1.2494, -0.0206,  0.2578, -0.0233,  0.1472,\n",
      "         0.0236, -0.6238,  0.1246,  0.0616, -0.2869,  0.4014,  0.5532, -1.4129,\n",
      "        -0.4798,  0.6900, -0.6634, -1.8203, -2.0788, -2.8562, -0.0763,  0.2591])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "q_weight: tensor([-28,  -4,  10,  ...,  54, -13,  96], dtype=torch.int32) q_bias: tensor([ -121,  -516, -1699,   569, -1510,  4203, -6796,  4092, -4270, -9502,\n",
      "        -5537,  5908,   -95,   653,   -79,   793,    72, -2856,   622,   251,\n",
      "         -726,  1874,  2512, -4509, -1252,  2364, -3188, -5803, -7854, -4950,\n",
      "         -218,  1122], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-1.0523e-05) tensor(0.0038)   bias tensor(-8.6891e-06) tensor(0.0002)\n",
      "features.10.conv.0.weight features.10.conv.2\n",
      "torch.Size([192, 32, 1, 1]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.0803]) torch.Size([1]) \n",
      "wscale= tensor([1.3179e-03, 2.4290e-03, 1.2040e-03, 1.0235e-03, 3.3958e-03, 1.7086e-03,\n",
      "        9.8876e-04, 1.1772e-03, 2.1760e-03, 1.0403e-03, 2.3407e-03, 2.6701e-03,\n",
      "        1.4089e-03, 3.6072e-03, 1.3329e-03, 2.5702e-03, 2.4947e-03, 1.4382e-03,\n",
      "        4.9920e-03, 1.6795e-03, 2.6870e-07, 2.5113e-03, 4.5158e-03, 1.6299e-03,\n",
      "        1.5005e-03, 2.4089e-03, 1.7088e-03, 1.7634e-03, 3.4783e-03, 5.3542e-07,\n",
      "        1.0850e-03, 8.4561e-04, 1.6345e-03, 2.1153e-03, 9.2823e-04, 1.2556e-03,\n",
      "        8.2033e-04, 1.1188e-03, 1.2456e-03, 1.6250e-03, 1.8465e-03, 1.6193e-03,\n",
      "        1.1991e-03, 2.0089e-03, 3.4684e-03, 1.1763e-03, 3.9297e-03, 1.5237e-03,\n",
      "        2.7134e-03, 2.8494e-03, 2.0655e-03, 3.4582e-03, 2.3112e-03, 1.9683e-03,\n",
      "        1.5679e-03, 3.3057e-03, 3.2555e-03, 1.0349e-03, 1.2318e-03, 1.4060e-03,\n",
      "        2.1420e-03, 1.7494e-03, 1.4677e-03, 1.9212e-03, 3.6349e-03, 3.7669e-03,\n",
      "        1.3722e-03, 4.1957e-03, 4.0483e-03, 1.4091e-03, 1.3637e-03, 2.2892e-03,\n",
      "        3.8365e-03, 1.3515e-03, 1.4306e-03, 3.3812e-03, 1.3349e-03, 2.4087e-03,\n",
      "        1.8326e-03, 3.6480e-03, 1.3368e-03, 2.5443e-03, 2.8574e-03, 1.0032e-03,\n",
      "        1.7457e-03, 1.1878e-03, 1.6038e-03, 9.0010e-04, 1.5641e-03, 2.0581e-03,\n",
      "        1.0899e-03, 5.4768e-03, 1.5658e-03, 1.9623e-03, 1.6842e-03, 4.0095e-03,\n",
      "        1.6331e-03, 3.0501e-06, 2.6967e-03, 1.1728e-03, 1.6494e-03, 1.6190e-03,\n",
      "        1.0290e-03, 2.4483e-03, 2.3937e-03, 3.5231e-03, 1.1983e-03, 2.6013e-03,\n",
      "        2.4223e-03, 1.0114e-03, 3.7427e-03, 1.1800e-03, 3.2209e-03, 2.5169e-03,\n",
      "        2.5903e-03, 9.5235e-04, 7.5792e-07, 2.1254e-03, 2.9261e-03, 1.8816e-03,\n",
      "        2.2475e-03, 1.1181e-03, 1.0793e-03, 5.3051e-03, 1.1794e-03, 1.9918e-03,\n",
      "        9.8169e-04, 4.2178e-03, 1.4405e-03, 2.3048e-03, 2.2190e-03, 1.4832e-03,\n",
      "        1.5231e-03, 1.5125e-03, 1.3794e-03, 8.6740e-04, 2.9542e-03, 1.5266e-03,\n",
      "        1.9531e-03, 1.4502e-03, 2.5122e-03, 3.7314e-03, 4.0866e-03, 1.2573e-03,\n",
      "        1.2593e-03, 1.3802e-03, 1.7812e-03, 1.9716e-03, 1.7002e-03, 9.5676e-04,\n",
      "        1.7715e-03, 2.5713e-03, 1.0369e-03, 1.8186e-03, 5.7944e-03, 1.6070e-03,\n",
      "        1.5068e-03, 1.7365e-03, 4.0888e-03, 1.4708e-03, 1.0628e-03, 1.3303e-03,\n",
      "        1.8094e-03, 1.5962e-03, 1.4070e-03, 2.4524e-03, 2.6119e-06, 3.4906e-03,\n",
      "        1.3825e-03, 2.2557e-03, 1.5308e-03, 1.1398e-03, 1.5813e-03, 1.2717e-03,\n",
      "        2.3239e-03, 1.7578e-03, 1.7412e-03, 9.6016e-04, 1.4196e-03, 1.9159e-03,\n",
      "        2.6641e-03, 1.6884e-03, 1.5519e-03, 1.4901e-03, 1.4754e-03, 1.8994e-03,\n",
      "        2.1276e-03, 1.1518e-03, 1.6276e-03, 1.6664e-03, 2.4877e-03, 1.1054e-03]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0765]) torch.Size([1])\n",
      "###: M= tensor([1.3818e-03, 2.5467e-03, 1.2624e-03, 1.0731e-03, 3.5604e-03, 1.7914e-03,\n",
      "        1.0367e-03, 1.2343e-03, 2.2815e-03, 1.0908e-03, 2.4542e-03, 2.7996e-03,\n",
      "        1.4772e-03, 3.7821e-03, 1.3975e-03, 2.6948e-03, 2.6157e-03, 1.5079e-03,\n",
      "        5.2340e-03, 1.7609e-03, 2.8172e-07, 2.6330e-03, 4.7347e-03, 1.7089e-03,\n",
      "        1.5732e-03, 2.5257e-03, 1.7916e-03, 1.8489e-03, 3.6469e-03, 5.6138e-07,\n",
      "        1.1376e-03, 8.8661e-04, 1.7137e-03, 2.2179e-03, 9.7323e-04, 1.3165e-03,\n",
      "        8.6010e-04, 1.1731e-03, 1.3060e-03, 1.7038e-03, 1.9360e-03, 1.6978e-03,\n",
      "        1.2573e-03, 2.1063e-03, 3.6366e-03, 1.2333e-03, 4.1202e-03, 1.5975e-03,\n",
      "        2.8449e-03, 2.9875e-03, 2.1656e-03, 3.6259e-03, 2.4232e-03, 2.0637e-03,\n",
      "        1.6439e-03, 3.4660e-03, 3.4133e-03, 1.0850e-03, 1.2915e-03, 1.4742e-03,\n",
      "        2.2458e-03, 1.8342e-03, 1.5389e-03, 2.0143e-03, 3.8111e-03, 3.9496e-03,\n",
      "        1.4387e-03, 4.3992e-03, 4.2446e-03, 1.4774e-03, 1.4299e-03, 2.4001e-03,\n",
      "        4.0225e-03, 1.4170e-03, 1.4999e-03, 3.5451e-03, 1.3996e-03, 2.5255e-03,\n",
      "        1.9215e-03, 3.8248e-03, 1.4016e-03, 2.6677e-03, 2.9959e-03, 1.0518e-03,\n",
      "        1.8303e-03, 1.2454e-03, 1.6816e-03, 9.4374e-04, 1.6399e-03, 2.1579e-03,\n",
      "        1.1428e-03, 5.7423e-03, 1.6418e-03, 2.0574e-03, 1.7658e-03, 4.2039e-03,\n",
      "        1.7123e-03, 3.1979e-06, 2.8274e-03, 1.2297e-03, 1.7293e-03, 1.6975e-03,\n",
      "        1.0789e-03, 2.5670e-03, 2.5097e-03, 3.6939e-03, 1.2563e-03, 2.7274e-03,\n",
      "        2.5397e-03, 1.0604e-03, 3.9241e-03, 1.2372e-03, 3.3771e-03, 2.6390e-03,\n",
      "        2.7158e-03, 9.9852e-04, 7.9466e-07, 2.2285e-03, 3.0680e-03, 1.9728e-03,\n",
      "        2.3565e-03, 1.1723e-03, 1.1316e-03, 5.5623e-03, 1.2365e-03, 2.0884e-03,\n",
      "        1.0293e-03, 4.4222e-03, 1.5104e-03, 2.4165e-03, 2.3265e-03, 1.5551e-03,\n",
      "        1.5970e-03, 1.5858e-03, 1.4463e-03, 9.0945e-04, 3.0975e-03, 1.6006e-03,\n",
      "        2.0478e-03, 1.5205e-03, 2.6340e-03, 3.9122e-03, 4.2847e-03, 1.3183e-03,\n",
      "        1.3204e-03, 1.4471e-03, 1.8676e-03, 2.0672e-03, 1.7826e-03, 1.0031e-03,\n",
      "        1.8574e-03, 2.6959e-03, 1.0872e-03, 1.9067e-03, 6.0753e-03, 1.6849e-03,\n",
      "        1.5798e-03, 1.8207e-03, 4.2870e-03, 1.5421e-03, 1.1143e-03, 1.3948e-03,\n",
      "        1.8971e-03, 1.6735e-03, 1.4752e-03, 2.5713e-03, 2.7386e-06, 3.6598e-03,\n",
      "        1.4495e-03, 2.3651e-03, 1.6050e-03, 1.1951e-03, 1.6579e-03, 1.3334e-03,\n",
      "        2.4366e-03, 1.8431e-03, 1.8256e-03, 1.0067e-03, 1.4884e-03, 2.0088e-03,\n",
      "        2.7933e-03, 1.7702e-03, 1.6271e-03, 1.5623e-03, 1.5469e-03, 1.9915e-03,\n",
      "        2.2308e-03, 1.2076e-03, 1.7065e-03, 1.7472e-03, 2.6084e-03, 1.1590e-03])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "conv_weight: tensor([[ 0.0148,  0.0684, -0.1037,  ...,  0.0240,  0.0060,  0.0943],\n",
      "        [ 0.2047,  0.0565,  0.0262,  ..., -0.1072,  0.2268,  0.2201],\n",
      "        [-0.0143,  0.0485, -0.1299,  ..., -0.1353, -0.0248,  0.0803],\n",
      "        ...,\n",
      "        [ 0.0032, -0.1326, -0.1608,  ..., -0.2073, -0.0403,  0.1280],\n",
      "        [ 0.0425,  0.0656, -0.0615,  ...,  0.1479,  0.0679, -0.0687],\n",
      "        [-0.0075,  0.0192, -0.1161,  ..., -0.0053,  0.0449, -0.0405]]) conv_bias: tensor([-4.6060e-01, -1.9127e-01, -5.6098e-01,  9.1909e-01,  2.9388e-01,\n",
      "         1.2329e+00,  1.0505e+00, -5.0660e-01, -1.9326e-01,  7.9102e-01,\n",
      "        -4.4052e-01,  4.0572e-01,  9.1119e-01,  6.2929e-01,  6.6396e-01,\n",
      "        -2.4890e-01,  3.8549e-01, -4.9866e-01,  2.3584e-01, -4.3002e-01,\n",
      "        -6.5256e-04, -1.9605e-01,  2.8060e-01, -4.5410e-01,  1.0999e+00,\n",
      "        -2.9221e-01, -4.0389e-01,  5.2448e-01,  3.0300e-01, -1.2825e-03,\n",
      "         8.3084e-01,  5.3553e-01,  9.8140e-01, -3.5686e-01, -5.0947e-01,\n",
      "         5.2733e-01, -6.0902e-01,  1.0148e+00, -5.4535e-01, -3.9159e-01,\n",
      "         4.7616e-01,  6.0325e-01,  8.4915e-01, -3.6501e-01,  5.0920e-01,\n",
      "         6.4795e-01,  5.6993e-02,  6.4226e-01,  1.4148e+00, -3.5095e-02,\n",
      "         1.3856e-01, -8.8059e-02,  5.1198e-01, -6.0007e-02, -4.4958e-01,\n",
      "        -1.5519e-01, -2.0533e-01,  8.3701e-01,  1.7212e+00, -5.5101e-01,\n",
      "         2.9224e-01, -2.1951e-01,  1.0835e+00, -9.6801e-02,  4.5939e-01,\n",
      "         2.3862e-02, -6.6890e-01,  2.3519e-01, -3.8741e-01,  1.0001e+00,\n",
      "         8.6771e-01, -1.7645e-01, -4.0774e-01,  3.8743e-01, -3.0682e-01,\n",
      "        -1.0624e-01,  1.3090e+00, -2.4836e-01,  1.5644e+00, -3.0350e-01,\n",
      "         8.0918e-01,  4.1805e-01,  1.3408e-01,  8.1575e-01, -3.0058e-01,\n",
      "         9.3915e-01,  1.0020e+00,  7.8304e-01, -4.5896e-01, -4.1907e-02,\n",
      "         9.4879e-01,  2.9158e-01, -6.1407e-01,  4.6439e-01, -4.3200e-01,\n",
      "        -2.7762e-01,  9.0133e-01, -5.6587e-03, -4.3706e-01,  9.6142e-01,\n",
      "         1.4797e+00,  4.8491e-01,  9.1271e-01, -4.1736e-01, -4.6264e-01,\n",
      "        -2.5444e-02, -5.2186e-01,  1.9017e-01,  3.9445e-01,  6.2993e-01,\n",
      "        -1.9268e-01,  1.8840e+00, -4.0621e-01, -1.4942e-01, -2.4047e-01,\n",
      "         9.6035e-01, -1.5544e-03, -2.7690e-01,  2.1483e-01,  3.7199e-01,\n",
      "         2.4774e-01,  1.0149e+00,  8.4582e-01, -5.6672e-01, -4.1404e-01,\n",
      "         5.2574e-01, -4.7828e-01,  2.8835e-01, -4.2287e-01, -5.8157e-01,\n",
      "         1.2506e+00,  4.8372e-01, -4.3077e-01,  7.3014e-01,  1.1633e+00,\n",
      "         9.2415e-01, -9.8945e-02,  8.5431e-01,  5.9393e-01,  9.1828e-01,\n",
      "        -3.0546e-01,  5.8348e-02,  9.9003e-02,  9.6117e-01, -2.6513e-01,\n",
      "        -4.5451e-01,  3.4553e-01,  5.1889e-01,  5.0239e-01,  5.3936e-01,\n",
      "         1.0907e+00, -7.8883e-02,  1.1028e+00, -3.1760e-01,  2.9645e-02,\n",
      "        -3.2079e-01, -4.3301e-01,  6.1039e-01, -2.9750e-02,  9.3702e-01,\n",
      "         5.8648e-01,  9.2400e-01, -1.1934e-01,  1.0138e+00, -4.2706e-01,\n",
      "         3.4147e-01, -7.3666e-03, -2.5411e-01,  1.2609e+00, -2.4962e-01,\n",
      "         6.3810e-01, -3.0253e-01, -4.2540e-01,  7.6877e-01,  1.2222e+00,\n",
      "        -2.9283e-01,  1.1810e+00, -4.7641e-01,  9.2622e-01, -5.5445e-01,\n",
      "        -5.0927e-01,  1.6592e+00,  4.3116e-01,  9.2529e-01,  6.7076e-01,\n",
      "         2.8630e-01,  1.3448e+00,  1.0441e+00,  1.5994e+00,  6.5486e-01,\n",
      "        -1.3212e-01,  1.0444e+00])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "q_weight: tensor([ 11,  52, -79,  ...,  -5,  41, -37], dtype=torch.int32) q_bias: tensor([ -4355,   -981,  -5806,  11190,   1078,   8992,  13239,  -5362,  -1107,\n",
      "          9474,  -2345,   1893,   8058,   2174,   6207,  -1207,   1925,  -4320,\n",
      "           589,  -3190, -30262,   -973,    774,  -3472,   9134,  -1512,  -2945,\n",
      "          3706,   1085, -29847,   9542,   7891,   7482,  -2102,  -6839,   5233,\n",
      "         -9251,  11302,  -5455,  -3003,   3213,   4642,   8824,  -2264,   1829,\n",
      "          6864,    181,   5252,   6497,   -153,    836,   -317,   2760,   -380,\n",
      "         -3573,   -585,   -786,  10078,  17411,  -4883,   1700,  -1564,   9198,\n",
      "          -628,   1575,     79,  -6074,    698,  -1192,   8844,   7928,   -960,\n",
      "         -1324,   3572,  -2672,   -392,  12219,  -1285,  10637,  -1037,   7543,\n",
      "          2047,    585,  10132,  -2145,   9852,   7785,  10840,  -3656,   -254,\n",
      "         10847,    663,  -4887,   2949,  -3196,   -863,   6877, -23118,  -2020,\n",
      "         10214,  11179,   3732,  11052,  -2124,  -2408,    -90,  -5427,    911,\n",
      "          2029,   7761,   -641,  19895,  -1571,   -740,  -1157,  12565, -25555,\n",
      "         -1623,    915,   2463,   1373,  11310,   9765,  -1331,  -4374,   3289,\n",
      "         -6071,    852,  -3658,  -3144,   7023,   4064,  -3524,   6015,  10508,\n",
      "         13276,   -417,   6973,   3789,   7890,  -1515,    195,    302,   9526,\n",
      "         -2623,  -4103,   2417,   3279,   3682,   7024,   7672,   -382,  13253,\n",
      "         -2176,     64,  -2487,  -3581,   4380,    -91,   7938,   6876,   8655,\n",
      "          -822,   7914,  -3782,   1735, -35143,   -907,  11365,  -1379,   5194,\n",
      "         -3307,  -3352,   7532,   6554,  -2076,   8452,  -6183,   8130,  -3606,\n",
      "         -2382,  12245,   3462,   7738,   5665,   1878,   7876,  11296,  12245,\n",
      "          4897,   -662,  11773], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(1.2604e-06) tensor(0.0027)   bias tensor(1.2486e-06) tensor(0.0002)\n",
      "features.10.conv.3.weight features.10.conv.5\n",
      "torch.Size([192, 1, 3, 3]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.0740]) torch.Size([1]) \n",
      "wscale= tensor([5.5944e-02, 3.0837e-03, 1.3928e-02, 8.9653e-03, 2.7320e-03, 2.6952e-02,\n",
      "        1.1793e-02, 4.2097e-02, 1.1151e-02, 1.9929e-02, 8.3617e-03, 1.3031e-02,\n",
      "        1.1960e-02, 2.2728e-03, 1.2693e-02, 2.6285e-02, 5.8271e-03, 4.3959e-02,\n",
      "        1.3686e-02, 1.7182e-02, 3.2171e-07, 1.1071e-02, 6.6835e-03, 2.5964e-02,\n",
      "        1.1593e-02, 8.1758e-03, 2.3702e-02, 8.0952e-03, 1.0081e-02, 4.7232e-06,\n",
      "        1.4800e-02, 1.1031e-02, 2.5145e-02, 1.1922e-02, 3.0564e-02, 8.5694e-03,\n",
      "        9.4502e-02, 1.3716e-02, 1.4287e-02, 8.2554e-03, 6.7620e-03, 1.3241e-02,\n",
      "        8.3356e-03, 2.4123e-02, 4.8093e-03, 8.7175e-03, 4.7517e-03, 1.2883e-02,\n",
      "        3.6140e-02, 3.8136e-03, 5.0816e-03, 1.3829e-02, 7.0778e-03, 8.0072e-03,\n",
      "        2.1276e-02, 1.4219e-02, 4.8060e-03, 1.5784e-02, 2.3969e-02, 3.7906e-02,\n",
      "        7.4990e-03, 1.0298e-02, 1.5789e-02, 1.5861e-02, 5.2180e-03, 3.2743e-03,\n",
      "        2.6023e-02, 3.1390e-03, 2.2806e-03, 1.4669e-02, 9.8624e-03, 1.0662e-02,\n",
      "        2.2120e-03, 1.3349e-02, 3.0296e-02, 8.3879e-03, 2.3461e-02, 4.6847e-03,\n",
      "        3.4166e-02, 9.2214e-03, 1.6165e-02, 7.5820e-03, 5.4079e-03, 2.0533e-02,\n",
      "        1.3885e-02, 1.7739e-02, 1.2298e-02, 1.0488e-02, 2.4769e-02, 6.3994e-03,\n",
      "        1.3858e-02, 8.9872e-03, 2.9913e-02, 7.1674e-03, 1.0238e-02, 5.6535e-03,\n",
      "        1.1324e-02, 1.0499e-04, 6.3173e-03, 1.5673e-02, 2.2472e-02, 1.9803e-02,\n",
      "        1.3322e-02, 1.5779e-02, 1.4185e-02, 5.0472e-03, 1.5847e-02, 6.2579e-03,\n",
      "        4.0300e-03, 9.0321e-03, 2.4987e-03, 1.6497e-02, 3.2164e-03, 7.5295e-03,\n",
      "        1.4211e-02, 9.7671e-03, 2.5526e-06, 4.3722e-03, 3.9740e-03, 1.1774e-02,\n",
      "        7.6609e-03, 1.3457e-02, 8.5617e-03, 4.3447e-03, 3.2440e-02, 8.3471e-03,\n",
      "        2.7887e-02, 7.2331e-03, 1.7597e-02, 2.6806e-02, 2.6322e-02, 1.2330e-02,\n",
      "        1.7663e-02, 9.0740e-03, 1.4224e-02, 1.2937e-02, 5.1616e-03, 1.5481e-02,\n",
      "        1.3526e-02, 1.1211e-02, 8.3749e-03, 4.0200e-03, 3.5245e-03, 1.2373e-02,\n",
      "        1.9756e-02, 1.7069e-02, 7.7039e-03, 9.6725e-03, 9.3276e-03, 9.5770e-03,\n",
      "        1.5126e-02, 7.3058e-03, 1.6335e-02, 1.0684e-02, 4.8228e-03, 1.8509e-02,\n",
      "        1.9118e-02, 7.6738e-03, 5.9657e-03, 7.3169e-03, 8.1648e-03, 9.8490e-03,\n",
      "        1.1052e-02, 1.1112e-02, 1.9545e-02, 4.3730e-03, 1.4435e-04, 4.7459e-03,\n",
      "        1.7848e-02, 1.6596e-02, 1.0313e-02, 1.5250e-02, 1.5283e-02, 1.6797e-02,\n",
      "        1.8166e-02, 1.1579e-02, 2.8370e-02, 1.6220e-02, 1.2935e-02, 1.6349e-02,\n",
      "        8.4325e-03, 2.2549e-02, 6.1321e-03, 1.6477e-02, 8.2859e-03, 7.7532e-03,\n",
      "        2.2236e-02, 1.6286e-02, 3.0591e-02, 1.1892e-02, 8.0588e-03, 1.0262e-02]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0704]) torch.Size([1])\n",
      "###: M= tensor([5.8790e-02, 3.2406e-03, 1.4636e-02, 9.4214e-03, 2.8710e-03, 2.8323e-02,\n",
      "        1.2393e-02, 4.4239e-02, 1.1718e-02, 2.0943e-02, 8.7871e-03, 1.3693e-02,\n",
      "        1.2569e-02, 2.3884e-03, 1.3339e-02, 2.7622e-02, 6.1236e-03, 4.6196e-02,\n",
      "        1.4382e-02, 1.8057e-02, 3.3808e-07, 1.1634e-02, 7.0235e-03, 2.7285e-02,\n",
      "        1.2183e-02, 8.5917e-03, 2.4907e-02, 8.5070e-03, 1.0594e-02, 4.9635e-06,\n",
      "        1.5553e-02, 1.1592e-02, 2.6425e-02, 1.2529e-02, 3.2119e-02, 9.0053e-03,\n",
      "        9.9310e-02, 1.4414e-02, 1.5014e-02, 8.6754e-03, 7.1060e-03, 1.3915e-02,\n",
      "        8.7597e-03, 2.5350e-02, 5.0540e-03, 9.1610e-03, 4.9934e-03, 1.3538e-02,\n",
      "        3.7978e-02, 4.0076e-03, 5.3401e-03, 1.4532e-02, 7.4378e-03, 8.4146e-03,\n",
      "        2.2358e-02, 1.4942e-02, 5.0505e-03, 1.6587e-02, 2.5189e-02, 3.9834e-02,\n",
      "        7.8805e-03, 1.0822e-02, 1.6592e-02, 1.6668e-02, 5.4835e-03, 3.4409e-03,\n",
      "        2.7347e-02, 3.2987e-03, 2.3966e-03, 1.5415e-02, 1.0364e-02, 1.1205e-02,\n",
      "        2.3245e-03, 1.4028e-02, 3.1838e-02, 8.8147e-03, 2.4655e-02, 4.9230e-03,\n",
      "        3.5904e-02, 9.6905e-03, 1.6987e-02, 7.9677e-03, 5.6830e-03, 2.1577e-02,\n",
      "        1.4592e-02, 1.8642e-02, 1.2924e-02, 1.1022e-02, 2.6030e-02, 6.7249e-03,\n",
      "        1.4563e-02, 9.4444e-03, 3.1435e-02, 7.5320e-03, 1.0758e-02, 5.9411e-03,\n",
      "        1.1901e-02, 1.1033e-04, 6.6387e-03, 1.6470e-02, 2.3615e-02, 2.0811e-02,\n",
      "        1.3999e-02, 1.6582e-02, 1.4907e-02, 5.3040e-03, 1.6654e-02, 6.5762e-03,\n",
      "        4.2351e-03, 9.4916e-03, 2.6258e-03, 1.7336e-02, 3.3800e-03, 7.9126e-03,\n",
      "        1.4934e-02, 1.0264e-02, 2.6825e-06, 4.5946e-03, 4.1762e-03, 1.2373e-02,\n",
      "        8.0506e-03, 1.4141e-02, 8.9973e-03, 4.5658e-03, 3.4091e-02, 8.7717e-03,\n",
      "        2.9306e-02, 7.6011e-03, 1.8492e-02, 2.8169e-02, 2.7661e-02, 1.2958e-02,\n",
      "        1.8562e-02, 9.5356e-03, 1.4948e-02, 1.3596e-02, 5.4242e-03, 1.6268e-02,\n",
      "        1.4214e-02, 1.1781e-02, 8.8010e-03, 4.2245e-03, 3.7038e-03, 1.3002e-02,\n",
      "        2.0761e-02, 1.7938e-02, 8.0958e-03, 1.0165e-02, 9.8021e-03, 1.0064e-02,\n",
      "        1.5896e-02, 7.6775e-03, 1.7166e-02, 1.1228e-02, 5.0681e-03, 1.9450e-02,\n",
      "        2.0090e-02, 8.0642e-03, 6.2692e-03, 7.6892e-03, 8.5802e-03, 1.0350e-02,\n",
      "        1.1615e-02, 1.1677e-02, 2.0540e-02, 4.5955e-03, 1.5170e-04, 4.9873e-03,\n",
      "        1.8756e-02, 1.7440e-02, 1.0838e-02, 1.6026e-02, 1.6060e-02, 1.7651e-02,\n",
      "        1.9090e-02, 1.2169e-02, 2.9813e-02, 1.7045e-02, 1.3593e-02, 1.7181e-02,\n",
      "        8.8616e-03, 2.3696e-02, 6.4441e-03, 1.7315e-02, 8.7074e-03, 8.1476e-03,\n",
      "        2.3367e-02, 1.7114e-02, 3.2148e-02, 1.2497e-02, 8.4688e-03, 1.0784e-02])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "conv_weight: tensor([[[-0.0077,  1.2006,  0.1587],\n",
      "         [ 0.3749,  2.9547,  0.4835],\n",
      "         [ 0.5718,  0.4913,  0.2524]],\n",
      "\n",
      "        [[-0.1424, -0.3154,  0.1444],\n",
      "         [-0.0129, -0.2198, -0.1807],\n",
      "         [ 0.0645, -0.2533, -0.1806]],\n",
      "\n",
      "        [[ 0.3663,  0.3135,  0.3177],\n",
      "         [ 0.5156,  1.0346,  0.4514],\n",
      "         [ 0.1579,  0.5486,  0.1262]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1438, -0.2781, -0.2159],\n",
      "         [ 0.2085, -0.5359,  0.1767],\n",
      "         [ 0.2781,  0.7006,  0.1987]],\n",
      "\n",
      "        [[ 0.0716,  0.0462,  0.1916],\n",
      "         [ 0.8754,  0.2648,  0.7706],\n",
      "         [ 0.3391, -0.0567,  0.2828]],\n",
      "\n",
      "        [[-0.1568, -0.9927, -0.2269],\n",
      "         [-0.2649, -0.8834, -0.1082],\n",
      "         [-0.0705,  0.4595, -0.0820]]]) conv_bias: tensor([-3.3672e-01,  8.0690e-01, -1.1462e-02, -1.0746e-01,  1.8577e+00,\n",
      "         7.3745e-01,  2.3633e+00, -2.6316e-01, -5.0230e-01, -7.5637e-01,\n",
      "        -1.0109e+00,  2.8619e+00, -3.1479e-01, -1.5426e+00, -9.8634e-01,\n",
      "        -5.9034e-01,  6.0488e-01, -1.4686e-02, -4.2791e-01,  2.3140e-01,\n",
      "        -1.4895e-04, -1.0632e-01,  1.3909e+00, -1.6467e+00,  2.1397e+00,\n",
      "         1.4946e+00,  3.3481e-02, -1.0577e-01, -6.2589e-01, -8.3366e-05,\n",
      "        -6.6423e-01, -1.2039e-01, -9.1688e-01, -8.9652e-02,  2.7072e-01,\n",
      "        -7.1616e-01,  8.6869e-03, -1.1458e+00,  2.0179e+00,  1.6926e+00,\n",
      "        -6.9400e-01, -3.2962e-01,  1.6747e+00,  2.3381e+00, -1.6810e+00,\n",
      "         2.0731e+00, -3.6584e-01,  1.5684e+00,  2.8998e+00,  1.9040e+00,\n",
      "         1.1688e+00, -1.0006e+00, -8.8277e-02,  1.2238e+00,  7.6377e-02,\n",
      "        -7.4733e-01,  2.1955e+00, -4.0299e-01,  6.6714e-01,  2.1447e+00,\n",
      "         6.5957e-01, -6.7322e-01, -9.7929e-02, -2.9327e-01, -8.4844e-01,\n",
      "         1.0474e+00, -9.1604e-02,  1.7740e+00,  1.4789e+00,  4.7987e-01,\n",
      "         5.8105e-02, -1.0186e+00,  1.2050e+00, -5.6313e-01, -5.0094e-01,\n",
      "        -1.6015e+00, -1.4124e+00, -2.9650e-03, -2.4030e+00, -4.3925e-01,\n",
      "        -3.8025e-01, -8.8960e-01, -3.8862e-01, -6.4234e-01, -2.1981e-01,\n",
      "         1.3711e-01,  1.9417e+00,  2.3149e+00, -9.4056e-01,  6.3102e-02,\n",
      "        -2.8793e-02, -3.9417e-01, -2.5443e-02,  1.0559e+00,  5.1975e-01,\n",
      "        -1.2706e+00,  8.9027e-01, -4.5406e-03,  1.2774e+00,  2.6869e+00,\n",
      "         2.7464e-01, -9.7062e-01,  2.4155e+00, -4.7221e-02, -3.5464e-01,\n",
      "        -1.0624e+00,  2.5099e+00,  2.1804e+00,  2.0619e-02, -1.3446e-01,\n",
      "         1.1192e+00,  3.9867e+00, -2.5340e-01, -9.2897e-01, -8.8816e-02,\n",
      "         3.0851e+00, -7.2737e-04,  1.3100e+00, -2.5363e-01, -6.6218e-01,\n",
      "        -2.8008e-01,  2.8344e+00,  2.0613e+00, -5.1558e-01,  2.2684e-02,\n",
      "        -6.5045e-01,  1.1378e+00,  2.8290e+00,  1.8255e+00, -1.2309e+00,\n",
      "        -8.2338e-01, -5.5206e-01, -4.0306e-01,  2.6739e+00,  8.0360e-01,\n",
      "         3.6084e-02, -3.6218e-02,  1.0782e-01, -1.7058e-01,  1.9364e+00,\n",
      "         1.1438e-02, -6.2105e-01,  4.0226e-02,  2.2358e+00, -5.0931e-01,\n",
      "         1.8479e+00, -4.9231e-01,  2.1260e+00, -7.3191e-01,  2.5932e-01,\n",
      "         1.4597e+00, -1.4535e+00, -5.2086e-01,  8.2294e-02, -3.8717e-01,\n",
      "        -1.5519e-01,  1.9653e+00,  9.6700e-01, -7.8070e-01, -2.4909e+00,\n",
      "         1.3023e+00, -8.0069e-01,  6.1001e-01, -7.3271e-01, -6.6411e-02,\n",
      "         1.1845e+00, -6.3428e-03, -3.4807e-01,  3.3613e+00, -7.2650e-01,\n",
      "         8.3376e-01,  1.0549e+00,  1.0698e+00, -2.8408e-01,  5.3297e-01,\n",
      "        -4.5427e-01, -1.6671e+00,  2.3356e-01, -2.9668e-01,  1.5698e+00,\n",
      "        -1.8288e-01,  6.1403e-01,  7.5055e-01, -4.9328e-01, -1.8533e-01,\n",
      "         9.1890e-01,  8.5346e-01,  2.3596e+00,  3.2266e+00, -3.6480e-01,\n",
      "        -4.5717e-01,  2.0069e+00])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "q_weight: tensor([ 0, 21,  3,  ..., -7, 45, -8], dtype=torch.int32) q_bias: tensor([  -81,  3535,   -11,  -162,  9185,   370,  2707,   -84,  -608,  -513,\n",
      "        -1633,  2967,  -356, -9169, -1050,  -303,  1402,    -5,  -422,   182,\n",
      "        -6255,  -130,  2811,  -857,  2493,  2470,    19,  -177,  -839,  -238,\n",
      "         -606,  -147,  -493,  -102,   120, -1129,     1, -1129,  1908,  2770,\n",
      "        -1386,  -336,  2714,  1309, -4722,  3212, -1040,  1645,  1084,  6744,\n",
      "         3107,  -977,  -168,  2065,    48,  -710,  6171,  -345,   376,   764,\n",
      "         1188,  -883,   -84,  -250, -2196,  4321,   -48,  7634,  8760,   442,\n",
      "           80, -1291,  7359,  -570,  -223, -2579,  -813,    -9,  -950,  -643,\n",
      "         -318, -1585,  -971,  -423,  -214,   104,  2133,  2981,  -513,   133,\n",
      "          -28,  -592,   -11,  1990,   686, -3036,  1062,  -584,  2731,  2316,\n",
      "          165,  -662,  2449,   -40,  -338, -2843,  2139,  4707,    69,  -201,\n",
      "         6051,  3264, -1064, -1667,   -84,  4267, -3849,  4048,  -862,  -760,\n",
      "         -494,  2845,  3252, -1603,     9, -1053,   551,  5283,  1401,  -620,\n",
      "         -423,  -605,  -308,  3981,   763,    38,   -95,    94,  -170,  2333,\n",
      "           18, -2087,   154,  2441,  -348,  1462,  -863,  2969, -1060,   366,\n",
      "         1304, -2688,  -431,   104, -1084,  -113,  1389,  1702, -1768, -4599,\n",
      "         2155, -1098,   746,  -891,   -46,  3659,  -594,  -991,  2544,  -591,\n",
      "         1092,   934,   946,  -228,   396,  -530,  -794,   195,  -310,  1297,\n",
      "         -293,   368,  1653,  -404,  -302,  1601,   518,  1957,  1425,  -414,\n",
      "         -766,  2642], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0001) tensor(0.0366)   bias tensor(1.8440e-05) tensor(0.0017)\n",
      "features.10.conv.6.weight features.10.conv.8\n",
      "torch.Size([32, 192, 1, 1]) conv_bias= torch.Size([32]) \n",
      "ascale= tensor([0.0664]) torch.Size([1]) \n",
      "wscale= tensor([0.0030, 0.0041, 0.0046, 0.0042, 0.0041, 0.0041, 0.0032, 0.0040, 0.0038,\n",
      "        0.0038, 0.0056, 0.0035, 0.0037, 0.0069, 0.0054, 0.0029, 0.0044, 0.0030,\n",
      "        0.0023, 0.0046, 0.0037, 0.0032, 0.0026, 0.0033, 0.0039, 0.0039, 0.0031,\n",
      "        0.0040, 0.0036, 0.0075, 0.0044, 0.0043]) torch.Size([32, 1, 1, 1]) \n",
      "oscale= tensor([0.1039]) torch.Size([1])\n",
      "###: M= tensor([0.0019, 0.0026, 0.0030, 0.0027, 0.0026, 0.0026, 0.0021, 0.0025, 0.0024,\n",
      "        0.0024, 0.0036, 0.0023, 0.0024, 0.0044, 0.0035, 0.0019, 0.0028, 0.0019,\n",
      "        0.0014, 0.0029, 0.0024, 0.0020, 0.0016, 0.0021, 0.0025, 0.0025, 0.0020,\n",
      "        0.0026, 0.0023, 0.0048, 0.0028, 0.0027])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "conv_weight: tensor([[ 0.0275,  0.0211,  0.0685,  ...,  0.0148, -0.0356,  0.0729],\n",
      "        [ 0.1410,  0.0334, -0.0606,  ..., -0.0845, -0.1536,  0.4777],\n",
      "        [-0.1612, -0.1328,  0.1644,  ..., -0.1006,  0.2757,  0.2059],\n",
      "        ...,\n",
      "        [ 0.1201,  0.0689,  0.0415,  ..., -0.0442, -0.0769,  0.1042],\n",
      "        [-0.2001, -0.1373,  0.2207,  ..., -0.1170, -0.1372, -0.0323],\n",
      "        [ 0.2539, -0.3208, -0.2844,  ...,  0.0793, -0.0954, -0.1308]]) conv_bias: tensor([-0.4405, -0.8505,  2.1149, -0.5632, -0.4041,  1.9935, -1.1204, -0.1022,\n",
      "         0.3520,  1.7870,  0.7634,  0.9400, -1.7065, -2.8947,  0.3732, -0.0641,\n",
      "         0.3155,  0.2743,  0.8818, -0.1684, -2.1236,  0.8741, -0.1764,  0.8502,\n",
      "         2.2039,  0.5161, -1.1559,  2.3610, -1.5012, -2.0663,  0.1362,  0.0051])\n",
      "torch.Size([32, 192, 1, 1]) torch.Size([32])\n",
      "q_weight: tensor([  9,   7,  23,  ...,  19, -22, -31], dtype=torch.int32) q_bias: tensor([-2223, -3098,  6849, -2013, -1495,  7343, -5254,  -389,  1397,  7025,\n",
      "         2037,  4011, -6926, -6314,  1038,  -333,  1071,  1363,  5854,  -552,\n",
      "        -8670,  4109, -1040,  3901,  8435,  2008, -5676,  8783, -6210, -4136,\n",
      "          467,    18], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(3.2588e-05) tensor(0.0038)   bias tensor(-4.6321e-05) tensor(6.8665e-05)\n",
      "features.11.conv.0.weight features.11.conv.2\n",
      "torch.Size([192, 32, 1, 1]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.1039]) torch.Size([1]) \n",
      "wscale= tensor([0.0012, 0.0028, 0.0017, 0.0008, 0.0025, 0.0016, 0.0021, 0.0017, 0.0010,\n",
      "        0.0012, 0.0030, 0.0015, 0.0025, 0.0037, 0.0012, 0.0047, 0.0020, 0.0012,\n",
      "        0.0042, 0.0034, 0.0015, 0.0051, 0.0008, 0.0029, 0.0025, 0.0020, 0.0022,\n",
      "        0.0012, 0.0011, 0.0021, 0.0018, 0.0020, 0.0011, 0.0017, 0.0014, 0.0010,\n",
      "        0.0015, 0.0037, 0.0023, 0.0011, 0.0023, 0.0045, 0.0026, 0.0037, 0.0012,\n",
      "        0.0020, 0.0028, 0.0052, 0.0017, 0.0035, 0.0018, 0.0021, 0.0031, 0.0025,\n",
      "        0.0045, 0.0016, 0.0031, 0.0030, 0.0017, 0.0020, 0.0009, 0.0029, 0.0018,\n",
      "        0.0038, 0.0026, 0.0021, 0.0013, 0.0038, 0.0026, 0.0032, 0.0025, 0.0014,\n",
      "        0.0019, 0.0020, 0.0020, 0.0023, 0.0030, 0.0008, 0.0027, 0.0039, 0.0031,\n",
      "        0.0020, 0.0014, 0.0014, 0.0015, 0.0030, 0.0030, 0.0015, 0.0018, 0.0015,\n",
      "        0.0015, 0.0035, 0.0019, 0.0016, 0.0029, 0.0019, 0.0049, 0.0035, 0.0012,\n",
      "        0.0016, 0.0022, 0.0025, 0.0034, 0.0018, 0.0012, 0.0011, 0.0038, 0.0039,\n",
      "        0.0041, 0.0077, 0.0042, 0.0009, 0.0055, 0.0043, 0.0026, 0.0038, 0.0015,\n",
      "        0.0010, 0.0019, 0.0040, 0.0048, 0.0021, 0.0037, 0.0016, 0.0015, 0.0012,\n",
      "        0.0024, 0.0019, 0.0051, 0.0009, 0.0016, 0.0061, 0.0010, 0.0018, 0.0014,\n",
      "        0.0022, 0.0020, 0.0033, 0.0019, 0.0022, 0.0014, 0.0025, 0.0013, 0.0016,\n",
      "        0.0047, 0.0027, 0.0026, 0.0026, 0.0039, 0.0018, 0.0010, 0.0043, 0.0009,\n",
      "        0.0015, 0.0016, 0.0012, 0.0015, 0.0032, 0.0025, 0.0016, 0.0019, 0.0037,\n",
      "        0.0043, 0.0024, 0.0022, 0.0015, 0.0015, 0.0032, 0.0037, 0.0017, 0.0068,\n",
      "        0.0025, 0.0040, 0.0020, 0.0069, 0.0032, 0.0040, 0.0008, 0.0014, 0.0037,\n",
      "        0.0024, 0.0058, 0.0010, 0.0019, 0.0021, 0.0015, 0.0016, 0.0036, 0.0026,\n",
      "        0.0012, 0.0024, 0.0010]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.1528]) torch.Size([1])\n",
      "###: M= tensor([0.0008, 0.0019, 0.0011, 0.0006, 0.0017, 0.0011, 0.0014, 0.0012, 0.0006,\n",
      "        0.0008, 0.0021, 0.0010, 0.0017, 0.0025, 0.0008, 0.0032, 0.0013, 0.0008,\n",
      "        0.0029, 0.0023, 0.0010, 0.0035, 0.0006, 0.0019, 0.0017, 0.0014, 0.0015,\n",
      "        0.0008, 0.0008, 0.0014, 0.0012, 0.0013, 0.0007, 0.0011, 0.0009, 0.0006,\n",
      "        0.0010, 0.0025, 0.0016, 0.0007, 0.0015, 0.0031, 0.0018, 0.0025, 0.0008,\n",
      "        0.0014, 0.0019, 0.0035, 0.0012, 0.0024, 0.0013, 0.0014, 0.0021, 0.0017,\n",
      "        0.0031, 0.0011, 0.0021, 0.0021, 0.0012, 0.0014, 0.0006, 0.0020, 0.0012,\n",
      "        0.0026, 0.0018, 0.0014, 0.0009, 0.0026, 0.0017, 0.0022, 0.0017, 0.0010,\n",
      "        0.0013, 0.0014, 0.0014, 0.0016, 0.0021, 0.0005, 0.0019, 0.0026, 0.0021,\n",
      "        0.0014, 0.0010, 0.0009, 0.0010, 0.0020, 0.0021, 0.0010, 0.0012, 0.0010,\n",
      "        0.0010, 0.0024, 0.0013, 0.0011, 0.0019, 0.0013, 0.0034, 0.0024, 0.0008,\n",
      "        0.0011, 0.0015, 0.0017, 0.0023, 0.0012, 0.0008, 0.0008, 0.0026, 0.0027,\n",
      "        0.0028, 0.0052, 0.0029, 0.0006, 0.0037, 0.0029, 0.0018, 0.0026, 0.0010,\n",
      "        0.0007, 0.0013, 0.0027, 0.0033, 0.0014, 0.0025, 0.0011, 0.0010, 0.0008,\n",
      "        0.0017, 0.0013, 0.0035, 0.0006, 0.0011, 0.0042, 0.0007, 0.0012, 0.0009,\n",
      "        0.0015, 0.0014, 0.0022, 0.0013, 0.0015, 0.0010, 0.0017, 0.0009, 0.0011,\n",
      "        0.0032, 0.0018, 0.0018, 0.0017, 0.0026, 0.0012, 0.0007, 0.0029, 0.0006,\n",
      "        0.0010, 0.0011, 0.0008, 0.0010, 0.0022, 0.0017, 0.0011, 0.0013, 0.0025,\n",
      "        0.0029, 0.0016, 0.0015, 0.0010, 0.0010, 0.0022, 0.0025, 0.0011, 0.0046,\n",
      "        0.0017, 0.0027, 0.0013, 0.0047, 0.0022, 0.0027, 0.0005, 0.0009, 0.0025,\n",
      "        0.0016, 0.0039, 0.0007, 0.0013, 0.0014, 0.0010, 0.0011, 0.0025, 0.0018,\n",
      "        0.0008, 0.0016, 0.0007])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "conv_weight: tensor([[ 0.0037,  0.0880,  0.0020,  ..., -0.0247, -0.0443, -0.0377],\n",
      "        [ 0.0349, -0.0416, -0.0965,  ..., -0.1147, -0.0568, -0.1626],\n",
      "        [-0.1286, -0.0752, -0.0313,  ..., -0.0271, -0.0942, -0.0787],\n",
      "        ...,\n",
      "        [-0.0486, -0.0142, -0.0850,  ...,  0.0135, -0.0504, -0.0232],\n",
      "        [-0.0585,  0.0588,  0.1043,  ..., -0.0831,  0.2001, -0.1071],\n",
      "        [ 0.0711, -0.0463,  0.0282,  ...,  0.0041,  0.0391, -0.1064]]) conv_bias: tensor([-0.6088,  1.1922, -0.4875,  1.8617,  2.3024,  1.9566,  0.1981,  1.5917,\n",
      "        -0.7593,  1.3856,  1.4987, -1.0068,  0.4526, -0.0956, -0.7093, -0.1068,\n",
      "         1.8106,  1.1033, -0.4105,  0.5526,  0.5384, -0.1459, -0.8236,  2.1104,\n",
      "         0.4086, -0.6339,  1.4105, -0.8514, -0.6567,  0.9740,  1.6819,  0.6413,\n",
      "        -0.8257,  0.5505,  1.7685, -0.7759, -0.5639,  0.7019,  0.0766,  0.8252,\n",
      "         2.1370,  0.8809, -0.2789,  0.3899,  0.9707,  0.1723,  1.3346, -0.5215,\n",
      "         1.2726,  0.6003, -0.4984, -0.5297,  0.5319,  0.3501,  0.3985,  0.5464,\n",
      "         0.7127,  2.9992,  1.8167,  0.8249, -0.6945,  0.7044,  0.8677, -0.6546,\n",
      "         1.2502, -0.4347, -0.5193,  0.1623,  3.0209,  0.5962, -0.4573, -0.7215,\n",
      "        -0.6583,  1.1393,  0.6271,  1.8572, -0.3499, -0.8387,  1.4749,  0.5171,\n",
      "         2.3451,  1.1428,  1.5405, -0.6347, -0.4478,  0.0060, -0.2442, -0.4973,\n",
      "         0.9529, -0.4133, -0.6098, -0.1694,  1.5103,  2.1217,  1.3048,  2.0048,\n",
      "        -0.4749, -0.1684,  1.1990,  0.5823, -0.5574, -0.7427,  0.0488,  1.2309,\n",
      "         1.0487, -0.9527,  0.1162,  0.1616, -0.3259,  1.0098, -0.5210, -0.8228,\n",
      "        -0.0869, -0.0402,  0.5371,  0.5644,  1.5752,  1.1921,  0.7145, -0.2029,\n",
      "        -0.4420, -0.3569,  0.0781, -0.7248,  1.0253,  1.8153, -0.5462, -0.1119,\n",
      "         0.7083,  1.1055, -0.4378,  0.1738,  1.6228,  0.3095,  0.5979, -0.4259,\n",
      "         0.7471,  0.1118,  0.5769,  0.1209, -0.7393,  0.7743,  1.2527, -0.5396,\n",
      "         0.9016,  0.5503, -0.5339, -0.1881,  0.7710, -0.6608,  0.9891,  0.3781,\n",
      "         0.5808,  1.3079, -0.3863, -0.7174,  0.7261, -0.0240,  0.4976,  0.6297,\n",
      "         0.5963, -0.3286,  0.2032, -0.0631, -0.5986,  0.7255, -0.6151,  1.1786,\n",
      "         0.4774,  0.9918, -0.4697, -0.3149, -0.4721,  0.7577,  0.1469,  1.9402,\n",
      "        -0.0132, -0.7055,  1.1389,  0.0062, -0.1156, -0.4057,  0.8291, -0.5001,\n",
      "        -0.2110,  1.1210, -0.6228,  1.5240, -0.6595, -0.8529,  1.1549, -0.7098])\n",
      "torch.Size([192, 32, 1, 1]) torch.Size([192])\n",
      "q_weight: tensor([   3,   71,    2,  ...,    4,   38, -105], dtype=torch.int32) q_bias: tensor([ -4744,   4091,  -2787,  21662,   8898,  11921,    905,   9006,  -7652,\n",
      "         10671,   4753,  -6670,   1763,   -249,  -5613,   -219,   8824,   8619,\n",
      "          -930,   1545,   3431,   -274,  -9479,   7087,   1575,  -3043,   6213,\n",
      "         -6889,  -5628,   4502,   8966,   3150,  -7538,   3182,  12484,  -7844,\n",
      "         -3716,   1813,    317,   7365,   9137,   1888,  -1043,   1018,   7725,\n",
      "           823,   4578,   -963,   7162,   1662,  -2609,  -2412,   1646,   1367,\n",
      "           848,   3241,   2196,   9507,  10263,   3886,  -7114,   2361,   4598,\n",
      "         -1648,   4601,  -2029,  -3740,    411,  11355,   1773,  -1740,  -4918,\n",
      "         -3345,   5390,   3008,   7611,  -1114, -10283,   5165,   1283,   7237,\n",
      "          5462,  10394,  -4429,  -2813,     19,   -775,  -3201,   5000,  -2732,\n",
      "         -4000,   -460,   7739,  13119,   4390,  10105,   -926,   -465,   9314,\n",
      "          3610,  -2469,  -2816,    138,   6729,   8685,  -8144,    297,    399,\n",
      "          -757,   1262,  -1191,  -9034,   -153,    -90,   1974,   1437,  10028,\n",
      "         11435,   3713,   -486,   -884,  -1655,    203,  -4285,   6736,  14796,\n",
      "         -2159,   -571,   1339,  11597,  -2648,    273,  15261,   1689,   4207,\n",
      "         -1880,   3509,    331,   2948,    538,  -4975,   2941,   8940,  -3192,\n",
      "          1850,   1979,  -1979,   -709,   1918,  -3467,   9256,    843,   6075,\n",
      "          8458,  -2380,  -5657,   4722,    -73,   1927,   3860,   2963,   -857,\n",
      "           457,   -254,  -2591,   4594,  -3922,   3547,   1248,   5741,   -666,\n",
      "         -1223,  -1143,   3695,    206,   5858,    -31,  -8646,   7989,     16,\n",
      "          -461,   -674,   8063,  -2514,   -971,   7340,  -3672,   4025,  -2463,\n",
      "         -7055,   4715,  -6715], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-6.5052e-07) tensor(0.0036)   bias tensor(5.4918e-06) tensor(0.0003)\n",
      "features.11.conv.3.weight features.11.conv.5\n",
      "torch.Size([192, 1, 3, 3]) conv_bias= torch.Size([192]) \n",
      "ascale= tensor([0.1494]) torch.Size([1]) \n",
      "wscale= tensor([0.0076, 0.0223, 0.0122, 0.0170, 0.0267, 0.0246, 0.0047, 0.0162, 0.0308,\n",
      "        0.0228, 0.0240, 0.0170, 0.0091, 0.0069, 0.0186, 0.0065, 0.0128, 0.0118,\n",
      "        0.0043, 0.0054, 0.0106, 0.0034, 0.0495, 0.0180, 0.0078, 0.0143, 0.0136,\n",
      "        0.0275, 0.0270, 0.0051, 0.0219, 0.0066, 0.0269, 0.0085, 0.0226, 0.1461,\n",
      "        0.0065, 0.0105, 0.0029, 0.0104, 0.0230, 0.0086, 0.0035, 0.0105, 0.0164,\n",
      "        0.0081, 0.0106, 0.0056, 0.0136, 0.0122, 0.0125, 0.0063, 0.0094, 0.0091,\n",
      "        0.0101, 0.0106, 0.0065, 0.0346, 0.0188, 0.0150, 0.0387, 0.0103, 0.0105,\n",
      "        0.0054, 0.0175, 0.0105, 0.0105, 0.0025, 0.0256, 0.0066, 0.0079, 0.0137,\n",
      "        0.0204, 0.0115, 0.0069, 0.0237, 0.0080, 0.1514, 0.0217, 0.0097, 0.0271,\n",
      "        0.0155, 0.0218, 0.0151, 0.0124, 0.0033, 0.0064, 0.0109, 0.0122, 0.0061,\n",
      "        0.0205, 0.0041, 0.0273, 0.0193, 0.0231, 0.0209, 0.0057, 0.0067, 0.0128,\n",
      "        0.0076, 0.0148, 0.0097, 0.0042, 0.0286, 0.0143, 0.0376, 0.0080, 0.0031,\n",
      "        0.0022, 0.0083, 0.0020, 0.0275, 0.0103, 0.0106, 0.0059, 0.0041, 0.0277,\n",
      "        0.0122, 0.0111, 0.0069, 0.0047, 0.0053, 0.0065, 0.0278, 0.0176, 0.0153,\n",
      "        0.0067, 0.0038, 0.0079, 0.0107, 0.0080, 0.0034, 0.0231, 0.0038, 0.0042,\n",
      "        0.0184, 0.0089, 0.0114, 0.0104, 0.0070, 0.0330, 0.0086, 0.0173, 0.0083,\n",
      "        0.0032, 0.0101, 0.0165, 0.0044, 0.0086, 0.0207, 0.0144, 0.0057, 0.0055,\n",
      "        0.0114, 0.0137, 0.0277, 0.0071, 0.0046, 0.0099, 0.0106, 0.0075, 0.0103,\n",
      "        0.0044, 0.0030, 0.0143, 0.0130, 0.0124, 0.0102, 0.0082, 0.0118, 0.0050,\n",
      "        0.0110, 0.0037, 0.0215, 0.0055, 0.0217, 0.0022, 0.0403, 0.0135, 0.0067,\n",
      "        0.0023, 0.0040, 0.0097, 0.0135, 0.0061, 0.0145, 0.0125, 0.0130, 0.0055,\n",
      "        0.0193, 0.0176, 0.0273]) torch.Size([192, 1, 1, 1]) \n",
      "oscale= tensor([0.0926]) torch.Size([1])\n",
      "###: M= tensor([0.0123, 0.0360, 0.0197, 0.0274, 0.0431, 0.0397, 0.0076, 0.0262, 0.0496,\n",
      "        0.0368, 0.0387, 0.0274, 0.0147, 0.0112, 0.0301, 0.0104, 0.0206, 0.0191,\n",
      "        0.0069, 0.0087, 0.0171, 0.0055, 0.0799, 0.0291, 0.0126, 0.0230, 0.0220,\n",
      "        0.0444, 0.0436, 0.0083, 0.0353, 0.0106, 0.0435, 0.0137, 0.0365, 0.2357,\n",
      "        0.0105, 0.0169, 0.0046, 0.0167, 0.0371, 0.0139, 0.0057, 0.0169, 0.0265,\n",
      "        0.0130, 0.0171, 0.0091, 0.0219, 0.0197, 0.0202, 0.0102, 0.0152, 0.0147,\n",
      "        0.0164, 0.0170, 0.0104, 0.0558, 0.0304, 0.0242, 0.0624, 0.0166, 0.0170,\n",
      "        0.0087, 0.0283, 0.0169, 0.0169, 0.0040, 0.0413, 0.0106, 0.0127, 0.0221,\n",
      "        0.0329, 0.0185, 0.0112, 0.0383, 0.0130, 0.2443, 0.0350, 0.0157, 0.0438,\n",
      "        0.0250, 0.0352, 0.0244, 0.0201, 0.0053, 0.0104, 0.0177, 0.0196, 0.0099,\n",
      "        0.0331, 0.0065, 0.0440, 0.0311, 0.0373, 0.0337, 0.0091, 0.0108, 0.0207,\n",
      "        0.0123, 0.0238, 0.0156, 0.0068, 0.0462, 0.0231, 0.0607, 0.0129, 0.0050,\n",
      "        0.0035, 0.0134, 0.0033, 0.0444, 0.0167, 0.0172, 0.0095, 0.0066, 0.0447,\n",
      "        0.0197, 0.0179, 0.0111, 0.0076, 0.0086, 0.0105, 0.0448, 0.0284, 0.0247,\n",
      "        0.0107, 0.0061, 0.0127, 0.0173, 0.0129, 0.0055, 0.0372, 0.0061, 0.0068,\n",
      "        0.0296, 0.0144, 0.0184, 0.0168, 0.0113, 0.0533, 0.0139, 0.0278, 0.0133,\n",
      "        0.0052, 0.0164, 0.0267, 0.0070, 0.0139, 0.0334, 0.0232, 0.0091, 0.0089,\n",
      "        0.0184, 0.0221, 0.0446, 0.0115, 0.0075, 0.0160, 0.0171, 0.0122, 0.0166,\n",
      "        0.0071, 0.0048, 0.0231, 0.0210, 0.0200, 0.0165, 0.0132, 0.0190, 0.0080,\n",
      "        0.0177, 0.0060, 0.0346, 0.0088, 0.0350, 0.0035, 0.0650, 0.0219, 0.0108,\n",
      "        0.0037, 0.0065, 0.0157, 0.0218, 0.0099, 0.0234, 0.0202, 0.0210, 0.0089,\n",
      "        0.0312, 0.0284, 0.0440])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "conv_weight: tensor([[[-0.6357, -0.5369, -0.7385],\n",
      "         [-0.7079, -0.2445, -0.6632],\n",
      "         [-0.5043, -0.1603, -0.6680]],\n",
      "\n",
      "        [[-0.0096, -0.2877,  0.0025],\n",
      "         [-0.2562,  1.0616, -0.2102],\n",
      "         [-0.0562, -0.0640, -0.0396]],\n",
      "\n",
      "        [[ 0.0509, -0.0643, -0.1789],\n",
      "         [ 1.1000, -0.1918, -0.7150],\n",
      "         [ 0.5451, -0.1406, -0.2518]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0581,  0.2855, -0.2854],\n",
      "         [ 1.5154,  0.2325, -1.5223],\n",
      "         [ 0.1100, -0.1963,  0.2226]],\n",
      "\n",
      "        [[ 0.0130, -0.0597, -0.0093],\n",
      "         [-0.0821, -0.3033, -0.1321],\n",
      "         [ 0.0430,  0.8188,  0.1296]],\n",
      "\n",
      "        [[ 0.3126, -0.0101,  0.3161],\n",
      "         [ 0.2551,  1.6977,  0.3745],\n",
      "         [ 0.3532,  0.5102,  0.3044]]]) conv_bias: tensor([ 1.6151e+00,  1.8767e+00,  2.9522e+00,  7.7047e-01,  2.0588e+00,\n",
      "         2.3039e+00,  1.7447e+00,  1.4947e+00,  2.5604e-01,  2.2002e+00,\n",
      "        -9.4532e-01,  1.5489e-01,  4.9473e-01, -9.5185e-02, -4.5229e-03,\n",
      "         4.7135e-01,  1.0187e+00,  8.6589e-01, -8.0225e-01, -7.5809e-01,\n",
      "         1.7070e+00, -7.6594e-01, -6.9446e-03,  2.6412e-01,  2.7335e+00,\n",
      "         1.7720e-02, -6.3494e-02, -3.2601e-02,  4.5230e-02, -1.7394e+00,\n",
      "        -1.6757e+00, -1.9101e+00,  2.1102e+00,  3.9984e-01,  2.5145e+00,\n",
      "         9.3643e-03, -5.7161e-02, -2.1451e-01,  1.1228e+00,  1.3691e+00,\n",
      "         1.5318e+00,  1.0381e-01,  1.5425e+00, -6.0822e-01,  1.9551e+00,\n",
      "        -7.5000e-02, -1.7334e-02,  7.4735e-01,  3.7089e+00, -9.2096e-01,\n",
      "        -1.1714e-01,  2.9819e+00,  3.9244e-01,  4.6208e-01,  1.7475e+00,\n",
      "        -8.9617e-02,  1.6472e+00,  1.4708e+00,  1.5432e-01,  1.3804e+00,\n",
      "        -2.7132e-01,  8.0311e-01,  2.5397e+00, -8.2785e-01,  1.6552e+00,\n",
      "        -1.8042e-01,  2.6320e+00,  9.3079e-01,  1.4118e+00,  6.8021e-01,\n",
      "         9.1021e-01,  1.5134e+00, -1.7960e-01,  2.4715e+00,  1.3402e+00,\n",
      "         7.0784e-01, -3.7505e-02,  5.0401e-01,  1.0149e+00, -1.0388e+00,\n",
      "         2.9532e+00,  8.6738e-01, -1.2103e+00,  1.1027e+00, -2.5533e-01,\n",
      "         1.1694e+00, -5.1218e-02,  8.8572e-01,  9.6088e-01,  9.0111e-01,\n",
      "         2.2597e+00,  1.0131e+00, -3.7169e-01,  2.7208e+00,  1.9082e+00,\n",
      "         2.0051e+00, -5.6457e-02, -8.7369e-01,  1.7128e+00,  8.6676e-01,\n",
      "        -3.3838e-01,  2.7227e+00,  3.9119e-01, -3.9670e-01,  2.1549e+00,\n",
      "        -3.8189e-03, -1.1393e-02,  1.4365e+00, -2.5673e-01,  6.0740e-01,\n",
      "         2.4308e+00,  8.4860e-02, -8.1478e-01, -8.8294e-01,  1.4365e+00,\n",
      "        -6.1639e-01,  2.9841e+00,  2.2794e+00,  3.1302e+00, -1.0038e+00,\n",
      "        -7.6112e-01, -3.4341e-03,  2.6161e-01, -2.8114e-01, -6.3701e-02,\n",
      "         4.0985e-01,  1.6904e+00,  3.6748e+00, -1.3116e+00,  2.1648e+00,\n",
      "         6.2881e-01, -5.3414e-01,  3.2999e+00,  9.7153e-01,  1.0569e+00,\n",
      "         8.9122e-01, -4.3053e-01, -1.1449e+00,  5.5178e-01,  2.4572e+00,\n",
      "        -6.1951e-01,  5.2861e-01, -2.8616e-01,  9.2248e-01, -4.2077e-01,\n",
      "        -1.0842e-01,  2.1829e+00,  2.0375e+00,  3.0101e+00,  7.2988e-02,\n",
      "         4.8985e-01,  3.7115e-02,  1.2674e+00,  2.3326e+00, -1.5842e-01,\n",
      "        -7.9405e-02,  1.7068e+00,  6.7312e-01,  2.5971e+00,  1.5154e+00,\n",
      "        -7.7809e-01, -1.4126e-02, -3.5577e-02,  1.0229e+00,  8.2546e-02,\n",
      "         9.7265e-02, -4.1436e-03,  1.6898e-01,  9.2880e-02,  1.6544e+00,\n",
      "        -7.0088e-01,  1.3597e+00,  2.3419e+00, -1.1849e-01, -2.3349e-01,\n",
      "         3.8210e-01,  2.6380e+00, -2.6122e-01, -5.9612e-03,  3.8612e-03,\n",
      "         1.2662e+00, -5.4134e-01,  1.7387e+00, -3.7967e-02,  1.3263e+00,\n",
      "        -1.2967e-01, -1.3828e-01,  2.1043e+00, -3.2258e-01,  3.1029e+00,\n",
      "        -4.9435e-01,  3.0915e-01])\n",
      "torch.Size([192, 1, 3, 3]) torch.Size([192])\n",
      "q_weight: tensor([-83, -70, -97,  ...,  13,  19,  11], dtype=torch.int32) q_bias: tensor([ 1414,   563,  1622,   303,   516,   627,  2481,   616,    56,   646,\n",
      "         -264,    61,   365,   -92,    -2,   488,   534,   490, -1255,  -944,\n",
      "         1078, -1514,    -1,    98,  2351,     8,   -31,    -8,    11, -2265,\n",
      "         -513, -1942,   524,   315,   744,     0,   -59,  -137,  2630,   884,\n",
      "          446,    81,  2932,  -388,   798,   -62,   -11,   892,  1826,  -504,\n",
      "          -63,  3168,   279,   339,  1153,   -57,  1703,   285,    55,   615,\n",
      "          -47,   522,  1613, -1025,   633,  -115,  1681,  2517,   370,   691,\n",
      "          776,   740,   -59,  1443,  1297,   200,   -31,    22,   313,  -714,\n",
      "          728,   375,  -371,   488,  -137,  2396,   -53,   542,   529,   986,\n",
      "          737,  1673,   -91,   944,   553,   643,   -67,  -877,   893,   760,\n",
      "         -154,  1885,   619,   -93,  1007,    -1,   -10,  3079,  -797,   489,\n",
      "         7973,    21,  -529,  -556,  1640, -1012,   722,  1249,  1888,  -979,\n",
      "        -1088,    -4,   270,   -68,   -24,   179,  1699,  6543, -1115,  1349,\n",
      "          525, -1043,   958,  1720,  1671,   325,  -324,  -674,   355,  2340,\n",
      "         -126,   411,  -111,   748,  -882,   -72,   884,  3128,  2344,    24,\n",
      "          228,    44,  1531,  1370,   -77,   -19,  1601,   975,  1756,   957,\n",
      "         -692,    -9,   -54,  2285,    39,    50,    -2,   111,    76,   942,\n",
      "         -946,   830,  4194,   -37,  -286,   118,  8073,   -43,    -3,     4,\n",
      "         3694,  -897,  1196,   -19,  1445,   -60,   -74,  1080,  -392,  1075,\n",
      "         -188,    76], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0003) tensor(0.0753)   bias tensor(7.3821e-05) tensor(0.0094)\n",
      "features.11.conv.6.weight features.11.conv.8\n",
      "torch.Size([48, 192, 1, 1]) conv_bias= torch.Size([48]) \n",
      "ascale= tensor([0.0903]) torch.Size([1]) \n",
      "wscale= tensor([0.0025, 0.0023, 0.0024, 0.0021, 0.0020, 0.0025, 0.0026, 0.0024, 0.0030,\n",
      "        0.0020, 0.0020, 0.0022, 0.0023, 0.0025, 0.0025, 0.0019, 0.0020, 0.0023,\n",
      "        0.0032, 0.0022, 0.0024, 0.0020, 0.0024, 0.0022, 0.0021, 0.0022, 0.0026,\n",
      "        0.0023, 0.0028, 0.0028, 0.0023, 0.0023, 0.0023, 0.0024, 0.0026, 0.0021,\n",
      "        0.0018, 0.0021, 0.0018, 0.0019, 0.0024, 0.0026, 0.0023, 0.0024, 0.0023,\n",
      "        0.0028, 0.0018, 0.0018]) torch.Size([48, 1, 1, 1]) \n",
      "oscale= tensor([0.0526]) torch.Size([1])\n",
      "###: M= tensor([0.0042, 0.0039, 0.0041, 0.0037, 0.0034, 0.0043, 0.0045, 0.0040, 0.0052,\n",
      "        0.0035, 0.0034, 0.0037, 0.0039, 0.0043, 0.0042, 0.0033, 0.0034, 0.0039,\n",
      "        0.0055, 0.0037, 0.0042, 0.0034, 0.0042, 0.0038, 0.0035, 0.0037, 0.0044,\n",
      "        0.0040, 0.0049, 0.0048, 0.0040, 0.0040, 0.0040, 0.0041, 0.0044, 0.0037,\n",
      "        0.0031, 0.0036, 0.0032, 0.0032, 0.0041, 0.0044, 0.0039, 0.0041, 0.0040,\n",
      "        0.0049, 0.0031, 0.0031])\n",
      "torch.Size([48, 192, 1, 1]) torch.Size([48])\n",
      "conv_weight: tensor([[ 0.0744, -0.1057,  0.0662,  ..., -0.0123,  0.0944,  0.0848],\n",
      "        [ 0.1097, -0.0378, -0.0695,  ...,  0.1065, -0.1025,  0.0638],\n",
      "        [-0.0517, -0.0417, -0.1249,  ...,  0.0403, -0.0013, -0.0565],\n",
      "        ...,\n",
      "        [ 0.0578, -0.0596,  0.0019,  ...,  0.0263, -0.0831,  0.0297],\n",
      "        [ 0.0076, -0.0942, -0.0508,  ..., -0.1219,  0.0110,  0.0322],\n",
      "        [-0.0100,  0.0795,  0.0402,  ..., -0.0715,  0.0519, -0.0243]]) conv_bias: tensor([-0.7051, -0.0188,  1.1416,  0.5546, -0.2543, -2.0419, -0.2685,  1.7753,\n",
      "        -0.0429,  0.2608,  2.3998,  0.4041,  0.7871,  1.3755,  1.4465,  0.7813,\n",
      "        -0.5362, -0.2010,  0.4776,  2.0590,  0.4071, -1.1411, -0.5035, -0.2499,\n",
      "        -1.3029, -0.9874,  0.2840, -0.1291,  0.6303,  0.8559,  0.1852, -0.4393,\n",
      "        -2.2331,  0.5973,  0.1177,  1.0770,  0.9731,  0.4485,  2.0857,  0.3365,\n",
      "        -1.1500, -1.4764, -1.2322, -1.2523,  0.1836, -0.7004,  1.4544,  0.5273])\n",
      "torch.Size([48, 192, 1, 1]) torch.Size([48])\n",
      "q_weight: tensor([ 30, -43,  27,  ..., -39,  29, -13], dtype=torch.int32) q_bias: tensor([ -3154,    -92,   5272,   2858,  -1432,  -9095,  -1133,   8366,   -158,\n",
      "          1429,  13511,   2066,   3846,   6118,   6518,   4532,  -2967,   -976,\n",
      "          1635,  10551,   1857,  -6319,  -2298,  -1249,  -7005,  -5052,   1234,\n",
      "          -619,   2460,   3405,    884,  -2092, -10626,   2795,    506,   5550,\n",
      "          5881,   2375,  12521,   1981,  -5363,  -6360,  -5934,  -5825,    872,\n",
      "         -2730,   8985,   3219], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-7.3006e-06) tensor(0.0016)   bias tensor(5.1542e-06) tensor(0.0001)\n",
      "features.12.conv.0.weight features.12.conv.2\n",
      "torch.Size([288, 48, 1, 1]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.0526]) torch.Size([1]) \n",
      "wscale= tensor([8.0179e-03, 2.4420e-03, 3.1437e-03, 3.8812e-03, 3.8214e-03, 3.4338e-03,\n",
      "        2.7286e-03, 2.5155e-03, 2.3245e-07, 3.6012e-03, 3.1033e-03, 2.6485e-03,\n",
      "        4.6078e-03, 4.9058e-03, 6.2708e-03, 2.4611e-03, 6.2841e-03, 4.4571e-03,\n",
      "        7.0405e-06, 2.7166e-03, 6.2847e-03, 4.0745e-03, 3.6142e-03, 4.6735e-03,\n",
      "        2.8549e-03, 8.6075e-03, 3.9323e-03, 2.1030e-03, 3.1957e-03, 2.9034e-03,\n",
      "        3.3143e-03, 2.3155e-03, 2.5967e-03, 2.2869e-03, 2.2857e-03, 2.4221e-03,\n",
      "        4.9811e-03, 2.6718e-03, 3.9774e-03, 2.2822e-03, 2.7867e-03, 8.1353e-03,\n",
      "        6.1121e-03, 6.9868e-03, 4.1019e-03, 4.8253e-07, 1.7784e-03, 4.3540e-03,\n",
      "        1.0137e-02, 4.7191e-03, 2.5283e-03, 2.3072e-03, 4.3449e-03, 3.2974e-03,\n",
      "        3.6931e-03, 8.7684e-03, 1.4626e-03, 3.8906e-03, 1.1431e-06, 1.0221e-02,\n",
      "        3.0400e-03, 3.0639e-03, 4.7591e-03, 2.6976e-03, 4.8438e-03, 7.3799e-03,\n",
      "        7.4011e-03, 2.6025e-03, 3.6658e-03, 2.8188e-03, 7.1056e-03, 4.7883e-03,\n",
      "        1.1921e-07, 6.8002e-03, 7.6863e-03, 5.5050e-03, 7.4083e-03, 4.0274e-03,\n",
      "        4.4871e-03, 6.7968e-03, 4.1731e-03, 3.4687e-03, 4.9536e-03, 1.0992e-02,\n",
      "        2.4197e-03, 2.4109e-03, 3.7775e-03, 2.7878e-03, 4.4032e-03, 8.9716e-03,\n",
      "        3.4968e-03, 3.0766e-03, 9.9605e-03, 5.9050e-03, 4.7376e-03, 2.0692e-03,\n",
      "        5.3030e-03, 4.7657e-03, 4.0653e-03, 1.9307e-03, 4.5292e-03, 6.4232e-03,\n",
      "        9.7694e-03, 2.6496e-03, 5.0393e-03, 3.9454e-03, 7.4200e-03, 1.2904e-05,\n",
      "        6.8007e-03, 2.0760e-03, 5.5018e-03, 2.4092e-03, 3.2546e-03, 2.8251e-03,\n",
      "        3.0143e-03, 2.9749e-03, 5.9769e-03, 4.8006e-06, 4.8321e-03, 2.3144e-03,\n",
      "        4.5694e-03, 4.1633e-03, 2.8161e-03, 4.2071e-03, 6.7238e-05, 3.6660e-03,\n",
      "        5.9649e-03, 3.4802e-03, 2.8772e-03, 6.8959e-03, 2.0800e-03, 5.4836e-03,\n",
      "        5.9029e-03, 1.2854e-05, 3.3693e-03, 1.1992e-06, 3.6935e-03, 1.9581e-03,\n",
      "        4.9021e-03, 3.1302e-03, 5.0097e-03, 3.0165e-03, 4.1021e-03, 3.8089e-03,\n",
      "        3.0011e-03, 5.1925e-03, 2.3135e-03, 2.2036e-03, 1.7994e-03, 7.6204e-03,\n",
      "        5.6530e-03, 7.6187e-03, 3.4272e-03, 2.3815e-03, 4.8381e-03, 4.0160e-03,\n",
      "        2.4892e-03, 3.1463e-03, 2.9080e-03, 2.5692e-03, 3.9183e-03, 3.8762e-03,\n",
      "        9.7610e-03, 4.8116e-03, 6.2345e-03, 1.3938e-05, 1.8171e-03, 6.4590e-03,\n",
      "        4.8358e-03, 7.3465e-03, 6.2539e-03, 4.1882e-03, 2.6381e-03, 4.2647e-03,\n",
      "        5.2201e-03, 2.6295e-03, 4.5678e-03, 5.6006e-03, 3.6251e-03, 1.8451e-03,\n",
      "        4.4624e-03, 6.5379e-06, 3.6977e-03, 2.9984e-03, 2.4413e-03, 2.5529e-03,\n",
      "        4.9347e-03, 4.4598e-03, 2.5391e-03, 2.7641e-03, 1.7892e-03, 3.8304e-03,\n",
      "        2.6113e-03, 2.5187e-03, 1.9858e-03, 1.0679e-02, 1.5087e-07, 4.0240e-03,\n",
      "        5.1231e-03, 1.1249e-02, 3.2511e-03, 2.0138e-03, 5.4447e-03, 5.2685e-03,\n",
      "        3.9324e-03, 5.5324e-03, 4.2221e-03, 2.8630e-03, 3.7088e-03, 4.4635e-03,\n",
      "        3.7132e-03, 7.8105e-03, 3.1514e-03, 2.8158e-03, 6.6708e-03, 3.7078e-03,\n",
      "        4.1164e-03, 2.8218e-03, 4.8151e-03, 3.4215e-03, 3.0879e-03, 3.9668e-03,\n",
      "        8.3765e-03, 7.6473e-03, 4.4343e-06, 4.3195e-03, 4.8559e-03, 3.1753e-03,\n",
      "        4.3566e-03, 2.7274e-03, 4.2604e-03, 3.0359e-03, 9.4913e-03, 2.1287e-03,\n",
      "        2.3274e-03, 5.8395e-03, 2.8845e-03, 7.7691e-03, 2.2905e-03, 4.0011e-03,\n",
      "        3.8606e-03, 4.1935e-03, 4.5328e-03, 6.6034e-03, 6.2628e-03, 1.5331e-03,\n",
      "        2.8965e-03, 2.8698e-03, 9.3457e-03, 5.2944e-03, 3.0567e-03, 2.2677e-03,\n",
      "        3.6392e-03, 4.7544e-03, 3.1219e-03, 4.3363e-03, 3.2037e-03, 3.3331e-03,\n",
      "        5.1752e-03, 4.1879e-03, 7.4582e-03, 2.6585e-03, 5.8526e-03, 2.9822e-03,\n",
      "        2.1316e-03, 3.0105e-03, 1.8583e-03, 1.3152e-06, 8.3555e-03, 8.1419e-03,\n",
      "        1.7283e-03, 1.8799e-03, 5.5919e-03, 3.2066e-03, 2.6194e-03, 3.8110e-03,\n",
      "        6.5812e-03, 3.2114e-03, 7.0319e-03, 4.1249e-03, 2.1075e-03, 1.4652e-03,\n",
      "        3.2763e-03, 5.2265e-03, 9.1695e-03, 2.7562e-03, 8.5480e-03, 2.1180e-03]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.1472]) torch.Size([1])\n",
      "###: M= tensor([2.8675e-03, 8.7335e-04, 1.1243e-03, 1.3880e-03, 1.3667e-03, 1.2280e-03,\n",
      "        9.7584e-04, 8.9962e-04, 8.3134e-08, 1.2879e-03, 1.1099e-03, 9.4720e-04,\n",
      "        1.6479e-03, 1.7545e-03, 2.2426e-03, 8.8016e-04, 2.2474e-03, 1.5940e-03,\n",
      "        2.5179e-06, 9.7156e-04, 2.2476e-03, 1.4572e-03, 1.2925e-03, 1.6714e-03,\n",
      "        1.0210e-03, 3.0783e-03, 1.4063e-03, 7.5210e-04, 1.1429e-03, 1.0383e-03,\n",
      "        1.1853e-03, 8.2811e-04, 9.2866e-04, 8.1787e-04, 8.1744e-04, 8.6624e-04,\n",
      "        1.7814e-03, 9.5552e-04, 1.4225e-03, 8.1618e-04, 9.9662e-04, 2.9095e-03,\n",
      "        2.1859e-03, 2.4987e-03, 1.4670e-03, 1.7257e-07, 6.3600e-04, 1.5571e-03,\n",
      "        3.6253e-03, 1.6877e-03, 9.0421e-04, 8.2513e-04, 1.5539e-03, 1.1793e-03,\n",
      "        1.3208e-03, 3.1359e-03, 5.2307e-04, 1.3914e-03, 4.0881e-07, 3.6552e-03,\n",
      "        1.0872e-03, 1.0958e-03, 1.7020e-03, 9.6476e-04, 1.7323e-03, 2.6393e-03,\n",
      "        2.6469e-03, 9.3073e-04, 1.3110e-03, 1.0081e-03, 2.5412e-03, 1.7125e-03,\n",
      "        4.2633e-08, 2.4320e-03, 2.7489e-03, 1.9688e-03, 2.6494e-03, 1.4403e-03,\n",
      "        1.6048e-03, 2.4308e-03, 1.4925e-03, 1.2405e-03, 1.7716e-03, 3.9310e-03,\n",
      "        8.6536e-04, 8.6222e-04, 1.3510e-03, 9.9700e-04, 1.5747e-03, 3.2086e-03,\n",
      "        1.2506e-03, 1.1003e-03, 3.5622e-03, 2.1118e-03, 1.6943e-03, 7.4000e-04,\n",
      "        1.8965e-03, 1.7044e-03, 1.4539e-03, 6.9048e-04, 1.6198e-03, 2.2972e-03,\n",
      "        3.4939e-03, 9.4757e-04, 1.8022e-03, 1.4110e-03, 2.6536e-03, 4.6149e-06,\n",
      "        2.4322e-03, 7.4245e-04, 1.9676e-03, 8.6161e-04, 1.1639e-03, 1.0104e-03,\n",
      "        1.0780e-03, 1.0639e-03, 2.1375e-03, 1.7169e-06, 1.7281e-03, 8.2770e-04,\n",
      "        1.6342e-03, 1.4890e-03, 1.0071e-03, 1.5046e-03, 2.4047e-05, 1.3111e-03,\n",
      "        2.1332e-03, 1.2446e-03, 1.0290e-03, 2.4662e-03, 7.4389e-04, 1.9611e-03,\n",
      "        2.1111e-03, 4.5972e-06, 1.2050e-03, 4.2887e-07, 1.3209e-03, 7.0029e-04,\n",
      "        1.7532e-03, 1.1195e-03, 1.7916e-03, 1.0788e-03, 1.4670e-03, 1.3622e-03,\n",
      "        1.0733e-03, 1.8570e-03, 8.2739e-04, 7.8808e-04, 6.4354e-04, 2.7253e-03,\n",
      "        2.0217e-03, 2.7247e-03, 1.2257e-03, 8.5171e-04, 1.7303e-03, 1.4363e-03,\n",
      "        8.9023e-04, 1.1252e-03, 1.0400e-03, 9.1882e-04, 1.4013e-03, 1.3863e-03,\n",
      "        3.4909e-03, 1.7208e-03, 2.2297e-03, 4.9848e-06, 6.4984e-04, 2.3099e-03,\n",
      "        1.7294e-03, 2.6274e-03, 2.2366e-03, 1.4979e-03, 9.4347e-04, 1.5252e-03,\n",
      "        1.8669e-03, 9.4038e-04, 1.6336e-03, 2.0030e-03, 1.2965e-03, 6.5988e-04,\n",
      "        1.5959e-03, 2.3382e-06, 1.3224e-03, 1.0723e-03, 8.7309e-04, 9.1300e-04,\n",
      "        1.7648e-03, 1.5950e-03, 9.0807e-04, 9.8855e-04, 6.3988e-04, 1.3699e-03,\n",
      "        9.3388e-04, 9.0079e-04, 7.1019e-04, 3.8191e-03, 5.3957e-08, 1.4391e-03,\n",
      "        1.8322e-03, 4.0231e-03, 1.1627e-03, 7.2022e-04, 1.9472e-03, 1.8842e-03,\n",
      "        1.4063e-03, 1.9786e-03, 1.5100e-03, 1.0239e-03, 1.3264e-03, 1.5963e-03,\n",
      "        1.3280e-03, 2.7933e-03, 1.1271e-03, 1.0070e-03, 2.3857e-03, 1.3260e-03,\n",
      "        1.4722e-03, 1.0092e-03, 1.7220e-03, 1.2236e-03, 1.1043e-03, 1.4187e-03,\n",
      "        2.9957e-03, 2.7349e-03, 1.5859e-06, 1.5448e-03, 1.7366e-03, 1.1356e-03,\n",
      "        1.5581e-03, 9.7540e-04, 1.5237e-03, 1.0857e-03, 3.3944e-03, 7.6130e-04,\n",
      "        8.3237e-04, 2.0884e-03, 1.0316e-03, 2.7785e-03, 8.1916e-04, 1.4309e-03,\n",
      "        1.3807e-03, 1.4997e-03, 1.6211e-03, 2.3616e-03, 2.2398e-03, 5.4830e-04,\n",
      "        1.0359e-03, 1.0263e-03, 3.3423e-03, 1.8935e-03, 1.0932e-03, 8.1100e-04,\n",
      "        1.3015e-03, 1.7003e-03, 1.1165e-03, 1.5508e-03, 1.1458e-03, 1.1920e-03,\n",
      "        1.8508e-03, 1.4977e-03, 2.6673e-03, 9.5078e-04, 2.0931e-03, 1.0665e-03,\n",
      "        7.6233e-04, 1.0767e-03, 6.6460e-04, 4.7038e-07, 2.9882e-03, 2.9118e-03,\n",
      "        6.1811e-04, 6.7231e-04, 1.9998e-03, 1.1468e-03, 9.3678e-04, 1.3629e-03,\n",
      "        2.3537e-03, 1.1485e-03, 2.5149e-03, 1.4752e-03, 7.5373e-04, 5.2401e-04,\n",
      "        1.1717e-03, 1.8692e-03, 3.2793e-03, 9.8571e-04, 3.0571e-03, 7.5747e-04])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "conv_weight: tensor([[ 6.4035e-01,  1.2562e-01, -5.5776e-01,  ..., -2.2460e-01,\n",
      "         -1.0870e-01,  1.0022e+00],\n",
      "        [ 1.2147e-01,  1.1937e-01,  1.3671e-01,  ..., -4.1708e-02,\n",
      "         -9.3526e-02, -7.0465e-02],\n",
      "        [-1.4535e-01, -7.1960e-02, -1.7853e-01,  ...,  9.6434e-02,\n",
      "          3.3104e-01,  7.4077e-02],\n",
      "        ...,\n",
      "        [ 2.2161e-01, -5.6254e-02,  7.7294e-02,  ...,  6.9646e-02,\n",
      "         -9.1310e-02,  2.1111e-01],\n",
      "        [-9.1136e-02, -9.4588e-02,  5.1640e-04,  ..., -9.5919e-01,\n",
      "         -9.0031e-01,  3.1892e-01],\n",
      "        [-7.4411e-02,  1.2356e-01, -1.3849e-01,  ..., -1.0902e-01,\n",
      "          8.6095e-02, -1.0643e-01]]) conv_bias: tensor([ 1.7455e-01,  8.6623e-01, -5.9549e-01, -5.2856e-01,  1.2144e+00,\n",
      "         8.6281e-01,  1.4295e+00,  1.1304e+00, -1.4049e-03, -1.0530e+00,\n",
      "        -6.1277e-01,  9.3283e-01,  4.3908e-01,  5.1940e-01, -1.4447e-02,\n",
      "         8.9665e-01, -4.1523e-01,  8.9342e-01, -1.4849e-02, -4.8270e-01,\n",
      "        -1.5246e-01,  5.5343e-01,  9.1818e-01, -4.4818e-01, -7.3610e-01,\n",
      "        -2.8448e-01,  4.9933e-01,  1.0408e+00,  1.2349e+00,  1.3899e+00,\n",
      "        -5.0246e-01,  1.1715e+00, -6.6738e-01, -7.2276e-01, -6.5331e-01,\n",
      "         1.2512e+00,  7.3285e-01,  1.1174e+00,  1.3283e-02,  1.4680e+00,\n",
      "        -4.8050e-01, -4.1876e-01,  1.0597e-01, -5.0752e-01,  3.9017e-01,\n",
      "        -1.0576e-03,  1.1868e+00, -6.8422e-01,  1.1680e-02, -6.0652e-01,\n",
      "         7.6500e-01, -4.9616e-01, -6.6854e-01, -5.7312e-01, -4.9294e-01,\n",
      "         1.4196e-01,  2.1277e+00, -5.6544e-01, -1.8498e-03, -1.0448e-01,\n",
      "        -5.5516e-01,  1.1737e+00,  5.6094e-01,  9.5706e-01,  3.0116e-01,\n",
      "        -1.9111e-01, -2.2973e-01,  1.1652e+00,  6.5911e-01,  1.0366e+00,\n",
      "        -4.7094e-01,  6.3621e-01, -8.2922e-04, -7.8655e-03, -3.4778e-01,\n",
      "         3.4155e-01,  5.5534e-02,  4.1983e-01, -5.8009e-01, -3.7587e-01,\n",
      "         4.8472e-01, -3.8085e-01, -3.6732e-02,  5.9701e-01, -7.7304e-01,\n",
      "        -9.5531e-01,  4.1699e-01,  1.3384e+00, -8.1084e-01, -3.3701e-01,\n",
      "        -4.9721e-01,  1.1654e+00,  4.0095e-01,  2.6100e-01, -2.9002e-01,\n",
      "         1.1751e+00,  1.6715e-01,  4.5862e-01, -2.7139e-01,  1.2611e+00,\n",
      "         6.1059e-01, -2.9304e-01, -1.6856e-01, -9.4047e-01,  5.6672e-01,\n",
      "         1.3875e+00, -3.0584e-01, -2.0646e-02,  3.2438e-02,  8.0531e-01,\n",
      "         6.8530e-01,  1.3410e+00, -4.7520e-01,  9.7098e-01, -4.2108e-01,\n",
      "         9.7468e-01,  2.3443e-01, -1.5486e-02, -4.1961e-01,  1.4771e+00,\n",
      "         5.0352e-01, -3.6074e-01,  5.6970e-01,  5.2102e-01, -1.2018e-01,\n",
      "         6.0820e-01, -2.4142e-01, -6.7999e-01,  6.3251e-01, -1.2914e-01,\n",
      "        -6.9273e-01, -5.7924e-02,  4.8299e-01, -2.4156e-02,  1.1556e+00,\n",
      "        -2.8644e-03, -5.4004e-01,  2.5369e+00, -5.0674e-01, -5.0947e-01,\n",
      "         4.1173e-01,  1.2387e+00, -5.2131e-01,  1.4050e+00,  1.1706e+00,\n",
      "        -4.3557e-01,  1.3261e+00,  7.9971e-01,  8.5843e-01, -6.3532e-01,\n",
      "        -2.3256e-01, -3.1822e-01,  9.3975e-01,  1.0906e+00,  2.9782e-01,\n",
      "        -3.3957e-01, -4.9119e-01, -5.6369e-01, -4.5561e-01,  1.0281e+00,\n",
      "        -4.7014e-01, -3.7524e-01,  1.2981e-01,  7.3467e-01, -5.9079e-02,\n",
      "        -2.2631e-02,  1.3498e+00, -4.8502e-01, -4.3883e-01,  4.1672e-01,\n",
      "         3.6664e-01, -1.2323e-01,  9.2698e-01,  7.3943e-01, -9.4639e-02,\n",
      "        -5.9949e-01, -3.4105e-01,  1.2495e+00, -7.3218e-01,  9.4178e-01,\n",
      "        -6.1787e-01, -6.8195e-03, -8.1992e-01,  4.6228e-01, -5.6444e-01,\n",
      "         1.1277e+00,  5.5641e-01, -7.7958e-01,  1.0667e+00,  9.1425e-01,\n",
      "         1.2499e+00, -6.6586e-01,  2.7357e+00,  9.8959e-01,  1.0816e+00,\n",
      "        -1.2869e-02, -1.1861e-03, -6.0924e-01, -5.2475e-01,  5.2712e-01,\n",
      "        -7.8178e-01, -7.6264e-01, -5.6112e-01, -5.9399e-01, -5.5160e-01,\n",
      "        -6.0515e-01,  6.8992e-01, -7.3112e-01,  7.2782e-01, -7.1911e-01,\n",
      "         1.5278e+00,  7.3762e-01,  7.8330e-01,  1.0942e+00, -2.7850e-01,\n",
      "        -1.2547e-01,  3.2630e-01,  9.8026e-01,  7.1318e-01,  1.0713e+00,\n",
      "         5.2579e-01,  6.3285e-01, -3.9211e-01,  3.1591e-01, -6.1252e-03,\n",
      "        -5.6705e-01, -1.8897e-01, -6.2843e-01, -6.4849e-01, -5.4423e-01,\n",
      "         7.4935e-01, -4.9466e-01, -1.0315e-03, -6.7833e-01,  1.4310e+00,\n",
      "         5.5133e-01, -6.3372e-01, -4.1557e-01,  6.8353e-01, -7.7382e-01,\n",
      "         8.9317e-01, -3.1544e-01, -8.8953e-02, -5.0160e-02, -3.0492e-01,\n",
      "         1.0672e+00, -3.4856e-01,  7.8775e-01,  8.1601e-02, -4.1014e-01,\n",
      "        -4.2199e-01,  9.0408e-01, -5.0691e-01,  5.5574e-01, -7.5197e-01,\n",
      "        -6.9883e-01,  4.5062e-01,  1.1480e+00,  5.2704e-01, -6.0292e-01,\n",
      "         6.6415e-03, -8.8913e-01,  4.8076e-01,  7.0081e-01,  9.9501e-01,\n",
      "        -6.7001e-01,  1.0870e+00, -1.7720e-03,  1.9634e-01, -2.6323e-01,\n",
      "         1.5978e+00,  1.2593e+00,  4.4288e-01,  1.1245e+00, -7.0320e-01,\n",
      "        -3.4681e-01,  3.1197e-01, -7.0267e-01, -4.0962e-01,  2.2106e-01,\n",
      "         8.2608e-01,  1.5313e+00,  8.4116e-01,  5.8585e-01,  2.1330e-01,\n",
      "        -6.5899e-01, -3.7317e-01,  7.1839e-01])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "q_weight: tensor([ 80,  16, -70,  ..., -51,  41, -50], dtype=torch.int32) q_bias: tensor([    414,    6739,   -3599,   -2587,    6038,    4774,    9953,    8537,\n",
      "        -114824,   -5555,   -3751,    6691,    1810,    2011,     -44,    6922,\n",
      "          -1255,    3808,  -40068,   -3376,    -461,    2581,    4827,   -1822,\n",
      "          -4898,    -628,    2412,    9403,    7341,    9095,   -2880,    9612,\n",
      "          -4883,   -6004,   -5430,    9814,    2795,    7946,      63,   12220,\n",
      "          -3276,    -978,     329,   -1380,    1807,  -41639,   12679,   -2986,\n",
      "             22,   -2442,    5748,   -4086,   -2923,   -3302,   -2536,     308,\n",
      "          27638,   -2761,  -30744,    -194,   -3470,    7278,    2239,    6740,\n",
      "           1181,    -492,    -590,    8506,    3416,    6987,   -1259,    2524,\n",
      "        -132154,     -22,    -860,    1179,     142,    1980,   -2456,   -1051,\n",
      "           2207,   -2086,    -141,    1032,   -6070,   -7528,    2097,    9121,\n",
      "          -3499,    -714,   -2701,    7196,     765,     840,   -1163,   10789,\n",
      "            599,    1828,   -1268,   12410,    2561,    -867,    -328,   -6744,\n",
      "           2137,    6681,    -783,  -30398,      91,    7370,    2366,   10575,\n",
      "          -2774,    6530,   -2654,    6225,     745,  -61286,   -1650,   12125,\n",
      "           2094,   -1646,    3843,    2353,  -33957,    3152,    -769,   -3712,\n",
      "           4177,    -356,   -6327,    -201,    1554,  -35702,    6516,  -45380,\n",
      "          -2778,   24614,   -1964,   -3092,    1561,    7801,   -2414,    7008,\n",
      "           7411,   -1594,   10890,    6895,    9063,   -1584,    -782,    -794,\n",
      "           5209,    8700,    1170,   -1606,   -3749,   -3404,   -2977,    7602,\n",
      "          -2280,   -1839,     253,    2901,    -180,  -30848,   14113,   -1427,\n",
      "          -1724,    1078,    1114,    -559,    6676,    3294,    -344,   -4331,\n",
      "          -1419,    4239,   -3837,    9697,   -2631,  -19817,   -4213,    2929,\n",
      "          -4393,    8392,    2142,   -3321,    7982,    6284,   13272,   -3303,\n",
      "          19904,    7464,   10348,     -23, -149364,   -2876,   -1946,     890,\n",
      "          -4568,   -7195,   -1958,   -2142,   -2665,   -2078,    3105,   -4852,\n",
      "           3728,   -3061,    7817,    1794,    4722,    7383,    -793,    -643,\n",
      "           1506,    6600,    2814,    5949,    3235,    3031,    -889,     785,\n",
      "         -26243,   -2494,    -739,   -3760,   -2828,   -3791,    3342,   -3096,\n",
      "             -2,   -6054,   11681,    1794,   -4174,   -1016,    5670,   -3674,\n",
      "           4395,   -1429,    -373,    -144,    -925,   13225,   -2286,    5215,\n",
      "            166,   -1472,   -2623,    7574,   -2646,    2221,   -4576,   -3062,\n",
      "           2672,    6544,    1935,   -2735,      17,   -6354,    1561,    4465,\n",
      "           8868,   -4228,   11113,  -25597,     446,    -614,   17564,   12727,\n",
      "           1505,    6662,   -5100,   -1729,     901,   -4157,   -1107,    1018,\n",
      "           7447,   19855,    4878,    2130,     442,   -4542,    -829,    6444],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-8.8057e-06) tensor(0.0055)   bias tensor(6.2947e-07) tensor(0.0002)\n",
      "features.12.conv.3.weight features.12.conv.5\n",
      "torch.Size([288, 1, 3, 3]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.1421]) torch.Size([1]) \n",
      "wscale= tensor([1.1538e-02, 7.9731e-03, 2.2948e-02, 2.1671e-02, 1.1474e-02, 1.3633e-02,\n",
      "        1.0127e-02, 1.8865e-02, 1.9628e-06, 3.0327e-02, 1.7811e-02, 9.2317e-03,\n",
      "        6.9874e-03, 8.2738e-03, 1.3098e-02, 1.2796e-02, 8.1296e-03, 1.9047e-02,\n",
      "        2.6442e-04, 2.0040e-02, 4.6181e-03, 1.2511e-02, 1.4306e-02, 5.4765e-03,\n",
      "        3.1763e-02, 6.4500e-03, 6.0551e-03, 1.0196e-02, 2.6447e-02, 1.4776e-02,\n",
      "        6.8509e-03, 1.2654e-02, 2.7648e-02, 1.3455e-02, 2.7858e-02, 7.3339e-03,\n",
      "        6.3319e-03, 1.5557e-02, 5.9407e-03, 1.6275e-02, 1.5152e-02, 5.0906e-03,\n",
      "        9.2629e-03, 5.0525e-03, 7.7139e-03, 2.9471e-06, 9.0044e-03, 1.2865e-02,\n",
      "        4.2434e-03, 7.6792e-03, 7.4807e-03, 1.1630e-02, 7.3632e-03, 2.0475e-02,\n",
      "        1.3998e-02, 3.1446e-03, 1.8865e-02, 1.4157e-02, 5.0128e-06, 5.2801e-03,\n",
      "        1.2988e-02, 1.0052e-02, 6.9152e-03, 1.6103e-02, 3.5383e-03, 4.7543e-03,\n",
      "        1.9992e-03, 1.4929e-02, 6.6786e-03, 1.5134e-02, 1.0925e-02, 7.0305e-03,\n",
      "        5.8893e-07, 3.5185e-03, 6.3513e-03, 1.9364e-02, 4.9546e-03, 7.7906e-03,\n",
      "        8.7300e-03, 1.0792e-02, 9.6494e-03, 1.1276e-02, 3.4164e-03, 4.5087e-03,\n",
      "        3.6703e-01, 2.5923e-02, 6.9084e-03, 1.2220e-02, 1.9580e-02, 5.2518e-03,\n",
      "        1.0905e-02, 1.7831e-02, 3.6689e-03, 7.2142e-03, 1.1568e-02, 1.5098e-02,\n",
      "        2.6391e-03, 3.3048e-03, 3.8207e-03, 1.6656e-02, 7.2664e-03, 1.1418e-02,\n",
      "        3.9794e-03, 2.1398e-02, 8.7233e-03, 2.4630e-02, 4.0975e-03, 3.3750e-04,\n",
      "        6.6608e-03, 8.0404e-03, 1.3548e-02, 1.6967e-02, 1.8284e-02, 6.4534e-03,\n",
      "        8.0284e-03, 1.0940e-02, 3.0933e-03, 1.4601e-04, 1.9998e-02, 1.8197e-02,\n",
      "        1.1985e-02, 6.4788e-03, 4.9629e-03, 3.5483e-03, 2.1220e-02, 1.3129e-02,\n",
      "        6.7767e-03, 3.1687e-02, 6.7433e-03, 4.6349e-03, 1.1345e-02, 2.9540e-03,\n",
      "        1.5530e-02, 4.8533e-04, 2.2256e-02, 1.0207e-05, 1.6800e-02, 3.7938e-02,\n",
      "        2.1560e-02, 1.5211e-02, 4.3455e-03, 1.5386e-02, 8.2481e-03, 1.5078e-02,\n",
      "        1.0014e-02, 6.9312e-03, 1.5122e-02, 6.4846e-03, 1.0276e-02, 9.4750e-03,\n",
      "        4.6948e-03, 3.7260e-03, 1.3304e-02, 1.3547e-02, 3.6553e-03, 5.2452e-03,\n",
      "        2.4150e-02, 2.9028e-02, 7.7912e-03, 1.6926e-02, 2.1837e-02, 8.1709e-03,\n",
      "        2.7999e-03, 1.2401e-02, 4.9473e-03, 8.9711e-04, 1.5565e-02, 1.2213e-02,\n",
      "        9.5347e-03, 3.8642e-03, 1.0217e-02, 1.0669e-02, 1.1715e-02, 1.3528e-02,\n",
      "        9.7726e-03, 9.7537e-03, 1.1149e-02, 1.7015e-02, 1.4894e-02, 9.3841e-03,\n",
      "        1.8068e-02, 1.5298e-04, 5.3345e-02, 6.0717e-03, 4.0940e-02, 2.3869e-02,\n",
      "        1.5156e-02, 9.2793e-03, 1.9829e-02, 1.2135e-02, 1.1180e-02, 1.6684e-02,\n",
      "        3.6417e-02, 8.7100e-03, 1.6484e-02, 6.7509e-03, 2.2896e-06, 1.2507e-02,\n",
      "        8.9884e-03, 3.9272e-03, 4.7615e-02, 2.8963e-02, 5.7201e-03, 1.0419e-02,\n",
      "        1.7339e-02, 1.1331e-02, 1.1201e-02, 1.7391e-02, 9.6995e-03, 5.5882e-03,\n",
      "        1.3198e-02, 3.9906e-03, 6.7214e-03, 1.2740e-02, 3.1034e-03, 1.2844e-02,\n",
      "        6.8116e-03, 1.5250e-02, 1.8350e-02, 1.2056e-02, 1.5063e-02, 6.3650e-03,\n",
      "        8.3072e-03, 4.8053e-03, 5.0959e-05, 8.4244e-03, 6.1550e-03, 1.0206e-02,\n",
      "        1.2300e-02, 1.4248e-02, 8.3122e-03, 1.4456e-02, 5.1382e-03, 2.8534e-02,\n",
      "        1.7490e-02, 8.6146e-03, 2.1556e-02, 7.7011e-03, 6.2833e-03, 2.3888e-02,\n",
      "        9.5808e-03, 1.1402e-02, 5.1309e-03, 3.8906e-03, 1.3039e-02, 8.9344e-03,\n",
      "        6.5914e-03, 6.5549e-03, 4.5797e-03, 6.2920e-03, 1.4776e-02, 9.0235e-03,\n",
      "        8.8753e-03, 4.8679e-03, 2.2337e-02, 1.6504e-02, 4.1945e-03, 2.2192e-02,\n",
      "        1.1576e-02, 8.9598e-03, 4.6737e-03, 1.9816e-02, 8.8693e-03, 1.6394e-02,\n",
      "        1.0258e-02, 3.7945e-02, 8.2984e-03, 4.8692e-06, 4.5037e-03, 6.7027e-03,\n",
      "        2.1039e-02, 1.4984e-02, 8.4195e-03, 1.5585e-02, 2.5193e-02, 1.3017e-02,\n",
      "        4.2931e-03, 3.7003e-02, 1.1383e-02, 1.0255e-02, 1.0232e-02, 1.7427e-02,\n",
      "        1.2175e-02, 4.5742e-03, 2.9001e-03, 2.8329e-02, 2.3313e-03, 7.2786e-03]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.3166]) torch.Size([1])\n",
      "###: M= tensor([5.1790e-03, 3.5790e-03, 1.0301e-02, 9.7279e-03, 5.1504e-03, 6.1197e-03,\n",
      "        4.5459e-03, 8.4684e-03, 8.8106e-07, 1.3613e-02, 7.9952e-03, 4.1440e-03,\n",
      "        3.1365e-03, 3.7140e-03, 5.8796e-03, 5.7441e-03, 3.6492e-03, 8.5499e-03,\n",
      "        1.1869e-04, 8.9956e-03, 2.0730e-03, 5.6161e-03, 6.4218e-03, 2.4583e-03,\n",
      "        1.4258e-02, 2.8953e-03, 2.7180e-03, 4.5770e-03, 1.1872e-02, 6.6328e-03,\n",
      "        3.0752e-03, 5.6802e-03, 1.2411e-02, 6.0396e-03, 1.2505e-02, 3.2921e-03,\n",
      "        2.8423e-03, 6.9832e-03, 2.6667e-03, 7.3057e-03, 6.8014e-03, 2.2851e-03,\n",
      "        4.1579e-03, 2.2680e-03, 3.4626e-03, 1.3229e-06, 4.0419e-03, 5.7748e-03,\n",
      "        1.9048e-03, 3.4471e-03, 3.3580e-03, 5.2206e-03, 3.3052e-03, 9.1910e-03,\n",
      "        6.2836e-03, 1.4115e-03, 8.4682e-03, 6.3548e-03, 2.2501e-06, 2.3701e-03,\n",
      "        5.8302e-03, 4.5122e-03, 3.1041e-03, 7.2285e-03, 1.5883e-03, 2.1341e-03,\n",
      "        8.9740e-04, 6.7015e-03, 2.9979e-03, 6.7933e-03, 4.9041e-03, 3.1559e-03,\n",
      "        2.6436e-07, 1.5794e-03, 2.8510e-03, 8.6920e-03, 2.2240e-03, 3.4971e-03,\n",
      "        3.9187e-03, 4.8442e-03, 4.3315e-03, 5.0616e-03, 1.5336e-03, 2.0239e-03,\n",
      "        1.6475e-01, 1.1636e-02, 3.1011e-03, 5.4853e-03, 8.7892e-03, 2.3574e-03,\n",
      "        4.8949e-03, 8.0041e-03, 1.6469e-03, 3.2383e-03, 5.1926e-03, 6.7773e-03,\n",
      "        1.1846e-03, 1.4835e-03, 1.7150e-03, 7.4766e-03, 3.2618e-03, 5.1255e-03,\n",
      "        1.7863e-03, 9.6053e-03, 3.9158e-03, 1.1056e-02, 1.8393e-03, 1.5150e-04,\n",
      "        2.9899e-03, 3.6092e-03, 6.0815e-03, 7.6163e-03, 8.2074e-03, 2.8968e-03,\n",
      "        3.6038e-03, 4.9108e-03, 1.3885e-03, 6.5543e-05, 8.9766e-03, 8.1684e-03,\n",
      "        5.3800e-03, 2.9082e-03, 2.2278e-03, 1.5928e-03, 9.5254e-03, 5.8933e-03,\n",
      "        3.0420e-03, 1.4224e-02, 3.0269e-03, 2.0805e-03, 5.0925e-03, 1.3260e-03,\n",
      "        6.9711e-03, 2.1786e-04, 9.9901e-03, 4.5817e-06, 7.5412e-03, 1.7030e-02,\n",
      "        9.6780e-03, 6.8277e-03, 1.9506e-03, 6.9067e-03, 3.7024e-03, 6.7681e-03,\n",
      "        4.4951e-03, 3.1113e-03, 6.7882e-03, 2.9108e-03, 4.6129e-03, 4.2531e-03,\n",
      "        2.1074e-03, 1.6725e-03, 5.9721e-03, 6.0809e-03, 1.6408e-03, 2.3545e-03,\n",
      "        1.0841e-02, 1.3030e-02, 3.4973e-03, 7.5980e-03, 9.8022e-03, 3.6678e-03,\n",
      "        1.2568e-03, 5.5664e-03, 2.2207e-03, 4.0270e-04, 6.9871e-03, 5.4821e-03,\n",
      "        4.2800e-03, 1.7346e-03, 4.5860e-03, 4.7892e-03, 5.2588e-03, 6.0723e-03,\n",
      "        4.3868e-03, 4.3783e-03, 5.0044e-03, 7.6376e-03, 6.6857e-03, 4.2123e-03,\n",
      "        8.1103e-03, 6.8668e-05, 2.3946e-02, 2.7255e-03, 1.8377e-02, 1.0714e-02,\n",
      "        6.8032e-03, 4.1653e-03, 8.9009e-03, 5.4470e-03, 5.0184e-03, 7.4890e-03,\n",
      "        1.6347e-02, 3.9098e-03, 7.3993e-03, 3.0303e-03, 1.0277e-06, 5.6141e-03,\n",
      "        4.0347e-03, 1.7629e-03, 2.1374e-02, 1.3001e-02, 2.5677e-03, 4.6768e-03,\n",
      "        7.7833e-03, 5.0864e-03, 5.0277e-03, 7.8063e-03, 4.3539e-03, 2.5084e-03,\n",
      "        5.9245e-03, 1.7913e-03, 3.0171e-03, 5.7188e-03, 1.3930e-03, 5.7656e-03,\n",
      "        3.0576e-03, 6.8453e-03, 8.2372e-03, 5.4116e-03, 6.7616e-03, 2.8571e-03,\n",
      "        3.7290e-03, 2.1570e-03, 2.2874e-05, 3.7816e-03, 2.7629e-03, 4.5814e-03,\n",
      "        5.5213e-03, 6.3958e-03, 3.7312e-03, 6.4889e-03, 2.3064e-03, 1.2808e-02,\n",
      "        7.8512e-03, 3.8669e-03, 9.6762e-03, 3.4569e-03, 2.8205e-03, 1.0723e-02,\n",
      "        4.3007e-03, 5.1183e-03, 2.3032e-03, 1.7464e-03, 5.8528e-03, 4.0105e-03,\n",
      "        2.9588e-03, 2.9424e-03, 2.0557e-03, 2.8244e-03, 6.6325e-03, 4.0505e-03,\n",
      "        3.9840e-03, 2.1851e-03, 1.0027e-02, 7.4086e-03, 1.8829e-03, 9.9617e-03,\n",
      "        5.1962e-03, 4.0219e-03, 2.0980e-03, 8.8949e-03, 3.9813e-03, 7.3589e-03,\n",
      "        4.6045e-03, 1.7033e-02, 3.7250e-03, 2.1857e-06, 2.0216e-03, 3.0087e-03,\n",
      "        9.4442e-03, 6.7261e-03, 3.7794e-03, 6.9958e-03, 1.1309e-02, 5.8431e-03,\n",
      "        1.9271e-03, 1.6610e-02, 5.1095e-03, 4.6032e-03, 4.5928e-03, 7.8228e-03,\n",
      "        5.4654e-03, 2.0533e-03, 1.3018e-03, 1.2716e-02, 1.0465e-03, 3.2672e-03])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "conv_weight: tensor([[[-0.0831,  0.1763, -0.0995],\n",
      "         [-0.1352,  0.6765, -0.1565],\n",
      "         [ 0.0455, -0.1223, -0.0095]],\n",
      "\n",
      "        [[-0.2569, -0.6190, -0.2499],\n",
      "         [-0.9060,  0.0687, -0.9236],\n",
      "         [-0.1755, -0.3550, -0.1075]],\n",
      "\n",
      "        [[-0.6204, -0.5031, -0.5591],\n",
      "         [-0.7807, -1.1738, -0.8620],\n",
      "         [ 1.8034, -1.3144,  1.7742]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0244,  2.1802,  1.1975],\n",
      "         [ 1.4157,  0.6834,  1.5860],\n",
      "         [ 0.6826,  0.4911,  0.6147]],\n",
      "\n",
      "        [[ 0.2167,  0.1433,  0.2260],\n",
      "         [ 0.1489,  0.0256,  0.1423],\n",
      "         [-0.1907, -0.2079, -0.2228]],\n",
      "\n",
      "        [[-0.0048, -0.6063, -0.0342],\n",
      "         [-0.8588, -0.2690, -0.7657],\n",
      "         [-0.1315, -0.4452, -0.1574]]]) conv_bias: tensor([-7.3689e-01,  2.2424e+00,  2.0289e+00, -3.7376e-01, -4.8516e-01,\n",
      "         4.0401e-01,  3.0919e+00, -1.3200e-02, -7.2065e-04, -1.1309e+00,\n",
      "        -5.7378e-01,  2.6886e-01, -7.6120e-01, -5.0817e-01, -5.9263e-01,\n",
      "        -1.7806e-02, -5.6421e-01, -1.0018e-01, -7.8490e-03, -8.6601e-02,\n",
      "         1.0557e+00, -1.1834e+00, -9.8978e-01,  1.5701e+00,  1.0686e+00,\n",
      "         4.0173e-01, -2.2081e+00,  2.4990e+00,  2.6792e+00,  3.4674e+00,\n",
      "         2.7906e+00,  1.1757e+00, -7.5858e-01,  1.3432e+00, -1.2077e-01,\n",
      "         8.1883e-01,  2.8457e+00, -2.9639e-01,  1.5467e+00, -7.2567e-02,\n",
      "        -1.3487e-02, -7.5360e-01, -6.7262e-01, -8.9305e-01, -5.2591e-01,\n",
      "        -6.9037e-04, -2.2121e-01,  3.7183e+00,  1.9578e-01, -8.0448e-01,\n",
      "         2.1539e+00, -1.3743e+00,  1.9578e+00, -8.3659e-01, -3.5829e-01,\n",
      "         1.4279e+00,  3.8177e+00,  1.9197e-02, -9.3277e-04, -3.7987e-01,\n",
      "         1.6645e+00,  1.8523e+00, -7.6481e-01, -9.9864e-02,  1.4223e+00,\n",
      "        -3.8737e-01,  1.5567e+00, -1.7787e-01, -2.5603e+00,  1.5813e-01,\n",
      "        -8.1470e-01,  2.7268e+00, -6.2434e-04,  1.6406e+00, -8.4115e-01,\n",
      "        -3.0086e-01, -1.5999e+00,  1.1235e+00, -9.4005e-01, -9.4705e-01,\n",
      "         1.8108e+00, -4.0163e-02,  1.2252e+00,  1.8214e+00, -5.6209e-01,\n",
      "         6.7704e-02, -1.6166e+00,  4.2778e-01,  2.5226e-02, -2.4950e-01,\n",
      "         1.0737e+00,  1.3719e+00, -9.3432e-01,  2.5750e+00, -6.8540e-01,\n",
      "        -1.6299e+00, -6.2366e-01,  1.3568e+00,  2.2058e+00, -5.4443e-01,\n",
      "         4.6253e-01, -7.5305e-01,  2.0505e+00,  1.3179e-01, -4.3063e-01,\n",
      "         3.1775e+00, -7.2446e-01, -1.0597e-02, -1.0494e+00,  1.6010e+00,\n",
      "        -9.4294e-01,  1.0162e+00, -8.3262e-01,  1.9552e+00,  1.2867e+00,\n",
      "         2.4790e+00,  1.3138e+00, -2.0482e-02, -1.0763e+00,  4.6866e+00,\n",
      "        -1.1576e+00,  2.8260e+00,  1.8207e+00,  1.2548e+00, -2.4013e-02,\n",
      "        -5.0248e-01,  1.9038e+00, -3.1420e-01,  1.5804e+00,  7.2407e-02,\n",
      "         3.6519e-02,  1.1803e+00, -1.2578e+00, -9.2735e-05, -5.0551e-01,\n",
      "        -2.5259e-03, -4.0595e-01,  4.8306e+00, -4.1735e-01, -7.9530e-01,\n",
      "         4.8503e-02, -4.3864e-01,  2.4059e+00,  2.9458e+00,  2.7164e+00,\n",
      "        -7.1384e-01,  6.4921e-01,  1.7823e+00,  2.4638e+00, -7.3804e-02,\n",
      "        -5.8929e-01,  9.3351e-01, -8.9378e-01, -2.0837e-01,  1.2622e+00,\n",
      "         1.3310e+00,  1.6897e+00,  3.5173e+00,  2.1757e+00, -1.0676e-02,\n",
      "        -1.4198e+00,  3.0635e+00,  1.4326e+00, -5.3381e-02, -1.1422e+00,\n",
      "        -7.0357e-03,  2.9015e+00, -6.4772e-01,  2.0710e+00, -1.2931e+00,\n",
      "        -9.2503e-01, -1.1979e+00, -1.2208e-01, -3.6302e-01,  2.6394e+00,\n",
      "         1.7171e+00, -1.1014e-01, -1.5507e+00, -2.0054e-01, -4.5604e-01,\n",
      "         1.0173e+00, -5.1713e-03, -6.0644e-01,  1.2770e+00, -5.0896e-01,\n",
      "        -2.1490e-02, -1.2891e+00,  2.9775e+00, -2.6749e-01,  1.6385e+00,\n",
      "        -4.1349e-01,  2.1440e+00,  3.6167e+00,  3.3413e+00, -2.3333e-01,\n",
      "         1.3836e+00, -1.0293e-03, -1.9326e-01, -1.1697e+00, -1.0652e+00,\n",
      "        -3.4557e-01, -3.3243e-01,  3.7406e+00, -4.4901e-01,  9.1477e-01,\n",
      "        -6.3065e-01, -8.4121e-02,  3.2149e+00, -4.4817e-01,  1.0614e+00,\n",
      "         2.6004e-01, -5.3592e-02,  1.9217e+00,  1.3279e-01, -1.0774e+00,\n",
      "        -5.5491e-01,  1.6363e+00,  1.5622e-01,  3.6322e+00, -2.5629e-01,\n",
      "        -2.1253e-01,  3.3877e-02, -1.1670e-01, -1.3565e-01, -2.2839e-03,\n",
      "        -4.0549e-01,  1.6154e+00, -9.8066e-01, -1.4712e-02, -4.7584e-01,\n",
      "        -5.4076e-02, -7.1635e-01, -9.9088e-01,  1.0533e+00,  3.7939e-01,\n",
      "        -4.2741e-01, -4.6812e-01, -7.2357e-01,  1.6679e+00, -3.1142e-01,\n",
      "        -2.1215e-01, -5.2867e-01,  2.8422e+00,  1.0325e+00, -1.6973e-01,\n",
      "         3.3736e+00,  1.2449e+00,  1.1196e+00, -7.3459e-01,  1.1764e+00,\n",
      "        -8.9676e-02,  2.4067e+00, -2.4707e-01,  1.5227e+00, -7.7525e-01,\n",
      "        -4.7763e-01,  1.5818e+00,  3.8090e+00, -7.0525e-01,  2.5144e+00,\n",
      "        -3.3629e-01,  1.1323e+00, -6.8231e-01,  2.6158e-02,  2.3830e+00,\n",
      "        -1.6128e+00,  2.9675e+00, -1.4910e-04,  5.2152e-01, -1.2351e+00,\n",
      "         2.3089e+00,  3.4086e+00,  1.4438e+00,  2.9819e+00,  6.7469e-02,\n",
      "        -1.1228e+00,  3.3611e+00, -8.9080e-02, -1.1572e+00, -5.6599e-01,\n",
      "         1.7919e+00,  3.2735e-01, -2.1327e-01,  2.6931e+00,  2.6793e+00,\n",
      "        -2.0584e+00,  1.6014e+00,  1.5579e+00])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "q_weight: tensor([ -7,  15,  -9,  ..., -18, -61, -22], dtype=torch.int32) q_bias: tensor([ -449,  1979,   622,  -121,  -298,   209,  2149,    -5, -2584,  -262,\n",
      "         -227,   205,  -767,  -432,  -318,   -10,  -488,   -37,  -209,   -30,\n",
      "         1609,  -666,  -487,  2018,   237,   438, -2566,  1725,   713,  1651,\n",
      "         2867,   654,  -193,   703,   -31,   786,  3163,  -134,  1832,   -31,\n",
      "           -6, -1042,  -511, -1244,  -480, -1649,  -173,  2034,   325,  -737,\n",
      "         2026,  -832,  1871,  -288,  -180,  3196,  1424,    10, -1310,  -506,\n",
      "          902,  1297,  -778,   -44,  2829,  -573,  5480,   -84, -2698,    74,\n",
      "         -525,  2729, -7461,  3282,  -932,  -109, -2273,  1015,  -758,  -618,\n",
      "         1321,   -25,  2524,  2843,   -11,    18, -1647,   246,     9,  -334,\n",
      "          693,   541, -1792,  2512,  -417,  -760, -1663,  2889,  4063,  -230,\n",
      "          448,  -464,  3626,    43,  -347,   908, -1244,  -221, -1109,  1401,\n",
      "         -490,   422,  -320,  2132,  1128,  1595,  2989,  -987,  -379,  1812,\n",
      "         -680,  3070,  2582,  2489,    -8,  -269,  1977,   -70,  1649,   110,\n",
      "           23,  2812,  -570,    -1,  -160, -1742,  -170,   896,  -136,  -368,\n",
      "           79,  -201,  2053,  1375,  1909,  -725,   302,  1934,  1687,   -55,\n",
      "         -883,  1763,  -473,  -108,  2430,  1786,   492,   853,  1965,    -4,\n",
      "         -458,  2639,  3601,   -30, -1625,   -55,  1312,  -373,  1529, -2355,\n",
      "         -637,  -790,   -73,  -189,  1901,  1239,   -70,  -641,   -95,  -342,\n",
      "          396,  -238,   -80,  1480,   -87,    -6,  -599,  2258,   -95,   950,\n",
      "         -260,   904,   699,  2700,  -100,  1442, -3164,  -109,  -916, -1909,\n",
      "          -51,   -81,  4602,  -303,   371,  -392,   -53,  1301,  -325,  1337,\n",
      "          139,   -95,  2012,    73, -2443,  -304,  1691,    72,  1393,  -150,\n",
      "          -99,    37,   -99,  -199,  -315,  -339,  1847,  -676,    -8,  -235,\n",
      "          -46,  -349, -1357,   260,   153,  -349,  -153,  -661,  1868,   -92,\n",
      "         -156,  -326,  3898,  1868,   -92,  2657,  1329,  1202, -1129,  1316,\n",
      "          -43,  1877,  -196,  2201,  -244,  -204,  2654,  1208,  -429,  1975,\n",
      "         -506,   402,  -541,    11,  1635,  -299,  2517,  -215,   815, -1297,\n",
      "          772,  1601,  1207,  1347,    19,  -607,  5510,   -17,  -715,  -388,\n",
      "         1233,   132,  -123,  4143,  6502,  -511,  4834,  1506],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(9.7099e-05) tensor(0.1368)   bias tensor(2.2105e-05) tensor(0.0116)\n",
      "features.12.conv.6.weight features.12.conv.8\n",
      "torch.Size([48, 288, 1, 1]) conv_bias= torch.Size([48]) \n",
      "ascale= tensor([0.2762]) torch.Size([1]) \n",
      "wscale= tensor([0.0029, 0.0040, 0.0038, 0.0041, 0.0026, 0.0023, 0.0030, 0.0022, 0.0038,\n",
      "        0.0030, 0.0037, 0.0031, 0.0030, 0.0045, 0.0032, 0.0032, 0.0028, 0.0035,\n",
      "        0.0032, 0.0027, 0.0027, 0.0034, 0.0025, 0.0038, 0.0024, 0.0036, 0.0029,\n",
      "        0.0030, 0.0034, 0.0031, 0.0039, 0.0039, 0.0030, 0.0028, 0.0029, 0.0032,\n",
      "        0.0034, 0.0031, 0.0034, 0.0034, 0.0032, 0.0031, 0.0037, 0.0026, 0.0028,\n",
      "        0.0026, 0.0033, 0.0032]) torch.Size([48, 1, 1, 1]) \n",
      "oscale= tensor([0.0864]) torch.Size([1])\n",
      "###: M= tensor([0.0092, 0.0129, 0.0121, 0.0131, 0.0084, 0.0073, 0.0096, 0.0070, 0.0123,\n",
      "        0.0097, 0.0117, 0.0099, 0.0097, 0.0145, 0.0104, 0.0103, 0.0088, 0.0111,\n",
      "        0.0101, 0.0088, 0.0088, 0.0109, 0.0078, 0.0121, 0.0077, 0.0117, 0.0093,\n",
      "        0.0097, 0.0109, 0.0099, 0.0126, 0.0126, 0.0097, 0.0091, 0.0091, 0.0103,\n",
      "        0.0110, 0.0100, 0.0109, 0.0108, 0.0101, 0.0098, 0.0117, 0.0085, 0.0090,\n",
      "        0.0084, 0.0106, 0.0104])\n",
      "torch.Size([48, 288, 1, 1]) torch.Size([48])\n",
      "conv_weight: tensor([[-0.0349,  0.0071,  0.0205,  ...,  0.1056, -0.0832, -0.1269],\n",
      "        [ 0.1190,  0.2125, -0.1618,  ..., -0.1032,  0.0041,  0.0762],\n",
      "        [-0.0336,  0.0367,  0.0962,  ...,  0.0170,  0.0366, -0.0466],\n",
      "        ...,\n",
      "        [-0.0043,  0.0109,  0.0116,  ..., -0.0537,  0.0815,  0.0714],\n",
      "        [ 0.0090,  0.0179, -0.0300,  ..., -0.0935, -0.0085,  0.0173],\n",
      "        [-0.0243,  0.1205,  0.0116,  ...,  0.0086, -0.0212, -0.0987]]) conv_bias: tensor([-0.8263,  3.0582, -0.4040,  2.7858,  0.2154,  0.9882,  0.1960,  0.4129,\n",
      "         0.3869,  0.4862,  0.8272, -0.0195, -0.2416, -1.1037, -0.6857, -1.0476,\n",
      "        -0.3770, -0.2748,  1.4977, -1.0532, -2.0206, -1.8331, -0.4719, -1.0354,\n",
      "        -1.0489, -0.4976,  1.2779,  1.2331,  0.1714,  0.3685,  2.6032,  0.0684,\n",
      "         2.4321,  1.1275, -0.6598,  0.2909,  1.7221,  1.5331, -2.4777,  1.8192,\n",
      "        -1.4012, -1.1904,  0.6091, -1.7099,  1.4910,  1.0669,  1.8124,  0.5267])\n",
      "torch.Size([48, 288, 1, 1]) torch.Size([48])\n",
      "q_weight: tensor([-12,   2,   7,  ...,   3,  -7, -30], dtype=torch.int32) q_bias: tensor([-1037,  2737,  -386,  2467,   299,  1574,   237,   687,   364,   578,\n",
      "          816,   -23,  -289,  -882,  -767, -1173,  -494,  -287,  1713, -1393,\n",
      "        -2663, -1954,  -697,  -988, -1579,  -494,  1583,  1472,   182,   432,\n",
      "         2388,    63,  2903,  1437,  -838,   326,  1809,  1783, -2631,  1954,\n",
      "        -1601, -1406,   604, -2337,  1915,  1463,  1987,   588],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-3.3545e-06) tensor(0.0023)   bias tensor(-3.0385e-05) tensor(0.0006)\n",
      "features.13.conv.0.weight features.13.conv.2\n",
      "torch.Size([288, 48, 1, 1]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.0864]) torch.Size([1]) \n",
      "wscale= tensor([1.3942e-03, 3.1079e-03, 1.8013e-03, 2.2525e-03, 1.9621e-03, 2.6047e-03,\n",
      "        8.4834e-07, 3.9995e-07, 1.4627e-03, 1.5023e-03, 1.2793e-03, 1.9905e-03,\n",
      "        1.7170e-03, 5.1177e-03, 1.4294e-03, 1.5758e-03, 1.1297e-03, 2.2391e-03,\n",
      "        9.7387e-03, 1.7270e-03, 3.6105e-03, 1.9955e-03, 2.8586e-03, 2.1229e-03,\n",
      "        1.4790e-03, 3.5559e-03, 2.0719e-03, 3.4362e-03, 1.9988e-06, 2.6634e-03,\n",
      "        1.3617e-03, 2.6897e-03, 2.3618e-03, 1.4840e-03, 1.4079e-03, 2.1081e-03,\n",
      "        3.1572e-03, 1.8081e-03, 2.0981e-07, 2.2180e-03, 2.2162e-03, 5.1420e-03,\n",
      "        1.7286e-03, 2.1411e-03, 1.3997e-03, 1.1920e-03, 2.9014e-03, 2.5534e-03,\n",
      "        3.7440e-03, 3.9053e-03, 1.5794e-03, 2.3708e-03, 2.4135e-03, 3.9710e-03,\n",
      "        2.0503e-03, 2.9503e-03, 4.2601e-03, 1.4343e-03, 4.6270e-03, 2.4608e-03,\n",
      "        3.3991e-03, 2.2031e-03, 2.4501e-03, 2.0703e-03, 1.2520e-03, 2.7001e-03,\n",
      "        2.4013e-03, 1.6204e-03, 1.4701e-06, 3.1717e-03, 1.3724e-03, 1.5961e-03,\n",
      "        2.1823e-03, 5.7158e-03, 1.4786e-03, 3.1759e-03, 3.1579e-03, 2.2304e-03,\n",
      "        2.4759e-03, 1.0493e-03, 1.2418e-03, 2.6913e-03, 2.2262e-03, 3.1347e-03,\n",
      "        7.8115e-03, 5.1984e-03, 2.9888e-03, 2.0840e-03, 2.3317e-03, 3.1497e-03,\n",
      "        8.9071e-04, 2.0228e-03, 2.8269e-07, 2.6393e-05, 2.5352e-03, 2.2501e-03,\n",
      "        4.5127e-03, 2.0249e-04, 1.6769e-03, 2.0451e-03, 3.3112e-03, 2.2110e-03,\n",
      "        2.3257e-03, 3.0664e-03, 1.3968e-03, 1.9294e-03, 1.1254e-03, 1.6209e-03,\n",
      "        2.2637e-03, 2.0744e-03, 1.1880e-03, 2.7473e-03, 1.5311e-03, 1.6889e-03,\n",
      "        1.5992e-03, 4.0776e-07, 1.9322e-07, 1.4766e-03, 1.9762e-03, 2.6683e-03,\n",
      "        1.7189e-03, 4.9337e-06, 2.8855e-03, 1.2458e-03, 2.5894e-03, 3.8419e-03,\n",
      "        1.6220e-03, 1.6022e-03, 1.3089e-06, 1.5642e-03, 2.6233e-03, 3.6697e-06,\n",
      "        3.9219e-03, 2.2275e-03, 1.7850e-03, 2.1584e-03, 1.9713e-03, 2.7349e-03,\n",
      "        2.3052e-03, 2.0621e-03, 1.2801e-03, 4.0555e-03, 1.8223e-03, 1.9690e-06,\n",
      "        3.8182e-03, 1.9946e-03, 1.4015e-03, 1.9746e-03, 2.3057e-03, 1.1598e-03,\n",
      "        2.2354e-03, 2.5321e-03, 1.2797e-03, 2.0148e-03, 1.7818e-03, 2.0853e-03,\n",
      "        5.6663e-03, 1.4522e-03, 2.8616e-03, 2.0868e-03, 1.3667e-03, 3.2602e-03,\n",
      "        1.3488e-03, 2.9439e-03, 1.2400e-03, 1.9800e-03, 1.0915e-03, 1.8823e-03,\n",
      "        4.0857e-03, 1.8218e-03, 1.3006e-03, 3.1929e-03, 2.7221e-07, 1.2024e-03,\n",
      "        5.0655e-03, 1.6261e-03, 1.9736e-03, 2.1020e-06, 2.2091e-03, 2.0139e-03,\n",
      "        2.6562e-03, 1.3571e-03, 3.4598e-07, 5.7175e-03, 3.0703e-03, 1.5132e-03,\n",
      "        2.0784e-03, 3.4551e-03, 3.2724e-03, 1.9004e-03, 3.3362e-03, 2.5547e-03,\n",
      "        1.8893e-03, 1.8436e-03, 1.5411e-03, 6.6328e-03, 2.7371e-03, 2.0332e-03,\n",
      "        1.7105e-03, 3.2590e-03, 2.8352e-03, 4.4374e-03, 2.3349e-03, 2.5781e-03,\n",
      "        4.0971e-03, 2.9509e-03, 2.5731e-03, 4.6066e-03, 2.6095e-03, 3.3856e-03,\n",
      "        1.4280e-03, 2.8451e-03, 2.3340e-03, 3.4227e-03, 2.1708e-03, 1.3585e-03,\n",
      "        2.2855e-07, 1.8290e-03, 2.0500e-03, 1.4292e-03, 1.9567e-03, 1.4317e-03,\n",
      "        1.3336e-03, 2.3495e-03, 1.4333e-03, 4.9778e-03, 1.4610e-03, 3.2193e-03,\n",
      "        5.5519e-03, 3.8984e-03, 2.5005e-03, 1.5961e-03, 2.0074e-03, 1.7486e-03,\n",
      "        1.3189e-03, 3.6620e-03, 3.2662e-03, 1.0810e-03, 3.2219e-03, 2.4666e-03,\n",
      "        1.8799e-03, 3.4438e-03, 5.8093e-03, 1.2211e-03, 1.2676e-03, 3.8302e-03,\n",
      "        2.3807e-05, 1.8575e-03, 1.7330e-03, 1.1559e-03, 1.7998e-03, 2.1821e-07,\n",
      "        1.1961e-03, 3.0071e-03, 1.5449e-03, 2.1403e-03, 9.6828e-04, 2.7169e-03,\n",
      "        4.2518e-03, 3.3132e-03, 4.3611e-03, 4.8708e-06, 2.7642e-03, 3.0528e-03,\n",
      "        1.9768e-03, 4.2853e-03, 3.8880e-03, 1.5612e-07, 1.6694e-03, 2.0398e-03,\n",
      "        5.0978e-03, 3.1672e-03, 1.3559e-03, 3.1461e-03, 3.0032e-07, 3.6408e-03,\n",
      "        3.2274e-03, 3.7284e-03, 2.8857e-03, 2.6580e-03, 2.0502e-03, 9.9995e-04,\n",
      "        1.9172e-03, 3.4384e-03, 2.6370e-03, 1.4933e-03, 3.1362e-06, 1.7459e-03]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.1324]) torch.Size([1])\n",
      "###: M= tensor([9.0916e-04, 2.0266e-03, 1.1746e-03, 1.4688e-03, 1.2794e-03, 1.6985e-03,\n",
      "        5.5319e-07, 2.6080e-07, 9.5381e-04, 9.7963e-04, 8.3421e-04, 1.2980e-03,\n",
      "        1.1196e-03, 3.3371e-03, 9.3208e-04, 1.0275e-03, 7.3667e-04, 1.4601e-03,\n",
      "        6.3504e-03, 1.1262e-03, 2.3543e-03, 1.3013e-03, 1.8640e-03, 1.3843e-03,\n",
      "        9.6442e-04, 2.3187e-03, 1.3511e-03, 2.2407e-03, 1.3034e-06, 1.7367e-03,\n",
      "        8.8792e-04, 1.7539e-03, 1.5401e-03, 9.6767e-04, 9.1809e-04, 1.3746e-03,\n",
      "        2.0588e-03, 1.1791e-03, 1.3681e-07, 1.4463e-03, 1.4452e-03, 3.3530e-03,\n",
      "        1.1272e-03, 1.3962e-03, 9.1274e-04, 7.7729e-04, 1.8920e-03, 1.6650e-03,\n",
      "        2.4414e-03, 2.5466e-03, 1.0299e-03, 1.5460e-03, 1.5738e-03, 2.5894e-03,\n",
      "        1.3370e-03, 1.9238e-03, 2.7779e-03, 9.3528e-04, 3.0172e-03, 1.6047e-03,\n",
      "        2.2165e-03, 1.4366e-03, 1.5976e-03, 1.3500e-03, 8.1641e-04, 1.7607e-03,\n",
      "        1.5658e-03, 1.0566e-03, 9.5860e-07, 2.0682e-03, 8.9494e-04, 1.0408e-03,\n",
      "        1.4230e-03, 3.7272e-03, 9.6418e-04, 2.0710e-03, 2.0592e-03, 1.4544e-03,\n",
      "        1.6145e-03, 6.8425e-04, 8.0973e-04, 1.7549e-03, 1.4517e-03, 2.0441e-03,\n",
      "        5.0937e-03, 3.3898e-03, 1.9489e-03, 1.3589e-03, 1.5205e-03, 2.0539e-03,\n",
      "        5.8082e-04, 1.3190e-03, 1.8433e-07, 1.7210e-05, 1.6532e-03, 1.4673e-03,\n",
      "        2.9427e-03, 1.3204e-04, 1.0934e-03, 1.3336e-03, 2.1592e-03, 1.4418e-03,\n",
      "        1.5166e-03, 1.9995e-03, 9.1085e-04, 1.2581e-03, 7.3385e-04, 1.0569e-03,\n",
      "        1.4761e-03, 1.3527e-03, 7.7469e-04, 1.7914e-03, 9.9838e-04, 1.1013e-03,\n",
      "        1.0428e-03, 2.6590e-07, 1.2600e-07, 9.6285e-04, 1.2887e-03, 1.7400e-03,\n",
      "        1.1209e-03, 3.2172e-06, 1.8816e-03, 8.1236e-04, 1.6885e-03, 2.5052e-03,\n",
      "        1.0577e-03, 1.0447e-03, 8.5352e-07, 1.0200e-03, 1.7106e-03, 2.3929e-06,\n",
      "        2.5574e-03, 1.4525e-03, 1.1639e-03, 1.4075e-03, 1.2855e-03, 1.7834e-03,\n",
      "        1.5032e-03, 1.3447e-03, 8.3475e-04, 2.6445e-03, 1.1883e-03, 1.2840e-06,\n",
      "        2.4898e-03, 1.3007e-03, 9.1388e-04, 1.2876e-03, 1.5035e-03, 7.5626e-04,\n",
      "        1.4576e-03, 1.6511e-03, 8.3446e-04, 1.3138e-03, 1.1619e-03, 1.3598e-03,\n",
      "        3.6949e-03, 9.4693e-04, 1.8660e-03, 1.3608e-03, 8.9117e-04, 2.1259e-03,\n",
      "        8.7951e-04, 1.9196e-03, 8.0858e-04, 1.2911e-03, 7.1171e-04, 1.2274e-03,\n",
      "        2.6642e-03, 1.1879e-03, 8.4806e-04, 2.0820e-03, 1.7751e-07, 7.8403e-04,\n",
      "        3.3031e-03, 1.0604e-03, 1.2869e-03, 1.3706e-06, 1.4405e-03, 1.3132e-03,\n",
      "        1.7321e-03, 8.8495e-04, 2.2561e-07, 3.7283e-03, 2.0021e-03, 9.8674e-04,\n",
      "        1.3553e-03, 2.2530e-03, 2.1338e-03, 1.2392e-03, 2.1755e-03, 1.6658e-03,\n",
      "        1.2320e-03, 1.2022e-03, 1.0049e-03, 4.3251e-03, 1.7848e-03, 1.3258e-03,\n",
      "        1.1154e-03, 2.1251e-03, 1.8487e-03, 2.8935e-03, 1.5226e-03, 1.6811e-03,\n",
      "        2.6716e-03, 1.9242e-03, 1.6778e-03, 3.0039e-03, 1.7016e-03, 2.2077e-03,\n",
      "        9.3116e-04, 1.8553e-03, 1.5219e-03, 2.2319e-03, 1.4155e-03, 8.8583e-04,\n",
      "        1.4903e-07, 1.1926e-03, 1.3368e-03, 9.3198e-04, 1.2759e-03, 9.3357e-04,\n",
      "        8.6960e-04, 1.5321e-03, 9.3466e-04, 3.2460e-03, 9.5272e-04, 2.0992e-03,\n",
      "        3.6203e-03, 2.5421e-03, 1.6305e-03, 1.0408e-03, 1.3090e-03, 1.1402e-03,\n",
      "        8.6000e-04, 2.3879e-03, 2.1298e-03, 7.0492e-04, 2.1009e-03, 1.6084e-03,\n",
      "        1.2258e-03, 2.2456e-03, 3.7882e-03, 7.9629e-04, 8.2660e-04, 2.4976e-03,\n",
      "        1.5524e-05, 1.2113e-03, 1.1301e-03, 7.5371e-04, 1.1736e-03, 1.4229e-07,\n",
      "        7.7994e-04, 1.9608e-03, 1.0074e-03, 1.3956e-03, 6.3139e-04, 1.7716e-03,\n",
      "        2.7725e-03, 2.1605e-03, 2.8438e-03, 3.1762e-06, 1.8025e-03, 1.9907e-03,\n",
      "        1.2891e-03, 2.7944e-03, 2.5353e-03, 1.0180e-07, 1.0886e-03, 1.3301e-03,\n",
      "        3.3241e-03, 2.0653e-03, 8.8414e-04, 2.0515e-03, 1.9583e-07, 2.3741e-03,\n",
      "        2.1046e-03, 2.4312e-03, 1.8817e-03, 1.7332e-03, 1.3369e-03, 6.5204e-04,\n",
      "        1.2502e-03, 2.2421e-03, 1.7196e-03, 9.7375e-04, 2.0451e-06, 1.1385e-03])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "conv_weight: tensor([[-1.2060e-01, -7.2708e-02, -1.1470e-01,  ...,  5.0905e-02,\n",
      "          4.6384e-02,  9.3592e-02],\n",
      "        [-1.0497e-01, -1.4126e-01, -2.7234e-01,  ...,  3.0906e-01,\n",
      "         -8.0448e-02, -1.2526e-01],\n",
      "        [-7.1706e-02,  6.4771e-02,  9.5380e-02,  ...,  6.6646e-02,\n",
      "          9.9981e-03,  3.3725e-02],\n",
      "        ...,\n",
      "        [ 4.5722e-02, -2.0670e-02, -8.8413e-02,  ..., -3.6018e-02,\n",
      "          6.2111e-02, -2.1085e-03],\n",
      "        [ 4.3722e-05,  6.6271e-06,  2.7115e-04,  ...,  2.1663e-04,\n",
      "         -3.6935e-05,  3.5491e-05],\n",
      "        [-2.7851e-03,  7.6712e-02, -1.1001e-01,  ...,  4.4013e-02,\n",
      "          5.4169e-02,  2.0136e-01]]) conv_bias: tensor([ 6.0268e-01, -3.2360e-01, -2.5928e-01, -6.5647e-01, -7.5813e-01,\n",
      "        -3.3627e-01, -2.0085e-03, -1.3220e-03, -5.4816e-01, -5.6759e-01,\n",
      "        -8.6889e-01, -3.0870e-01, -6.7973e-01,  4.0415e-01,  6.9154e-01,\n",
      "         1.0582e+00, -5.9446e-01,  5.9071e-01,  1.1630e-01,  8.3333e-01,\n",
      "        -9.7713e-02, -7.2933e-01,  5.6149e-01, -5.7727e-01, -4.3312e-01,\n",
      "         2.7046e-01, -3.9872e-01, -1.9764e-01, -1.1490e-02,  4.9995e-01,\n",
      "        -6.8369e-01,  8.8702e-01, -2.6096e-01, -6.3054e-01,  6.2996e-01,\n",
      "        -4.8574e-01, -8.2857e-01, -6.4463e-01, -5.8497e-03, -4.1562e-01,\n",
      "        -5.8610e-01,  1.0964e-01,  1.3801e+00, -4.2176e-01, -5.5953e-01,\n",
      "         6.5288e-01,  5.6950e-01, -4.7826e-01, -2.8240e-01, -3.5690e-01,\n",
      "        -6.9737e-01, -7.6874e-01, -5.2964e-01, -2.1070e-01, -7.3029e-01,\n",
      "         1.0328e-02,  4.3954e-01, -4.9266e-01,  3.7484e-02, -4.3094e-01,\n",
      "        -3.0385e-01, -3.0440e-01,  6.1643e-01, -5.8397e-01, -5.1418e-01,\n",
      "        -5.6617e-01, -9.9362e-01,  1.0898e+00, -2.7187e-03, -2.9260e-01,\n",
      "        -4.2384e-01,  8.3249e-01,  7.5961e-01, -5.1186e-01, -7.3462e-01,\n",
      "        -1.9836e-01, -6.6790e-01,  1.2287e+00,  3.4819e-01,  1.0450e+00,\n",
      "        -8.0588e-01,  4.0480e-01, -4.5985e-01, -2.0131e-01, -2.1242e-01,\n",
      "        -6.7005e-02,  3.6022e-01, -6.1382e-01,  6.6351e-01,  3.0146e-01,\n",
      "         1.0726e+00,  8.2176e-01, -1.0919e-03, -6.3438e-02,  4.2282e-01,\n",
      "        -5.7959e-01, -1.3129e-01, -3.5188e-01, -6.6910e-01, -4.7583e-01,\n",
      "        -5.3169e-01,  6.7190e-01, -7.3639e-01,  9.1392e-02,  1.2759e+00,\n",
      "        -5.2126e-01, -1.1026e+00,  5.6190e-01,  5.8824e-01, -4.2677e-01,\n",
      "        -5.4014e-01, -6.2296e-01, -6.5434e-01,  7.0701e-01,  5.8830e-01,\n",
      "        -1.7222e-03, -8.4093e-04, -4.6102e-01,  6.9008e-01, -5.8873e-01,\n",
      "        -4.7867e-01, -1.2511e-02, -2.5304e-01, -5.9887e-01, -2.9866e-01,\n",
      "         6.4855e-02,  1.4783e+00, -6.3681e-01, -3.4896e-03,  7.1060e-01,\n",
      "         4.5353e-01, -1.5718e-02,  2.8739e-02, -6.8194e-01,  1.4617e+00,\n",
      "        -8.3164e-01, -6.3708e-01, -4.8308e-01,  1.1737e+00,  6.2457e-01,\n",
      "         1.1534e+00, -5.3682e-01,  1.0501e+00, -3.9414e-03, -1.4071e-01,\n",
      "        -6.3673e-01,  1.0036e+00, -6.2820e-01, -2.0538e-01, -5.8725e-01,\n",
      "         7.0971e-01,  1.1741e+00, -8.1837e-01, -7.7145e-01, -5.7392e-01,\n",
      "         6.5401e-01, -1.5169e-01,  1.0515e+00,  8.7691e-01, -5.4104e-01,\n",
      "         1.4602e+00, -3.0605e-01,  1.2644e+00,  8.3558e-01, -6.3395e-01,\n",
      "        -7.1782e-01,  1.7913e+00, -6.0896e-01, -6.1579e-01, -5.1829e-01,\n",
      "         8.6068e-01,  3.1833e-01, -1.1477e-03,  1.6380e+00, -1.6996e-01,\n",
      "         1.2190e+00, -3.7621e-01, -3.9020e-03,  8.8623e-01,  5.8559e-01,\n",
      "         1.1197e+00, -7.0060e-01, -1.6826e-03,  2.8719e-01,  1.3622e+00,\n",
      "        -5.9636e-01,  6.5258e-01,  3.4290e-02, -6.7201e-01, -7.5779e-01,\n",
      "        -7.1943e-01,  3.5741e-01, -6.5005e-01,  1.0069e+00,  1.1463e+00,\n",
      "         4.8872e-01, -3.5976e-01, -3.6427e-01, -3.9244e-01,  2.6726e-01,\n",
      "         2.7119e-01,  5.5127e-02, -3.7615e-01, -3.1429e-01,  2.0331e-01,\n",
      "        -3.0726e-01, -4.8085e-01, -2.2061e-01,  3.4215e-01, -8.2558e-03,\n",
      "        -6.6186e-01, -2.7995e-01, -3.0794e-01, -4.3493e-01, -5.5585e-01,\n",
      "        -7.1575e-01, -5.0373e-03,  9.4269e-01, -7.1496e-01,  1.0247e+00,\n",
      "        -6.1905e-01, -5.2960e-01,  1.1775e+00,  9.4941e-01,  1.4123e+00,\n",
      "        -4.2453e-01,  4.2480e-01, -2.2228e-02, -1.8161e-01,  2.6762e-01,\n",
      "         2.5218e-01, -5.4870e-01, -6.3496e-01, -6.1642e-01, -7.0370e-01,\n",
      "         1.5861e-01,  7.8987e-01,  1.1490e+00, -1.8257e-01, -3.5065e-01,\n",
      "        -8.5181e-01,  7.1117e-01, -3.8920e-01, -5.9210e-01, -9.1301e-01,\n",
      "         2.3819e-01, -4.6968e-02,  1.5326e+00, -6.9956e-01, -6.5942e-01,\n",
      "        -2.2136e-01, -9.2541e-04,  8.7574e-01,  9.6750e-01,  1.3807e+00,\n",
      "        -6.8368e-01,  1.5167e+00, -4.5904e-01, -4.5528e-01,  4.2143e-01,\n",
      "         1.6449e-01, -1.1858e-02, -4.9934e-01,  3.0722e-01,  1.0703e+00,\n",
      "        -4.3444e-01, -5.0709e-02, -8.5416e-04, -7.2961e-01, -6.5636e-01,\n",
      "         1.2990e-02,  4.5679e-01, -7.7172e-01, -4.2648e-01, -1.4311e-03,\n",
      "        -2.6460e-01, -3.8303e-01,  5.6124e-01, -3.0348e-01, -5.3485e-01,\n",
      "        -7.1768e-01,  1.6347e+00, -5.2734e-01,  1.7995e-01,  1.4941e-01,\n",
      "         1.2620e+00, -1.0100e-02, -6.8410e-01])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "q_weight: tensor([-86, -52, -82,  ...,  25,  31, 115], dtype=torch.int32) q_bias: tensor([   5005,   -1206,   -1667,   -3375,   -4474,   -1495,  -27416,  -38276,\n",
      "          -4340,   -4375,   -7865,   -1796,   -4584,     914,    5602,    7776,\n",
      "          -6093,    3055,     138,    5587,    -313,   -4232,    2274,   -3149,\n",
      "          -3391,     881,   -2228,    -666,  -66562,    2174,   -5814,    3819,\n",
      "          -1279,   -4920,    5181,   -2668,   -3039,   -4128, -322846,   -2170,\n",
      "          -3062,     247,    9245,   -2281,   -4629,    6342,    2273,   -2169,\n",
      "           -873,   -1058,   -5113,   -3755,   -2541,    -614,   -4124,      41,\n",
      "           1195,   -3977,      94,   -2028,   -1035,   -1600,    2913,   -3266,\n",
      "          -4756,   -2428,   -4791,    7788,  -21415,   -1068,   -3576,    6040,\n",
      "           4031,   -1037,   -5753,    -723,   -2449,    6379,    1628,   11532,\n",
      "          -7515,    1742,   -2392,    -744,    -315,    -149,    1396,   -3411,\n",
      "           3295,    1108,   13944,    4704,  -44728,  -27833,    1931,   -2983,\n",
      "           -337,  -20123,   -4620,   -2694,   -1859,    3519,   -3666,     345,\n",
      "          10577,   -3128,  -11345,    4014,    3009,   -2382,   -5265,   -2626,\n",
      "          -4949,    4848,    4260,  -48906,  -50395,   -3615,    4043,   -2555,\n",
      "          -3225,  -29365,   -1015,   -5566,   -1336,     195,   10553,   -4603,\n",
      "         -30872,    5261,    2002,  -49598,      85,   -3545,    9483,   -4462,\n",
      "          -3742,   -2045,    5896,    3507,   10433,   -1533,    6673,  -23178,\n",
      "           -427,   -3696,    8292,   -3684,   -1031,   -5863,    3676,    5369,\n",
      "          -7405,   -4434,   -3730,    3632,    -310,    8385,    3548,   -3002,\n",
      "          12372,   -1087,   10855,    3287,   -5920,   -4198,   19004,   -3746,\n",
      "          -1745,   -3294,    7663,    1154,  -48820,   15775,    -389,    8681,\n",
      "          -2207,  -21496,    4645,    3367,    4881,   -5978,  -56314,     582,\n",
      "           5137,   -4563,    3636,     115,   -2378,   -4617,   -2497,    1620,\n",
      "          -3984,    6324,    8613,     853,   -1522,   -2075,   -2657,     950,\n",
      "           1108,     144,   -1865,   -1412,     575,   -1206,   -2164,    -555,\n",
      "           1518,     -28,   -5367,   -1139,   -1528,   -1471,   -2965,   -6101,\n",
      "        -255218,    5968,   -4038,    8302,   -3664,   -4283,   10224,    4679,\n",
      "          11410,    -988,    3367,     -80,    -379,     795,    1168,   -3981,\n",
      "          -3663,   -4082,   -6178,     502,    2800,   12308,    -656,   -1646,\n",
      "          -5247,    2391,    -776,   -5615,   -8340,     720,  -22845,    9554,\n",
      "          -4674,   -6606,   -1424,  -49108,    8478,    3726,   10349,   -3699,\n",
      "          18138,   -1956,   -1240,    1473,     437,  -28192,   -2092,    1165,\n",
      "           6270,   -1174,    -151,  -63353,   -5061,   -3726,      30,    1670,\n",
      "          -6591,   -1570,  -55179,    -842,   -1374,    1743,   -1218,   -2330,\n",
      "          -4053,   18930,   -3185,     606,     656,    9786,  -37292,   -4537],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-3.6525e-06) tensor(0.0049)   bias tensor(-2.1601e-06) tensor(0.0002)\n",
      "features.13.conv.3.weight features.13.conv.5\n",
      "torch.Size([288, 1, 3, 3]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.1265]) torch.Size([1]) \n",
      "wscale= tensor([1.1009e-02, 7.7916e-03, 9.8111e-03, 3.7654e-02, 1.5652e-02, 7.2502e-03,\n",
      "        5.8209e-06, 4.9817e-06, 3.4430e-02, 1.8467e-02, 6.9495e-02, 5.5145e-03,\n",
      "        6.1848e-02, 7.5143e-03, 7.9453e-03, 9.1306e-03, 4.0509e-02, 5.9609e-03,\n",
      "        1.3024e-02, 1.2572e-02, 4.4369e-03, 3.9049e-02, 6.0125e-03, 1.2198e-02,\n",
      "        3.7376e-02, 3.6091e-03, 1.4435e-02, 1.3044e-02, 1.0724e-03, 7.6793e-03,\n",
      "        3.5824e-02, 6.9344e-03, 6.4741e-03, 1.9092e-02, 7.7320e-03, 1.4383e-02,\n",
      "        1.6222e-02, 1.8161e-02, 6.1744e-05, 2.0351e-02, 1.3399e-02, 3.8616e-03,\n",
      "        2.0595e-02, 1.1801e-02, 4.3201e-02, 9.4835e-03, 1.0308e-02, 1.7097e-02,\n",
      "        1.0074e-02, 4.0486e-03, 6.4979e-02, 3.3160e-02, 2.2010e-02, 5.0133e-03,\n",
      "        4.0225e-02, 8.5751e-03, 4.5049e-03, 1.1105e-02, 1.2217e-02, 2.0428e-02,\n",
      "        7.6975e-03, 1.3656e-02, 1.4087e-02, 1.3991e-02, 1.8741e-02, 2.9932e-02,\n",
      "        7.5399e-02, 1.2478e-02, 4.8234e-06, 3.7931e-03, 1.0766e-02, 1.0111e-02,\n",
      "        9.2790e-03, 4.1260e-03, 4.6042e-02, 4.0481e-03, 2.0076e-02, 2.2703e-02,\n",
      "        4.8546e-03, 8.4109e-03, 5.6346e-02, 7.7512e-03, 2.4302e-02, 4.2632e-03,\n",
      "        7.1350e-03, 4.2606e-03, 7.3347e-03, 2.5322e-02, 7.0816e-03, 8.1049e-03,\n",
      "        1.2915e-02, 1.0293e-02, 1.8289e-06, 2.7962e-03, 7.8901e-03, 1.5671e-02,\n",
      "        1.2292e-02, 3.5691e-02, 1.2942e-02, 9.9680e-03, 8.2160e-03, 1.9629e-02,\n",
      "        3.2620e-02, 5.4932e-03, 1.0445e-02, 2.4890e-02, 4.0423e-01, 7.8284e-03,\n",
      "        1.0275e-02, 2.2648e-02, 6.3220e-02, 1.0830e-02, 4.6198e-02, 7.7410e-03,\n",
      "        6.9066e-03, 5.1805e-06, 7.6979e-07, 2.7591e-02, 1.5119e-02, 2.6321e-02,\n",
      "        1.0825e-01, 1.6959e-04, 5.3746e-03, 5.0261e-02, 1.3689e-02, 3.4291e-03,\n",
      "        1.5091e-02, 2.1941e-02, 1.9114e-05, 1.3936e-02, 4.8766e-03, 1.4817e-04,\n",
      "        3.4441e-03, 2.4250e-02, 1.9532e-02, 6.3043e-02, 2.5017e-02, 2.1026e-02,\n",
      "        1.2722e-02, 1.2501e-02, 1.0588e-02, 7.3264e-03, 8.1863e-03, 1.4948e-05,\n",
      "        7.4173e-03, 3.3647e-02, 1.4341e-02, 2.4605e-02, 7.3950e-03, 3.6844e-01,\n",
      "        1.2598e-02, 1.5958e-02, 9.9776e-02, 3.1963e-02, 1.6355e-02, 6.4177e-03,\n",
      "        3.4293e-03, 1.4549e-02, 1.2412e-02, 1.8437e-02, 2.1117e-02, 9.1262e-03,\n",
      "        1.7092e-02, 1.5338e-02, 2.8903e-02, 1.7554e-02, 2.3262e-02, 4.6016e-02,\n",
      "        1.3900e-02, 1.3526e-02, 8.5259e-03, 8.1733e-03, 1.4568e-06, 1.2462e-02,\n",
      "        2.4865e-03, 1.2727e-02, 2.5434e-02, 2.0391e-05, 1.5248e-02, 6.8676e-03,\n",
      "        1.7779e-02, 3.3515e-02, 4.7283e-06, 6.8455e-03, 1.4818e-02, 3.0011e-02,\n",
      "        8.0334e-03, 3.8803e-03, 1.0540e-02, 8.6965e-02, 6.2723e-03, 6.4554e-03,\n",
      "        2.0173e-02, 1.4447e-02, 1.5362e-02, 3.1054e-03, 7.7048e-03, 1.2670e-02,\n",
      "        1.4415e-02, 3.2982e-03, 5.1086e-03, 3.3637e-03, 1.4898e-02, 9.1906e-03,\n",
      "        4.8109e-03, 1.1973e-02, 1.0464e-02, 4.7412e-03, 4.3919e-03, 7.7117e-03,\n",
      "        4.6499e-02, 8.7565e-03, 9.1132e-03, 4.9686e-03, 1.7759e-02, 2.8691e-02,\n",
      "        4.5218e-05, 1.7460e-02, 3.9633e-02, 1.3273e-02, 2.7092e-02, 2.5566e-02,\n",
      "        1.1650e-02, 9.5886e-03, 1.5709e-02, 7.4799e-03, 8.4035e-03, 5.0309e-03,\n",
      "        6.1608e-03, 3.6236e-03, 4.7343e-03, 1.5164e-02, 2.6101e-02, 2.0675e-02,\n",
      "        7.3985e-02, 4.7252e-03, 8.2776e-03, 1.0852e-02, 6.1321e-03, 2.2973e-02,\n",
      "        2.9771e-02, 1.1256e-02, 5.2434e-03, 4.3804e-02, 1.5375e-01, 3.8297e-03,\n",
      "        1.5000e-03, 1.4749e-02, 2.3808e-02, 3.2010e-02, 1.3793e-02, 7.2139e-07,\n",
      "        9.0257e-03, 2.1554e-02, 1.5533e-02, 1.9338e-02, 1.5657e-02, 1.5428e-02,\n",
      "        6.6122e-03, 1.1368e-02, 3.9002e-03, 2.9192e-04, 1.4178e-02, 7.5671e-03,\n",
      "        1.9693e-02, 3.3229e-03, 3.1096e-03, 1.4292e-06, 2.5972e-02, 1.7027e-02,\n",
      "        4.8787e-03, 6.4378e-03, 3.6097e-02, 1.6287e-02, 1.8984e-06, 1.1304e-02,\n",
      "        5.2050e-03, 8.3747e-03, 2.0279e-02, 4.2784e-02, 2.6440e-02, 1.8579e-02,\n",
      "        3.2570e-02, 6.8321e-03, 7.5327e-03, 1.0556e-02, 8.5480e-05, 1.9952e-02]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.2029]) torch.Size([1])\n",
      "###: M= tensor([6.8665e-03, 4.8596e-03, 6.1191e-03, 2.3485e-02, 9.7620e-03, 4.5219e-03,\n",
      "        3.6304e-06, 3.1070e-06, 2.1474e-02, 1.1518e-02, 4.3343e-02, 3.4394e-03,\n",
      "        3.8574e-02, 4.6866e-03, 4.9554e-03, 5.6947e-03, 2.5265e-02, 3.7177e-03,\n",
      "        8.1231e-03, 7.8411e-03, 2.7672e-03, 2.4355e-02, 3.7499e-03, 7.6080e-03,\n",
      "        2.3311e-02, 2.2510e-03, 9.0031e-03, 8.1354e-03, 6.6882e-04, 4.7895e-03,\n",
      "        2.2343e-02, 4.3249e-03, 4.0378e-03, 1.1907e-02, 4.8224e-03, 8.9704e-03,\n",
      "        1.0118e-02, 1.1327e-02, 3.8509e-05, 1.2693e-02, 8.3571e-03, 2.4085e-03,\n",
      "        1.2845e-02, 7.3599e-03, 2.6944e-02, 5.9148e-03, 6.4287e-03, 1.0664e-02,\n",
      "        6.2830e-03, 2.5251e-03, 4.0527e-02, 2.0681e-02, 1.3728e-02, 3.1267e-03,\n",
      "        2.5088e-02, 5.3482e-03, 2.8097e-03, 6.9258e-03, 7.6194e-03, 1.2741e-02,\n",
      "        4.8008e-03, 8.5169e-03, 8.7858e-03, 8.7259e-03, 1.1689e-02, 1.8668e-02,\n",
      "        4.7026e-02, 7.7823e-03, 3.0083e-06, 2.3657e-03, 6.7146e-03, 6.3063e-03,\n",
      "        5.7873e-03, 2.5733e-03, 2.8716e-02, 2.5248e-03, 1.2521e-02, 1.4159e-02,\n",
      "        3.0277e-03, 5.2458e-03, 3.5142e-02, 4.8344e-03, 1.5157e-02, 2.6589e-03,\n",
      "        4.4500e-03, 2.6573e-03, 4.5746e-03, 1.5793e-02, 4.4167e-03, 5.0550e-03,\n",
      "        8.0548e-03, 6.4196e-03, 1.1407e-06, 1.7439e-03, 4.9210e-03, 9.7741e-03,\n",
      "        7.6666e-03, 2.2260e-02, 8.0715e-03, 6.2169e-03, 5.1243e-03, 1.2242e-02,\n",
      "        2.0345e-02, 3.4260e-03, 6.5145e-03, 1.5524e-02, 2.5211e-01, 4.8825e-03,\n",
      "        6.4087e-03, 1.4125e-02, 3.9430e-02, 6.7548e-03, 2.8814e-02, 4.8280e-03,\n",
      "        4.3076e-03, 3.2310e-06, 4.8011e-07, 1.7208e-02, 9.4298e-03, 1.6416e-02,\n",
      "        6.7515e-02, 1.0577e-04, 3.3521e-03, 3.1347e-02, 8.5377e-03, 2.1387e-03,\n",
      "        9.4122e-03, 1.3685e-02, 1.1921e-05, 8.6916e-03, 3.0415e-03, 9.2415e-05,\n",
      "        2.1481e-03, 1.5125e-02, 1.2182e-02, 3.9319e-02, 1.5603e-02, 1.3113e-02,\n",
      "        7.9346e-03, 7.7965e-03, 6.6039e-03, 4.5694e-03, 5.1057e-03, 9.3227e-06,\n",
      "        4.6261e-03, 2.0985e-02, 8.9445e-03, 1.5346e-02, 4.6122e-03, 2.2979e-01,\n",
      "        7.8574e-03, 9.9529e-03, 6.2229e-02, 1.9935e-02, 1.0200e-02, 4.0026e-03,\n",
      "        2.1388e-03, 9.0738e-03, 7.7411e-03, 1.1499e-02, 1.3170e-02, 5.6919e-03,\n",
      "        1.0660e-02, 9.5659e-03, 1.8027e-02, 1.0948e-02, 1.4508e-02, 2.8700e-02,\n",
      "        8.6696e-03, 8.4363e-03, 5.3175e-03, 5.0976e-03, 9.0860e-07, 7.7722e-03,\n",
      "        1.5508e-03, 7.9379e-03, 1.5863e-02, 1.2718e-05, 9.5102e-03, 4.2833e-03,\n",
      "        1.1089e-02, 2.0903e-02, 2.9490e-06, 4.2695e-03, 9.2418e-03, 1.8718e-02,\n",
      "        5.0104e-03, 2.4201e-03, 6.5737e-03, 5.4239e-02, 3.9120e-03, 4.0262e-03,\n",
      "        1.2582e-02, 9.0103e-03, 9.5809e-03, 1.9368e-03, 4.8054e-03, 7.9021e-03,\n",
      "        8.9906e-03, 2.0571e-03, 3.1862e-03, 2.0979e-03, 9.2919e-03, 5.7321e-03,\n",
      "        3.0005e-03, 7.4676e-03, 6.5263e-03, 2.9571e-03, 2.7392e-03, 4.8097e-03,\n",
      "        2.9001e-02, 5.4613e-03, 5.6838e-03, 3.0989e-03, 1.1076e-02, 1.7894e-02,\n",
      "        2.8202e-05, 1.0890e-02, 2.4719e-02, 8.2783e-03, 1.6897e-02, 1.5946e-02,\n",
      "        7.2662e-03, 5.9803e-03, 9.7978e-03, 4.6651e-03, 5.2412e-03, 3.1377e-03,\n",
      "        3.8424e-03, 2.2600e-03, 2.9528e-03, 9.4578e-03, 1.6279e-02, 1.2895e-02,\n",
      "        4.6144e-02, 2.9471e-03, 5.1627e-03, 6.7681e-03, 3.8245e-03, 1.4328e-02,\n",
      "        1.8568e-02, 7.0202e-03, 3.2703e-03, 2.7320e-02, 9.5890e-02, 2.3885e-03,\n",
      "        9.3555e-04, 9.1991e-03, 1.4849e-02, 1.9964e-02, 8.6027e-03, 4.4993e-07,\n",
      "        5.6292e-03, 1.3443e-02, 9.6878e-03, 1.2061e-02, 9.7649e-03, 9.6222e-03,\n",
      "        4.1240e-03, 7.0901e-03, 2.4325e-03, 1.8207e-04, 8.8424e-03, 4.7195e-03,\n",
      "        1.2283e-02, 2.0724e-03, 1.9394e-03, 8.9139e-07, 1.6198e-02, 1.0619e-02,\n",
      "        3.0428e-03, 4.0152e-03, 2.2513e-02, 1.0158e-02, 1.1840e-06, 7.0502e-03,\n",
      "        3.2463e-03, 5.2232e-03, 1.2648e-02, 2.6684e-02, 1.6490e-02, 1.1588e-02,\n",
      "        2.0314e-02, 4.2611e-03, 4.6981e-03, 6.5837e-03, 5.3313e-05, 1.2444e-02])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "conv_weight: tensor([[[-3.5286e-01, -2.1455e-01,  4.0333e-01],\n",
      "         [-8.7677e-01, -1.5484e-01,  9.8855e-01],\n",
      "         [-9.8999e-02,  1.4924e-01, -5.1543e-02]],\n",
      "\n",
      "        [[-1.3156e-01, -4.9226e-01, -1.5487e-01],\n",
      "         [ 8.4886e-02,  7.1511e-01,  1.5004e-01],\n",
      "         [-3.0827e-01, -1.6605e-01, -3.3214e-01]],\n",
      "\n",
      "        [[-3.5134e-01,  6.4093e-02, -9.4602e-03],\n",
      "         [-7.4494e-01, -7.9932e-02,  8.4298e-01],\n",
      "         [-5.2426e-01, -6.0096e-01, -9.6133e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7586e-01, -4.9341e-01, -1.7845e-01],\n",
      "         [-7.6392e-01,  9.9572e-01, -8.1874e-01],\n",
      "         [-2.0061e-01, -2.6000e-01, -1.2573e-01]],\n",
      "\n",
      "        [[ 1.2160e-03, -1.0856e-02, -1.5435e-03],\n",
      "         [ 7.4025e-03, -7.0170e-03,  9.1839e-03],\n",
      "         [ 6.8770e-03,  3.1691e-03,  5.1611e-03]],\n",
      "\n",
      "        [[ 3.0320e-01,  7.6537e-01,  2.0530e-01],\n",
      "         [ 5.0075e-01,  1.4119e+00,  6.5035e-01],\n",
      "         [ 4.2867e-01,  5.8018e-01,  3.0554e-01]]]) conv_bias: tensor([-2.9252e-01,  2.8090e+00,  4.0598e+00, -6.2741e-01,  3.4410e+00,\n",
      "         1.8641e+00,  1.8824e-04,  6.9345e-04,  9.5316e-01, -1.0332e+00,\n",
      "         2.2846e-01,  1.1175e+00,  3.3393e-01, -1.2560e+00,  2.1568e+00,\n",
      "        -6.6604e-01,  2.2549e+00,  1.6610e+00, -1.8201e+00, -1.3226e+00,\n",
      "         1.4418e+00,  6.9524e-02,  1.7112e+00, -4.2903e-01,  9.4969e-02,\n",
      "         2.6732e+00, -6.8910e-01, -3.7153e-01, -2.2546e-02,  7.5329e-01,\n",
      "         1.7503e+00, -1.4880e+00, -1.2486e+00, -1.6038e+00,  1.5653e+00,\n",
      "         2.8343e+00, -5.8670e-01,  3.1682e+00, -1.8457e-03, -4.4679e-01,\n",
      "         2.8031e+00, -5.7270e-01,  7.6738e-01, -3.7493e-01,  3.8003e+00,\n",
      "         2.2902e+00,  1.9423e+00, -6.1378e-01, -1.1654e+00, -4.4933e-01,\n",
      "         1.1208e+00, -3.7498e-01,  7.5306e-02,  2.1056e+00, -9.1545e-02,\n",
      "        -6.7002e-01,  1.6912e+00,  1.4157e+00, -7.6884e-01, -2.0389e+00,\n",
      "        -6.4210e-01,  2.6013e+00, -2.6987e-01, -1.7472e+00,  1.1995e+00,\n",
      "         1.5621e-03, -3.2180e-01, -3.5354e-01,  1.7369e-03,  2.0852e+00,\n",
      "         1.3768e+00, -4.1089e-01, -1.5061e+00, -1.3281e-01, -3.4309e-01,\n",
      "        -2.1124e+00, -1.1779e+00,  2.4353e+00,  9.8913e-01,  2.6165e+00,\n",
      "         4.6282e-03, -1.4269e+00, -9.4776e-01,  1.3912e+00, -6.2347e-01,\n",
      "         2.0923e+00, -3.4693e-02, -3.2756e-01,  2.4702e-01,  1.2301e-02,\n",
      "        -7.8735e-01,  2.6473e+00, -2.2183e-04, -8.9620e-03,  2.8757e+00,\n",
      "         1.3225e+00, -4.3466e-01, -5.3676e-01,  3.2804e+00,  2.1918e+00,\n",
      "        -3.9480e-01,  3.5831e+00,  1.7946e+00,  1.3719e+00,  2.6863e+00,\n",
      "        -1.3927e+00, -7.1592e-01,  1.4938e+00, -1.4324e+00, -1.0942e+00,\n",
      "        -7.7192e-01, -2.1640e-01, -4.9269e-01,  1.4863e+00,  1.4524e+00,\n",
      "        -9.6638e-04, -4.0026e-04,  3.2808e+00, -1.3911e-01, -8.3188e-01,\n",
      "        -3.1637e-01, -1.8308e-02, -6.4859e-01,  6.7055e-02,  6.6947e-01,\n",
      "        -2.1057e+00,  3.0390e+00,  4.2673e+00,  1.0965e-03, -2.3096e-01,\n",
      "         1.9505e+00, -7.4168e-03, -2.2222e-01, -4.0405e-01, -1.9340e+00,\n",
      "        -2.7020e+00,  4.2309e+00, -1.3477e+00, -7.1063e-01, -1.0893e-01,\n",
      "        -4.4910e-01, -8.9275e-01, -2.5404e+00, -2.2004e-03,  5.4012e-02,\n",
      "        -8.4338e-01, -1.8921e+00,  5.8657e-02, -6.0213e-01, -1.0120e-01,\n",
      "        -4.4696e-01, -5.9689e-01, -4.8714e-01, -6.1415e-01, -2.3303e-01,\n",
      "         1.7260e+00, -8.4449e-01,  2.8520e+00,  6.3740e-01,  1.0274e+00,\n",
      "         3.1135e+00, -4.0949e-01,  1.6945e+00, -8.1731e-01,  3.3883e+00,\n",
      "        -5.1011e-02,  4.7385e+00, -3.5101e-01, -1.7248e+00,  2.5719e+00,\n",
      "         2.9719e+00,  1.0411e-01, -5.5698e-04,  4.3388e+00,  8.1476e-01,\n",
      "         2.6794e+00,  6.4957e-01, -2.7590e-03,  1.6715e+00,  1.6219e+00,\n",
      "        -5.4853e-01, -8.1957e-01, -4.9426e-04,  1.5185e+00,  2.2131e+00,\n",
      "         2.4271e+00,  1.8281e+00,  1.3982e+00,  1.0009e+00, -8.7674e-01,\n",
      "         2.9672e+00,  1.6943e+00, -2.2656e-01, -1.8609e+00,  1.9576e+00,\n",
      "        -1.4957e+00, -1.7348e+00, -2.5957e-01,  3.3173e+00,  2.2103e+00,\n",
      "        -9.1029e-01,  1.7974e+00, -5.4562e-01,  1.7831e+00, -2.9084e-01,\n",
      "        -2.6763e-01,  2.6163e+00, -5.2864e-01,  1.5183e+00,  1.9250e-02,\n",
      "        -4.4031e-01, -6.5455e-01,  1.8857e+00,  2.0900e+00, -1.8558e+00,\n",
      "        -3.9427e-01, -1.4778e-03, -2.4829e-01, -1.0694e+00,  8.5076e-01,\n",
      "         1.7272e+00, -8.0706e-02,  2.1167e+00, -9.2075e-01,  3.7511e+00,\n",
      "        -6.4916e-01, -2.6301e-05,  1.2284e+00, -2.0214e+00,  3.6303e+00,\n",
      "         1.5402e+00,  2.9920e+00,  3.0962e-01,  3.0868e+00, -4.8314e-02,\n",
      "         1.6014e+00,  1.3860e+00, -4.2076e-01,  7.6641e-01, -6.5912e-01,\n",
      "         9.6618e-02,  5.9062e-01, -1.3107e+00, -4.0352e-01,  7.9335e-02,\n",
      "        -2.0225e+00, -2.5235e-02, -2.9517e+00, -2.0932e-02,  2.5280e+00,\n",
      "        -1.2878e+00, -6.8079e-04,  2.8335e+00, -1.0922e+00,  3.5090e+00,\n",
      "        -1.7181e-01,  4.4062e+00, -8.4664e-01, -1.3387e+00, -3.6502e-01,\n",
      "        -2.0717e+00, -1.1381e-02,  8.5824e-02,  1.8106e+00,  1.5202e+00,\n",
      "        -4.0351e-01,  1.4706e+00, -4.8187e-04, -6.7320e-01,  1.6415e+00,\n",
      "        -2.4768e-01,  2.8536e+00,  1.2518e+00, -6.5118e-01, -6.1518e-04,\n",
      "        -9.1481e-01,  1.9076e-02, -3.2562e-01, -1.1147e+00, -2.0837e+00,\n",
      "        -8.4309e-01,  2.8491e+00,  9.9920e-01, -2.8791e-01, -2.7621e-01,\n",
      "         2.3490e+00, -2.1356e-03, -1.3181e+00])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "q_weight: tensor([-32, -19,  37,  ...,  21,  29,  15], dtype=torch.int32) q_bias: tensor([ -210,  2849,  3270,  -132,  1737,  2032,   256,  1100,   219,  -442,\n",
      "           26,  1602,    43, -1321,  2145,  -576,   440,  2202, -1104,  -831,\n",
      "         2568,    14,  2249,  -278,    20,  5854,  -377,  -225,  -166,   775,\n",
      "          386, -1696, -1524,  -664,  1600,  1557,  -286,  1379,  -236,  -174,\n",
      "         1653, -1172,   294,  -251,   695,  1909,  1489,  -284,  -914,  -877,\n",
      "          136,   -89,    27,  3319,   -18,  -618,  2967,  1008,  -497,  -789,\n",
      "         -659,  1505,  -151,  -987,   506,     0,   -34,  -224,  2846,  4345,\n",
      "         1011,  -321, -1283,  -254,   -59, -4124,  -464,   848,  1610,  2459,\n",
      "            1, -1455,  -308,  2579,  -691,  3881,   -37,  -102,   276,    12,\n",
      "         -482,  2033,  -959,   -25,  2880,   667,  -279,  -119,  2003,  1738,\n",
      "         -380,  1443,   435,  1974,  2033,  -442,   -14,  1508, -1102,  -382,\n",
      "          -96,  -158,   -84,  1517,  1662, -1474, -4109,   940,   -73,  -250,\n",
      "          -23,  -853,  -954,    11,   387, -4853,  1592,  1537,   453,  -131,\n",
      "         3161,  -396,  -510,  -132,  -783,  -339,  1337,  -507,  -441,   -69,\n",
      "         -335,  -963, -2453, -1163,    58,  -198, -1043,    19,  -643,    -2,\n",
      "         -280,  -296,   -39,  -152,  -113,  2126, -1946,  1549,   406,   440,\n",
      "         1165,  -355,   784,  -421,   926,   -23,  1610,   -60,  -981,  1503,\n",
      "         2755,   101, -3022,  2752,  2590,  1664,   202, -1069,   866,  1866,\n",
      "         -244,  -193,  -826,  1753,  1180,   639,  1798,  2848,   751,   -80,\n",
      "         3739,  2074,   -89, -1018,  1007, -3806, -1779,  -162,  1819,  5296,\n",
      "        -1408,  4223,  -289,  1533,  -478,  -177,  1976,  -881,  2732,    20,\n",
      "          -75,  -591,  1635,  3324,  -826,  -109,  -258,  -112,  -213,   507,\n",
      "          504,   -25,  1436,  -759,  1887,  -686,     0,  1930, -2593,  7918,\n",
      "         2571,  1559,    94,  1180,    -5,  2678,  1323,  -306,   988,  -227,\n",
      "           26,   415, -1976,   -73,     4, -4174,  -133, -1582,    -7,   624,\n",
      "         -738, -7458,  2481,  -400,  1785,   -70,  2224,  -434, -1600,  -254,\n",
      "        -4198,  -308,    48,  1891,   610,  -960,  3738, -2665,  -205,   762,\n",
      "         -401,  3503,   274,  -316, -2561,  -640,    29,  -307,  -434,  -385,\n",
      "         -252,  1212,   242,  -333,  -290,  1759,  -197,  -522],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(5.4898e-05) tensor(0.1520)   bias tensor(-5.9422e-06) tensor(0.0052)\n",
      "features.13.conv.6.weight features.13.conv.8\n",
      "torch.Size([48, 288, 1, 1]) conv_bias= torch.Size([48]) \n",
      "ascale= tensor([0.1929]) torch.Size([1]) \n",
      "wscale= tensor([0.0035, 0.0063, 0.0051, 0.0056, 0.0053, 0.0033, 0.0048, 0.0030, 0.0095,\n",
      "        0.0047, 0.0053, 0.0055, 0.0053, 0.0053, 0.0050, 0.0046, 0.0049, 0.0046,\n",
      "        0.0054, 0.0039, 0.0046, 0.0068, 0.0040, 0.0078, 0.0042, 0.0051, 0.0039,\n",
      "        0.0032, 0.0046, 0.0057, 0.0062, 0.0043, 0.0063, 0.0046, 0.0048, 0.0051,\n",
      "        0.0055, 0.0065, 0.0061, 0.0064, 0.0055, 0.0053, 0.0055, 0.0057, 0.0043,\n",
      "        0.0040, 0.0050, 0.0048]) torch.Size([48, 1, 1, 1]) \n",
      "oscale= tensor([0.1177]) torch.Size([1])\n",
      "###: M= tensor([0.0058, 0.0104, 0.0083, 0.0091, 0.0087, 0.0055, 0.0079, 0.0050, 0.0156,\n",
      "        0.0077, 0.0086, 0.0090, 0.0087, 0.0087, 0.0082, 0.0075, 0.0081, 0.0075,\n",
      "        0.0089, 0.0064, 0.0075, 0.0112, 0.0066, 0.0128, 0.0070, 0.0084, 0.0064,\n",
      "        0.0052, 0.0075, 0.0094, 0.0101, 0.0071, 0.0103, 0.0076, 0.0079, 0.0083,\n",
      "        0.0090, 0.0106, 0.0100, 0.0106, 0.0089, 0.0088, 0.0090, 0.0093, 0.0070,\n",
      "        0.0065, 0.0082, 0.0079])\n",
      "torch.Size([48, 288, 1, 1]) torch.Size([48])\n",
      "conv_weight: tensor([[ 8.1589e-02,  1.2913e-01,  4.4479e-02,  ...,  5.9077e-02,\n",
      "          1.5476e-04, -2.1489e-03],\n",
      "        [ 2.0473e-01, -1.1340e-01, -1.6406e-01,  ...,  4.5236e-02,\n",
      "          1.8071e-04, -1.6586e-01],\n",
      "        [ 2.4243e-02, -1.0891e-01, -1.4007e-01,  ...,  1.9150e-01,\n",
      "         -1.4568e-04,  1.0712e-02],\n",
      "        ...,\n",
      "        [-6.8516e-02,  2.2711e-01, -1.0035e-01,  ..., -2.6056e-02,\n",
      "         -6.4692e-04,  2.0910e-02],\n",
      "        [-1.3287e-01, -1.1132e-01,  3.9575e-02,  ...,  1.8642e-02,\n",
      "         -1.2660e-03,  1.4572e-01],\n",
      "        [ 2.5157e-01, -5.2430e-02, -8.9527e-02,  ...,  3.1267e-02,\n",
      "          4.1243e-04, -1.0875e-01]]) conv_bias: tensor([-2.4903e+00,  6.1228e-01,  2.0042e+00, -6.0126e+00, -8.0031e-01,\n",
      "        -5.7114e-01,  1.0406e+00, -5.0295e-01, -1.4172e-02, -1.7698e+00,\n",
      "        -4.4220e-01, -1.0585e+00, -4.7093e+00, -1.5950e+00, -2.0053e+00,\n",
      "         5.1893e-01,  2.4247e+00, -1.4468e+00,  3.4719e-01, -3.8859e-04,\n",
      "        -8.8861e-01,  4.2959e+00,  1.1682e-01, -4.2737e-01,  1.8222e+00,\n",
      "        -5.9526e-01, -1.4581e+00, -1.9555e+00, -2.6806e-02, -1.3964e+00,\n",
      "         3.8040e+00, -2.2002e+00, -1.5533e-01,  7.6505e-01, -2.5159e+00,\n",
      "         5.1693e-02, -2.2986e+00,  5.3196e-01,  1.7880e+00,  2.9821e+00,\n",
      "        -1.9553e+00, -5.2425e+00, -4.0683e+00, -6.0404e+00,  1.2674e+00,\n",
      "         1.0937e+00,  1.0071e+00,  1.1126e+00])\n",
      "torch.Size([48, 288, 1, 1]) torch.Size([48])\n",
      "q_weight: tensor([ 23,  37,  13,  ...,   6,   0, -23], dtype=torch.int32) q_bias: tensor([-3656,   501,  2046, -5608,  -777,  -886,  1122,  -863,    -8, -1945,\n",
      "         -436,  -995, -4598, -1558, -2066,   589,  2552, -1633,   331,    -1,\n",
      "        -1010,  3266,   150,  -283,  2223,  -604, -1927, -3218,   -30, -1264,\n",
      "         3185, -2638,  -128,   856, -2693,    53, -2173,   425,  1514,  2402,\n",
      "        -1858, -5085, -3831, -5514,  1543,  1425,  1050,  1194],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(1.3757e-05) tensor(0.0047)   bias tensor(1.1463e-06) tensor(0.0005)\n",
      "features.14.conv.0.weight features.14.conv.2\n",
      "torch.Size([288, 48, 1, 1]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.1177]) torch.Size([1]) \n",
      "wscale= tensor([0.0016, 0.0013, 0.0011, 0.0019, 0.0025, 0.0011, 0.0012, 0.0011, 0.0011,\n",
      "        0.0013, 0.0042, 0.0016, 0.0013, 0.0010, 0.0013, 0.0016, 0.0011, 0.0008,\n",
      "        0.0019, 0.0015, 0.0014, 0.0037, 0.0012, 0.0023, 0.0012, 0.0010, 0.0006,\n",
      "        0.0012, 0.0014, 0.0010, 0.0031, 0.0008, 0.0007, 0.0014, 0.0009, 0.0035,\n",
      "        0.0010, 0.0012, 0.0011, 0.0011, 0.0011, 0.0009, 0.0011, 0.0017, 0.0035,\n",
      "        0.0010, 0.0010, 0.0016, 0.0042, 0.0027, 0.0017, 0.0024, 0.0011, 0.0016,\n",
      "        0.0021, 0.0032, 0.0032, 0.0015, 0.0017, 0.0018, 0.0057, 0.0022, 0.0022,\n",
      "        0.0021, 0.0013, 0.0009, 0.0016, 0.0008, 0.0025, 0.0011, 0.0016, 0.0011,\n",
      "        0.0017, 0.0014, 0.0013, 0.0012, 0.0017, 0.0009, 0.0009, 0.0005, 0.0011,\n",
      "        0.0013, 0.0013, 0.0014, 0.0010, 0.0013, 0.0016, 0.0009, 0.0035, 0.0011,\n",
      "        0.0015, 0.0015, 0.0011, 0.0010, 0.0016, 0.0015, 0.0010, 0.0016, 0.0014,\n",
      "        0.0011, 0.0011, 0.0012, 0.0010, 0.0008, 0.0012, 0.0017, 0.0035, 0.0008,\n",
      "        0.0007, 0.0010, 0.0013, 0.0005, 0.0011, 0.0013, 0.0007, 0.0026, 0.0010,\n",
      "        0.0031, 0.0012, 0.0010, 0.0010, 0.0012, 0.0014, 0.0011, 0.0014, 0.0031,\n",
      "        0.0012, 0.0008, 0.0011, 0.0009, 0.0019, 0.0027, 0.0012, 0.0012, 0.0015,\n",
      "        0.0011, 0.0031, 0.0021, 0.0010, 0.0022, 0.0009, 0.0014, 0.0009, 0.0027,\n",
      "        0.0015, 0.0019, 0.0010, 0.0016, 0.0010, 0.0012, 0.0009, 0.0015, 0.0011,\n",
      "        0.0012, 0.0010, 0.0005, 0.0009, 0.0019, 0.0009, 0.0010, 0.0016, 0.0011,\n",
      "        0.0015, 0.0008, 0.0014, 0.0015, 0.0010, 0.0011, 0.0014, 0.0042, 0.0017,\n",
      "        0.0008, 0.0023, 0.0016, 0.0013, 0.0028, 0.0009, 0.0011, 0.0011, 0.0009,\n",
      "        0.0012, 0.0015, 0.0014, 0.0025, 0.0008, 0.0009, 0.0013, 0.0013, 0.0012,\n",
      "        0.0012, 0.0020, 0.0010, 0.0010, 0.0026, 0.0017, 0.0006, 0.0010, 0.0011,\n",
      "        0.0012, 0.0015, 0.0012, 0.0013, 0.0010, 0.0007, 0.0016, 0.0011, 0.0027,\n",
      "        0.0007, 0.0034, 0.0008, 0.0022, 0.0010, 0.0012, 0.0011, 0.0013, 0.0018,\n",
      "        0.0011, 0.0010, 0.0029, 0.0017, 0.0026, 0.0013, 0.0008, 0.0024, 0.0011,\n",
      "        0.0011, 0.0010, 0.0011, 0.0008, 0.0027, 0.0014, 0.0013, 0.0011, 0.0019,\n",
      "        0.0010, 0.0017, 0.0011, 0.0077, 0.0033, 0.0016, 0.0015, 0.0016, 0.0012,\n",
      "        0.0010, 0.0021, 0.0012, 0.0015, 0.0014, 0.0017, 0.0025, 0.0018, 0.0012,\n",
      "        0.0005, 0.0010, 0.0027, 0.0029, 0.0008, 0.0023, 0.0019, 0.0011, 0.0013,\n",
      "        0.0013, 0.0015, 0.0024, 0.0009, 0.0011, 0.0014, 0.0011, 0.0009, 0.0008,\n",
      "        0.0011, 0.0013, 0.0022, 0.0012, 0.0022, 0.0014, 0.0019, 0.0008, 0.0013,\n",
      "        0.0015, 0.0021, 0.0021, 0.0030, 0.0019, 0.0039, 0.0008, 0.0015, 0.0028]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.2830]) torch.Size([1])\n",
      "###: M= tensor([0.0007, 0.0005, 0.0005, 0.0008, 0.0010, 0.0004, 0.0005, 0.0005, 0.0004,\n",
      "        0.0005, 0.0017, 0.0007, 0.0005, 0.0004, 0.0006, 0.0007, 0.0005, 0.0003,\n",
      "        0.0008, 0.0006, 0.0006, 0.0015, 0.0005, 0.0010, 0.0005, 0.0004, 0.0003,\n",
      "        0.0005, 0.0006, 0.0004, 0.0013, 0.0004, 0.0003, 0.0006, 0.0004, 0.0014,\n",
      "        0.0004, 0.0005, 0.0005, 0.0005, 0.0005, 0.0004, 0.0005, 0.0007, 0.0014,\n",
      "        0.0004, 0.0004, 0.0007, 0.0017, 0.0011, 0.0007, 0.0010, 0.0005, 0.0007,\n",
      "        0.0009, 0.0013, 0.0013, 0.0006, 0.0007, 0.0008, 0.0024, 0.0009, 0.0009,\n",
      "        0.0009, 0.0005, 0.0004, 0.0007, 0.0003, 0.0010, 0.0004, 0.0007, 0.0004,\n",
      "        0.0007, 0.0006, 0.0005, 0.0005, 0.0007, 0.0004, 0.0004, 0.0002, 0.0005,\n",
      "        0.0005, 0.0006, 0.0006, 0.0004, 0.0005, 0.0007, 0.0004, 0.0015, 0.0005,\n",
      "        0.0006, 0.0006, 0.0005, 0.0004, 0.0007, 0.0006, 0.0004, 0.0007, 0.0006,\n",
      "        0.0005, 0.0005, 0.0005, 0.0004, 0.0004, 0.0005, 0.0007, 0.0014, 0.0003,\n",
      "        0.0003, 0.0004, 0.0005, 0.0002, 0.0005, 0.0005, 0.0003, 0.0011, 0.0004,\n",
      "        0.0013, 0.0005, 0.0004, 0.0004, 0.0005, 0.0006, 0.0004, 0.0006, 0.0013,\n",
      "        0.0005, 0.0003, 0.0004, 0.0004, 0.0008, 0.0011, 0.0005, 0.0005, 0.0006,\n",
      "        0.0005, 0.0013, 0.0009, 0.0004, 0.0009, 0.0004, 0.0006, 0.0004, 0.0011,\n",
      "        0.0006, 0.0008, 0.0004, 0.0007, 0.0004, 0.0005, 0.0004, 0.0006, 0.0004,\n",
      "        0.0005, 0.0004, 0.0002, 0.0004, 0.0008, 0.0004, 0.0004, 0.0006, 0.0004,\n",
      "        0.0006, 0.0003, 0.0006, 0.0006, 0.0004, 0.0005, 0.0006, 0.0018, 0.0007,\n",
      "        0.0003, 0.0009, 0.0007, 0.0005, 0.0012, 0.0004, 0.0005, 0.0005, 0.0004,\n",
      "        0.0005, 0.0006, 0.0006, 0.0010, 0.0003, 0.0004, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0008, 0.0004, 0.0004, 0.0011, 0.0007, 0.0002, 0.0004, 0.0004,\n",
      "        0.0005, 0.0006, 0.0005, 0.0005, 0.0004, 0.0003, 0.0007, 0.0004, 0.0011,\n",
      "        0.0003, 0.0014, 0.0003, 0.0009, 0.0004, 0.0005, 0.0005, 0.0006, 0.0007,\n",
      "        0.0004, 0.0004, 0.0012, 0.0007, 0.0011, 0.0005, 0.0004, 0.0010, 0.0004,\n",
      "        0.0004, 0.0004, 0.0004, 0.0004, 0.0011, 0.0006, 0.0005, 0.0005, 0.0008,\n",
      "        0.0004, 0.0007, 0.0005, 0.0032, 0.0014, 0.0007, 0.0006, 0.0007, 0.0005,\n",
      "        0.0004, 0.0009, 0.0005, 0.0006, 0.0006, 0.0007, 0.0010, 0.0008, 0.0005,\n",
      "        0.0002, 0.0004, 0.0011, 0.0012, 0.0003, 0.0010, 0.0008, 0.0005, 0.0005,\n",
      "        0.0005, 0.0006, 0.0010, 0.0004, 0.0005, 0.0006, 0.0005, 0.0004, 0.0003,\n",
      "        0.0005, 0.0005, 0.0009, 0.0005, 0.0009, 0.0006, 0.0008, 0.0004, 0.0005,\n",
      "        0.0006, 0.0009, 0.0009, 0.0013, 0.0008, 0.0016, 0.0003, 0.0006, 0.0012])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "conv_weight: tensor([[ 0.1411, -0.0472, -0.0898,  ...,  0.1990,  0.0014, -0.0176],\n",
      "        [ 0.0251, -0.0632,  0.0051,  ..., -0.0103,  0.1465,  0.0136],\n",
      "        [ 0.0761,  0.1281, -0.0497,  ...,  0.0207, -0.0006, -0.0159],\n",
      "        ...,\n",
      "        [ 0.0357, -0.0041,  0.0155,  ...,  0.0327, -0.0154, -0.0420],\n",
      "        [ 0.0443,  0.0315,  0.0174,  ..., -0.0679,  0.0184, -0.0250],\n",
      "        [-0.0038,  0.1489,  0.0978,  ..., -0.0808, -0.0581, -0.1449]]) conv_bias: tensor([ 1.0292e+00, -7.1107e-01, -9.2910e-01, -3.3338e-01,  1.5429e+00,\n",
      "        -1.1568e+00, -9.6567e-01, -1.0577e+00, -9.3776e-01, -9.1292e-01,\n",
      "        -3.6459e-01, -1.2306e+00, -1.0971e+00,  1.2575e+00, -8.1917e-01,\n",
      "        -7.8765e-01, -8.7021e-01, -9.0004e-01, -7.0737e-01, -9.4132e-01,\n",
      "        -7.0369e-01,  2.6126e-01, -1.2605e+00, -4.2698e-02, -8.9024e-01,\n",
      "        -6.7506e-01,  2.7877e+00, -1.0164e+00, -9.2468e-01, -1.2519e+00,\n",
      "        -1.3285e-01, -1.1368e+00, -7.6359e-01, -8.8842e-01, -1.1927e+00,\n",
      "         2.2646e-01, -1.1240e+00, -1.0282e+00, -9.0481e-01, -9.6511e-01,\n",
      "        -8.9686e-01, -1.0632e+00, -7.6945e-01, -7.8347e-01,  2.4386e-01,\n",
      "        -9.3007e-01, -1.1378e+00, -8.4731e-01, -4.2672e-01,  4.4259e-01,\n",
      "        -1.0629e+00,  6.3927e-01, -1.0417e+00,  7.0328e-01, -4.8558e-01,\n",
      "         3.6161e+00,  4.8116e+00, -8.4233e-01,  1.5266e+00, -6.2034e-01,\n",
      "        -1.7071e-01, -2.3633e-01, -6.9466e-01, -9.8051e-01, -8.8816e-01,\n",
      "        -1.1602e+00, -6.7420e-01, -1.2531e+00, -2.5489e-01,  1.2849e+00,\n",
      "        -5.7687e-01, -8.8624e-01, -9.0733e-01, -5.8946e-01, -9.2750e-01,\n",
      "        -6.5736e-01, -7.2631e-01, -1.1514e+00, -1.0990e+00, -8.0353e-01,\n",
      "        -8.8149e-01, -8.6149e-01, -9.6458e-01, -1.0840e+00, -1.1360e+00,\n",
      "        -9.8579e-01, -7.0351e-01, -9.1505e-01,  9.1671e-02, -7.3200e-01,\n",
      "        -7.7207e-01, -6.6510e-01, -7.8905e-01, -8.8436e-01, -7.2296e-01,\n",
      "        -8.2476e-01, -1.2340e+00, -7.9291e-01,  1.0205e+00, -1.2361e+00,\n",
      "        -6.6128e-01, -1.2034e+00, -1.2040e+00, -1.0657e+00, -1.0938e+00,\n",
      "        -8.4692e-01, -8.0797e-02, -9.5137e-01, -1.0815e+00, -1.1272e+00,\n",
      "        -8.1736e-01,  2.0741e+00, -1.2035e+00, -6.2713e-01, -1.0027e+00,\n",
      "         6.3205e-01, -9.2757e-01,  5.3650e-01, -7.1257e-01, -1.1336e+00,\n",
      "        -1.1109e+00, -9.7710e-01, -1.1791e+00, -1.0542e+00, -8.2138e-01,\n",
      "         1.6957e-01, -1.1334e+00, -1.1505e+00, -9.5429e-01, -9.6970e-01,\n",
      "        -8.9455e-01,  2.9475e-01, -9.1754e-01, -1.0140e+00, -5.1730e-01,\n",
      "        -6.6707e-01,  5.2946e-01, -5.5596e-01,  8.6129e-01, -7.9384e-01,\n",
      "        -8.5474e-01, -1.0383e+00, -1.2043e+00,  7.1896e+00, -7.6146e-01,\n",
      "        -4.9804e-01, -9.0850e-01,  9.2259e-01, -9.9933e-01, -5.8712e-01,\n",
      "        -8.9811e-01, -8.9946e-01, -1.0829e+00, -1.0378e+00, -1.0805e+00,\n",
      "        -9.3358e-01, -1.0881e+00, -1.0046e+00, -9.5826e-01, -9.7511e-01,\n",
      "         1.0849e+00, -6.9081e-01, -6.9859e-01, -8.6726e-01, -8.0918e-01,\n",
      "        -8.4739e-01, -1.0578e+00, -8.8977e-01, -1.0674e+00, -4.8172e-01,\n",
      "        -4.7070e-01, -9.7769e-01,  5.4129e-01,  1.6804e+00, -9.4148e-01,\n",
      "         5.5581e+00, -1.2617e+00,  1.4995e+00,  1.3299e+00, -7.0655e-01,\n",
      "        -1.0690e+00, -6.4418e-01,  1.7844e+00, -8.8484e-01, -1.1037e+00,\n",
      "        -1.0890e+00, -1.0293e+00, -9.0749e-01, -8.2539e-01, -1.0489e+00,\n",
      "        -9.3184e-01, -9.8781e-01, -9.0906e-01,  2.1502e+00,  3.3975e-01,\n",
      "        -1.1442e+00, -9.9368e-01, -9.8442e-01, -8.2469e-01, -1.0819e+00,\n",
      "        -8.7331e-01, -1.1043e+00, -1.1122e+00, -7.1196e-01, -1.0532e+00,\n",
      "        -1.1472e+00,  2.3325e-01, -8.1664e-01, -7.0347e-01, -9.6399e-01,\n",
      "        -5.1419e-01, -9.1046e-01, -8.6286e-01, -8.6370e-01, -1.0777e+00,\n",
      "        -5.2363e-01, -1.1063e+00,  1.0913e+00, -4.8856e-01, -1.0199e+00,\n",
      "         4.7220e-01, -8.2829e-01, -1.1229e+00, -3.2565e-01, -1.0090e+00,\n",
      "         1.8112e+00, -1.2146e+00,  1.1174e+00, -9.7194e-01, -2.7771e-01,\n",
      "        -6.9955e-01, -1.0537e+00, -9.0386e-01, -5.3085e-01, -9.0484e-01,\n",
      "         1.3326e+00, -1.0870e+00,  5.7020e-03,  4.7477e-02, -9.0675e-01,\n",
      "        -8.2498e-01, -6.5650e-01, -7.8744e-01, -1.2676e+00, -5.9875e-01,\n",
      "        -9.6837e-01,  7.5539e-01,  1.1990e+00, -1.0377e+00, -5.7517e-01,\n",
      "        -7.8020e-01, -9.0959e-01, -8.3408e-01, -9.5111e-01,  2.3841e-01,\n",
      "         3.9518e-01,  1.2323e+00,  7.7846e-01, -4.3575e-01, -9.4378e-01,\n",
      "        -1.0406e+00, -8.9893e-01, -9.7988e-01, -6.5791e-01, -8.1208e-01,\n",
      "        -1.1671e+00,  1.6297e+00,  1.0392e+00,  1.2540e+00, -1.2795e+00,\n",
      "        -1.0385e+00, -1.1552e+00, -1.0442e+00, -1.0926e+00, -2.7928e-01,\n",
      "        -8.9943e-01, -5.8574e-01, -1.0306e+00, -7.9096e-01,  3.8613e-01,\n",
      "         2.1384e+00, -7.3739e-01, -1.7231e-02, -7.3082e-01, -2.7003e-02,\n",
      "        -9.2610e-01, -6.4388e-01,  2.0643e-01])\n",
      "torch.Size([288, 48, 1, 1]) torch.Size([288])\n",
      "q_weight: tensor([ 86, -29, -54,  ..., -29, -21, -52], dtype=torch.int32) q_bias: tensor([  5301,  -4609,  -7191,  -1497,   5276,  -9089,  -6656,  -7889,  -7525,\n",
      "         -6146,   -740,  -6571,  -7238,  11069,  -5167,  -4231,  -6701,  -9144,\n",
      "         -3237,  -5351,  -4309,    606,  -9288,   -157,  -6068,  -5523,  39273,\n",
      "         -7209,  -5812, -10168,   -361, -11423,  -9781,  -5236, -11796,    553,\n",
      "         -9664,  -7545,  -6696,  -7398,  -6629,  -9878,  -6010,  -4008,    596,\n",
      "         -7617,  -9435,  -4403,   -866,   1380,  -5241,   2234,  -7699,   3654,\n",
      "         -2005,   9516,  12828,  -4744,   7641,  -2865,   -253,   -928,  -2695,\n",
      "         -4027,  -5907, -11269,  -3518, -12831,   -859,  10273,  -3117,  -6987,\n",
      "         -4534,  -3569,  -6036,  -4722,  -3734, -10617, -10797, -13249,  -6522,\n",
      "         -5639,  -6193,  -6389,  -9240,  -6341,  -3744,  -8845,    221,  -5640,\n",
      "         -4438,  -3792,  -5970,  -7173,  -3805,  -4783, -10206,  -4129,   6300,\n",
      "         -9667,  -4954,  -8261,  -9941, -10684,  -7553,  -4149,   -198, -10339,\n",
      "        -12556,  -9570,  -5498,  39027,  -9135,  -4243, -12025,   2058,  -8152,\n",
      "          1477,  -4969, -10096,  -9310,  -6653,  -7083,  -8464,  -4978,    459,\n",
      "         -7833, -12223,  -7553,  -8738,  -4058,    927,  -6418,  -7244,  -2882,\n",
      "         -5181,   1470,  -2298,   7041,  -3099,  -7906,  -6386, -11571,  22472,\n",
      "         -4393,  -2270,  -7913,   4865,  -8883,  -4223,  -8337,  -5237,  -8606,\n",
      "         -7116,  -8845, -14852,  -9790,  -4501,  -8715,  -8264,   5914,  -5566,\n",
      "         -3940,  -9208,  -4913,  -4943,  -9202,  -6689,  -6658,   -970,  -2403,\n",
      "        -10701,   2019,   8937,  -6348,  16879, -12223,  11531,  10260,  -6593,\n",
      "         -7354,  -3568,  11053,  -3000, -11213, -10787,  -6803,  -6004,  -5900,\n",
      "         -7197,  -3881,  -8731,  -7498,   7023,   1712, -16484,  -8713,  -7803,\n",
      "         -5632,  -5972,  -6364,  -7306,  -9196,  -8106,  -5473,  -9057,    739,\n",
      "         -9405,  -1774, -10271,  -1963,  -7387,  -6182,  -6392,  -6916,  -2515,\n",
      "         -8924,   8839,  -1436,  -5046,   1572,  -5508, -11246,  -1165,  -7966,\n",
      "         14611, -10379,   9000,  -9718,   -882,  -4125,  -7031,  -7085,  -2322,\n",
      "         -7401,   6841,  -8318,      6,    122,  -4875,  -4612,  -3466,  -5475,\n",
      "        -10446,  -2412,  -6999,   4203,   7152,  -5068,  -1952,  -3639,  -6429,\n",
      "        -13153,  -8207,    742,   1152,  13656,   2876,  -1919,  -7086,  -7049,\n",
      "         -5884,  -5657,  -2292,  -7495,  -8951,   9581,   8094,  11993, -13615,\n",
      "         -7928,  -7492,  -4048,  -8046,  -1075,  -5563,  -2682, -10318,  -5098,\n",
      "          2130,   8661,  -3036,    -49,  -3239,    -58,  -9621,  -3697,    627],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-3.9837e-06) tensor(0.0037)   bias tensor(-4.7163e-06) tensor(0.0003)\n",
      "features.14.conv.3.weight features.14.conv.5\n",
      "torch.Size([288, 1, 3, 3]) conv_bias= torch.Size([288]) \n",
      "ascale= tensor([0.2718]) torch.Size([1]) \n",
      "wscale= tensor([0.0078, 0.0158, 0.0424, 0.0065, 0.0058, 0.0469, 0.0257, 0.0640, 0.0419,\n",
      "        0.0142, 0.0026, 0.0503, 0.0316, 0.0081, 0.0159, 0.0157, 0.0354, 0.2455,\n",
      "        0.0085, 0.0184, 0.0128, 0.0043, 0.0845, 0.0039, 0.0254, 0.0115, 0.0082,\n",
      "        0.0256, 0.0413, 0.0917, 0.0031, 0.0409, 0.2991, 0.0124, 0.0630, 0.0025,\n",
      "        0.0446, 0.0605, 0.0280, 0.0159, 0.0249, 0.0470, 0.0266, 0.0183, 0.0031,\n",
      "        0.0318, 0.0117, 0.0161, 0.0039, 0.0042, 0.0118, 0.0041, 0.1827, 0.0043,\n",
      "        0.0052, 0.0257, 0.0261, 0.0080, 0.0040, 0.0064, 0.0030, 0.0046, 0.0071,\n",
      "        0.0170, 0.0204, 0.0585, 0.0124, 0.0842, 0.0055, 0.0077, 0.0102, 0.0344,\n",
      "        0.0056, 0.0125, 0.0141, 0.0216, 0.0119, 0.0300, 0.0596, 0.1925, 0.0279,\n",
      "        0.0230, 0.0106, 0.0220, 0.0201, 0.0233, 0.0112, 0.2892, 0.0027, 0.0109,\n",
      "        0.0331, 0.0085, 0.0304, 0.0225, 0.0101, 0.0098, 0.0776, 0.0116, 0.0068,\n",
      "        0.0587, 0.0087, 0.0605, 0.0389, 0.0466, 0.0437, 0.0090, 0.0057, 0.0445,\n",
      "        0.0535, 0.0906, 0.0536, 0.0116, 0.0602, 0.0089, 0.2203, 0.0044, 0.0214,\n",
      "        0.0033, 0.0115, 0.0421, 0.0369, 0.0375, 0.0317, 0.0464, 0.0185, 0.0021,\n",
      "        0.1044, 0.0932, 0.0169, 0.0424, 0.0078, 0.0042, 0.0192, 0.0221, 0.0062,\n",
      "        0.0152, 0.0031, 0.0066, 0.0093, 0.0097, 0.3063, 0.0196, 0.0783, 0.0409,\n",
      "        0.0141, 0.0057, 0.0187, 0.0046, 0.0502, 0.0100, 0.0151, 0.0072, 0.0159,\n",
      "        0.0170, 0.0252, 0.2798, 0.0259, 0.0168, 0.1076, 0.0316, 0.0037, 0.0137,\n",
      "        0.0161, 0.0262, 0.0140, 0.0234, 0.0608, 0.0427, 0.0296, 0.0079, 0.0100,\n",
      "        0.0926, 0.0036, 0.0059, 0.0452, 0.0168, 0.0809, 0.0085, 0.0087, 0.0171,\n",
      "        0.0179, 0.0063, 0.0122, 0.0091, 0.0671, 0.0357, 0.0279, 0.0114, 0.0208,\n",
      "        0.0642, 0.0166, 0.0314, 0.0452, 0.0097, 0.0053, 0.3312, 0.0696, 0.0386,\n",
      "        0.0195, 0.0184, 0.0163, 0.2541, 0.1426, 0.3815, 0.0149, 0.0180, 0.0033,\n",
      "        0.3328, 0.0033, 0.2692, 0.0028, 0.0202, 0.0412, 0.0270, 0.0111, 0.0103,\n",
      "        0.0463, 0.0061, 0.0043, 0.0307, 0.0038, 0.0147, 0.4027, 0.0028, 0.0308,\n",
      "        0.0087, 0.0558, 0.0068, 0.0318, 0.0023, 0.0153, 0.0310, 0.0392, 0.0046,\n",
      "        0.0590, 0.0051, 0.0302, 0.0023, 0.0025, 0.0270, 0.0142, 0.0085, 0.0119,\n",
      "        0.0394, 0.0075, 0.0164, 0.0052, 0.0056, 0.0131, 0.0056, 0.0115, 0.0131,\n",
      "        0.2151, 0.0329, 0.0039, 0.0023, 0.0074, 0.0038, 0.0046, 0.3237, 0.0210,\n",
      "        0.0318, 0.0155, 0.0071, 0.0118, 0.0544, 0.0081, 0.0062, 0.0085, 0.1668,\n",
      "        0.0317, 0.0281, 0.0192, 0.0187, 0.0051, 0.0155, 0.0064, 0.0404, 0.0106,\n",
      "        0.0070, 0.0093, 0.0102, 0.0034, 0.0138, 0.0024, 0.0900, 0.0129, 0.0025]) torch.Size([288, 1, 1, 1]) \n",
      "oscale= tensor([0.1674]) torch.Size([1])\n",
      "###: M= tensor([0.0126, 0.0257, 0.0689, 0.0106, 0.0094, 0.0762, 0.0417, 0.1040, 0.0681,\n",
      "        0.0230, 0.0043, 0.0816, 0.0514, 0.0132, 0.0259, 0.0255, 0.0574, 0.3986,\n",
      "        0.0138, 0.0299, 0.0208, 0.0070, 0.1373, 0.0063, 0.0412, 0.0187, 0.0133,\n",
      "        0.0415, 0.0671, 0.1489, 0.0051, 0.0664, 0.4856, 0.0202, 0.1023, 0.0040,\n",
      "        0.0723, 0.0982, 0.0454, 0.0258, 0.0404, 0.0762, 0.0432, 0.0298, 0.0050,\n",
      "        0.0517, 0.0189, 0.0261, 0.0063, 0.0068, 0.0191, 0.0067, 0.2967, 0.0069,\n",
      "        0.0084, 0.0417, 0.0424, 0.0130, 0.0064, 0.0103, 0.0049, 0.0074, 0.0115,\n",
      "        0.0276, 0.0331, 0.0949, 0.0201, 0.1367, 0.0089, 0.0124, 0.0166, 0.0558,\n",
      "        0.0091, 0.0203, 0.0229, 0.0351, 0.0193, 0.0488, 0.0967, 0.3126, 0.0453,\n",
      "        0.0374, 0.0172, 0.0358, 0.0326, 0.0378, 0.0182, 0.4695, 0.0045, 0.0177,\n",
      "        0.0538, 0.0138, 0.0494, 0.0366, 0.0164, 0.0160, 0.1259, 0.0188, 0.0110,\n",
      "        0.0954, 0.0141, 0.0983, 0.0631, 0.0757, 0.0709, 0.0146, 0.0092, 0.0722,\n",
      "        0.0869, 0.1471, 0.0869, 0.0188, 0.0978, 0.0145, 0.3576, 0.0071, 0.0347,\n",
      "        0.0053, 0.0186, 0.0684, 0.0599, 0.0608, 0.0514, 0.0753, 0.0301, 0.0034,\n",
      "        0.1695, 0.1514, 0.0274, 0.0688, 0.0127, 0.0068, 0.0312, 0.0358, 0.0100,\n",
      "        0.0246, 0.0051, 0.0107, 0.0151, 0.0158, 0.4972, 0.0318, 0.1271, 0.0663,\n",
      "        0.0229, 0.0092, 0.0303, 0.0075, 0.0815, 0.0162, 0.0245, 0.0116, 0.0258,\n",
      "        0.0276, 0.0409, 0.4543, 0.0421, 0.0273, 0.1747, 0.0513, 0.0061, 0.0222,\n",
      "        0.0261, 0.0426, 0.0228, 0.0379, 0.0987, 0.0693, 0.0481, 0.0128, 0.0163,\n",
      "        0.1503, 0.0059, 0.0096, 0.0734, 0.0273, 0.1313, 0.0138, 0.0141, 0.0277,\n",
      "        0.0291, 0.0102, 0.0199, 0.0148, 0.1090, 0.0579, 0.0454, 0.0185, 0.0337,\n",
      "        0.1042, 0.0270, 0.0509, 0.0734, 0.0158, 0.0086, 0.5378, 0.1130, 0.0626,\n",
      "        0.0317, 0.0300, 0.0265, 0.4125, 0.2315, 0.6193, 0.0242, 0.0292, 0.0053,\n",
      "        0.5403, 0.0053, 0.4371, 0.0046, 0.0327, 0.0669, 0.0439, 0.0181, 0.0166,\n",
      "        0.0751, 0.0098, 0.0070, 0.0498, 0.0062, 0.0239, 0.6539, 0.0046, 0.0499,\n",
      "        0.0141, 0.0906, 0.0110, 0.0517, 0.0038, 0.0248, 0.0504, 0.0637, 0.0075,\n",
      "        0.0958, 0.0082, 0.0490, 0.0038, 0.0040, 0.0439, 0.0230, 0.0138, 0.0193,\n",
      "        0.0639, 0.0122, 0.0266, 0.0084, 0.0091, 0.0213, 0.0091, 0.0186, 0.0212,\n",
      "        0.3492, 0.0534, 0.0064, 0.0037, 0.0121, 0.0062, 0.0074, 0.5255, 0.0340,\n",
      "        0.0516, 0.0251, 0.0115, 0.0192, 0.0883, 0.0132, 0.0101, 0.0138, 0.2709,\n",
      "        0.0514, 0.0456, 0.0311, 0.0304, 0.0083, 0.0251, 0.0104, 0.0656, 0.0173,\n",
      "        0.0114, 0.0151, 0.0165, 0.0056, 0.0225, 0.0040, 0.1462, 0.0209, 0.0040])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "conv_weight: tensor([[[ 2.4755e-02, -3.9113e-03, -3.2144e-01],\n",
      "         [ 9.5051e-03,  1.5310e-01, -5.3808e-01],\n",
      "         [ 1.8825e-02,  4.8287e-02, -4.6316e-01]],\n",
      "\n",
      "        [[ 3.2979e-01,  6.7597e-01,  4.8090e-01],\n",
      "         [ 4.1006e-01,  1.0964e+00,  8.8311e-01],\n",
      "         [ 2.0689e-01,  6.2109e-01,  4.8334e-01]],\n",
      "\n",
      "        [[ 7.0503e-01,  1.2854e+00,  9.5560e-01],\n",
      "         [ 1.3427e+00,  2.1548e+00,  1.7527e+00],\n",
      "         [ 8.1491e-01,  1.3995e+00,  1.1637e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4149e+00,  4.7441e+00,  3.3928e+00],\n",
      "         [ 1.6727e+00,  2.5201e+00,  2.2573e+00],\n",
      "         [-2.8793e-01, -6.9695e-01, -4.0453e-01]],\n",
      "\n",
      "        [[-3.6414e-01, -4.6179e-01, -4.3617e-01],\n",
      "         [-6.9901e-01, -8.6198e-01, -9.2179e-01],\n",
      "         [-5.7263e-01, -8.2874e-01, -8.4539e-01]],\n",
      "\n",
      "        [[-8.6016e-02, -1.1346e-01, -7.5019e-02],\n",
      "         [-1.3284e-01, -2.2102e-01, -1.7427e-01],\n",
      "         [-1.2771e-01, -1.5445e-01, -1.8010e-01]]]) conv_bias: tensor([ 1.4971e+00,  3.5800e-02,  1.1154e-01,  9.8324e-03,  5.0077e+00,\n",
      "         3.0648e+00,  7.7073e-02,  1.3239e-01,  2.2069e+00,  3.6574e+00,\n",
      "         4.6250e+00,  7.0579e-02,  1.4894e-01,  2.6459e+00, -4.0033e-02,\n",
      "         3.1658e+00,  1.9825e-01,  1.5845e+00,  3.1990e-01,  2.7199e+00,\n",
      "         1.4442e+00,  4.0683e+00,  6.4140e-02,  1.5982e+00,  7.5955e-02,\n",
      "         1.1112e+00,  2.3555e+00,  1.4290e-01,  8.0535e-02,  1.5336e-01,\n",
      "         2.8742e+00,  1.4556e-01,  1.2802e-01,  5.0151e-02,  1.3749e-01,\n",
      "         3.4481e+00,  1.7480e-01,  1.4006e-01,  6.0714e-02,  8.0934e-02,\n",
      "         3.7206e+00,  1.1577e-01,  3.3346e+00,  6.8564e-02,  3.5603e+00,\n",
      "         5.5959e-02,  4.0016e+00,  7.5200e-02,  3.8630e+00,  2.1353e+00,\n",
      "         7.1120e-02,  4.9303e+00,  2.1110e-01,  2.1904e+00,  2.0598e-02,\n",
      "         9.5545e-01,  6.2517e-01,  1.6438e+00,  4.3505e+00,  4.4802e-02,\n",
      "         4.3051e+00,  2.0002e+00, -2.8669e-02,  7.0007e-02,  1.4757e-01,\n",
      "         1.2335e-01,  1.7573e+00,  1.4174e-01,  7.7748e-02,  3.0128e+00,\n",
      "         3.6548e+00,  1.9986e+00, -3.6650e-02,  4.3414e-02,  1.4822e-01,\n",
      "         1.1919e-02,  3.6610e+00,  7.6773e-02,  1.3777e-02,  2.1087e-01,\n",
      "         3.9005e-02,  7.2795e-02,  8.1899e-02,  2.0433e+00,  6.7836e-02,\n",
      "         3.0913e+00,  4.2868e-02,  7.1638e-02,  3.6963e+00,  1.5774e+00,\n",
      "         3.5733e+00,  7.4343e-02, -3.7016e-02,  1.7670e+00,  2.9227e+00,\n",
      "         2.2709e+00,  1.4440e-01,  6.6701e-02,  2.0965e+00,  1.3746e-01,\n",
      "         1.7069e+00,  1.2647e-01,  7.7107e-02,  1.2092e-01,  1.2863e-01,\n",
      "         3.1222e+00,  4.7688e+00,  2.1269e+00,  1.2438e-01,  1.2304e-01,\n",
      "        -1.1255e-01, -5.7485e-02,  7.7884e-03,  1.6054e+00,  2.3113e-01,\n",
      "         5.0527e+00,  1.8380e+00,  4.0898e+00,  1.4340e+00,  1.1693e-01,\n",
      "         9.8327e-02,  3.3994e+00,  6.9583e-02,  1.1760e-01,  6.7761e-02,\n",
      "         4.4462e+00,  1.8215e-02,  1.6086e-01,  7.3520e-02,  7.4556e-01,\n",
      "         3.1983e+00, -2.2715e-01,  7.1462e-02,  8.0023e-02,  3.2793e+00,\n",
      "         1.5890e+00,  3.4356e-02,  2.0096e+00,  2.2342e+00,  6.6933e-02,\n",
      "         2.8892e-01,  7.9529e-02,  1.1831e-01,  8.1982e+00,  3.5648e+00,\n",
      "         3.4855e+00,  1.3117e+00,  2.3005e+00,  2.5197e+00,  1.1466e+00,\n",
      "         1.7234e+00,  3.3601e+00,  3.3329e+00,  1.9679e+00,  6.0380e-02,\n",
      "         3.2293e+00,  7.6926e-02,  8.1179e-02,  1.1899e-01,  7.9954e-02,\n",
      "         3.1152e+00,  1.2587e+00,  6.7090e-02,  5.3637e-02, -1.9946e-02,\n",
      "         2.9027e+00,  2.7326e-01,  7.9856e-02,  1.0653e-01,  3.3667e+00,\n",
      "        -1.1670e-01,  1.1558e-01,  3.0343e+00,  5.4828e+00,  5.6870e-02,\n",
      "         8.9065e+00,  9.5285e-02,  3.1371e+00,  3.2540e+00,  1.2399e+00,\n",
      "         2.3181e+00,  2.1480e+00,  3.7555e+00,  5.1233e+00,  1.2134e-01,\n",
      "         1.3972e-01,  1.2094e-01,  7.1906e-02,  6.4422e-02, -7.3181e-02,\n",
      "         3.2556e+00,  7.9478e-02,  1.4313e-01,  2.2525e+00,  1.7485e+00,\n",
      "         1.3642e-01,  1.5096e-01,  6.4202e-02,  3.8901e+00,  4.5309e+00,\n",
      "         6.8872e-02,  2.5774e-01,  1.5456e-01,  3.6697e-01,  7.5039e-02,\n",
      "         1.5542e-01,  1.6623e+00,  2.5076e+00,  3.0848e+00,  1.5904e-01,\n",
      "         3.0094e+00,  7.3999e-02,  1.2739e-01,  3.1919e+00,  4.6992e+00,\n",
      "         1.5290e+00,  6.7678e-02,  3.2182e+00,  3.9795e+00,  4.8145e-02,\n",
      "         1.8823e+00,  4.6063e-02,  2.9892e+00,  4.0660e+00,  1.2806e-01,\n",
      "         2.3580e+00,  7.8713e-02,  2.8903e+00,  5.8537e-02,  1.5368e-02,\n",
      "         6.8861e-02,  7.6689e-02,  1.2461e-01,  5.4012e-02,  2.0570e-02,\n",
      "         4.7985e+00,  1.3064e-01,  1.0171e-01,  4.4713e+00,  2.4013e-01,\n",
      "         5.0074e-02,  3.7582e+00,  1.6262e+00, -3.6220e-04,  4.6016e+00,\n",
      "         7.6975e-02,  1.9536e+00,  3.0513e+00,  1.3537e-01,  1.5134e-02,\n",
      "         2.5031e+00,  3.8091e+00,  5.9486e-01,  4.3919e-02,  1.2544e+00,\n",
      "         2.4802e+00,  3.0186e+00,  4.1482e+00,  2.8950e-02,  2.1941e-02,\n",
      "         7.5946e-02,  1.1428e-01,  7.4759e-02,  1.4760e-01,  3.6177e+00,\n",
      "         1.5954e-01,  2.6829e+00,  2.2957e+00,  2.1535e+00,  4.6903e+00,\n",
      "         6.6814e-02,  7.4242e-02,  2.2963e+00,  7.0496e-02, -1.1174e-01,\n",
      "         1.4320e+00,  3.5466e+00,  4.4500e-02,  4.4069e+00,  1.5512e+00,\n",
      "         5.3026e+00,  3.5913e+00,  1.4122e+00,  3.3549e+00,  4.2329e+00,\n",
      "         3.5132e-01,  1.3053e+00,  2.1498e+00])\n",
      "torch.Size([288, 1, 3, 3]) torch.Size([288])\n",
      "q_weight: tensor([  3,  -1, -41,  ..., -52, -63, -73], dtype=torch.int32) q_bias: tensor([ 710,    8,   10,    6, 3193,  240,   11,    8,  194,  950, 6474,    5,\n",
      "          17, 1195,   -9,  743,   21,   24,  138,  543,  415, 3469,    3, 1503,\n",
      "          11,  355, 1055,   21,    7,    6, 3374,   13,    2,   15,    8, 5104,\n",
      "          14,    9,    8,   19,  550,    9,  461,   14, 4282,    6, 1262,   17,\n",
      "        3654, 1875,   22, 4421,    4, 1894,   15,  137,   88,  754, 4031,   26,\n",
      "        5290, 1616,  -15,   15,   27,    8,  521,    6,   52, 1447, 1312,  214,\n",
      "         -24,   13,   39,    2, 1134,    9,    1,    4,    5,   12,   28,  341,\n",
      "          12,  488,   14,    1, 4949,  531,  397,   32,   -4,  288, 1062,  850,\n",
      "           7,   21, 1141,    9,  723,    8,    7,   10,   11, 1275, 3091,  176,\n",
      "           9,    5,   -8,  -18,    0,  660,    4, 4222,  316, 4608,  460,   10,\n",
      "          10,  334,    8,    9,   13, 7715,    1,    6,   16,   65, 1510, -200,\n",
      "          14,   13, 1950,  386,   41, 1119,  886,   25,    3,   15,    6,  738,\n",
      "         928, 2251,  259, 1834,  185,  423,  420, 1727,  771,  426,    9,   42,\n",
      "          11,   18,    4,    9, 3061,  338,   15,    8,   -5,  457,   17,    7,\n",
      "          13, 1571,  -43,    5, 3083, 3418,    5, 1951,    4, 1362, 1378,  267,\n",
      "         475, 1261, 1129, 2064,    7,   14,   16,   23,   11,   -4,  721,    9,\n",
      "          12,  852, 1219,    2,    8,    6,  734,  904,   16,    4,    4,    4,\n",
      "          19,   32, 1876,   28, 3455,    2, 3936,   14,   11,  434, 1552,  549,\n",
      "           5, 1957, 3395,    6, 1826,   12,   27, 5282,   15, 1002,    5, 1562,\n",
      "           7,   24,   17,    9,   12,   43,    1, 3480,   16,  161, 6702,   33,\n",
      "          13, 1629,  503,    0, 2256,   17, 1382, 2013,   38,   10,  804, 1072,\n",
      "          10,    5, 1172, 3971, 1496, 3989,   23,    0,   13,   13,   18,   76,\n",
      "        1127,   11, 1212, 1361,  929,  103,    8,   10,  441,   14,  -80,  341,\n",
      "        2046,    4, 1523,  810, 2095, 1298, 1507,  892, 6372,   14,  373, 3201],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0001) tensor(0.1688)   bias tensor(-0.0002) tensor(0.0392)\n",
      "features.14.conv.6.weight features.14.conv.8\n",
      "torch.Size([80, 288, 1, 1]) conv_bias= torch.Size([80]) \n",
      "ascale= tensor([0.1603]) torch.Size([1]) \n",
      "wscale= tensor([0.0016, 0.0020, 0.0023, 0.0017, 0.0018, 0.0020, 0.0015, 0.0015, 0.0019,\n",
      "        0.0017, 0.0018, 0.0016, 0.0015, 0.0017, 0.0017, 0.0019, 0.0017, 0.0018,\n",
      "        0.0018, 0.0023, 0.0017, 0.0016, 0.0017, 0.0017, 0.0018, 0.0018, 0.0020,\n",
      "        0.0016, 0.0016, 0.0013, 0.0020, 0.0016, 0.0017, 0.0014, 0.0015, 0.0018,\n",
      "        0.0018, 0.0017, 0.0014, 0.0022, 0.0021, 0.0017, 0.0021, 0.0017, 0.0019,\n",
      "        0.0021, 0.0018, 0.0019, 0.0024, 0.0015, 0.0017, 0.0017, 0.0016, 0.0021,\n",
      "        0.0017, 0.0016, 0.0019, 0.0019, 0.0017, 0.0017, 0.0019, 0.0014, 0.0019,\n",
      "        0.0018, 0.0017, 0.0014, 0.0021, 0.0017, 0.0017, 0.0017, 0.0026, 0.0017,\n",
      "        0.0016, 0.0018, 0.0017, 0.0015, 0.0016, 0.0017, 0.0019, 0.0017]) torch.Size([80, 1, 1, 1]) \n",
      "oscale= tensor([0.0647]) torch.Size([1])\n",
      "###: M= tensor([0.0039, 0.0049, 0.0056, 0.0042, 0.0044, 0.0050, 0.0038, 0.0037, 0.0048,\n",
      "        0.0042, 0.0045, 0.0039, 0.0037, 0.0042, 0.0043, 0.0046, 0.0043, 0.0045,\n",
      "        0.0044, 0.0058, 0.0043, 0.0041, 0.0043, 0.0042, 0.0044, 0.0044, 0.0049,\n",
      "        0.0039, 0.0040, 0.0033, 0.0051, 0.0039, 0.0042, 0.0034, 0.0038, 0.0044,\n",
      "        0.0044, 0.0043, 0.0034, 0.0053, 0.0052, 0.0041, 0.0052, 0.0041, 0.0046,\n",
      "        0.0051, 0.0045, 0.0047, 0.0059, 0.0038, 0.0042, 0.0043, 0.0040, 0.0052,\n",
      "        0.0043, 0.0040, 0.0046, 0.0047, 0.0042, 0.0042, 0.0047, 0.0036, 0.0047,\n",
      "        0.0044, 0.0042, 0.0034, 0.0052, 0.0042, 0.0042, 0.0042, 0.0065, 0.0041,\n",
      "        0.0039, 0.0044, 0.0041, 0.0037, 0.0039, 0.0042, 0.0047, 0.0043])\n",
      "torch.Size([80, 288, 1, 1]) torch.Size([80])\n",
      "conv_weight: tensor([[-0.0958, -0.0434,  0.0170,  ...,  0.0147, -0.0216,  0.0545],\n",
      "        [ 0.0208, -0.0154, -0.0620,  ...,  0.0065,  0.0018, -0.0517],\n",
      "        [ 0.0596,  0.0584, -0.0245,  ...,  0.0718,  0.0403,  0.0174],\n",
      "        ...,\n",
      "        [-0.0242, -0.1120, -0.0329,  ..., -0.0313,  0.0432,  0.0182],\n",
      "        [-0.0294,  0.0111,  0.0083,  ..., -0.0152, -0.0553,  0.0340],\n",
      "        [ 0.0504, -0.0233,  0.0483,  ..., -0.0633, -0.0164,  0.0425]]) conv_bias: tensor([ 2.2241,  2.5741, -1.7284,  1.1434, -1.1118, -0.8972,  1.0954,  0.2277,\n",
      "        -0.7865,  0.8498,  0.2173,  0.4437,  2.1584, -0.8494, -0.6778,  0.9138,\n",
      "        -1.2288, -0.8175,  1.7921, -0.1398,  0.6823,  0.1459,  1.2774, -0.3587,\n",
      "        -0.1475, -0.4142,  0.4298, -1.2490,  0.2456, -2.6232, -0.5061,  2.3964,\n",
      "         0.6529, -0.0596,  2.9138, -0.4261, -2.2145,  0.3158, -0.3501,  1.0826,\n",
      "         1.4686, -0.0310,  1.9965, -1.9419,  2.2813, -1.6087,  1.1768,  2.0483,\n",
      "         2.3031,  1.8042, -3.4823, -2.3137,  1.3772,  0.2260, -0.2835,  0.3818,\n",
      "        -0.4841,  1.1899,  0.8595,  2.0917,  2.8671,  1.9675,  1.1857,  3.0460,\n",
      "         2.1924, -1.0146,  0.2377, -0.8459, -2.0345, -2.8912,  2.7287, -2.4548,\n",
      "        -1.7640,  0.5673,  2.1751,  0.3988, -1.4117, -2.1082, -0.7608,  1.2345])\n",
      "torch.Size([80, 288, 1, 1]) torch.Size([80])\n",
      "q_weight: tensor([-60, -27,  11,  ..., -36,  -9,  24], dtype=torch.int32) q_bias: tensor([  8758,   8118,  -4752,   4227,  -3902,  -2792,   4463,    946,  -2525,\n",
      "          3142,    753,   1747,   8921,  -3163,  -2436,   3069,  -4453,  -2806,\n",
      "          6330,   -374,   2460,    552,   4633,  -1318,   -516,  -1461,   1363,\n",
      "         -4999,    954, -12249,  -1546,   9567,   2376,   -275,  11789,  -1491,\n",
      "         -7727,   1126,  -1569,   3131,   4352,   -116,   5895,  -7278,   7608,\n",
      "         -4887,   4016,   6759,   6037,   7406, -12841,  -8306,   5346,    678,\n",
      "         -1025,   1460,  -1624,   3946,   3155,   7667,   9511,   8494,   3861,\n",
      "         10675,   8013,  -4654,    706,  -3087,  -7567, -10713,   6493,  -9265,\n",
      "         -6949,   1993,   8151,   1661,  -5544,  -7692,  -2519,   4419],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-7.1884e-06) tensor(0.0013)   bias tensor(-4.9931e-06) tensor(0.0002)\n",
      "features.15.conv.0.weight features.15.conv.2\n",
      "torch.Size([480, 80, 1, 1]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.0647]) torch.Size([1]) \n",
      "wscale= tensor([2.7987e-03, 2.8547e-05, 4.4410e-03, 4.1412e-03, 2.2291e-03, 2.2997e-03,\n",
      "        5.4503e-03, 2.2272e-03, 3.9837e-03, 2.6723e-03, 3.9630e-03, 6.8887e-03,\n",
      "        5.0521e-03, 4.1665e-03, 5.3220e-03, 2.8138e-03, 6.7364e-03, 3.8971e-03,\n",
      "        6.8772e-03, 3.4673e-03, 5.1979e-03, 4.9317e-03, 3.0547e-03, 5.4614e-03,\n",
      "        2.5817e-03, 2.7939e-03, 5.6639e-03, 6.1167e-03, 4.7255e-03, 2.8922e-03,\n",
      "        1.8673e-03, 2.7864e-03, 8.2326e-03, 2.8873e-03, 5.8215e-03, 5.2962e-03,\n",
      "        2.3050e-03, 5.5203e-03, 4.2625e-03, 5.8707e-03, 7.3303e-03, 5.3487e-03,\n",
      "        3.4256e-03, 2.0763e-03, 2.2936e-03, 7.4694e-03, 2.3269e-03, 2.4911e-03,\n",
      "        3.0444e-03, 5.3841e-03, 7.0738e-03, 2.0401e-03, 4.5710e-03, 3.7236e-03,\n",
      "        8.3365e-03, 4.8987e-03, 2.1922e-03, 4.9953e-03, 5.1756e-03, 4.7713e-03,\n",
      "        3.2528e-03, 5.0785e-03, 5.1474e-03, 3.4844e-03, 7.3201e-03, 6.5235e-03,\n",
      "        5.2480e-03, 5.2765e-03, 2.9378e-03, 5.8379e-03, 2.7669e-03, 4.3599e-03,\n",
      "        3.0883e-03, 4.1357e-03, 2.4847e-03, 3.2418e-03, 5.3203e-03, 3.1546e-03,\n",
      "        3.9805e-03, 5.9344e-03, 2.5939e-03, 2.8556e-03, 2.7773e-03, 3.6826e-03,\n",
      "        3.0305e-03, 3.4434e-03, 3.0467e-03, 3.7374e-03, 5.1223e-03, 4.7597e-03,\n",
      "        1.0023e-05, 2.9423e-03, 2.9515e-03, 2.1942e-03, 5.2931e-03, 6.6898e-03,\n",
      "        6.2758e-03, 3.5461e-03, 5.6433e-03, 2.9133e-03, 3.6508e-03, 5.9735e-03,\n",
      "        5.0770e-03, 4.0228e-03, 2.9537e-03, 3.0964e-03, 2.9000e-03, 2.1309e-03,\n",
      "        3.7862e-03, 2.8359e-03, 2.6543e-03, 2.0413e-03, 4.6664e-03, 3.0244e-03,\n",
      "        5.3317e-03, 4.3615e-03, 2.5846e-03, 5.5149e-03, 5.3529e-03, 2.8646e-03,\n",
      "        2.7332e-03, 2.1154e-03, 2.1827e-03, 9.0591e-03, 4.9014e-03, 6.2745e-03,\n",
      "        4.5946e-03, 2.6657e-03, 2.5772e-03, 2.1388e-03, 3.2247e-03, 4.9999e-03,\n",
      "        2.7876e-03, 3.7307e-03, 3.4655e-03, 1.0842e-03, 3.0884e-03, 4.5752e-03,\n",
      "        4.9402e-03, 5.8077e-03, 2.3880e-03, 5.4971e-03, 7.8115e-03, 5.5965e-03,\n",
      "        2.5651e-03, 2.7400e-03, 6.9338e-03, 2.0718e-03, 3.9595e-03, 3.5877e-03,\n",
      "        4.9922e-03, 5.0194e-03, 4.5734e-03, 2.4899e-03, 9.6953e-06, 4.2191e-03,\n",
      "        3.2713e-03, 6.0944e-03, 4.1346e-03, 1.8557e-03, 3.1615e-03, 1.9589e-03,\n",
      "        2.5562e-03, 3.3300e-03, 5.2748e-03, 2.3868e-03, 1.5130e-04, 6.7207e-03,\n",
      "        3.3601e-03, 5.2865e-03, 7.5280e-03, 3.3957e-03, 5.7581e-03, 2.5208e-03,\n",
      "        3.0302e-03, 5.1222e-03, 4.6084e-03, 6.2774e-03, 3.1069e-03, 2.3337e-03,\n",
      "        3.3561e-03, 3.8046e-03, 2.9482e-03, 2.0305e-03, 5.7609e-03, 4.9584e-03,\n",
      "        3.8286e-03, 3.8964e-03, 5.0701e-03, 2.4867e-03, 4.6526e-03, 3.6777e-03,\n",
      "        3.1635e-03, 5.8018e-03, 5.4571e-03, 3.8967e-03, 6.3750e-03, 2.2309e-03,\n",
      "        4.8690e-03, 2.0224e-03, 2.7290e-03, 5.0607e-03, 5.4320e-03, 3.6593e-03,\n",
      "        7.1999e-03, 5.2984e-03, 2.4601e-03, 2.6113e-03, 5.4462e-03, 3.7183e-03,\n",
      "        2.1880e-03, 2.1177e-03, 2.5790e-03, 2.6697e-03, 2.7795e-03, 3.6198e-03,\n",
      "        3.3982e-03, 3.1091e-03, 2.9540e-03, 2.8899e-03, 3.9792e-03, 8.1211e-03,\n",
      "        3.3579e-03, 9.7783e-06, 7.7077e-03, 3.5071e-03, 2.4953e-03, 4.3096e-03,\n",
      "        2.9863e-03, 4.9346e-03, 2.9427e-03, 3.5587e-03, 4.2488e-03, 4.5645e-03,\n",
      "        2.5389e-03, 3.6340e-03, 3.3445e-03, 4.1425e-03, 2.2043e-03, 3.2994e-03,\n",
      "        2.9522e-03, 2.1378e-03, 2.9444e-03, 2.1399e-07, 5.6430e-03, 2.2612e-03,\n",
      "        4.7008e-03, 4.8749e-03, 1.9471e-03, 5.5672e-03, 2.1994e-03, 7.0154e-03,\n",
      "        7.8316e-03, 2.3237e-03, 4.7988e-03, 5.2358e-03, 2.3281e-03, 2.6850e-03,\n",
      "        5.3260e-03, 3.2731e-03, 5.7498e-03, 3.6495e-03, 3.3444e-03, 4.2428e-03,\n",
      "        6.1506e-03, 2.3524e-03, 2.9615e-03, 2.7608e-03, 1.6771e-03, 2.7292e-03,\n",
      "        6.8027e-03, 5.1977e-03, 3.8373e-03, 3.8569e-03, 6.7558e-03, 3.0123e-03,\n",
      "        3.2319e-03, 5.3081e-03, 3.4820e-03, 3.3608e-03, 7.2412e-03, 3.9795e-04,\n",
      "        5.6725e-03, 2.6551e-03, 4.1603e-03, 4.4267e-03, 3.5506e-03, 3.8236e-03,\n",
      "        2.9752e-03, 4.8075e-03, 3.1545e-03, 4.1135e-03, 2.5036e-03, 5.4994e-03,\n",
      "        4.4777e-03, 6.2236e-03, 5.2775e-03, 2.5134e-03, 4.4671e-03, 3.8948e-03,\n",
      "        3.8793e-03, 2.1836e-03, 3.2867e-03, 5.3331e-03, 8.4323e-03, 3.0406e-03,\n",
      "        2.4469e-03, 2.6630e-03, 2.3420e-03, 3.7890e-03, 3.6602e-03, 4.3116e-03,\n",
      "        3.1718e-03, 6.5524e-03, 5.4471e-03, 3.2737e-03, 2.1091e-03, 5.3476e-03,\n",
      "        2.4017e-03, 3.1475e-03, 4.0169e-03, 4.0158e-03, 3.5520e-03, 5.4335e-03,\n",
      "        2.3464e-03, 5.3338e-03, 4.3590e-03, 6.5172e-03, 4.2569e-03, 3.8912e-03,\n",
      "        4.0616e-03, 8.0678e-03, 2.8057e-03, 5.2788e-03, 5.0894e-03, 4.3302e-03,\n",
      "        4.4065e-03, 5.5187e-03, 2.6648e-03, 3.9734e-03, 4.4746e-03, 6.8332e-03,\n",
      "        4.6457e-03, 2.7091e-03, 4.2725e-03, 3.5093e-03, 7.6178e-03, 3.0494e-03,\n",
      "        5.0909e-03, 3.7945e-03, 6.2852e-03, 3.1722e-03, 3.2710e-03, 8.7397e-03,\n",
      "        3.3013e-03, 3.6544e-03, 3.1335e-03, 1.9505e-03, 2.4611e-03, 6.5801e-03,\n",
      "        8.3937e-03, 5.0979e-03, 4.7000e-03, 5.9505e-03, 3.1580e-03, 3.3530e-03,\n",
      "        9.7292e-03, 2.0000e-03, 4.8840e-03, 7.6902e-03, 4.9215e-03, 5.7141e-03,\n",
      "        2.8711e-03, 2.4254e-03, 2.8008e-03, 2.6696e-03, 8.1153e-03, 6.0070e-03,\n",
      "        3.3965e-03, 5.1252e-03, 2.7915e-03, 2.4239e-03, 5.2002e-03, 3.3690e-03,\n",
      "        3.0784e-03, 4.2637e-03, 2.8986e-03, 3.6874e-03, 5.0507e-03, 4.2398e-03,\n",
      "        3.0560e-03, 2.5162e-03, 4.8163e-03, 3.8416e-03, 3.6583e-03, 3.6386e-03,\n",
      "        6.3900e-03, 3.2591e-03, 5.9092e-03, 8.5627e-03, 6.4009e-03, 3.6153e-03,\n",
      "        3.8363e-03, 3.9412e-03, 2.2115e-03, 5.8904e-03, 5.7174e-03, 2.9250e-03,\n",
      "        6.4286e-03, 4.0609e-03, 5.7028e-03, 5.5345e-03, 7.5801e-03, 3.7121e-03,\n",
      "        2.8138e-03, 7.0662e-03, 8.9047e-06, 2.7645e-03, 6.1097e-03, 2.3667e-03,\n",
      "        6.6691e-03, 6.0015e-03, 3.3996e-03, 6.1448e-03, 6.6179e-03, 1.9562e-03,\n",
      "        5.7350e-03, 3.7452e-03, 4.4864e-03, 7.1953e-03, 6.9640e-03, 6.0636e-03,\n",
      "        4.3390e-03, 3.6251e-03, 4.6204e-03, 2.8447e-03, 9.6698e-03, 2.0070e-03,\n",
      "        6.7408e-03, 5.3894e-03, 4.9336e-03, 5.4665e-03, 6.6180e-03, 4.6053e-03,\n",
      "        7.5738e-03, 5.4550e-03, 2.3574e-03, 4.8606e-03, 3.4691e-03, 2.8639e-03,\n",
      "        5.2332e-03, 3.3001e-03, 8.0213e-03, 4.9589e-03, 5.4535e-03, 4.2071e-03,\n",
      "        4.1473e-03, 2.7147e-03, 3.7680e-03, 3.5517e-03, 2.4309e-03, 3.4174e-03,\n",
      "        1.2775e-04, 3.0845e-03, 4.5156e-03, 2.6297e-03, 2.9072e-03, 2.3177e-03,\n",
      "        4.9866e-03, 7.9621e-03, 6.2508e-03, 6.7491e-03, 9.1432e-03, 3.1741e-03,\n",
      "        3.7000e-03, 4.1772e-03, 7.9920e-03, 3.5819e-03, 6.5683e-03, 3.1786e-03]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.1897]) torch.Size([1])\n",
      "###: M= tensor([9.5436e-04, 9.7346e-06, 1.5144e-03, 1.4122e-03, 7.6012e-04, 7.8420e-04,\n",
      "        1.8585e-03, 7.5947e-04, 1.3584e-03, 9.1124e-04, 1.3514e-03, 2.3491e-03,\n",
      "        1.7228e-03, 1.4208e-03, 1.8148e-03, 9.5951e-04, 2.2971e-03, 1.3289e-03,\n",
      "        2.3452e-03, 1.1824e-03, 1.7725e-03, 1.6817e-03, 1.0417e-03, 1.8623e-03,\n",
      "        8.8036e-04, 9.5274e-04, 1.9314e-03, 2.0858e-03, 1.6114e-03, 9.8626e-04,\n",
      "        6.3674e-04, 9.5015e-04, 2.8073e-03, 9.8459e-04, 1.9851e-03, 1.8060e-03,\n",
      "        7.8601e-04, 1.8824e-03, 1.4535e-03, 2.0019e-03, 2.4996e-03, 1.8239e-03,\n",
      "        1.1681e-03, 7.0801e-04, 7.8213e-04, 2.5471e-03, 7.9347e-04, 8.4946e-04,\n",
      "        1.0382e-03, 1.8360e-03, 2.4122e-03, 6.9568e-04, 1.5587e-03, 1.2697e-03,\n",
      "        2.8428e-03, 1.6705e-03, 7.4754e-04, 1.7034e-03, 1.7649e-03, 1.6270e-03,\n",
      "        1.1092e-03, 1.7318e-03, 1.7553e-03, 1.1882e-03, 2.4962e-03, 2.2245e-03,\n",
      "        1.7896e-03, 1.7993e-03, 1.0018e-03, 1.9907e-03, 9.4353e-04, 1.4867e-03,\n",
      "        1.0531e-03, 1.4103e-03, 8.4728e-04, 1.1054e-03, 1.8142e-03, 1.0757e-03,\n",
      "        1.3574e-03, 2.0236e-03, 8.8454e-04, 9.7377e-04, 9.4708e-04, 1.2558e-03,\n",
      "        1.0334e-03, 1.1742e-03, 1.0389e-03, 1.2745e-03, 1.7467e-03, 1.6231e-03,\n",
      "        3.4180e-06, 1.0033e-03, 1.0065e-03, 7.4823e-04, 1.8049e-03, 2.2812e-03,\n",
      "        2.1400e-03, 1.2092e-03, 1.9244e-03, 9.9343e-04, 1.2449e-03, 2.0370e-03,\n",
      "        1.7313e-03, 1.3718e-03, 1.0072e-03, 1.0559e-03, 9.8890e-04, 7.2665e-04,\n",
      "        1.2911e-03, 9.6705e-04, 9.0511e-04, 6.9608e-04, 1.5912e-03, 1.0313e-03,\n",
      "        1.8181e-03, 1.4873e-03, 8.8136e-04, 1.8806e-03, 1.8253e-03, 9.7683e-04,\n",
      "        9.3202e-04, 7.2136e-04, 7.4429e-04, 3.0892e-03, 1.6714e-03, 2.1396e-03,\n",
      "        1.5668e-03, 9.0902e-04, 8.7882e-04, 7.2934e-04, 1.0996e-03, 1.7050e-03,\n",
      "        9.5057e-04, 1.2722e-03, 1.1817e-03, 3.6973e-04, 1.0531e-03, 1.5601e-03,\n",
      "        1.6846e-03, 1.9804e-03, 8.1433e-04, 1.8745e-03, 2.6637e-03, 1.9084e-03,\n",
      "        8.7470e-04, 9.3434e-04, 2.3644e-03, 7.0648e-04, 1.3502e-03, 1.2234e-03,\n",
      "        1.7023e-03, 1.7116e-03, 1.5595e-03, 8.4905e-04, 3.3061e-06, 1.4387e-03,\n",
      "        1.1155e-03, 2.0782e-03, 1.4099e-03, 6.3280e-04, 1.0781e-03, 6.6800e-04,\n",
      "        8.7167e-04, 1.1355e-03, 1.7987e-03, 8.1391e-04, 5.1592e-05, 2.2918e-03,\n",
      "        1.1458e-03, 1.8027e-03, 2.5671e-03, 1.1579e-03, 1.9635e-03, 8.5958e-04,\n",
      "        1.0333e-03, 1.7467e-03, 1.5715e-03, 2.1406e-03, 1.0595e-03, 7.9581e-04,\n",
      "        1.1444e-03, 1.2974e-03, 1.0053e-03, 6.9240e-04, 1.9645e-03, 1.6908e-03,\n",
      "        1.3056e-03, 1.3287e-03, 1.7289e-03, 8.4796e-04, 1.5865e-03, 1.2541e-03,\n",
      "        1.0788e-03, 1.9784e-03, 1.8609e-03, 1.3288e-03, 2.1739e-03, 7.6074e-04,\n",
      "        1.6604e-03, 6.8964e-04, 9.3059e-04, 1.7257e-03, 1.8523e-03, 1.2478e-03,\n",
      "        2.4552e-03, 1.8068e-03, 8.3891e-04, 8.9046e-04, 1.8572e-03, 1.2679e-03,\n",
      "        7.4611e-04, 7.2215e-04, 8.7946e-04, 9.1037e-04, 9.4781e-04, 1.2343e-03,\n",
      "        1.1588e-03, 1.0602e-03, 1.0073e-03, 9.8547e-04, 1.3569e-03, 2.7693e-03,\n",
      "        1.1450e-03, 3.3344e-06, 2.6284e-03, 1.1959e-03, 8.5091e-04, 1.4696e-03,\n",
      "        1.0183e-03, 1.6827e-03, 1.0035e-03, 1.2135e-03, 1.4489e-03, 1.5565e-03,\n",
      "        8.6579e-04, 1.2392e-03, 1.1405e-03, 1.4126e-03, 7.5166e-04, 1.1251e-03,\n",
      "        1.0067e-03, 7.2900e-04, 1.0041e-03, 7.2970e-08, 1.9243e-03, 7.7108e-04,\n",
      "        1.6030e-03, 1.6623e-03, 6.6397e-04, 1.8984e-03, 7.5000e-04, 2.3923e-03,\n",
      "        2.6706e-03, 7.9239e-04, 1.6364e-03, 1.7854e-03, 7.9388e-04, 9.1559e-04,\n",
      "        1.8162e-03, 1.1161e-03, 1.9607e-03, 1.2445e-03, 1.1405e-03, 1.4468e-03,\n",
      "        2.0974e-03, 8.0218e-04, 1.0099e-03, 9.4143e-04, 5.7189e-04, 9.3065e-04,\n",
      "        2.3197e-03, 1.7724e-03, 1.3085e-03, 1.3152e-03, 2.3037e-03, 1.0272e-03,\n",
      "        1.1021e-03, 1.8101e-03, 1.1874e-03, 1.1460e-03, 2.4693e-03, 1.3570e-04,\n",
      "        1.9343e-03, 9.0541e-04, 1.4187e-03, 1.5095e-03, 1.2108e-03, 1.3039e-03,\n",
      "        1.0146e-03, 1.6394e-03, 1.0757e-03, 1.4027e-03, 8.5372e-04, 1.8753e-03,\n",
      "        1.5269e-03, 2.1223e-03, 1.7996e-03, 8.5708e-04, 1.5233e-03, 1.3281e-03,\n",
      "        1.3228e-03, 7.4463e-04, 1.1208e-03, 1.8186e-03, 2.8754e-03, 1.0368e-03,\n",
      "        8.3439e-04, 9.0809e-04, 7.9863e-04, 1.2921e-03, 1.2481e-03, 1.4703e-03,\n",
      "        1.0816e-03, 2.2344e-03, 1.8575e-03, 1.1163e-03, 7.1922e-04, 1.8236e-03,\n",
      "        8.1900e-04, 1.0733e-03, 1.3698e-03, 1.3694e-03, 1.2112e-03, 1.8528e-03,\n",
      "        8.0013e-04, 1.8189e-03, 1.4864e-03, 2.2224e-03, 1.4516e-03, 1.3269e-03,\n",
      "        1.3850e-03, 2.7511e-03, 9.5675e-04, 1.8001e-03, 1.7355e-03, 1.4766e-03,\n",
      "        1.5026e-03, 1.8819e-03, 9.0870e-04, 1.3549e-03, 1.5258e-03, 2.3301e-03,\n",
      "        1.5842e-03, 9.2380e-04, 1.4569e-03, 1.1967e-03, 2.5977e-03, 1.0398e-03,\n",
      "        1.7360e-03, 1.2939e-03, 2.1433e-03, 1.0817e-03, 1.1154e-03, 2.9803e-03,\n",
      "        1.1258e-03, 1.2461e-03, 1.0685e-03, 6.6512e-04, 8.3925e-04, 2.2438e-03,\n",
      "        2.8623e-03, 1.7384e-03, 1.6027e-03, 2.0291e-03, 1.0769e-03, 1.1434e-03,\n",
      "        3.3177e-03, 6.8200e-04, 1.6654e-03, 2.6224e-03, 1.6782e-03, 1.9485e-03,\n",
      "        9.7907e-04, 8.2708e-04, 9.5508e-04, 9.1035e-04, 2.7674e-03, 2.0484e-03,\n",
      "        1.1582e-03, 1.7477e-03, 9.5191e-04, 8.2657e-04, 1.7733e-03, 1.1488e-03,\n",
      "        1.0497e-03, 1.4539e-03, 9.8845e-04, 1.2574e-03, 1.7223e-03, 1.4458e-03,\n",
      "        1.0421e-03, 8.5801e-04, 1.6424e-03, 1.3100e-03, 1.2475e-03, 1.2408e-03,\n",
      "        2.1790e-03, 1.1114e-03, 2.0151e-03, 2.9199e-03, 2.1827e-03, 1.2328e-03,\n",
      "        1.3082e-03, 1.3440e-03, 7.5413e-04, 2.0086e-03, 1.9496e-03, 9.9744e-04,\n",
      "        2.1922e-03, 1.3848e-03, 1.9447e-03, 1.8873e-03, 2.5848e-03, 1.2658e-03,\n",
      "        9.5951e-04, 2.4096e-03, 3.0365e-06, 9.4269e-04, 2.0834e-03, 8.0703e-04,\n",
      "        2.2742e-03, 2.0465e-03, 1.1593e-03, 2.0954e-03, 2.2567e-03, 6.6708e-04,\n",
      "        1.9557e-03, 1.2771e-03, 1.5299e-03, 2.4536e-03, 2.3747e-03, 2.0677e-03,\n",
      "        1.4796e-03, 1.2362e-03, 1.5756e-03, 9.7004e-04, 3.2974e-03, 6.8439e-04,\n",
      "        2.2986e-03, 1.8378e-03, 1.6824e-03, 1.8641e-03, 2.2567e-03, 1.5704e-03,\n",
      "        2.5827e-03, 1.8602e-03, 8.0389e-04, 1.6575e-03, 1.1830e-03, 9.7661e-04,\n",
      "        1.7845e-03, 1.1253e-03, 2.7353e-03, 1.6910e-03, 1.8596e-03, 1.4346e-03,\n",
      "        1.4142e-03, 9.2573e-04, 1.2849e-03, 1.2111e-03, 8.2896e-04, 1.1653e-03,\n",
      "        4.3562e-05, 1.0518e-03, 1.5398e-03, 8.9673e-04, 9.9136e-04, 7.9034e-04,\n",
      "        1.7004e-03, 2.7151e-03, 2.1316e-03, 2.3015e-03, 3.1179e-03, 1.0824e-03,\n",
      "        1.2617e-03, 1.4244e-03, 2.7253e-03, 1.2214e-03, 2.2398e-03, 1.0839e-03])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "conv_weight: tensor([[ 4.7213e-02,  9.5990e-02,  2.6951e-02,  ..., -1.1906e-01,\n",
      "          1.3102e-01,  7.8220e-02],\n",
      "        [ 2.4411e-04,  1.1576e-03, -1.4469e-03,  ..., -7.9268e-04,\n",
      "         -7.3121e-04, -1.8729e-04],\n",
      "        [ 2.8551e-01, -2.6649e-01, -3.9273e-02,  ..., -7.6876e-02,\n",
      "         -2.1389e-01,  5.1783e-02],\n",
      "        ...,\n",
      "        [ 1.3354e-01, -8.9168e-02, -1.9037e-02,  ...,  5.5517e-02,\n",
      "         -2.0531e-02, -9.4230e-02],\n",
      "        [ 4.7536e-01, -4.7634e-01,  3.5365e-01,  ...,  4.5027e-01,\n",
      "          4.1103e-01,  5.0439e-01],\n",
      "        [ 1.1041e-01, -2.0234e-01,  2.2685e-01,  ...,  1.6980e-01,\n",
      "         -3.4854e-01, -1.1700e-01]]) conv_bias: tensor([ 9.5072e-01, -5.4948e-02, -2.8912e-01,  4.3005e-01,  9.6204e-01,\n",
      "        -1.5545e-01,  6.7773e-01,  5.5080e-01, -6.5612e-01,  6.7183e-01,\n",
      "        -9.3034e-02, -2.0832e-02, -7.4583e-01, -5.5916e-01,  2.5063e-01,\n",
      "         7.2140e-01, -3.0550e-01,  1.4536e+00,  2.5155e-01, -7.5798e-01,\n",
      "         3.9069e-01,  3.8099e-01,  1.3174e+00,  3.3102e-01, -4.0833e-01,\n",
      "         1.6388e+00,  1.1204e+00, -1.2720e-01,  6.1968e-01,  7.6320e-01,\n",
      "         1.1757e+00,  7.1956e-01,  3.3462e-01,  8.5839e-01,  1.7105e-01,\n",
      "         6.2875e-01, -6.3143e-01,  6.1286e-01,  7.0189e-01,  2.2614e-01,\n",
      "        -2.1180e-01,  1.6183e-01,  8.6439e-01, -5.6323e-01,  9.8987e-01,\n",
      "        -2.1171e-01,  8.2439e-01,  7.8413e-01,  6.4436e-01,  3.8578e-01,\n",
      "         4.1216e-01,  6.8220e-01,  4.9678e-01,  1.3354e+00,  1.0001e-02,\n",
      "         7.6967e-01,  9.2394e-01,  1.1454e-01,  8.9859e-01,  2.2489e+00,\n",
      "         9.4174e-01,  4.4664e-01,  4.9579e-01, -5.9561e-01,  2.1182e-01,\n",
      "         5.8627e-01,  7.9558e-01,  1.4039e-01,  6.3566e-01, -4.5488e-01,\n",
      "         9.5058e-01,  2.7294e-01, -5.5789e-01,  8.3992e-01,  7.9342e-01,\n",
      "        -7.4811e-01, -4.9346e-01,  1.0082e+00,  1.4444e+00, -4.4849e-01,\n",
      "         7.0662e-01, -6.4384e-01,  7.7697e-01,  1.1426e+00,  6.3640e-01,\n",
      "        -6.9728e-01,  7.7000e-01, -7.4534e-01,  7.0873e-02,  1.0730e+00,\n",
      "        -1.9542e-02,  1.2831e+00, -5.8366e-01, -6.5765e-01,  6.3848e-01,\n",
      "        -3.1251e-01,  5.5532e-01, -4.0594e-01,  1.0722e-01, -6.8599e-01,\n",
      "         7.5986e-01,  6.4636e-01,  2.2754e-01, -4.4836e-01,  6.8652e-01,\n",
      "        -3.5732e-01,  1.0119e+00,  9.7548e-01, -6.5267e-01,  5.7356e-01,\n",
      "         3.0851e-01,  1.4683e+00,  5.5560e-01, -7.0996e-01,  5.5667e-01,\n",
      "         2.3063e-01,  1.2550e+00,  2.9853e-01, -3.8034e-01,  1.0827e+00,\n",
      "         1.9336e+00,  1.1752e+00,  1.2716e+00, -1.8848e-01,  5.1698e-01,\n",
      "        -6.9432e-02,  3.8142e-01, -5.2446e-01,  1.0148e+00,  1.0809e+00,\n",
      "         6.5131e-01,  4.1777e-01, -2.6502e-01,  1.0303e+00,  7.1816e-01,\n",
      "        -8.2631e-01,  1.0186e+00,  1.8713e-01, -2.1244e-01,  6.9238e-01,\n",
      "         1.3426e+00,  6.3037e-01,  1.8479e-01,  2.4778e-01,  5.4646e-01,\n",
      "         8.6796e-01,  1.7417e-01,  1.0734e+00,  7.3591e-01,  7.7029e-01,\n",
      "        -4.9510e-01,  1.8144e+00,  1.4933e-01,  7.3650e-01, -2.7012e-02,\n",
      "         4.0419e-01,  9.1503e-01, -4.7974e-01,  5.7801e-02,  1.4686e+00,\n",
      "         1.7091e+00,  1.0702e+00,  8.6826e-01,  1.2602e+00,  6.2726e-02,\n",
      "         1.1277e+00, -1.9857e-01,  3.2054e-01,  8.1751e-01, -2.1471e-01,\n",
      "         4.3898e-01,  9.3483e-01, -3.4265e-01,  8.6144e-01,  1.1748e+00,\n",
      "         6.0712e-01,  3.3462e-01,  3.0883e-01,  5.1354e-01,  1.0697e+00,\n",
      "         4.4872e-01,  3.4813e-01,  1.3571e+00,  1.5576e+00,  1.6066e+00,\n",
      "        -6.7869e-02, -5.1936e-01,  1.2538e+00,  3.4660e-01, -4.8986e-01,\n",
      "        -2.4328e-01,  7.5662e-01,  9.8033e-01, -1.2517e-01, -2.1924e-01,\n",
      "         8.9318e-01,  1.5502e-01,  7.0553e-01,  1.6637e+00,  9.6538e-01,\n",
      "         1.1882e+00,  5.2288e-01, -9.0718e-01,  9.4834e-01,  4.7383e-02,\n",
      "        -2.2466e-01,  9.2440e-01,  9.6784e-01, -3.3624e-01, -6.4601e-01,\n",
      "         9.2875e-01, -7.9195e-01,  9.6185e-01,  5.8427e-01,  6.5606e-01,\n",
      "        -4.1795e-01,  8.6756e-01,  1.0541e+00, -5.2419e-01,  7.5242e-01,\n",
      "         6.2528e-01, -4.9128e-01,  6.1887e-01, -1.5991e-02,  3.5424e-01,\n",
      "         8.0004e-01, -6.3580e-01,  3.8488e-02,  1.4933e+00,  3.6820e-01,\n",
      "         1.2173e+00, -3.8963e-01,  9.2837e-01, -6.9406e-01, -4.5689e-01,\n",
      "         5.8659e-01,  1.5078e+00,  1.4843e+00,  1.1256e+00,  8.2746e-01,\n",
      "         7.9299e-01,  5.8675e-01,  6.5385e-01, -1.0806e-03, -2.6655e-01,\n",
      "         1.0982e+00,  8.4418e-01,  3.6408e-01,  9.5481e-01,  6.9597e-01,\n",
      "         1.1333e+00,  5.4626e-01,  3.2965e-01,  9.1331e-01,  1.3484e+00,\n",
      "        -2.8209e-01,  1.4299e+00,  8.3114e-01,  3.7499e-01,  6.3086e-01,\n",
      "        -1.8890e-01,  7.4780e-01,  1.4960e+00, -4.3545e-01,  2.1190e-01,\n",
      "         8.6951e-01, -5.9307e-01,  1.2389e+00,  1.4728e+00,  1.9451e+00,\n",
      "         4.2454e-01, -2.8954e-01,  7.3897e-01,  1.2030e+00,  2.2368e-01,\n",
      "        -7.6914e-01,  7.4880e-01, -3.2840e-01,  5.8753e-01,  2.4819e-01,\n",
      "         4.1465e-01, -2.2079e-01,  6.5140e-01,  5.9125e-01,  9.2191e-01,\n",
      "         5.1669e-01,  6.5277e-01,  2.2368e-01,  7.0785e-01, -1.5039e-01,\n",
      "         2.8533e-01, -5.7318e-01,  6.7383e-01, -2.8562e-01,  1.3210e+00,\n",
      "         6.1645e-01,  5.2922e-02,  5.8965e-01, -4.8662e-01, -7.3849e-01,\n",
      "        -4.9486e-01,  8.3809e-01,  1.0172e+00, -3.4701e-01, -4.8609e-01,\n",
      "         9.3829e-01,  1.0271e+00,  1.2099e+00, -5.0236e-01, -2.8767e-01,\n",
      "         9.3713e-01, -3.3681e-01,  9.8773e-01,  1.6540e-01, -2.5402e-01,\n",
      "         8.0813e-01,  1.0019e+00, -6.3556e-01,  1.1684e+00,  5.8391e-01,\n",
      "         3.2094e-01,  6.7856e-01,  6.8541e-01,  4.6012e-01,  1.1455e+00,\n",
      "        -3.6988e-01,  1.1742e+00,  4.9818e-03,  1.5108e+00, -3.5957e-01,\n",
      "         1.6059e+00, -3.5332e-01,  8.0881e-01,  3.1918e-01, -3.4024e-01,\n",
      "         7.4269e-01,  1.6485e+00, -4.5830e-02,  8.0336e-01, -5.4032e-01,\n",
      "         1.4019e+00,  2.0429e-01, -1.6675e-01,  8.3064e-01,  6.0409e-01,\n",
      "         1.1172e+00, -5.5054e-01,  7.5971e-01, -3.1314e-01,  8.5323e-01,\n",
      "         5.0303e-01,  1.2577e+00,  6.2648e-01,  8.4750e-01,  9.3830e-01,\n",
      "        -2.9923e-01,  5.8778e-01,  1.2476e+00,  7.2297e-01, -2.7729e-01,\n",
      "        -2.0859e-01,  1.1996e+00,  4.6036e-01,  4.0666e-01, -5.5204e-01,\n",
      "        -7.2305e-01,  3.7599e-01,  1.0469e+00,  7.7991e-01,  5.3834e-01,\n",
      "         6.1956e-01, -4.2741e-01,  8.3816e-01, -3.2953e-01,  8.4506e-01,\n",
      "         5.5464e-01, -6.8868e-02, -8.5479e-02,  8.9949e-01,  4.4865e-01,\n",
      "         1.7433e+00, -3.7633e-01, -3.7442e-01,  1.2695e+00,  2.4358e-01,\n",
      "         5.5310e-01,  8.0598e-01, -3.6847e-01,  6.6033e-01, -5.5211e-01,\n",
      "         7.0433e-01,  8.8169e-01, -4.1521e-01,  6.8280e-01,  5.9264e-01,\n",
      "        -1.5713e-01, -5.0204e-01,  6.9945e-01, -1.9312e-01,  2.9803e-01,\n",
      "        -4.4458e-01, -4.1599e-01,  4.2212e-01,  9.0707e-01,  8.5150e-01,\n",
      "         2.1017e-01,  8.0362e-01,  9.9326e-01,  4.7202e-01,  1.7229e+00,\n",
      "         7.4616e-01,  6.2136e-01,  8.6908e-01,  1.1182e+00,  4.9938e-01,\n",
      "        -2.6908e-02, -1.5557e-02, -6.6317e-01, -6.4987e-01, -8.8671e-01,\n",
      "        -1.1864e-03, -2.5247e-01,  4.1808e-01, -3.6549e-01,  2.8465e-01,\n",
      "         9.7208e-01,  4.6311e-01, -4.1518e-01,  1.0100e+00,  5.2811e-01,\n",
      "        -7.6507e-02,  6.1036e-01,  1.0882e+00,  5.5166e-01, -3.6744e-01,\n",
      "        -6.8023e-01,  3.0286e-01,  1.4827e+00,  6.0548e-01,  9.4746e-01,\n",
      "         5.6948e-01,  4.0547e-02,  8.6233e-01,  1.2704e+00, -3.5143e-01,\n",
      "         7.0586e-01,  9.8251e-01,  4.8877e-01,  3.4332e-01,  6.9438e-01,\n",
      "        -4.2655e-01,  8.2526e-01,  1.1928e-01, -6.8127e-01,  1.8565e-01,\n",
      "        -1.5191e-01,  7.4866e-01,  7.0256e-01,  3.8588e-01,  5.3929e-01,\n",
      "        -6.5787e-01,  7.6932e-01, -5.1370e-01, -6.6787e-01,  5.4493e-01,\n",
      "         5.3285e-01,  8.6704e-01,  1.0068e+00,  7.7774e-01,  5.1467e-01,\n",
      "         3.2489e-01,  1.9652e-01,  5.1140e-01,  8.7539e-01,  1.3376e+00,\n",
      "         4.7846e-01, -2.1368e-01,  1.1075e+00, -2.5504e-01,  1.1032e+00])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "q_weight: tensor([  17,   34,   10,  ...,   53, -110,  -37], dtype=torch.int32) q_bias: tensor([  5252, -29758,  -1006,   1605,   6672,  -1045,   1922,   3823,  -2546,\n",
      "          3887,   -363,    -47,  -2282,  -2075,    728,   3964,   -701,   5766,\n",
      "           565,  -3380,   1162,   1194,   6667,    937,  -2445,   9068,   3058,\n",
      "          -322,   2027,   4080,   9734,   3992,    628,   4596,    454,   1835,\n",
      "         -4235,   1716,   2546,    596,   -447,    468,   3901,  -4194,   6672,\n",
      "          -438,   5477,   4866,   3272,   1108,    901,   5170,   1680,   5545,\n",
      "            19,   2429,   6516,    355,   2684,   7287,   4476,   1360,   1489,\n",
      "         -2643,    447,   1389,   2344,    411,   3345,  -1205,   5311,    968,\n",
      "         -2793,   3140,   4937,  -3568,  -1434,   4941,   5610,  -1168,   4212,\n",
      "         -3486,   4325,   4797,   3247,  -3131,   3907,  -3083,    214,   3485,\n",
      "        -30142,   6742,  -3057,  -4634,   1865,   -722,   1368,  -1770,    294,\n",
      "         -3640,   3218,   1673,    693,  -1723,   3593,  -1784,   5394,   7077,\n",
      "         -2665,   3127,   1797,  11121,   1841,  -3629,   1614,    817,   7507,\n",
      "           837,  -1098,   5843,  10937,   8589,   9007,   -322,   1631,   -171,\n",
      "          1283,  -3042,   6087,   7813,   3123,   1292,  -1470,   4270,   3204,\n",
      "        -11782,   5099,    632,   -665,   1843,   8692,   1773,    366,    684,\n",
      "          3294,   4897,    388,   8010,   2873,   3319,  -1533,   5588,    505,\n",
      "          4573, -43073,   1481,   4324,  -1217,    216,  12235,   8358,   8446,\n",
      "          5251,   5851,    184,   7304, -20290,    737,   3761,   -628,    902,\n",
      "          4256,   -920,   5283,   5994,   1832,   1123,    761,   2555,   7086,\n",
      "          2067,   1415,   7117,  11859,   4311,   -212,  -2097,   4975,   1057,\n",
      "         -3045,   -808,   3181,   4791,   -334,   -621,   3544,    376,   4889,\n",
      "          5283,   7380,   6731,   1597,  -2582,   4007,    102,   -656,   5809,\n",
      "          5730,   -954,  -2686,   6562,  -5781,   5766,   3383,   3649,  -1785,\n",
      "          3947,   5242,  -2743,   4025,   2429,   -935,   2849, -25282,    711,\n",
      "          3527,  -3939,    138,   7731,   1154,   6395,  -1693,   3378,  -2351,\n",
      "         -2782,   2496,   6970,   5540,   7894,   3877,   4153,   4243,   3433,\n",
      "        -78073,   -730,   7508,   2776,   1155,   7581,   1933,   7966,   1204,\n",
      "           651,   6076,   4344,   -833,   9495,   4786,   1088,   2980,   -508,\n",
      "          3168,   6915,  -1587,    533,   5714,  -3096,   6938,  13577,  11018,\n",
      "           965,   -861,   2977,   4822,    512,  -3947,   3582,   -956,   2609,\n",
      "          1142,    885,  -8577,   1775,   3443,   3426,   1805,   2842,    904,\n",
      "          3678,   -484,   1398,  -2154,   4161,   -803,   4561,   1531,    155,\n",
      "          3627,  -1684,  -2931,  -1972,   5934,   4785,  -1006,   -891,   4771,\n",
      "          6490,   7024,  -3316,  -1174,   3958,  -1208,   4814,    390,   -721,\n",
      "          3816,   7344,  -1837,   7521,   2868,   1235,   2612,   2983,   1309,\n",
      "          7547,  -1072,   4165,     12,   5487,  -1429,   6113,   -677,   4457,\n",
      "           935,  -1034,   2652,   5784,   -128,   4661,  -2102,   4844,    462,\n",
      "          -555,   4740,   2186,   4922,  -1117,   3852,   -951,   3476,   1237,\n",
      "          6129,   2961,   1499,   4394,  -1266,   2900,   9889,   4541,   -651,\n",
      "          -384,   3638,   1514,   1057,  -2703,  -3334,    597,   8093,   2469,\n",
      "          1082,   1946,  -1156,   4513,  -2100,   4665,   3212,   -131,   -220,\n",
      "          4094,   1353,   9655,  -2400,  -1113,   5825,   1223,   2005,   4299,\n",
      "         -1545,   2021,  -2013,   3563,   5417,  -1333,   2748,   2504,   -668,\n",
      "         -1215,   3318,   -505,    538,  -1074,  -1779,   1701,   3558,   5953,\n",
      "           552,   2173,   5250,   1135,   6559,   2023,   1736,   1773,   4657,\n",
      "          2744,    -59, -27009,  -3709,  -1644,  -5792,     -3,   -650,   1901,\n",
      "          -920,    665,   7682,   1248,  -1714,   3481,   1135,   -170,   1556,\n",
      "          3877,   2353,  -1229,  -3697,    484,  11421,   1389,   2718,   1785,\n",
      "           115,   2014,   4265,   -717,   2000,   6443,   1555,   1530,   3748,\n",
      "         -1260,   3866,    230,  -2124,    526,   -558,   2791,   4001,   1583,\n",
      "          2347,  -4184,   3480, -62168,  -3347,   1866,   3133,   4611,   6716,\n",
      "          2411,    999,    804,    450,    865,   4264,   5589,   1771,   -413,\n",
      "          4780,   -600,   5366], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-9.7652e-07) tensor(0.0048)   bias tensor(-1.5372e-06) tensor(0.0003)\n",
      "features.15.conv.3.weight features.15.conv.5\n",
      "torch.Size([480, 1, 3, 3]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.1755]) torch.Size([1]) \n",
      "wscale= tensor([8.8433e-03, 5.0594e-03, 6.3443e-03, 7.2080e-03, 5.6317e-03, 6.4411e-03,\n",
      "        8.7082e-03, 7.6492e-03, 1.0802e-02, 7.1346e-03, 4.7124e-03, 3.4474e-03,\n",
      "        8.7845e-03, 9.9737e-03, 7.8564e-03, 5.9782e-03, 3.7765e-03, 1.2739e-02,\n",
      "        3.4905e-03, 5.9560e-02, 8.9201e-03, 7.6283e-03, 1.1778e-02, 6.2223e-03,\n",
      "        5.6407e-03, 1.5462e-02, 1.6818e-02, 2.6147e-03, 4.6265e-03, 7.7362e-03,\n",
      "        9.0149e-03, 4.5362e-03, 2.5748e-03, 1.0614e-02, 6.2629e-03, 1.2319e-02,\n",
      "        1.0242e-02, 5.6449e-03, 6.5929e-03, 7.5519e-03, 9.2053e-03, 2.8858e-03,\n",
      "        5.5026e-03, 1.5589e-02, 7.2843e-03, 5.8356e-03, 8.3354e-03, 8.9641e-03,\n",
      "        7.9092e-03, 9.6961e-03, 4.5831e-03, 7.7225e-03, 4.4186e-03, 1.7252e-02,\n",
      "        1.3707e-02, 1.1876e-02, 8.4608e-03, 4.9511e-03, 9.3407e-03, 1.9983e-02,\n",
      "        8.8856e-03, 5.2226e-03, 8.6183e-03, 1.0784e-02, 2.2639e-03, 8.0441e-03,\n",
      "        5.2499e-03, 3.2415e-03, 8.5191e-03, 4.9627e-03, 5.7947e-03, 6.0342e-03,\n",
      "        3.6860e-02, 9.0530e-03, 1.1984e-02, 1.0417e-02, 7.0234e-03, 1.2615e-02,\n",
      "        1.1251e-02, 1.1920e-02, 6.2644e-03, 6.7078e-03, 1.0641e-02, 1.0080e-02,\n",
      "        6.6521e-03, 1.2720e-02, 7.5072e-03, 1.0258e-02, 2.8429e-03, 5.8928e-03,\n",
      "        4.3425e-04, 6.2793e-03, 5.3781e-03, 1.1593e-02, 8.0711e-03, 3.4836e-03,\n",
      "        2.7289e-03, 3.4743e-03, 9.0114e-03, 1.2303e-02, 8.3762e-03, 1.0054e-02,\n",
      "        4.8905e-03, 7.7838e-03, 1.2548e-02, 1.4244e-02, 9.2658e-03, 9.6624e-03,\n",
      "        9.8273e-03, 3.8113e-03, 5.8395e-03, 1.4564e-02, 4.6031e-03, 1.0267e-02,\n",
      "        6.0300e-03, 4.9158e-03, 6.6710e-03, 2.8178e-03, 4.7591e-03, 9.1306e-03,\n",
      "        1.6500e-02, 9.4221e-03, 1.8673e-02, 2.4826e-03, 5.4889e-03, 1.9501e-03,\n",
      "        2.7415e-03, 4.1514e-02, 6.0969e-03, 7.9997e-03, 1.1620e-02, 4.6907e-03,\n",
      "        1.0046e-02, 1.2078e-02, 5.4632e-03, 7.6861e-01, 6.0671e-03, 8.2019e-03,\n",
      "        7.9880e-03, 4.6017e-03, 9.4201e-03, 6.2065e-03, 3.9830e-03, 3.3206e-03,\n",
      "        6.2767e-03, 7.6677e-03, 6.9790e-03, 6.5048e-03, 1.4107e-02, 9.7291e-03,\n",
      "        4.2335e-03, 1.4230e-02, 4.6925e-03, 9.4212e-03, 6.0455e-04, 5.7221e-03,\n",
      "        7.8895e-03, 3.3789e-03, 3.5356e-03, 1.1767e-02, 1.5016e-02, 1.1026e-02,\n",
      "        1.1039e-02, 9.2452e-03, 7.7667e-03, 1.2966e-02, 9.2502e-02, 3.3543e-03,\n",
      "        8.1812e-03, 2.8856e-03, 3.4807e-03, 1.1029e-02, 6.5905e-03, 7.1414e-03,\n",
      "        8.0898e-03, 6.0287e-03, 6.4318e-03, 2.1029e-03, 5.1320e-03, 9.4223e-03,\n",
      "        9.8827e-03, 5.7475e-03, 1.0484e-02, 1.3787e-02, 1.3020e-02, 5.7375e-03,\n",
      "        1.4417e-02, 1.3184e-02, 4.9582e-03, 1.2761e-01, 6.8798e-03, 7.6989e-03,\n",
      "        1.0614e-02, 8.7594e-03, 3.2953e-03, 5.1882e-03, 2.9245e-03, 6.3566e-03,\n",
      "        1.4522e-02, 7.7739e-03, 9.1285e-03, 1.2460e-02, 7.5595e-03, 9.4822e-03,\n",
      "        3.7875e-03, 1.8219e-03, 7.3961e-03, 5.0896e-03, 6.9687e-03, 1.7462e-02,\n",
      "        7.1338e-03, 1.6825e-02, 6.9472e-03, 5.5623e-03, 7.5371e-03, 4.2924e-03,\n",
      "        7.0300e-03, 8.4466e-03, 1.7367e-02, 1.1103e-02, 9.0275e-03, 6.4808e-03,\n",
      "        4.9234e-03, 5.1747e-04, 4.3647e-03, 1.1438e-02, 1.1981e-02, 1.0020e-02,\n",
      "        1.3739e-02, 5.1419e-03, 1.1168e-02, 5.8533e-03, 8.3782e-03, 6.5181e-03,\n",
      "        1.1069e-02, 1.4713e-02, 1.4554e-02, 1.2736e-02, 9.6571e-03, 1.0450e-02,\n",
      "        1.2516e-02, 7.1583e-03, 9.4351e-03, 9.9852e-07, 3.1913e-03, 1.0602e-02,\n",
      "        5.7238e-03, 9.4778e-03, 8.7723e-03, 1.0056e-02, 8.9403e-03, 7.5495e-03,\n",
      "        4.7479e-03, 9.9708e-03, 1.4742e-02, 1.1728e-02, 1.3201e-02, 1.0529e-02,\n",
      "        3.3845e-03, 1.1006e-02, 6.7642e-03, 4.0289e-03, 9.9781e-03, 5.4868e-03,\n",
      "        5.9327e-03, 6.9804e-03, 7.5941e-03, 7.7294e-03, 1.0791e-02, 9.7828e-03,\n",
      "        4.2973e-03, 5.9410e-03, 5.9575e-03, 1.1384e-02, 7.5898e-03, 3.1652e-02,\n",
      "        1.4665e-02, 1.0586e-02, 7.3810e-03, 5.8393e-03, 4.7482e-03, 6.9550e-02,\n",
      "        6.1205e-03, 7.4113e-03, 1.0916e-02, 8.0434e-03, 9.2251e-03, 7.9675e-03,\n",
      "        1.0378e-02, 6.6464e-03, 4.5528e-03, 4.9971e-03, 6.4074e-03, 9.8107e-03,\n",
      "        6.5449e-03, 4.6183e-03, 2.0397e-03, 8.7258e-03, 1.4576e-02, 1.5416e-02,\n",
      "        5.5472e-03, 7.1769e-03, 9.9979e-03, 3.7361e-03, 2.3668e-03, 9.6062e-03,\n",
      "        6.7466e-03, 1.1410e-02, 1.0896e-02, 9.4368e-03, 6.6065e-03, 1.0717e-02,\n",
      "        9.6325e-03, 3.4485e-03, 3.2424e-03, 9.5271e-03, 7.6838e-03, 3.7178e-03,\n",
      "        7.9359e-03, 6.1946e-03, 3.6901e-03, 5.0547e-03, 6.6536e-03, 3.4357e-03,\n",
      "        1.0252e-02, 5.7484e-03, 6.3568e-03, 4.7630e-03, 9.8327e-03, 7.3086e-03,\n",
      "        1.0147e-02, 2.6852e-03, 8.9350e-03, 8.2913e-03, 1.2589e-02, 9.3649e-03,\n",
      "        1.5602e-02, 5.3869e-03, 6.3679e-03, 8.7914e-03, 2.5423e-02, 9.3467e-03,\n",
      "        2.7642e-03, 9.2638e-03, 8.2147e-03, 5.5812e-03, 4.3365e-03, 6.1605e-03,\n",
      "        8.0255e-03, 1.0072e-02, 6.6718e-03, 1.4373e-02, 7.0976e-03, 6.0130e-03,\n",
      "        9.0443e-03, 7.8786e-03, 5.0698e-03, 1.2560e-02, 9.1578e-03, 4.9571e-03,\n",
      "        2.4907e-03, 8.1843e-03, 6.3978e-03, 5.2573e-03, 1.1172e-02, 2.5550e-02,\n",
      "        4.2059e-03, 1.4822e-02, 6.1995e-03, 3.3577e-03, 1.1931e-02, 3.6303e-02,\n",
      "        6.1282e-03, 4.7692e-02, 8.8310e-03, 6.6683e-03, 6.8221e-03, 6.8690e-03,\n",
      "        8.2839e-03, 6.1983e-03, 1.3127e-02, 3.8365e-02, 5.6476e-03, 4.6470e-03,\n",
      "        7.4866e-03, 7.2208e-03, 9.7329e-03, 7.8343e-03, 7.2964e-03, 1.8421e-02,\n",
      "        6.8180e-03, 8.3676e-03, 9.5964e-03, 1.3515e-02, 6.2640e-03, 1.1906e-02,\n",
      "        4.4992e-03, 5.8877e-03, 1.0680e-02, 5.9256e-03, 2.8042e-03, 9.5799e-03,\n",
      "        1.3318e-02, 7.4959e-03, 5.1099e-03, 6.5324e-03, 8.1194e-03, 7.2760e-03,\n",
      "        6.7876e-03, 1.1364e-02, 6.3724e-03, 6.0294e-03, 7.1397e-03, 7.5699e-03,\n",
      "        5.0701e-03, 8.9822e-03, 2.0480e-04, 1.2184e-02, 9.8248e-03, 3.3919e-02,\n",
      "        2.7959e-03, 6.9092e-03, 4.4439e-03, 6.2819e-03, 4.9290e-03, 8.4203e-03,\n",
      "        6.4141e-03, 5.4518e-03, 1.0559e-02, 4.5229e-03, 6.7546e-03, 8.4405e-03,\n",
      "        7.6457e-03, 5.4579e-03, 1.1054e-02, 2.3883e-02, 2.6679e-03, 1.4435e-02,\n",
      "        5.2127e-03, 8.5612e-03, 4.0044e-03, 1.0585e-02, 3.0795e-03, 9.6624e-03,\n",
      "        8.1665e-03, 7.3272e-03, 1.1126e-02, 8.6275e-03, 4.4725e-03, 6.7977e-03,\n",
      "        7.2143e-03, 6.1933e-03, 3.8109e-03, 1.3221e-02, 2.5154e-03, 3.7073e-03,\n",
      "        1.2168e-02, 6.7978e-03, 8.7844e-03, 3.5930e-03, 4.5364e-02, 7.7924e-03,\n",
      "        1.6142e-01, 3.7744e-02, 1.0444e-02, 9.2869e-03, 8.9650e-03, 9.6346e-03,\n",
      "        6.2686e-03, 3.5782e-03, 1.1408e-02, 5.3928e-03, 7.5092e-03, 5.7904e-03,\n",
      "        1.0650e-02, 1.0349e-02, 5.2532e-03, 1.0748e-02, 4.0537e-03, 9.6927e-03]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.0910]) torch.Size([1])\n",
      "###: M= tensor([1.7044e-02, 9.7510e-03, 1.2227e-02, 1.3892e-02, 1.0854e-02, 1.2414e-02,\n",
      "        1.6783e-02, 1.4742e-02, 2.0819e-02, 1.3751e-02, 9.0821e-03, 6.6442e-03,\n",
      "        1.6930e-02, 1.9222e-02, 1.5142e-02, 1.1522e-02, 7.2785e-03, 2.4551e-02,\n",
      "        6.7273e-03, 1.1479e-01, 1.7192e-02, 1.4702e-02, 2.2699e-02, 1.1992e-02,\n",
      "        1.0871e-02, 2.9800e-02, 3.2413e-02, 5.0392e-03, 8.9165e-03, 1.4910e-02,\n",
      "        1.7374e-02, 8.7426e-03, 4.9624e-03, 2.0456e-02, 1.2070e-02, 2.3742e-02,\n",
      "        1.9740e-02, 1.0879e-02, 1.2706e-02, 1.4555e-02, 1.7741e-02, 5.5617e-03,\n",
      "        1.0605e-02, 3.0044e-02, 1.4039e-02, 1.1247e-02, 1.6065e-02, 1.7276e-02,\n",
      "        1.5243e-02, 1.8687e-02, 8.8329e-03, 1.4884e-02, 8.5159e-03, 3.3250e-02,\n",
      "        2.6418e-02, 2.2889e-02, 1.6306e-02, 9.5422e-03, 1.8002e-02, 3.8514e-02,\n",
      "        1.7125e-02, 1.0065e-02, 1.6610e-02, 2.0783e-02, 4.3633e-03, 1.5503e-02,\n",
      "        1.0118e-02, 6.2472e-03, 1.6419e-02, 9.5645e-03, 1.1168e-02, 1.1630e-02,\n",
      "        7.1041e-02, 1.7448e-02, 2.3096e-02, 2.0076e-02, 1.3536e-02, 2.4313e-02,\n",
      "        2.1684e-02, 2.2973e-02, 1.2073e-02, 1.2928e-02, 2.0508e-02, 1.9427e-02,\n",
      "        1.2821e-02, 2.4514e-02, 1.4469e-02, 1.9771e-02, 5.4791e-03, 1.1357e-02,\n",
      "        8.3692e-04, 1.2102e-02, 1.0365e-02, 2.2344e-02, 1.5555e-02, 6.7140e-03,\n",
      "        5.2593e-03, 6.6959e-03, 1.7368e-02, 2.3712e-02, 1.6143e-02, 1.9378e-02,\n",
      "        9.4254e-03, 1.5002e-02, 2.4184e-02, 2.7453e-02, 1.7858e-02, 1.8622e-02,\n",
      "        1.8940e-02, 7.3455e-03, 1.1254e-02, 2.8068e-02, 8.8714e-03, 1.9787e-02,\n",
      "        1.1622e-02, 9.4742e-03, 1.2857e-02, 5.4307e-03, 9.1722e-03, 1.7597e-02,\n",
      "        3.1800e-02, 1.8159e-02, 3.5989e-02, 4.7847e-03, 1.0579e-02, 3.7584e-03,\n",
      "        5.2838e-03, 8.0010e-02, 1.1751e-02, 1.5418e-02, 2.2396e-02, 9.0403e-03,\n",
      "        1.9361e-02, 2.3277e-02, 1.0529e-02, 1.4813e+00, 1.1693e-02, 1.5807e-02,\n",
      "        1.5395e-02, 8.8688e-03, 1.8155e-02, 1.1962e-02, 7.6764e-03, 6.3998e-03,\n",
      "        1.2097e-02, 1.4778e-02, 1.3451e-02, 1.2537e-02, 2.7188e-02, 1.8751e-02,\n",
      "        8.1592e-03, 2.7425e-02, 9.0438e-03, 1.8157e-02, 1.1651e-03, 1.1028e-02,\n",
      "        1.5205e-02, 6.5121e-03, 6.8141e-03, 2.2679e-02, 2.8941e-02, 2.1251e-02,\n",
      "        2.1275e-02, 1.7818e-02, 1.4969e-02, 2.4989e-02, 1.7828e-01, 6.4648e-03,\n",
      "        1.5768e-02, 5.5614e-03, 6.7084e-03, 2.1256e-02, 1.2702e-02, 1.3764e-02,\n",
      "        1.5591e-02, 1.1619e-02, 1.2396e-02, 4.0530e-03, 9.8909e-03, 1.8159e-02,\n",
      "        1.9047e-02, 1.1077e-02, 2.0206e-02, 2.6571e-02, 2.5093e-02, 1.1058e-02,\n",
      "        2.7786e-02, 2.5409e-02, 9.5559e-03, 2.4595e-01, 1.3259e-02, 1.4838e-02,\n",
      "        2.0457e-02, 1.6882e-02, 6.3510e-03, 9.9992e-03, 5.6364e-03, 1.2251e-02,\n",
      "        2.7989e-02, 1.4982e-02, 1.7593e-02, 2.4014e-02, 1.4569e-02, 1.8275e-02,\n",
      "        7.2996e-03, 3.5114e-03, 1.4255e-02, 9.8092e-03, 1.3431e-02, 3.3654e-02,\n",
      "        1.3749e-02, 3.2426e-02, 1.3389e-02, 1.0720e-02, 1.4526e-02, 8.2726e-03,\n",
      "        1.3549e-02, 1.6279e-02, 3.3472e-02, 2.1399e-02, 1.7399e-02, 1.2490e-02,\n",
      "        9.4889e-03, 9.9731e-04, 8.4120e-03, 2.2044e-02, 2.3090e-02, 1.9312e-02,\n",
      "        2.6479e-02, 9.9099e-03, 2.1524e-02, 1.1281e-02, 1.6147e-02, 1.2562e-02,\n",
      "        2.1334e-02, 2.8356e-02, 2.8049e-02, 2.4546e-02, 1.8612e-02, 2.0140e-02,\n",
      "        2.4122e-02, 1.3796e-02, 1.8184e-02, 1.9244e-06, 6.1506e-03, 2.0433e-02,\n",
      "        1.1032e-02, 1.8266e-02, 1.6907e-02, 1.9381e-02, 1.7231e-02, 1.4550e-02,\n",
      "        9.1505e-03, 1.9217e-02, 2.8411e-02, 2.2603e-02, 2.5442e-02, 2.0293e-02,\n",
      "        6.5230e-03, 2.1211e-02, 1.3037e-02, 7.7648e-03, 1.9231e-02, 1.0575e-02,\n",
      "        1.1434e-02, 1.3453e-02, 1.4636e-02, 1.4897e-02, 2.0797e-02, 1.8854e-02,\n",
      "        8.2822e-03, 1.1450e-02, 1.1482e-02, 2.1941e-02, 1.4628e-02, 6.1003e-02,\n",
      "        2.8264e-02, 2.0401e-02, 1.4225e-02, 1.1254e-02, 9.1512e-03, 1.3404e-01,\n",
      "        1.1796e-02, 1.4284e-02, 2.1038e-02, 1.5502e-02, 1.7779e-02, 1.5356e-02,\n",
      "        2.0002e-02, 1.2809e-02, 8.7745e-03, 9.6309e-03, 1.2349e-02, 1.8908e-02,\n",
      "        1.2614e-02, 8.9008e-03, 3.9311e-03, 1.6817e-02, 2.8093e-02, 2.9712e-02,\n",
      "        1.0691e-02, 1.3832e-02, 1.9269e-02, 7.2006e-03, 4.5616e-03, 1.8514e-02,\n",
      "        1.3003e-02, 2.1990e-02, 2.0999e-02, 1.8187e-02, 1.2733e-02, 2.0655e-02,\n",
      "        1.8565e-02, 6.6462e-03, 6.2490e-03, 1.8362e-02, 1.4809e-02, 7.1653e-03,\n",
      "        1.5295e-02, 1.1939e-02, 7.1119e-03, 9.7420e-03, 1.2823e-02, 6.6217e-03,\n",
      "        1.9759e-02, 1.1079e-02, 1.2251e-02, 9.1797e-03, 1.8950e-02, 1.4086e-02,\n",
      "        1.9556e-02, 5.1751e-03, 1.7220e-02, 1.5980e-02, 2.4263e-02, 1.8049e-02,\n",
      "        3.0069e-02, 1.0382e-02, 1.2273e-02, 1.6944e-02, 4.8998e-02, 1.8014e-02,\n",
      "        5.3274e-03, 1.7854e-02, 1.5832e-02, 1.0757e-02, 8.3578e-03, 1.1873e-02,\n",
      "        1.5468e-02, 1.9412e-02, 1.2858e-02, 2.7702e-02, 1.3679e-02, 1.1589e-02,\n",
      "        1.7431e-02, 1.5184e-02, 9.7710e-03, 2.4207e-02, 1.7650e-02, 9.5538e-03,\n",
      "        4.8004e-03, 1.5773e-02, 1.2330e-02, 1.0132e-02, 2.1531e-02, 4.9242e-02,\n",
      "        8.1061e-03, 2.8565e-02, 1.1948e-02, 6.4712e-03, 2.2995e-02, 6.9966e-02,\n",
      "        1.1811e-02, 9.1917e-02, 1.7020e-02, 1.2852e-02, 1.3148e-02, 1.3239e-02,\n",
      "        1.5966e-02, 1.1946e-02, 2.5299e-02, 7.3940e-02, 1.0885e-02, 8.9561e-03,\n",
      "        1.4429e-02, 1.3917e-02, 1.8758e-02, 1.5099e-02, 1.4062e-02, 3.5502e-02,\n",
      "        1.3140e-02, 1.6127e-02, 1.8495e-02, 2.6047e-02, 1.2073e-02, 2.2946e-02,\n",
      "        8.6713e-03, 1.1347e-02, 2.0584e-02, 1.1420e-02, 5.4046e-03, 1.8463e-02,\n",
      "        2.5667e-02, 1.4447e-02, 9.8483e-03, 1.2590e-02, 1.5648e-02, 1.4023e-02,\n",
      "        1.3082e-02, 2.1901e-02, 1.2282e-02, 1.1620e-02, 1.3760e-02, 1.4589e-02,\n",
      "        9.7716e-03, 1.7311e-02, 3.9472e-04, 2.3481e-02, 1.8935e-02, 6.5371e-02,\n",
      "        5.3884e-03, 1.3316e-02, 8.5647e-03, 1.2107e-02, 9.4997e-03, 1.6228e-02,\n",
      "        1.2362e-02, 1.0507e-02, 2.0350e-02, 8.7170e-03, 1.3018e-02, 1.6267e-02,\n",
      "        1.4735e-02, 1.0519e-02, 2.1304e-02, 4.6030e-02, 5.1417e-03, 2.7820e-02,\n",
      "        1.0046e-02, 1.6500e-02, 7.7176e-03, 2.0400e-02, 5.9352e-03, 1.8622e-02,\n",
      "        1.5739e-02, 1.4122e-02, 2.1443e-02, 1.6628e-02, 8.6198e-03, 1.3101e-02,\n",
      "        1.3904e-02, 1.1936e-02, 7.3447e-03, 2.5481e-02, 4.8479e-03, 7.1450e-03,\n",
      "        2.3452e-02, 1.3101e-02, 1.6930e-02, 6.9248e-03, 8.7429e-02, 1.5018e-02,\n",
      "        3.1111e-01, 7.2744e-02, 2.0129e-02, 1.7899e-02, 1.7278e-02, 1.8569e-02,\n",
      "        1.2081e-02, 6.8963e-03, 2.1986e-02, 1.0393e-02, 1.4472e-02, 1.1160e-02,\n",
      "        2.0526e-02, 1.9946e-02, 1.0125e-02, 2.0714e-02, 7.8127e-03, 1.8681e-02])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "conv_weight: tensor([[[-0.4062, -0.2210, -0.3483],\n",
      "         [-0.2847, -0.0895, -0.2168],\n",
      "         [-0.6351, -0.5147, -0.6770]],\n",
      "\n",
      "        [[-0.2134,  0.1223, -0.1215],\n",
      "         [ 0.1564,  0.6425,  0.2293],\n",
      "         [-0.2109,  0.0927, -0.1287]],\n",
      "\n",
      "        [[ 0.2587,  0.2289,  0.2474],\n",
      "         [ 0.2283, -0.3453,  0.2282],\n",
      "         [ 0.1062,  0.1396,  0.0775]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0835, -0.0459,  0.1428],\n",
      "         [-0.1668, -0.3494,  0.5428],\n",
      "         [-0.1236, -0.0337,  0.0817]],\n",
      "\n",
      "        [[ 0.1265,  0.3319,  0.1469],\n",
      "         [ 0.0659,  0.0082,  0.0722],\n",
      "         [-0.0787, -0.0649, -0.0826]],\n",
      "\n",
      "        [[-0.0247, -0.0482,  0.0984],\n",
      "         [-0.3099, -0.3610,  0.6232],\n",
      "         [-0.2316, -0.0481,  0.2667]]]) conv_bias: tensor([ 2.1170e+00, -2.7428e-02, -8.8827e-01, -1.0182e+00,  1.5533e+00,\n",
      "         1.3053e+00,  1.3240e+00,  1.4441e+00,  1.2746e-01,  1.2782e+00,\n",
      "         1.6663e-01, -3.6484e-01, -8.5670e-01, -2.6556e-01,  7.0473e-03,\n",
      "        -3.8371e-02, -9.4291e-01,  8.8509e-01,  4.9938e-02, -1.0992e+00,\n",
      "         4.7448e-01, -1.0731e-01,  3.3927e-01,  9.0789e-01,  9.3097e-01,\n",
      "         8.0555e-01,  2.3336e+00,  8.2328e-01, -7.5593e-01, -9.7374e-02,\n",
      "         2.3008e+00, -1.1996e-01,  1.2881e+00,  1.4741e-03,  1.1414e+00,\n",
      "        -2.2655e-02,  1.4126e+00,  5.5387e-02, -3.4929e-01, -8.8214e-03,\n",
      "        -3.8179e-01,  9.4756e-01, -7.9060e-02, -1.7974e-02, -1.7446e-01,\n",
      "         3.9767e-02,  1.9502e+00,  1.6876e+00, -1.2875e-01, -4.2294e-02,\n",
      "         1.9098e-01,  1.7079e+00,  6.5514e-02,  2.9879e+00, -2.8483e-01,\n",
      "         1.8255e-01,  2.0367e+00, -4.6323e-01,  1.6378e+00,  2.0168e+00,\n",
      "        -7.4568e-02, -6.1342e-01,  2.2733e+00,  2.3786e+00,  9.9968e-01,\n",
      "        -1.0316e-01, -2.1176e-01,  1.1339e+00, -4.1608e-01, -1.1807e+00,\n",
      "        -3.2218e-01, -1.2368e+00, -9.0367e-01,  4.4356e-01,  1.7793e+00,\n",
      "        -8.1772e-01, -2.0346e-02,  1.1534e-01,  2.1323e+00, -5.5655e-01,\n",
      "         1.3098e+00,  1.7722e+00, -6.8141e-02,  3.7819e-01,  6.6010e-02,\n",
      "         3.5408e+00,  1.6299e+00,  3.4025e-02,  1.0335e+00, -3.3306e-01,\n",
      "        -2.8248e-03, -4.1569e-01,  1.4694e+00, -6.6086e-01, -7.3842e-01,\n",
      "        -1.8504e+00,  2.1147e+00,  8.2489e-01, -2.9079e-01, -4.7328e-02,\n",
      "        -6.7349e-02, -4.1509e-01,  7.2531e-01,  1.8152e+00,  7.6771e-03,\n",
      "        -5.4012e-02,  4.1963e-01, -4.3815e-02, -4.9335e-02,  1.3863e+00,\n",
      "         1.0452e+00,  3.2059e+00,  1.1371e+00,  3.9294e-02, -9.0985e-02,\n",
      "         1.0972e+00,  1.7276e+00,  8.7393e-01, -1.0988e-01, -2.6109e-01,\n",
      "         1.0262e+00, -1.2782e-01,  1.9203e+00, -1.8232e-01, -1.6287e-01,\n",
      "        -7.4579e-01,  1.0257e+00,  3.0709e-02, -1.1703e-01,  1.9119e+00,\n",
      "        -6.3393e-01, -1.6133e+00,  3.1841e-02,  1.6613e+00,  1.3123e+00,\n",
      "        -6.5754e-01, -3.7018e-01, -5.5120e-01, -1.0474e+00, -1.1095e+00,\n",
      "        -7.1715e-02, -8.8951e-01, -1.3517e+00,  2.6051e+00, -1.2348e-01,\n",
      "         1.8922e+00,  1.1346e-01,  2.0396e+00, -1.8693e-02,  2.0191e+00,\n",
      "        -5.7332e-01,  2.5510e+00,  1.2191e+00, -2.5415e-01, -2.2833e-02,\n",
      "         8.8439e-01, -9.6532e-02,  6.9570e-02,  3.8671e-02,  9.1838e-01,\n",
      "         4.6943e-01,  2.0623e+00,  1.6136e+00, -2.4205e-01, -8.3441e-01,\n",
      "         5.6281e-01, -5.1714e-01,  1.1280e+00,  3.8957e-02,  1.0277e+00,\n",
      "        -5.0498e-01, -2.2031e-01, -1.0896e+00, -5.7423e-02, -2.7584e-01,\n",
      "         1.0248e-01,  1.4797e-01,  1.2832e+00,  1.2514e+00,  1.8426e-01,\n",
      "        -1.2673e-02,  1.2536e+00,  7.3852e-01,  2.8443e+00,  2.5594e+00,\n",
      "        -7.2963e-01,  1.8872e+00,  9.4798e-01,  1.8983e+00, -5.5564e-01,\n",
      "         1.2979e+00, -3.7907e-02,  1.1895e+00, -4.6873e-01, -3.7162e-02,\n",
      "         1.2041e+00,  1.1511e+00,  1.5034e+00,  1.8790e+00,  2.2871e+00,\n",
      "        -8.9484e-01,  7.7230e-02, -2.8861e-01,  1.7721e+00, -3.5531e-01,\n",
      "         9.7441e-01, -1.5309e-01,  2.2861e+00, -7.7057e-01, -2.1036e-01,\n",
      "        -1.5298e-01,  2.3545e+00,  1.9248e+00, -2.4545e-01,  1.4329e+00,\n",
      "        -6.7621e-01,  3.3407e-02,  1.3857e-01, -8.2775e-02, -9.1492e-02,\n",
      "        -7.0945e-02, -5.5982e-01,  1.2918e+00, -1.3927e-02, -2.1296e-01,\n",
      "        -1.0894e+00,  3.2322e-01, -9.8987e-01,  4.1056e-01,  1.1193e+00,\n",
      "         5.3966e-01,  1.0065e+00, -1.5370e+00,  1.2985e-02,  1.2086e+00,\n",
      "         1.0432e-01,  1.1745e+00,  1.1019e+00, -1.2443e-01,  4.5171e-01,\n",
      "        -1.7303e-01,  1.3961e+00,  1.4764e+00, -2.4882e-04,  7.6012e-01,\n",
      "         9.0087e-01,  4.8688e-01, -5.9516e-01,  2.7238e+00, -2.1976e-01,\n",
      "         1.7939e+00,  1.3277e+00,  2.3324e+00, -4.4518e-01,  1.8883e+00,\n",
      "        -2.8072e-01,  1.8193e+00, -1.4974e-01,  1.0530e+00, -5.3346e-02,\n",
      "        -6.3692e-01,  1.0222e+00,  2.2367e+00,  7.8387e-01, -5.1767e-01,\n",
      "         1.7026e+00, -3.3411e-01,  9.9561e-02,  2.6194e+00, -2.2863e-01,\n",
      "         1.2995e+00,  2.7035e-03, -9.2894e-01,  5.6206e-01, -1.1015e+00,\n",
      "        -2.8994e-02, -6.0842e-01, -8.9356e-01, -7.4006e-01, -3.3620e-01,\n",
      "        -9.7575e-01, -1.7754e-01,  1.0576e+00,  3.9844e-02,  1.2578e+00,\n",
      "         1.2695e-01, -1.1788e-01,  3.1333e-02, -3.1867e-02, -2.1041e-02,\n",
      "         1.0011e+00, -9.7688e-01, -2.2008e-01, -1.7932e-01,  1.3927e+00,\n",
      "        -1.2981e-01,  1.0161e+00, -3.0990e-01, -7.3239e-01, -1.7017e-03,\n",
      "        -1.0124e-01, -2.7449e-01,  8.2332e-01, -3.8198e-02,  2.4243e+00,\n",
      "         8.2203e-02, -9.3617e-02,  1.8425e+00, -1.9103e-02,  1.0870e+00,\n",
      "         4.3977e-03, -1.2033e+00, -6.3286e-02, -1.2467e+00,  1.0076e+00,\n",
      "         8.6184e-03,  2.1905e+00,  1.0788e-01, -8.5422e-02,  9.4945e-01,\n",
      "         8.9669e-01,  9.7011e-01,  2.5384e-02,  2.8752e-01, -2.8040e-01,\n",
      "        -9.0533e-01,  1.2335e-01,  8.7081e-01,  2.0212e+00,  1.2149e+00,\n",
      "         5.0783e-02,  4.2942e-01, -1.4046e-03, -3.6247e-02, -1.8278e+00,\n",
      "        -1.7761e-01,  1.9761e+00,  8.3399e-01, -1.6508e-01, -1.1762e+00,\n",
      "         6.4459e-01, -2.3390e-01,  1.1030e+00,  1.7849e+00, -8.9095e-01,\n",
      "         3.9738e-01,  1.4474e+00,  1.6584e+00, -9.5488e-01,  1.2708e+00,\n",
      "         1.7745e+00, -3.5023e-01, -6.1703e-01, -1.1686e+00,  5.9105e-01,\n",
      "        -7.4528e-01,  9.6011e-01, -2.5912e-01, -1.9477e-01, -1.8179e+00,\n",
      "        -6.0058e-01, -3.4319e-01, -2.3177e-01, -1.6719e-01, -7.0738e-01,\n",
      "         1.2480e+00, -8.1544e-01,  1.4701e+00, -1.2764e+00, -4.5137e-01,\n",
      "         1.9924e-01, -7.3717e-01,  1.4520e+00, -4.0158e-01,  8.4727e-02,\n",
      "         1.5206e+00, -1.7000e-01, -8.7264e-02, -3.6219e-02,  1.0348e+00,\n",
      "         1.2113e+00, -5.6336e-01, -2.5465e-02,  5.4361e-02, -1.3694e-01,\n",
      "        -2.3268e-01,  1.0649e+00, -1.3678e-01, -1.0404e+00, -5.6608e-01,\n",
      "        -2.1749e-01, -2.4468e-01, -3.7303e-01, -8.3038e-01,  1.3089e+00,\n",
      "        -1.9305e-01, -7.4281e-01,  7.7055e-01, -1.1152e-01, -6.6928e-01,\n",
      "        -4.1883e-01, -5.1707e-05,  3.6002e-01, -3.0687e-02,  1.6151e+00,\n",
      "        -1.1041e+00, -1.0126e-01, -2.3568e-01,  8.7413e-01,  7.5914e-01,\n",
      "        -1.0465e+00, -1.7086e+00, -1.1818e+00, -3.6530e-01,  1.1831e+00,\n",
      "        -6.5579e-01, -3.8185e-03,  2.7565e-02,  4.5402e-02,  2.4985e+00,\n",
      "         1.2554e+00, -7.2318e-01,  1.0708e+00, -8.9962e-02,  1.0161e+00,\n",
      "         1.9763e+00,  2.6790e-02,  8.8914e-01,  3.1051e-01,  6.0748e-02,\n",
      "        -7.7748e-01,  8.1906e-01, -5.9184e-01,  1.3444e-01,  3.2179e-02,\n",
      "         2.7240e+00, -1.2696e+00, -7.2334e-01,  1.8519e+00, -1.7546e+00,\n",
      "         9.2434e-01, -2.5786e-01,  1.4843e+00, -7.4527e-01, -1.1043e+00,\n",
      "         3.6353e-01,  1.5796e+00, -7.9413e-01,  1.2338e+00, -1.5036e-01,\n",
      "         1.6974e-01,  1.4964e+00, -9.4478e-01, -6.4532e-01, -1.5480e+00,\n",
      "         1.5552e+00, -4.5290e-01, -8.2249e-02, -2.4369e-01,  9.9957e-01,\n",
      "         1.4865e-03, -5.7152e-02, -3.4436e-01, -7.0447e-02,  2.1391e+00,\n",
      "         3.2511e-01,  1.9569e+00,  1.1843e+00, -6.6071e-01, -1.0953e+00,\n",
      "         2.1505e+00, -1.7799e-01,  1.7554e+00,  1.4245e+00,  5.7115e-01,\n",
      "         8.2427e-03, -7.7428e-01,  6.3546e-04, -2.0343e-01, -2.3903e-02])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "q_weight: tensor([-46, -25, -39,  ..., -24,  -5,  28], dtype=torch.int32) q_bias: tensor([ 1364,   -31,  -798,  -805,  1572,  1155,   866,  1076,    67,  1021,\n",
      "          202,  -603,  -556,  -152,     5,   -37, -1423,   396,    82,  -105,\n",
      "          303,   -80,   164,   832,   941,   297,   791,  1794,  -931,   -72,\n",
      "         1454,  -151,  2851,     1,  1039,   -10,   786,    56,  -302,    -7,\n",
      "         -236,  1871,   -82,    -7,  -136,    39,  1333,  1073,   -93,   -25,\n",
      "          237,  1260,    84,   987,  -118,    88,  1372,  -533,   999,   575,\n",
      "          -48,  -669,  1503,  1257,  2516,   -73,  -230,  1994,  -278, -1356,\n",
      "         -317, -1168,  -140,   279,   846,  -447,   -17,    52,  1080,  -266,\n",
      "         1192,  1506,   -36,   214,    57,  1586,  1237,    19,  2072,  -322,\n",
      "          -37,  -377,  1557,  -325,  -521, -3027,  4416,  1353,  -184,   -22,\n",
      "          -46,  -235,   845,  1329,     3,   -22,   258,   -26,   -29,  2073,\n",
      "         1020,  1254,  1408,    22,   -86,  1272,  1476,  1767,  -132,  -163,\n",
      "          354,   -77,   586,  -419,  -169, -2179,  2132,     4,  -109,  1362,\n",
      "         -311, -1960,    18,   784,  1369,    -5,  -348,  -383,  -747, -1374,\n",
      "          -43,  -817, -1934,  4471,  -112,  1406,    93,  1787,    -8,  1183,\n",
      "         -772,  1022,  1481,  -154,  -215,   881,   -70,   117,    62,   445,\n",
      "          178,  1066,   833,  -149,  -612,   247,   -32,  1916,    27,  2030,\n",
      "         -827,  -114,  -942,   -46,  -194,    97,   131,  3477,  1390,   111,\n",
      "           -7,  1243,   401,  1176,  1120,  -725,   746,   410,  2182,   -25,\n",
      "         1075,   -28,   639,  -305,   -64,  1323,  2243,  1348,   737,  1677,\n",
      "         -559,    35,  -218,  1065,  -535,  3048,  -118,  2560,  -630,   -69,\n",
      "         -122,   798,  1579,  -251,  1083,  -898,    27,    93,   -27,   -47,\n",
      "          -45,  -492,  1495,  -153,  -278,  -543,   154,  -563,   170,  1241,\n",
      "          275,   980, -1045,    11,   622,    40,   460,   493,   -73,   246,\n",
      "          -79,  1111,   892, -1420,  1357,   484,   485,  -358,  1769,  -125,\n",
      "         1143,  1002,  2800,  -254,   730,  -136,   785,   -81,  1773,   -28,\n",
      "         -537,  1446,  1277,   814,  -497,  1390,  -251,    73,  1383,  -133,\n",
      "         1723,     3,  -889,   281,  -827,    -5,  -236,  -481,  -571,  -328,\n",
      "        -1171,   -15,   985,    31,   657,    90,   -73,    22,   -17,   -18,\n",
      "         1253, -1114,  -196,  -104,  1213,  -160,  2839,  -202,  -286,    -1,\n",
      "         -104,  -218,   469,   -58,  5837,    49,   -79,   920,   -10,   656,\n",
      "            4,  -640,   -37, -2060,  1771,     5,  1625,   165,   -61,   873,\n",
      "         1385,  1094,    22,   477,  -156,  -898,   111,  1042,  1171,   947,\n",
      "           29,   911,    -1,   -25,  -827,  -108,   722,   882,  -148,  -762,\n",
      "          144,  -143,  2274,  1098,  -618,   406,  1902,  1534,  -678,   719,\n",
      "         1516,  -139,  -495, -1108,   372,  -539,  1079,  -118,  -121, -2090,\n",
      "        -1374,  -239,  -206,  -181,  -361,   278, -1105,   565, -1173,  -766,\n",
      "           95,  -116,  1350,   -48,    55,  1300,  -142,   -72,   -25,   951,\n",
      "          526,   -84,   -26,    67,  -104,  -184,   624,   -99,  -813,  -175,\n",
      "         -182,  -167,  -222,  -350,  1191,   -92,  -941,   746,   -60,  -644,\n",
      "         -851,     0,   154,   -23,  1801,  -963,   -71,  -185,   734,   381,\n",
      "         -936, -1615,  -943,  -275,  1330,  -416,  -106,    13,    26,   420,\n",
      "         2559,  -596,  1373,   -82,  1175,  1338,    24,   929,   168,    77,\n",
      "         -656,   553,  -441,   140,    17,   650, -2712,  -286,  2025, -1168,\n",
      "         1315,  -139,  2747,  -440,  -771,   283,   809,  -525,  1572,  -126,\n",
      "          134,  1377, -1413,  -278, -3507,  2391,  -212,   -69,  -158,  1585,\n",
      "            0,   -42,   -12,   -11,  1167,   200,  1244,   700,  -601, -1744,\n",
      "         1074,  -188,  1332,  1402,   306,     5,  -840,     0,  -286,   -14],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0003) tensor(0.3347)   bias tensor(9.0623e-05) tensor(0.0168)\n",
      "features.15.conv.6.weight features.15.conv.8\n",
      "torch.Size([80, 480, 1, 1]) conv_bias= torch.Size([80]) \n",
      "ascale= tensor([0.0797]) torch.Size([1]) \n",
      "wscale= tensor([0.0027, 0.0027, 0.0027, 0.0022, 0.0022, 0.0020, 0.0024, 0.0026, 0.0023,\n",
      "        0.0023, 0.0019, 0.0026, 0.0021, 0.0027, 0.0027, 0.0023, 0.0018, 0.0028,\n",
      "        0.0025, 0.0039, 0.0023, 0.0024, 0.0029, 0.0024, 0.0021, 0.0025, 0.0028,\n",
      "        0.0023, 0.0023, 0.0026, 0.0024, 0.0024, 0.0022, 0.0021, 0.0022, 0.0022,\n",
      "        0.0024, 0.0022, 0.0025, 0.0028, 0.0020, 0.0025, 0.0031, 0.0021, 0.0020,\n",
      "        0.0023, 0.0029, 0.0026, 0.0024, 0.0027, 0.0019, 0.0027, 0.0023, 0.0038,\n",
      "        0.0035, 0.0022, 0.0015, 0.0024, 0.0020, 0.0022, 0.0023, 0.0023, 0.0021,\n",
      "        0.0022, 0.0027, 0.0022, 0.0028, 0.0023, 0.0019, 0.0025, 0.0013, 0.0026,\n",
      "        0.0021, 0.0020, 0.0023, 0.0025, 0.0024, 0.0027, 0.0021, 0.0018]) torch.Size([80, 1, 1, 1]) \n",
      "oscale= tensor([0.0697]) torch.Size([1])\n",
      "###: M= tensor([0.0031, 0.0031, 0.0031, 0.0025, 0.0025, 0.0023, 0.0028, 0.0030, 0.0026,\n",
      "        0.0026, 0.0022, 0.0030, 0.0024, 0.0031, 0.0030, 0.0026, 0.0020, 0.0033,\n",
      "        0.0029, 0.0045, 0.0026, 0.0028, 0.0034, 0.0027, 0.0025, 0.0029, 0.0032,\n",
      "        0.0026, 0.0026, 0.0029, 0.0027, 0.0028, 0.0025, 0.0024, 0.0025, 0.0025,\n",
      "        0.0027, 0.0025, 0.0028, 0.0032, 0.0023, 0.0028, 0.0035, 0.0024, 0.0023,\n",
      "        0.0027, 0.0033, 0.0029, 0.0028, 0.0031, 0.0022, 0.0030, 0.0026, 0.0044,\n",
      "        0.0040, 0.0025, 0.0017, 0.0027, 0.0023, 0.0025, 0.0026, 0.0026, 0.0024,\n",
      "        0.0026, 0.0031, 0.0026, 0.0032, 0.0027, 0.0022, 0.0028, 0.0015, 0.0029,\n",
      "        0.0024, 0.0023, 0.0026, 0.0029, 0.0028, 0.0031, 0.0024, 0.0020])\n",
      "torch.Size([80, 480, 1, 1]) torch.Size([80])\n",
      "conv_weight: tensor([[ 0.1047, -0.0053, -0.0002,  ...,  0.0393, -0.0832,  0.0085],\n",
      "        [-0.0635,  0.0014,  0.0154,  ...,  0.0762, -0.1542, -0.0663],\n",
      "        [-0.0092,  0.0036,  0.0756,  ...,  0.0188, -0.0257, -0.0255],\n",
      "        ...,\n",
      "        [ 0.0011, -0.0002,  0.0443,  ...,  0.1190,  0.0435,  0.0371],\n",
      "        [-0.0478,  0.0013,  0.0888,  ..., -0.0418, -0.0942, -0.0588],\n",
      "        [ 0.0302,  0.0025,  0.1085,  ...,  0.1129, -0.0168,  0.0674]]) conv_bias: tensor([ 0.0732,  1.3961,  0.2604,  0.1227,  0.2735,  1.3339,  1.7660,  1.2404,\n",
      "         2.2348, -1.2367, -1.2645, -0.0398, -0.0808, -0.8507, -2.2392,  2.8921,\n",
      "         0.2834,  0.1535, -0.2790, -1.0980, -0.7936,  0.6941,  1.4443, -1.3238,\n",
      "         0.1080, -0.2271,  0.5479,  0.1153,  0.4615,  0.9074,  2.3374, -1.6553,\n",
      "         0.5993, -1.2259, -2.1704,  0.0459, -0.9447,  0.0914,  0.6165, -2.1033,\n",
      "         0.3190, -0.8467, -1.4304, -1.7776, -1.3204, -1.5690, -1.5919, -0.2949,\n",
      "         1.3343,  0.3125, -0.1257, -1.4688,  0.0309, -0.4541, -1.3819, -0.4065,\n",
      "         0.8735,  1.1692,  1.3378, -1.9090,  0.0164, -1.1866,  0.8889, -1.4159,\n",
      "         0.0716,  2.0043, -0.2989, -1.6232,  1.0641, -0.7258, -0.7976, -0.6532,\n",
      "        -0.8791, -0.0213, -0.7590,  0.6623, -4.6875,  0.9420, -0.4991, -1.2432])\n",
      "torch.Size([80, 480, 1, 1]) torch.Size([80])\n",
      "q_weight: tensor([38, -2,  0,  ..., 63, -9, 38], dtype=torch.int32) q_bias: tensor([   335,   6560,   1222,    700,   1560,   8302,   9106,   5953,  12105,\n",
      "         -6797,  -8377,   -192,   -480,  -3898, -10539,  15939,   1995,    677,\n",
      "         -1372,  -3499,  -4324,   3562,   6165,  -7061,    632,  -1137,   2495,\n",
      "           642,   2541,   4416,  12260,  -8566,   3417,  -7237, -12483,    260,\n",
      "         -4993,    516,   3152,  -9450,   1958,  -4282,  -5817, -10427,  -8209,\n",
      "         -8433,  -6832,  -1439,   6832,   1466,   -817,  -6930,    170,  -1496,\n",
      "         -4982,  -2341,   7211,   6101,   8421, -10889,     91,  -6586,   5230,\n",
      "         -7921,    332,  11197,  -1353,  -8770,   7036,  -3704,  -7463,  -3193,\n",
      "         -5310,   -134,  -4182,   3305, -24111,   4353,  -2942,  -8708],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(6.8063e-06) tensor(0.0020)   bias tensor(-1.1781e-06) tensor(0.0001)\n",
      "features.16.conv.0.weight features.16.conv.2\n",
      "torch.Size([480, 80, 1, 1]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.0697]) torch.Size([1]) \n",
      "wscale= tensor([9.1197e-04, 1.2596e-03, 2.2146e-03, 1.3994e-03, 4.0710e-03, 3.1161e-03,\n",
      "        2.1627e-03, 1.9721e-03, 2.3552e-03, 4.2718e-03, 1.4939e-03, 1.8455e-03,\n",
      "        1.4789e-03, 9.8757e-04, 2.3289e-03, 1.4241e-03, 1.3232e-03, 3.2474e-03,\n",
      "        3.5331e-03, 2.1406e-03, 1.6271e-03, 2.3468e-03, 2.0394e-03, 1.2546e-03,\n",
      "        2.6870e-03, 1.1135e-03, 1.7309e-03, 1.6233e-03, 1.7113e-03, 1.0017e-03,\n",
      "        2.3934e-03, 1.2617e-03, 2.3860e-03, 1.5032e-03, 1.7173e-03, 1.5202e-03,\n",
      "        1.2693e-03, 1.3633e-03, 1.9642e-03, 2.2717e-03, 2.3932e-03, 1.2452e-03,\n",
      "        1.1290e-03, 3.2609e-03, 1.4255e-03, 1.0643e-03, 3.3538e-03, 2.3769e-06,\n",
      "        1.7082e-03, 1.7042e-03, 4.0441e-03, 2.4507e-03, 4.3780e-03, 2.1288e-03,\n",
      "        1.8526e-03, 3.0823e-03, 2.1832e-03, 2.2832e-03, 3.7232e-03, 9.9117e-04,\n",
      "        1.2990e-03, 3.6576e-03, 4.6230e-03, 1.8012e-03, 2.4656e-03, 2.8982e-03,\n",
      "        1.0482e-03, 1.5240e-03, 1.2917e-03, 1.7416e-03, 2.0426e-03, 2.0198e-03,\n",
      "        1.5030e-03, 2.6959e-03, 1.3140e-03, 1.1432e-03, 1.5074e-03, 3.5911e-03,\n",
      "        1.2159e-03, 1.1677e-03, 1.2413e-03, 3.8498e-07, 3.0770e-03, 3.0557e-03,\n",
      "        2.2615e-03, 1.1937e-03, 1.4731e-03, 1.6483e-03, 1.8386e-03, 1.5506e-03,\n",
      "        1.5943e-03, 1.9172e-03, 2.9493e-03, 1.6234e-03, 1.3203e-03, 1.7193e-03,\n",
      "        1.6372e-03, 1.2949e-03, 1.3726e-03, 8.6968e-07, 2.7213e-03, 1.3322e-03,\n",
      "        2.3686e-03, 1.0553e-03, 2.1368e-03, 3.1638e-03, 2.7696e-03, 2.4209e-03,\n",
      "        2.8976e-03, 1.1921e-07, 2.9663e-03, 1.9901e-03, 2.2046e-03, 1.3501e-03,\n",
      "        2.0461e-03, 1.3932e-03, 1.0265e-03, 1.5673e-03, 1.6484e-03, 3.4328e-03,\n",
      "        9.2725e-04, 1.2697e-03, 1.1668e-03, 4.1626e-03, 3.7187e-03, 3.6650e-03,\n",
      "        3.7281e-03, 9.0670e-04, 1.3918e-03, 1.8732e-03, 2.3414e-03, 2.3256e-03,\n",
      "        1.6187e-03, 1.2006e-03, 1.9016e-03, 2.1719e-03, 9.5164e-04, 2.2669e-03,\n",
      "        2.4637e-03, 1.2213e-03, 2.3874e-03, 2.3708e-03, 1.8610e-03, 1.3743e-03,\n",
      "        1.3574e-03, 1.4309e-03, 1.4101e-03, 3.7715e-03, 2.0748e-03, 2.4678e-03,\n",
      "        2.9771e-03, 3.9050e-03, 3.1180e-03, 1.7562e-03, 1.1181e-03, 1.4136e-03,\n",
      "        3.2392e-03, 1.1763e-03, 3.9001e-03, 1.4902e-03, 1.0907e-03, 3.2208e-03,\n",
      "        1.9808e-03, 4.3550e-03, 3.4247e-03, 2.9028e-03, 1.7005e-03, 1.4262e-03,\n",
      "        3.9176e-03, 1.6601e-03, 1.2818e-03, 1.4382e-03, 1.8115e-03, 2.7784e-03,\n",
      "        1.5005e-03, 2.0489e-03, 4.4193e-03, 3.7010e-03, 3.5594e-03, 4.0523e-03,\n",
      "        1.7334e-03, 3.1613e-03, 1.5314e-03, 1.0027e-03, 2.7991e-03, 1.4622e-03,\n",
      "        3.5822e-03, 2.4313e-03, 2.1543e-03, 1.1419e-03, 2.1901e-03, 9.7332e-04,\n",
      "        1.2375e-03, 1.7364e-03, 3.2166e-03, 3.0289e-03, 1.5608e-03, 2.9820e-03,\n",
      "        2.3847e-03, 1.3587e-03, 2.8518e-03, 3.2263e-03, 3.8706e-03, 1.9409e-03,\n",
      "        9.2835e-04, 2.7578e-03, 2.8717e-03, 1.2799e-03, 1.3215e-03, 1.0405e-03,\n",
      "        4.3241e-03, 1.1733e-03, 9.8689e-04, 2.9987e-03, 2.9465e-03, 4.3016e-03,\n",
      "        1.5963e-03, 4.0195e-03, 1.4215e-03, 1.1303e-03, 3.2016e-03, 3.0915e-03,\n",
      "        4.6648e-06, 1.7180e-03, 2.6451e-03, 2.9772e-03, 2.2816e-03, 3.1687e-03,\n",
      "        1.6945e-03, 2.1340e-03, 2.4588e-03, 1.2897e-03, 2.2424e-03, 1.3631e-03,\n",
      "        2.3214e-03, 8.4726e-04, 1.3044e-03, 4.1894e-03, 2.1166e-03, 8.7936e-04,\n",
      "        1.1830e-03, 1.1434e-03, 3.9361e-03, 1.1358e-03, 2.9407e-03, 1.2080e-03,\n",
      "        1.1506e-03, 1.6960e-03, 4.7112e-03, 1.2015e-03, 2.3688e-03, 1.4171e-03,\n",
      "        3.5130e-03, 1.0731e-03, 1.6354e-03, 1.5362e-03, 1.1170e-03, 3.6651e-03,\n",
      "        1.4530e-03, 2.6517e-03, 1.2509e-03, 1.4024e-03, 1.6713e-03, 3.2918e-03,\n",
      "        1.9416e-03, 2.0664e-03, 1.4672e-03, 2.3351e-03, 1.5316e-03, 2.8867e-03,\n",
      "        1.2907e-03, 1.4378e-03, 1.2970e-03, 2.8136e-03, 2.9126e-03, 2.2529e-03,\n",
      "        1.9188e-03, 9.3766e-04, 4.4344e-03, 1.2403e-03, 3.0146e-03, 1.4837e-03,\n",
      "        2.1236e-03, 1.4933e-03, 1.4099e-03, 2.2385e-03, 1.7334e-03, 4.1810e-03,\n",
      "        2.0964e-03, 1.1045e-03, 2.5277e-03, 1.2161e-03, 1.3102e-03, 1.6313e-03,\n",
      "        1.7045e-03, 2.1669e-03, 1.3177e-03, 1.5019e-03, 9.7932e-04, 2.7363e-03,\n",
      "        3.6531e-03, 1.4643e-03, 2.1690e-03, 2.9049e-06, 2.6592e-03, 3.2640e-03,\n",
      "        4.1661e-03, 3.3878e-03, 1.9686e-03, 1.2812e-03, 2.8807e-03, 1.3138e-03,\n",
      "        1.8005e-06, 4.1332e-03, 2.0425e-03, 1.2494e-03, 1.7685e-03, 1.6326e-03,\n",
      "        1.4048e-03, 1.5997e-07, 9.9902e-04, 1.5334e-03, 2.3060e-03, 2.6311e-03,\n",
      "        3.4008e-03, 1.3501e-03, 1.2215e-03, 1.9556e-03, 1.4035e-03, 3.8286e-03,\n",
      "        2.0094e-03, 2.1205e-03, 1.9692e-03, 8.6143e-04, 1.8587e-03, 7.3009e-04,\n",
      "        1.5127e-03, 2.0672e-03, 3.6516e-03, 3.9452e-03, 2.1220e-03, 1.0029e-03,\n",
      "        1.7635e-03, 8.7111e-04, 1.8296e-03, 1.0456e-03, 3.5857e-03, 1.8071e-03,\n",
      "        1.6337e-03, 2.6147e-03, 1.0463e-03, 1.1336e-03, 3.2655e-03, 1.8642e-03,\n",
      "        1.1025e-03, 1.7674e-03, 1.7891e-03, 2.3310e-03, 3.3916e-03, 2.8432e-03,\n",
      "        1.5427e-03, 4.3237e-03, 1.6662e-03, 1.5268e-03, 1.2877e-03, 1.5329e-03,\n",
      "        3.3803e-04, 1.4490e-03, 1.1001e-03, 3.5866e-03, 1.4312e-03, 1.8654e-03,\n",
      "        3.7454e-03, 1.6235e-03, 1.5162e-03, 2.0685e-03, 1.0352e-03, 4.2983e-03,\n",
      "        2.8163e-03, 1.3686e-03, 1.9102e-03, 7.7608e-04, 1.5231e-03, 1.6513e-03,\n",
      "        1.8894e-03, 1.8079e-03, 1.4630e-03, 1.5668e-03, 1.7960e-03, 3.6422e-03,\n",
      "        1.6020e-03, 2.1832e-03, 1.1858e-03, 2.5957e-03, 1.2542e-03, 3.6788e-03,\n",
      "        3.2367e-03, 3.8641e-03, 1.2815e-03, 6.5958e-04, 4.1628e-03, 2.6153e-03,\n",
      "        3.7133e-03, 1.8163e-03, 1.8786e-03, 4.0743e-03, 1.8974e-03, 1.7823e-03,\n",
      "        2.0519e-03, 1.8147e-03, 1.7354e-03, 1.3056e-03, 1.4409e-03, 1.4433e-03,\n",
      "        3.8047e-03, 2.0568e-03, 5.6066e-07, 2.0787e-03, 3.5423e-03, 1.5840e-03,\n",
      "        3.5257e-03, 1.0391e-03, 1.6124e-03, 2.7594e-03, 1.5092e-03, 1.9155e-03,\n",
      "        3.3970e-03, 2.4368e-03, 3.1111e-03, 1.1546e-03, 1.7130e-03, 1.3260e-03,\n",
      "        3.1819e-03, 3.1491e-03, 2.2379e-03, 1.2044e-03, 3.1141e-03, 1.4405e-03,\n",
      "        2.0772e-03, 7.7523e-04, 1.5204e-03, 1.3318e-03, 2.9780e-03, 1.6224e-03,\n",
      "        8.4337e-04, 6.9370e-04, 1.2480e-03, 4.2104e-03, 3.2367e-03, 3.7563e-03,\n",
      "        1.4463e-03, 1.2521e-03, 2.2577e-03, 1.7043e-03, 4.1672e-03, 1.3044e-03,\n",
      "        1.5918e-03, 1.3949e-03, 4.2743e-03, 1.2084e-03, 1.2962e-03, 1.5081e-03,\n",
      "        3.4116e-03, 1.5044e-03, 2.9835e-03, 1.1435e-03, 1.1934e-03, 2.0291e-03,\n",
      "        3.3448e-03, 1.2087e-03, 1.6953e-03, 1.5393e-03, 3.1459e-03, 5.2433e-04,\n",
      "        1.5446e-07, 1.5124e-03, 1.9200e-03, 3.0527e-03, 1.2096e-03, 3.7590e-03]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.1046]) torch.Size([1])\n",
      "###: M= tensor([6.0774e-04, 8.3939e-04, 1.4758e-03, 9.3257e-04, 2.7130e-03, 2.0766e-03,\n",
      "        1.4413e-03, 1.3142e-03, 1.5695e-03, 2.8468e-03, 9.9553e-04, 1.2299e-03,\n",
      "        9.8558e-04, 6.5813e-04, 1.5520e-03, 9.4903e-04, 8.8182e-04, 2.1641e-03,\n",
      "        2.3545e-03, 1.4265e-03, 1.0843e-03, 1.5640e-03, 1.3591e-03, 8.3610e-04,\n",
      "        1.7906e-03, 7.4204e-04, 1.1535e-03, 1.0818e-03, 1.1404e-03, 6.6752e-04,\n",
      "        1.5949e-03, 8.4082e-04, 1.5901e-03, 1.0018e-03, 1.1444e-03, 1.0131e-03,\n",
      "        8.4586e-04, 9.0853e-04, 1.3090e-03, 1.5139e-03, 1.5948e-03, 8.2978e-04,\n",
      "        7.5239e-04, 2.1731e-03, 9.4995e-04, 7.0923e-04, 2.2350e-03, 1.5840e-06,\n",
      "        1.1384e-03, 1.1357e-03, 2.6950e-03, 1.6332e-03, 2.9175e-03, 1.4186e-03,\n",
      "        1.2346e-03, 2.0541e-03, 1.4549e-03, 1.5215e-03, 2.4812e-03, 6.6052e-04,\n",
      "        8.6567e-04, 2.4375e-03, 3.0808e-03, 1.2004e-03, 1.6431e-03, 1.9314e-03,\n",
      "        6.9855e-04, 1.0156e-03, 8.6078e-04, 1.1606e-03, 1.3612e-03, 1.3460e-03,\n",
      "        1.0016e-03, 1.7966e-03, 8.7567e-04, 7.6185e-04, 1.0046e-03, 2.3931e-03,\n",
      "        8.1029e-04, 7.7816e-04, 8.2724e-04, 2.5655e-07, 2.0506e-03, 2.0363e-03,\n",
      "        1.5071e-03, 7.9552e-04, 9.8169e-04, 1.0984e-03, 1.2253e-03, 1.0333e-03,\n",
      "        1.0625e-03, 1.2777e-03, 1.9654e-03, 1.0819e-03, 8.7988e-04, 1.1458e-03,\n",
      "        1.0911e-03, 8.6291e-04, 9.1471e-04, 5.7956e-07, 1.8135e-03, 8.8780e-04,\n",
      "        1.5784e-03, 7.0323e-04, 1.4240e-03, 2.1084e-03, 1.8457e-03, 1.6133e-03,\n",
      "        1.9310e-03, 7.9442e-08, 1.9768e-03, 1.3262e-03, 1.4692e-03, 8.9970e-04,\n",
      "        1.3636e-03, 9.2844e-04, 6.8408e-04, 1.0444e-03, 1.0985e-03, 2.2877e-03,\n",
      "        6.1793e-04, 8.4611e-04, 7.7754e-04, 2.7740e-03, 2.4781e-03, 2.4424e-03,\n",
      "        2.4844e-03, 6.0423e-04, 9.2752e-04, 1.2483e-03, 1.5603e-03, 1.5498e-03,\n",
      "        1.0787e-03, 8.0012e-04, 1.2672e-03, 1.4473e-03, 6.3418e-04, 1.5107e-03,\n",
      "        1.6419e-03, 8.1389e-04, 1.5910e-03, 1.5799e-03, 1.2402e-03, 9.1586e-04,\n",
      "        9.0456e-04, 9.5354e-04, 9.3968e-04, 2.5133e-03, 1.3826e-03, 1.6446e-03,\n",
      "        1.9840e-03, 2.6023e-03, 2.0779e-03, 1.1704e-03, 7.4510e-04, 9.4205e-04,\n",
      "        2.1587e-03, 7.8389e-04, 2.5991e-03, 9.9309e-04, 7.2686e-04, 2.1464e-03,\n",
      "        1.3200e-03, 2.9022e-03, 2.2822e-03, 1.9344e-03, 1.1332e-03, 9.5046e-04,\n",
      "        2.6107e-03, 1.1063e-03, 8.5422e-04, 9.5842e-04, 1.2072e-03, 1.8515e-03,\n",
      "        9.9995e-04, 1.3654e-03, 2.9451e-03, 2.4664e-03, 2.3720e-03, 2.7005e-03,\n",
      "        1.1552e-03, 2.1067e-03, 1.0205e-03, 6.6823e-04, 1.8653e-03, 9.7440e-04,\n",
      "        2.3872e-03, 1.6203e-03, 1.4357e-03, 7.6099e-04, 1.4595e-03, 6.4863e-04,\n",
      "        8.2466e-04, 1.1571e-03, 2.1436e-03, 2.0185e-03, 1.0402e-03, 1.9872e-03,\n",
      "        1.5892e-03, 9.0544e-04, 1.9005e-03, 2.1500e-03, 2.5794e-03, 1.2934e-03,\n",
      "        6.1866e-04, 1.8378e-03, 1.9137e-03, 8.5292e-04, 8.8063e-04, 6.9340e-04,\n",
      "        2.8816e-03, 7.8190e-04, 6.5767e-04, 1.9983e-03, 1.9636e-03, 2.8666e-03,\n",
      "        1.0638e-03, 2.6786e-03, 9.4727e-04, 7.5323e-04, 2.1336e-03, 2.0602e-03,\n",
      "        3.1087e-06, 1.1449e-03, 1.7627e-03, 1.9840e-03, 1.5205e-03, 2.1116e-03,\n",
      "        1.1292e-03, 1.4221e-03, 1.6386e-03, 8.5946e-04, 1.4944e-03, 9.0839e-04,\n",
      "        1.5470e-03, 5.6462e-04, 8.6923e-04, 2.7919e-03, 1.4105e-03, 5.8601e-04,\n",
      "        7.8838e-04, 7.6197e-04, 2.6230e-03, 7.5691e-04, 1.9597e-03, 8.0500e-04,\n",
      "        7.6676e-04, 1.1302e-03, 3.1396e-03, 8.0071e-04, 1.5786e-03, 9.4435e-04,\n",
      "        2.3411e-03, 7.1510e-04, 1.0899e-03, 1.0237e-03, 7.4435e-04, 2.4425e-03,\n",
      "        9.6830e-04, 1.7671e-03, 8.3360e-04, 9.3455e-04, 1.1138e-03, 2.1937e-03,\n",
      "        1.2939e-03, 1.3771e-03, 9.7777e-04, 1.5561e-03, 1.0206e-03, 1.9237e-03,\n",
      "        8.6014e-04, 9.5815e-04, 8.6432e-04, 1.8750e-03, 1.9410e-03, 1.5014e-03,\n",
      "        1.2787e-03, 6.2486e-04, 2.9551e-03, 8.2655e-04, 2.0090e-03, 9.8876e-04,\n",
      "        1.4152e-03, 9.9518e-04, 9.3957e-04, 1.4918e-03, 1.1552e-03, 2.7862e-03,\n",
      "        1.3971e-03, 7.3607e-04, 1.6845e-03, 8.1045e-04, 8.7311e-04, 1.0871e-03,\n",
      "        1.1359e-03, 1.4440e-03, 8.7813e-04, 1.0009e-03, 6.5263e-04, 1.8235e-03,\n",
      "        2.4344e-03, 9.7579e-04, 1.4454e-03, 1.9358e-06, 1.7721e-03, 2.1751e-03,\n",
      "        2.7763e-03, 2.2577e-03, 1.3119e-03, 8.5383e-04, 1.9197e-03, 8.7550e-04,\n",
      "        1.1999e-06, 2.7544e-03, 1.3611e-03, 8.3262e-04, 1.1786e-03, 1.0880e-03,\n",
      "        9.3618e-04, 1.0661e-07, 6.6575e-04, 1.0219e-03, 1.5368e-03, 1.7534e-03,\n",
      "        2.2663e-03, 8.9974e-04, 8.1404e-04, 1.3032e-03, 9.3530e-04, 2.5514e-03,\n",
      "        1.3390e-03, 1.4131e-03, 1.3123e-03, 5.7407e-04, 1.2387e-03, 4.8654e-04,\n",
      "        1.0081e-03, 1.3776e-03, 2.4335e-03, 2.6291e-03, 1.4141e-03, 6.6831e-04,\n",
      "        1.1752e-03, 5.8052e-04, 1.2192e-03, 6.9680e-04, 2.3895e-03, 1.2043e-03,\n",
      "        1.0887e-03, 1.7425e-03, 6.9724e-04, 7.5543e-04, 2.1761e-03, 1.2423e-03,\n",
      "        7.3469e-04, 1.1778e-03, 1.1922e-03, 1.5534e-03, 2.2602e-03, 1.8947e-03,\n",
      "        1.0280e-03, 2.8813e-03, 1.1104e-03, 1.0174e-03, 8.5814e-04, 1.0215e-03,\n",
      "        2.2526e-04, 9.6560e-04, 7.3312e-04, 2.3902e-03, 9.5374e-04, 1.2431e-03,\n",
      "        2.4960e-03, 1.0819e-03, 1.0104e-03, 1.3784e-03, 6.8984e-04, 2.8644e-03,\n",
      "        1.8768e-03, 9.1207e-04, 1.2729e-03, 5.1719e-04, 1.0150e-03, 1.1004e-03,\n",
      "        1.2591e-03, 1.2048e-03, 9.7494e-04, 1.0441e-03, 1.1969e-03, 2.4272e-03,\n",
      "        1.0676e-03, 1.4549e-03, 7.9020e-04, 1.7298e-03, 8.3583e-04, 2.4516e-03,\n",
      "        2.1570e-03, 2.5751e-03, 8.5399e-04, 4.3955e-04, 2.7741e-03, 1.7429e-03,\n",
      "        2.4746e-03, 1.2104e-03, 1.2519e-03, 2.7151e-03, 1.2644e-03, 1.1877e-03,\n",
      "        1.3674e-03, 1.2094e-03, 1.1565e-03, 8.7007e-04, 9.6023e-04, 9.6184e-04,\n",
      "        2.5355e-03, 1.3707e-03, 3.7363e-07, 1.3853e-03, 2.3606e-03, 1.0556e-03,\n",
      "        2.3496e-03, 6.9248e-04, 1.0745e-03, 1.8389e-03, 1.0057e-03, 1.2765e-03,\n",
      "        2.2638e-03, 1.6239e-03, 2.0733e-03, 7.6944e-04, 1.1415e-03, 8.8366e-04,\n",
      "        2.1205e-03, 2.0986e-03, 1.4914e-03, 8.0264e-04, 2.0753e-03, 9.5994e-04,\n",
      "        1.3842e-03, 5.1662e-04, 1.0132e-03, 8.8753e-04, 1.9846e-03, 1.0812e-03,\n",
      "        5.6203e-04, 4.6229e-04, 8.3168e-04, 2.8058e-03, 2.1569e-03, 2.5032e-03,\n",
      "        9.6384e-04, 8.3443e-04, 1.5046e-03, 1.1358e-03, 2.7771e-03, 8.6924e-04,\n",
      "        1.0608e-03, 9.2957e-04, 2.8484e-03, 8.0526e-04, 8.6381e-04, 1.0050e-03,\n",
      "        2.2735e-03, 1.0025e-03, 1.9882e-03, 7.6206e-04, 7.9527e-04, 1.3522e-03,\n",
      "        2.2290e-03, 8.0551e-04, 1.1297e-03, 1.0258e-03, 2.0964e-03, 3.4942e-04,\n",
      "        1.0293e-07, 1.0079e-03, 1.2795e-03, 2.0344e-03, 8.0606e-04, 2.5050e-03])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "conv_weight: tensor([[-0.0048, -0.0180, -0.0011,  ..., -0.0087,  0.0852,  0.0302],\n",
      "        [-0.0487,  0.1075, -0.0432,  ...,  0.0173,  0.0603,  0.0211],\n",
      "        [ 0.0947,  0.0748,  0.1599,  ...,  0.1083, -0.1351,  0.1482],\n",
      "        ...,\n",
      "        [ 0.1339, -0.0587, -0.0259,  ..., -0.0560, -0.0564,  0.1476],\n",
      "        [ 0.0342, -0.0731, -0.0214,  ...,  0.0013,  0.0203,  0.0215],\n",
      "        [ 0.0738, -0.0205, -0.1388,  ...,  0.2487,  0.2399,  0.0657]]) conv_bias: tensor([ 9.7533e-01,  7.9458e-01,  3.6971e-01, -7.2245e-01, -6.7723e-01,\n",
      "         5.2367e-01,  4.8608e-01,  1.0066e+00, -4.8437e-01, -2.8734e-01,\n",
      "         7.1505e-01,  5.8629e-01,  8.5428e-01, -8.8847e-01, -2.3870e-01,\n",
      "        -5.5962e-01, -5.2501e-01, -9.6957e-02,  1.8084e-01, -4.0677e-01,\n",
      "         9.6013e-01, -4.3280e-01,  3.6311e-01, -5.7150e-01, -3.0759e-01,\n",
      "        -6.3333e-01, -8.7938e-01,  8.3832e-01, -6.0050e-01, -7.4085e-01,\n",
      "         7.1532e-01,  9.5484e-01,  6.8835e-01, -4.4854e-01, -4.8361e-01,\n",
      "        -6.3501e-01, -5.7892e-01,  8.4018e-01, -5.7965e-01, -6.6107e-01,\n",
      "         5.1829e-01,  1.6360e+00,  1.7075e+00,  2.6863e-01,  5.7501e-01,\n",
      "        -6.3433e-01,  4.2792e-01, -6.7275e-03, -3.4975e-01,  6.2438e-01,\n",
      "        -9.9665e-02, -4.8896e-01,  4.0372e-01, -4.0387e-01,  6.1633e-01,\n",
      "         3.7554e-01, -1.7078e-01, -6.2179e-01, -2.3942e-01, -7.4822e-01,\n",
      "        -3.9390e-01,  7.7759e-02,  2.4708e-01,  1.0160e+00, -2.6455e-01,\n",
      "         4.7617e-01,  7.9521e-01,  3.7194e-01,  1.6590e+00, -3.6979e-01,\n",
      "         1.4334e+00,  1.8879e-01,  1.1264e+00,  1.3522e-02,  2.2980e+00,\n",
      "         1.0912e+00,  8.6128e-01,  8.2815e-01, -7.4066e-01, -3.7055e-01,\n",
      "         1.1402e+00, -4.6421e-03,  4.4431e-01,  3.0664e-01, -3.8600e-01,\n",
      "        -6.7496e-01,  7.4771e-01,  1.1692e+00,  6.8773e-01,  7.5651e-01,\n",
      "         6.8709e-01,  1.3740e-01, -6.1509e-01, -2.7854e-01,  1.1367e+00,\n",
      "        -4.5704e-01, -8.5577e-01, -6.8117e-01,  7.5589e-01, -2.6057e-03,\n",
      "         2.8966e-01,  6.6226e-01,  5.9627e-01, -7.5623e-01,  8.7819e-01,\n",
      "        -3.0388e-01, -4.8994e-01, -6.6094e-01, -3.1165e-01, -7.5913e-04,\n",
      "        -2.2814e-01, -2.6266e-01, -2.5834e-01,  1.6700e+00, -5.4901e-01,\n",
      "        -6.5230e-01, -4.0742e-01,  1.2315e+00,  5.3369e-01, -1.4573e-01,\n",
      "        -6.3404e-01, -5.0833e-01,  5.5757e-01, -3.1217e-01,  6.5977e-01,\n",
      "        -1.7287e-01,  4.3729e-01, -4.8781e-01,  6.5577e-01,  8.5965e-01,\n",
      "         7.8663e-02, -5.5867e-01,  8.1884e-01, -6.2429e-01, -1.4820e-01,\n",
      "         2.2958e-01,  1.0517e+00, -7.4801e-01, -4.6570e-01,  6.8339e-01,\n",
      "         3.6816e-01, -4.9264e-01, -5.2684e-01, -4.3603e-01,  6.3029e-01,\n",
      "        -6.5813e-01,  7.6580e-01, -1.8704e-01, -4.8206e-01, -8.1621e-01,\n",
      "         4.7099e-01, -6.1931e-01, -5.8277e-02,  9.9025e-01,  1.5333e+00,\n",
      "        -3.8753e-01, -4.6815e-01,  6.6438e-01, -3.6126e-01, -4.4369e-01,\n",
      "        -5.5130e-01,  1.8614e-01,  7.8688e-01,  6.5540e-01,  3.1055e-01,\n",
      "         4.1429e-03, -5.8982e-01, -3.4240e-01, -5.4545e-02,  4.3551e-01,\n",
      "         1.9011e+00,  6.5797e-01,  1.7453e+00, -4.1543e-01,  4.8648e-01,\n",
      "         2.8837e-01, -2.3788e-01,  1.5055e-01, -1.4966e-01, -5.0428e-01,\n",
      "         5.5250e-01,  5.1412e-01, -5.6395e-01,  8.8616e-01,  2.9591e-01,\n",
      "         8.6734e-01,  2.2255e-01,  3.1376e-01,  6.4744e-01, -6.3908e-01,\n",
      "         4.4333e-01, -6.2198e-01, -5.2164e-01, -3.6059e-01, -1.4002e-01,\n",
      "         7.5152e-01, -7.4203e-01, -1.9144e-01,  1.0191e+00,  8.9040e-01,\n",
      "         7.0159e-01,  4.9719e-01,  4.4310e-01, -5.4240e-01,  8.7683e-01,\n",
      "        -7.9741e-01,  2.8116e-02,  1.0398e+00, -4.0934e-01,  9.2154e-01,\n",
      "         3.7823e-03,  1.7818e+00, -6.9971e-01, -6.6018e-01, -9.8679e-02,\n",
      "        -1.9012e-01,  1.8498e+00,  2.2733e-01,  9.5879e-01,  9.2245e-01,\n",
      "        -3.3363e-01,  3.6604e-01, -7.9450e-03, -6.4785e-01, -5.6472e-01,\n",
      "         2.4094e-01, -3.4666e-01,  5.3665e-01, -6.2077e-01, -2.9720e-01,\n",
      "        -3.9275e-02,  6.9199e-01, -3.6122e-01, -3.8830e-01, -5.7387e-01,\n",
      "         8.5232e-01,  6.3410e-01,  7.6017e-02, -5.1289e-01,  1.0255e+00,\n",
      "         8.3442e-01,  8.1622e-01, -1.3376e-03,  1.2197e+00,  4.3277e-01,\n",
      "         7.7780e-01,  8.8306e-01, -4.6067e-01, -5.0086e-01,  6.9812e-01,\n",
      "        -4.9675e-01, -2.7023e-01, -9.0136e-02,  1.5234e+00, -3.9795e-01,\n",
      "         1.2930e+00,  8.6863e-01, -1.4824e-01, -5.5355e-01, -5.8136e-01,\n",
      "         9.7979e-01, -1.9259e-01, -3.2474e-01,  5.8632e-01, -4.7230e-01,\n",
      "        -1.4659e-01,  8.9521e-01, -1.3908e-01,  9.7430e-01,  8.9782e-02,\n",
      "         7.9965e-01, -8.1445e-01,  1.1622e+00, -4.5240e-02,  2.4797e-01,\n",
      "         3.2081e-01,  5.2710e-01,  7.3481e-01, -8.4663e-02,  6.8315e-01,\n",
      "        -5.2524e-01,  1.7672e+00, -3.8748e-01, -5.8877e-01,  7.6784e-01,\n",
      "         6.5064e-01,  4.8676e-01, -4.8491e-01, -5.9052e-01, -7.3277e-01,\n",
      "        -3.4953e-01, -3.3422e-01,  5.7934e-01, -6.3712e-01,  7.2856e-01,\n",
      "         1.2502e+00, -3.5764e-01,  7.3128e-01,  9.1158e-01, -3.2087e-01,\n",
      "         1.2900e-01,  6.3312e-01, -6.0897e-01, -7.2905e-03,  3.4173e-01,\n",
      "        -1.6055e-01,  4.7741e-01, -3.5665e-01, -2.2402e-01, -5.2514e-01,\n",
      "         4.2279e-01, -8.9595e-01, -4.5573e-03, -9.2077e-01,  6.5539e-01,\n",
      "        -4.6290e-01,  1.2727e+00,  1.0685e+00,  6.2059e-01, -2.2252e-03,\n",
      "        -7.6042e-01, -3.1543e-01,  6.1366e-01, -3.5626e-01,  4.6634e-01,\n",
      "        -2.8356e-01, -2.5537e-01,  3.1114e-01, -4.5612e-01,  4.2421e-01,\n",
      "         8.4530e-01, -4.1844e-01, -6.4387e-01,  1.5499e+00,  7.2420e-01,\n",
      "         9.3168e-01,  1.6360e+00,  7.6903e-01,  2.9055e-01,  5.9383e-01,\n",
      "        -3.3890e-01, -4.1495e-01, -4.7649e-01,  1.0797e+00,  9.5758e-01,\n",
      "         5.8381e-01,  5.1872e-01,  1.7789e+00, -2.2176e-01,  1.4479e-01,\n",
      "        -6.5849e-01,  1.3502e+00, -3.8441e-01, -5.2541e-01, -7.1375e-01,\n",
      "         7.9545e-01, -4.1582e-01,  4.6529e-01, -4.6983e-01,  4.6241e-01,\n",
      "        -2.2988e-01, -4.5851e-01,  1.1841e-01, -2.7092e-01,  8.3814e-01,\n",
      "         4.0419e-01, -3.7994e-01, -2.5551e-01, -7.0163e-01,  4.4651e-01,\n",
      "        -3.8808e-01,  7.0757e-01,  2.7610e-02, -4.7439e-01,  1.0558e+00,\n",
      "        -6.4870e-01, -6.2914e-01, -1.5694e-01,  1.4027e-01, -4.1725e-01,\n",
      "        -2.1395e-01,  7.7690e-01, -6.2452e-01, -5.5883e-01, -5.5519e-01,\n",
      "        -5.9419e-01,  8.2491e-01,  4.4774e-01, -6.5724e-01,  3.5437e-01,\n",
      "        -5.1816e-01,  1.5919e+00,  1.0302e+00, -2.4585e-01,  1.1738e+00,\n",
      "        -1.9954e-01, -4.5813e-01, -1.0653e-01, -7.8765e-01, -8.2792e-01,\n",
      "         5.3495e-01,  6.3127e-01, -2.9471e-01,  6.9496e-01, -5.9925e-01,\n",
      "        -8.0509e-01,  8.1023e-01,  6.5252e-01, -2.9845e-01, -6.8906e-01,\n",
      "         4.0434e-01, -6.2594e-01, -8.2819e-01,  9.8788e-01, -2.4525e-01,\n",
      "         1.8304e-01, -1.6762e-03, -7.1229e-01, -1.3377e-01, -5.2317e-01,\n",
      "        -1.6309e-02, -6.0379e-01, -2.9498e-01, -2.0210e-01, -5.0168e-01,\n",
      "        -4.5129e-01,  2.2664e-01,  2.7836e-01, -6.7545e-02,  1.6815e+00,\n",
      "        -4.4975e-01,  9.0204e-01,  1.1155e-01, -3.2673e-01,  2.5480e-01,\n",
      "         8.7832e-01,  3.6149e-01, -5.6169e-01,  4.4820e-01,  8.6935e-01,\n",
      "        -6.5203e-01,  8.4481e-01,  5.1574e-02,  6.8933e-01,  1.0258e+00,\n",
      "        -9.9571e-01,  9.9617e-01,  1.6084e-01, -7.5903e-02, -2.6517e-03,\n",
      "         9.7510e-01,  6.5408e-01,  6.5120e-01, -3.8469e-01, -2.3496e-01,\n",
      "        -6.9526e-01, -5.1821e-01, -7.5021e-01, -3.3938e-01,  1.1674e+00,\n",
      "        -4.4850e-01, -5.8667e-01, -2.9109e-01, -4.2887e-01, -6.1584e-01,\n",
      "        -4.1913e-01,  8.8791e-01, -3.0289e-01, -3.5087e-01, -5.6149e-01,\n",
      "         1.6368e+00,  6.0550e-01,  4.0043e-01, -5.9959e-01, -6.8106e-04,\n",
      "        -4.1394e-01,  3.1465e-01, -1.1622e-01,  1.0521e+00, -3.0211e-01])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "q_weight: tensor([ -5, -20,  -1,  ...,  66,  64,  17], dtype=torch.int32) q_bias: tensor([  15344,    9051,    2395,   -7407,   -2387,    2411,    3225,    7324,\n",
      "          -2951,    -965,    6868,    4558,    8288,  -12908,   -1471,   -5638,\n",
      "          -5693,    -428,     734,   -2726,    8466,   -2646,    2555,   -6535,\n",
      "          -1642,   -8161,   -7289,    7410,   -5035,  -10612,    4288,   10858,\n",
      "           4139,   -4281,   -4041,   -5993,   -6544,    8842,   -4234,   -4175,\n",
      "           3107,   18851,   21699,    1182,    5788,   -8552,    1831,  -40609,\n",
      "          -2938,    5257,    -354,   -2863,    1323,   -2722,    4773,    1748,\n",
      "          -1122,   -3907,    -923,  -10831,   -4351,     305,     767,    8093,\n",
      "          -1539,    2357,   10885,    3502,   18428,   -3046,   10069,    1341,\n",
      "          10752,      72,   25091,   13695,    8198,    3309,   -8740,   -4553,\n",
      "          13178, -173008,    2072,    1440,   -2449,   -8112,    7283,   10178,\n",
      "           5367,    7000,    6183,    1028,   -2992,   -2462,   12352,   -3814,\n",
      "          -7499,   -7548,    7901,  -42987,    1527,    7132,    3612,  -10282,\n",
      "           5897,   -1378,   -2538,   -3917,   -1543,  -91367,   -1103,   -1894,\n",
      "          -1681,   17747,   -3850,   -6718,   -5695,   11274,    4645,    -609,\n",
      "          -9811,   -5744,    6856,   -1076,    2546,    -677,    1683,   -7719,\n",
      "           6760,    6584,     482,   -3447,    7258,   -7460,   -1118,    1517,\n",
      "          15856,   -4734,   -2712,    8028,    2212,   -2981,   -4062,   -4552,\n",
      "           6662,   -6599,    7792,    -712,   -3334,   -4745,    2270,   -2275,\n",
      "           -268,    8090,   19676,   -3933,   -2074,    8104,   -1329,   -4272,\n",
      "          -7252,     829,    5700,    2159,    1301,      20,   -4977,   -3445,\n",
      "           -200,    3764,   21280,    6564,   13823,   -2145,    4652,    2019,\n",
      "           -772,     584,    -603,   -1785,    4573,    2333,   -5284,   12680,\n",
      "           1517,    8511,     891,    1852,    4312,   -8030,    2904,   -9169,\n",
      "          -6048,   -2980,    -625,    3560,   -6821,    -921,    6132,    9403,\n",
      "           3530,    2211,    1642,   -4010,   13551,   -4149,     140,   11657,\n",
      "          -4444,   12707,      13,   21788,  -10173,   -3159,    -480,    -634,\n",
      "          16626,     811,    9678,   11709,   -1495,    1699,  -24437,   -5411,\n",
      "          -3063,    1161,   -2180,    2430,   -5256,   -1998,    -229,    7698,\n",
      "          -2311,   -4087,   -3547,   14433,    6975,     260,   -3477,   16732,\n",
      "          10120,   10242,      -5,   15408,    2111,    9238,   11012,   -3897,\n",
      "          -1525,    8336,   -3009,   -2736,    -368,   20369,   -3491,   12077,\n",
      "          11158,    -580,   -5466,   -3146,   11238,   -1970,   -2788,    2556,\n",
      "          -3490,   -1018,    8754,    -855,    9127,     446,    8889,   -8127,\n",
      "          12856,    -231,    1222,    2043,    3941,   11244,    -274,    7903,\n",
      "          -2500,   17089,   -2618,   -5657,    7814,    4170,    4029,   -1664,\n",
      "          -4041,   -9519,   -1984,   -3943,    6344,   -5604,    6133,    8278,\n",
      "          -3894,    6986,   13355,   -1682,     507,    6204,   -4028,  -36009,\n",
      "           1844,    -706,    1644,   -1510,   -1633,   -5881,    2106,   -9785,\n",
      "         -36317,   -3196,    4604,   -5316,   10325,    9390,    6338, -199571,\n",
      "         -10921,   -2951,    3818,   -1943,    1967,   -3013,   -2999,    2283,\n",
      "          -4663,    1590,    6036,   -2831,   -4691,   25815,    5590,   18309,\n",
      "          15517,    5338,    1142,    2160,   -2291,   -5937,   -3877,   17783,\n",
      "           7509,    8011,    2076,   14124,   -1948,     795,   -9030,   17089,\n",
      "          -1689,   -4044,   -9289,    6457,   -3335,    2864,   -1988,    2333,\n",
      "          -2138,   -1522,    1020,   -2546,    9339,    3783,  -16127,   -2530,\n",
      "          -9151,    1786,   -3891,    5442,     106,   -4192,    9991,   -4500,\n",
      "          -8720,    -524,     715,   -4374,   -1607,   14363,   -5883,   -4856,\n",
      "          -4216,   -4716,    8090,    4100,   -5250,    1396,   -4641,   10462,\n",
      "          12466,   -1359,   13428,    -778,   -2031,    -396,   -8819,  -18010,\n",
      "           1844,    3463,   -1139,    5490,   -4577,   -2835,    6127,    5253,\n",
      "          -2087,   -5448,    3343,   -6879,   -8247,    9820,    -925,    1277,\n",
      "         -42896,   -4916,    -542,   -4739,     -66,   -8337,   -2625,   -1051,\n",
      "          -4769,   -3380,     957,    1639,    -311,   20895,   -3767,    9760,\n",
      "            503,   -1489,    1634,   10463,    1665,   -5595,    3096,   16090,\n",
      "          -6153,    9101,     248,    6096,   17452,  -20594,   11452,     548,\n",
      "           -336,     -10,    9673,    7495,    4138,   -3238,    -809,   -7648,\n",
      "          -4671,   -7716,   -1139,   13861,   -4964,   -5581,   -1224,   -4090,\n",
      "          -2962,   -5259,   10675,   -2142,   -1505,   -6665,   13852,    5644,\n",
      "           1826,  -16407,  -63264,   -3927,    2351,    -546,   12480,   -1153],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-1.8707e-07) tensor(0.0023)   bias tensor(8.3476e-07) tensor(0.0001)\n",
      "features.16.conv.3.weight features.16.conv.5\n",
      "torch.Size([480, 1, 3, 3]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.0990]) torch.Size([1]) \n",
      "wscale= tensor([1.3008e-02, 1.0335e-02, 6.1439e-03, 7.8215e-02, 3.0466e-03, 9.8294e-03,\n",
      "        6.0047e-03, 1.1308e-02, 9.5509e-03, 5.3793e-03, 7.9957e-03, 6.4678e-03,\n",
      "        7.8520e-03, 6.5905e-02, 9.1438e-03, 3.1310e-02, 2.7424e-02, 3.4842e-03,\n",
      "        7.5139e-03, 1.3095e-02, 7.5617e-03, 1.0307e-02, 6.3218e-03, 3.1224e-02,\n",
      "        1.9137e-02, 1.9490e-02, 1.7837e-02, 6.6268e-03, 2.8145e-02, 3.6765e-02,\n",
      "        9.3089e-03, 9.9509e-03, 5.5336e-03, 2.0388e-02, 1.3176e-02, 1.8424e-02,\n",
      "        2.9753e-02, 8.1196e-03, 5.8329e-03, 1.0691e-02, 5.5912e-03, 1.9732e-02,\n",
      "        2.3136e-02, 5.2806e-03, 7.1113e-03, 7.1027e-02, 2.5290e-03, 1.9002e-05,\n",
      "        1.1703e-02, 5.0930e-03, 5.6531e-03, 2.0971e-02, 2.9813e-03, 9.2007e-03,\n",
      "        4.8157e-03, 3.9849e-03, 6.3466e-03, 1.5123e-02, 5.6224e-03, 2.7238e-02,\n",
      "        2.4706e-02, 5.8220e-03, 6.4511e-03, 9.8232e-03, 4.3342e-03, 4.3890e-03,\n",
      "        8.9669e-03, 9.3697e-03, 2.0037e-02, 1.5400e-02, 1.3604e-02, 5.6324e-03,\n",
      "        8.7643e-03, 4.2941e-03, 3.3544e-02, 7.5291e-03, 5.5117e-03, 6.8560e-03,\n",
      "        9.0261e-02, 1.7723e-02, 1.0625e-02, 3.4681e-05, 3.3540e-03, 5.1852e-03,\n",
      "        2.7806e-02, 1.5893e-01, 9.7188e-03, 1.5228e-02, 7.1205e-03, 9.8016e-03,\n",
      "        5.1185e-03, 5.8913e-03, 2.5246e-02, 9.7159e-03, 1.1761e-02, 9.8109e-03,\n",
      "        2.5259e-02, 2.3067e-02, 8.1835e-03, 1.1931e-05, 6.2486e-03, 8.7512e-03,\n",
      "        7.0921e-03, 3.4027e-02, 8.1169e-03, 9.4739e-03, 1.0623e-02, 2.7596e-02,\n",
      "        4.5581e-03, 1.0436e-06, 1.4632e-02, 4.5389e-03, 7.4262e-03, 2.1199e-02,\n",
      "        1.8719e-02, 1.3490e-02, 1.4153e-02, 1.2232e-02, 9.2951e-03, 3.5343e-03,\n",
      "        1.9603e-01, 4.2113e-02, 7.8445e-03, 4.0621e-03, 6.1912e-03, 4.1797e-03,\n",
      "        2.9713e-03, 1.1279e-01, 5.9230e-03, 9.8995e-03, 6.8528e-03, 1.3783e-02,\n",
      "        8.3249e-03, 3.7654e-02, 7.5781e-03, 5.4345e-03, 1.2100e-02, 9.6944e-03,\n",
      "        2.0208e-02, 7.2309e-03, 9.6109e-03, 9.1257e-03, 2.1401e-02, 1.9749e-02,\n",
      "        7.3049e-03, 1.0044e-01, 7.2547e-03, 3.0257e-03, 7.8138e-03, 1.6511e-02,\n",
      "        3.5239e-03, 4.2530e-03, 7.7657e-03, 6.6213e-03, 2.1852e-02, 2.1687e-02,\n",
      "        7.2391e-03, 1.0105e-02, 5.1387e-03, 2.5855e-02, 2.2785e-02, 2.7616e-03,\n",
      "        8.5415e-03, 1.6564e-03, 7.5256e-03, 3.4953e-03, 3.5229e-02, 1.1006e-02,\n",
      "        2.9908e-03, 6.7868e-03, 2.1632e-02, 6.5371e-03, 1.5364e-02, 5.4173e-03,\n",
      "        8.5351e-03, 6.1640e-03, 5.9125e-03, 4.4045e-03, 6.2492e-03, 4.7772e-03,\n",
      "        5.3385e-03, 6.5744e-03, 1.4964e-02, 1.2348e-02, 6.7435e-03, 8.3678e-03,\n",
      "        8.9296e-03, 6.2670e-03, 8.2054e-03, 3.5481e-02, 5.0398e-03, 1.2214e-01,\n",
      "        2.2527e-02, 1.8094e-02, 4.9171e-03, 4.3000e-03, 1.0096e-02, 5.3958e-03,\n",
      "        9.0504e-03, 7.5155e-03, 3.9268e-03, 4.3136e-03, 1.0897e-02, 3.0148e-02,\n",
      "        8.5317e-03, 1.2836e-02, 3.5660e-03, 9.8328e-03, 3.0424e-02, 8.2227e-03,\n",
      "        4.8874e-03, 2.3088e-02, 3.5458e-02, 9.1567e-03, 9.7166e-03, 4.7309e-03,\n",
      "        2.5011e-02, 9.0957e-03, 1.3352e-02, 9.0741e-03, 6.2561e-03, 6.7478e-03,\n",
      "        1.5254e-04, 2.4683e-01, 1.3644e-02, 6.5020e-03, 1.0980e-02, 7.8454e-03,\n",
      "        1.8143e-02, 1.5980e-02, 1.0252e-02, 7.8502e-03, 4.3254e-03, 4.3757e-02,\n",
      "        1.1153e-02, 1.2631e-02, 7.4110e-03, 4.2678e-03, 1.5102e-02, 8.7206e-03,\n",
      "        7.3732e-03, 1.1509e-02, 3.2125e-03, 1.4869e-02, 3.4697e-03, 8.1168e-03,\n",
      "        9.4541e-03, 9.5242e-03, 3.7871e-03, 9.9887e-03, 8.3065e-03, 1.2245e-02,\n",
      "        7.1367e-03, 1.9438e-02, 1.7472e-02, 1.1109e-02, 1.3353e-02, 6.2006e-03,\n",
      "        2.0582e-02, 1.5539e-02, 8.7888e-03, 1.0575e-02, 8.1638e-03, 4.4721e-03,\n",
      "        3.5351e-02, 5.9457e-03, 8.4152e-03, 4.3390e-03, 1.0122e-02, 3.7454e-03,\n",
      "        8.5220e-03, 4.0988e-02, 1.1495e-02, 7.9778e-03, 6.0553e-03, 5.6256e-03,\n",
      "        5.9558e-03, 8.1554e-03, 3.6034e-03, 7.2416e-03, 1.1133e-02, 2.4624e-02,\n",
      "        1.9384e-02, 2.6122e-02, 1.0357e-02, 8.5572e-03, 6.5927e-03, 7.8470e-03,\n",
      "        1.7848e-02, 2.7882e-02, 1.6730e-02, 2.5081e-02, 7.7749e-03, 1.7107e-02,\n",
      "        1.3477e-02, 1.8040e-02, 2.4583e-02, 7.4786e-03, 1.1033e-02, 4.5167e-03,\n",
      "        7.1180e-03, 8.4972e-03, 3.1483e-02, 9.4749e-05, 3.1099e-03, 1.0875e-02,\n",
      "        3.1384e-03, 4.5477e-03, 6.9663e-03, 2.5475e-02, 8.4196e-03, 2.3201e-02,\n",
      "        2.0518e-05, 6.3174e-03, 9.1520e-03, 2.5448e-02, 1.0814e-02, 1.0089e-02,\n",
      "        9.6413e-03, 7.2351e-06, 7.6618e-02, 1.9026e-02, 8.1384e-03, 6.4112e-03,\n",
      "        1.0635e-02, 2.8869e-02, 1.6518e-02, 5.3317e-03, 3.0146e-02, 5.0220e-03,\n",
      "        9.9174e-03, 1.0129e-02, 2.1615e-02, 1.7993e-02, 7.0322e-03, 1.1373e-02,\n",
      "        1.6318e-02, 7.6690e-03, 6.8452e-03, 7.8216e-03, 1.6576e-02, 1.5276e-02,\n",
      "        2.7677e-02, 1.0505e-02, 1.0546e-02, 8.4027e-03, 4.2245e-03, 1.8175e-02,\n",
      "        7.2322e-03, 3.0127e-03, 4.0443e-02, 1.5052e-02, 9.1696e-03, 1.4229e-02,\n",
      "        5.6108e-02, 1.0025e-02, 1.3271e-02, 9.6429e-03, 5.7299e-03, 5.3194e-03,\n",
      "        1.1850e-02, 3.3619e-03, 5.4435e-03, 1.3408e-02, 8.3252e-03, 7.5191e-03,\n",
      "        9.0547e-04, 6.8763e-02, 7.1540e-02, 6.6652e-03, 1.9691e-02, 6.5926e-03,\n",
      "        4.0563e-03, 8.0022e-03, 1.0907e-02, 1.6535e-02, 2.4310e-01, 6.0646e-03,\n",
      "        4.2332e-03, 1.0247e-02, 7.9543e-03, 1.1015e-02, 2.0999e-02, 1.0856e-02,\n",
      "        1.9822e-02, 1.3707e-02, 7.5223e-03, 6.4541e-03, 1.4366e-02, 7.3141e-03,\n",
      "        7.1891e-03, 2.0905e-02, 1.2538e-02, 1.0388e-02, 1.1542e-02, 4.1820e-03,\n",
      "        3.8671e-03, 6.3435e-03, 2.0893e-02, 4.3033e-01, 4.9567e-03, 3.9746e-03,\n",
      "        4.1122e-03, 6.7955e-03, 3.1498e-02, 6.9099e-03, 9.5718e-03, 7.1102e-03,\n",
      "        1.1362e-02, 1.6478e-02, 7.3526e-03, 4.4184e-02, 9.9942e-02, 1.0229e-02,\n",
      "        6.9159e-03, 6.0057e-03, 6.4046e-06, 2.5615e-02, 6.9474e-03, 2.1754e-02,\n",
      "        3.0272e-03, 9.2516e-02, 1.1991e-02, 5.6280e-03, 3.7709e-02, 2.9830e-02,\n",
      "        7.4819e-03, 9.5319e-03, 9.0377e-03, 1.8587e-02, 1.6442e-02, 9.7561e-03,\n",
      "        2.8501e-03, 6.0858e-03, 5.5510e-03, 1.0828e-02, 4.8488e-03, 2.4776e-02,\n",
      "        8.0196e-03, 1.4974e-02, 9.5112e-03, 1.0163e-02, 5.7936e-03, 9.0739e-03,\n",
      "        1.1705e-02, 2.2802e+00, 1.1235e-02, 8.2505e-03, 7.6130e-03, 6.7113e-03,\n",
      "        1.1831e-02, 6.6721e-03, 7.9913e-03, 1.4349e-02, 3.3178e-03, 3.8079e-02,\n",
      "        2.7818e-02, 1.7390e-02, 4.3542e-03, 9.8355e-03, 2.1263e-02, 3.2361e-02,\n",
      "        3.0694e-03, 9.5608e-03, 8.6087e-03, 2.0216e-02, 9.3163e-03, 7.0892e-03,\n",
      "        1.4601e-02, 1.2932e-02, 1.6448e-02, 6.0937e-03, 7.2432e-03, 3.6753e-01,\n",
      "        1.2330e-06, 9.9171e-03, 6.7035e-03, 4.6234e-03, 1.4963e-02, 6.7841e-03]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.1388]) torch.Size([1])\n",
      "###: M= tensor([9.2763e-03, 7.3705e-03, 4.3815e-03, 5.5779e-02, 2.1727e-03, 7.0097e-03,\n",
      "        4.2822e-03, 8.0642e-03, 6.8111e-03, 3.8362e-03, 5.7021e-03, 4.6124e-03,\n",
      "        5.5996e-03, 4.7000e-02, 6.5208e-03, 2.2328e-02, 1.9557e-02, 2.4847e-03,\n",
      "        5.3585e-03, 9.3389e-03, 5.3926e-03, 7.3506e-03, 4.5084e-03, 2.2267e-02,\n",
      "        1.3648e-02, 1.3899e-02, 1.2720e-02, 4.7259e-03, 2.0072e-02, 2.6219e-02,\n",
      "        6.6386e-03, 7.0964e-03, 3.9463e-03, 1.4540e-02, 9.3967e-03, 1.3139e-02,\n",
      "        2.1218e-02, 5.7905e-03, 4.1597e-03, 7.6242e-03, 3.9874e-03, 1.4072e-02,\n",
      "        1.6499e-02, 3.7658e-03, 5.0714e-03, 5.0653e-02, 1.8036e-03, 1.3551e-05,\n",
      "        8.3461e-03, 3.6321e-03, 4.0315e-03, 1.4955e-02, 2.1261e-03, 6.5614e-03,\n",
      "        3.4343e-03, 2.8418e-03, 4.5261e-03, 1.0785e-02, 4.0095e-03, 1.9425e-02,\n",
      "        1.7619e-02, 4.1519e-03, 4.6005e-03, 7.0054e-03, 3.0909e-03, 3.1300e-03,\n",
      "        6.3947e-03, 6.6819e-03, 1.4289e-02, 1.0982e-02, 9.7013e-03, 4.0167e-03,\n",
      "        6.2502e-03, 3.0623e-03, 2.3922e-02, 5.3693e-03, 3.9306e-03, 4.8893e-03,\n",
      "        6.4369e-02, 1.2639e-02, 7.5774e-03, 2.4733e-05, 2.3919e-03, 3.6978e-03,\n",
      "        1.9830e-02, 1.1334e-01, 6.9309e-03, 1.0860e-02, 5.0779e-03, 6.9899e-03,\n",
      "        3.6502e-03, 4.2013e-03, 1.8004e-02, 6.9288e-03, 8.3875e-03, 6.9966e-03,\n",
      "        1.8013e-02, 1.6450e-02, 5.8360e-03, 8.5084e-06, 4.4562e-03, 6.2409e-03,\n",
      "        5.0577e-03, 2.4266e-02, 5.7885e-03, 6.7563e-03, 7.5757e-03, 1.9680e-02,\n",
      "        3.2505e-03, 7.4425e-07, 1.0435e-02, 3.2369e-03, 5.2960e-03, 1.5118e-02,\n",
      "        1.3349e-02, 9.6202e-03, 1.0093e-02, 8.7234e-03, 6.6288e-03, 2.5205e-03,\n",
      "        1.3980e-01, 3.0033e-02, 5.5943e-03, 2.8968e-03, 4.4152e-03, 2.9807e-03,\n",
      "        2.1190e-03, 8.0435e-02, 4.2240e-03, 7.0598e-03, 4.8870e-03, 9.8290e-03,\n",
      "        5.9368e-03, 2.6853e-02, 5.4043e-03, 3.8756e-03, 8.6290e-03, 6.9135e-03,\n",
      "        1.4411e-02, 5.1567e-03, 6.8539e-03, 6.5079e-03, 1.5262e-02, 1.4084e-02,\n",
      "        5.2094e-03, 7.1628e-02, 5.1736e-03, 2.1578e-03, 5.5724e-03, 1.1775e-02,\n",
      "        2.5131e-03, 3.0330e-03, 5.5381e-03, 4.7220e-03, 1.5583e-02, 1.5466e-02,\n",
      "        5.1625e-03, 7.2061e-03, 3.6647e-03, 1.8438e-02, 1.6249e-02, 1.9694e-03,\n",
      "        6.0913e-03, 1.1812e-03, 5.3668e-03, 2.4926e-03, 2.5123e-02, 7.8491e-03,\n",
      "        2.1329e-03, 4.8400e-03, 1.5427e-02, 4.6619e-03, 1.0957e-02, 3.8633e-03,\n",
      "        6.0867e-03, 4.3958e-03, 4.2165e-03, 3.1410e-03, 4.4566e-03, 3.4068e-03,\n",
      "        3.8071e-03, 4.6885e-03, 1.0671e-02, 8.8061e-03, 4.8091e-03, 5.9674e-03,\n",
      "        6.3681e-03, 4.4693e-03, 5.8516e-03, 2.5303e-02, 3.5941e-03, 8.7107e-02,\n",
      "        1.6065e-02, 1.2903e-02, 3.5066e-03, 3.0665e-03, 7.1996e-03, 3.8480e-03,\n",
      "        6.4542e-03, 5.3596e-03, 2.8004e-03, 3.0762e-03, 7.7710e-03, 2.1500e-02,\n",
      "        6.0843e-03, 9.1536e-03, 2.5431e-03, 7.0122e-03, 2.1697e-02, 5.8639e-03,\n",
      "        3.4854e-03, 1.6465e-02, 2.5287e-02, 6.5301e-03, 6.9293e-03, 3.3738e-03,\n",
      "        1.7836e-02, 6.4865e-03, 9.5217e-03, 6.4711e-03, 4.4615e-03, 4.8122e-03,\n",
      "        1.0878e-04, 1.7602e-01, 9.7303e-03, 4.6369e-03, 7.8305e-03, 5.5949e-03,\n",
      "        1.2938e-02, 1.1396e-02, 7.3113e-03, 5.5983e-03, 3.0846e-03, 3.1205e-02,\n",
      "        7.9537e-03, 9.0080e-03, 5.2851e-03, 3.0436e-03, 1.0770e-02, 6.2191e-03,\n",
      "        5.2581e-03, 8.2074e-03, 2.2910e-03, 1.0603e-02, 2.4744e-03, 5.7884e-03,\n",
      "        6.7421e-03, 6.7921e-03, 2.7007e-03, 7.1234e-03, 5.9237e-03, 8.7324e-03,\n",
      "        5.0895e-03, 1.3862e-02, 1.2460e-02, 7.9224e-03, 9.5224e-03, 4.4219e-03,\n",
      "        1.4678e-02, 1.1082e-02, 6.2677e-03, 7.5414e-03, 5.8220e-03, 3.1893e-03,\n",
      "        2.5210e-02, 4.2401e-03, 6.0013e-03, 3.0944e-03, 7.2187e-03, 2.6710e-03,\n",
      "        6.0774e-03, 2.9231e-02, 8.1973e-03, 5.6893e-03, 4.3183e-03, 4.0119e-03,\n",
      "        4.2474e-03, 5.8160e-03, 2.5698e-03, 5.1643e-03, 7.9397e-03, 1.7560e-02,\n",
      "        1.3824e-02, 1.8629e-02, 7.3860e-03, 6.1025e-03, 4.7016e-03, 5.5960e-03,\n",
      "        1.2728e-02, 1.9884e-02, 1.1931e-02, 1.7886e-02, 5.5446e-03, 1.2200e-02,\n",
      "        9.6107e-03, 1.2865e-02, 1.7531e-02, 5.3333e-03, 7.8681e-03, 3.2211e-03,\n",
      "        5.0762e-03, 6.0597e-03, 2.2452e-02, 6.7570e-05, 2.2178e-03, 7.7553e-03,\n",
      "        2.2381e-03, 3.2432e-03, 4.9680e-03, 1.8167e-02, 6.0044e-03, 1.6546e-02,\n",
      "        1.4633e-05, 4.5052e-03, 6.5267e-03, 1.8148e-02, 7.7122e-03, 7.1952e-03,\n",
      "        6.8756e-03, 5.1597e-06, 5.4640e-02, 1.3568e-02, 5.8038e-03, 4.5721e-03,\n",
      "        7.5845e-03, 2.0588e-02, 1.1780e-02, 3.8023e-03, 2.1499e-02, 3.5814e-03,\n",
      "        7.0725e-03, 7.2232e-03, 1.5415e-02, 1.2832e-02, 5.0150e-03, 8.1103e-03,\n",
      "        1.1637e-02, 5.4691e-03, 4.8816e-03, 5.5779e-03, 1.1821e-02, 1.0894e-02,\n",
      "        1.9738e-02, 7.4915e-03, 7.5208e-03, 5.9923e-03, 3.0127e-03, 1.2962e-02,\n",
      "        5.1576e-03, 2.1485e-03, 2.8842e-02, 1.0734e-02, 6.5392e-03, 1.0147e-02,\n",
      "        4.0013e-02, 7.1492e-03, 9.4645e-03, 6.8768e-03, 4.0863e-03, 3.7935e-03,\n",
      "        8.4508e-03, 2.3975e-03, 3.8820e-03, 9.5620e-03, 5.9370e-03, 5.3622e-03,\n",
      "        6.4573e-04, 4.9038e-02, 5.1018e-02, 4.7532e-03, 1.4043e-02, 4.7014e-03,\n",
      "        2.8927e-03, 5.7067e-03, 7.7783e-03, 1.1792e-02, 1.7336e-01, 4.3249e-03,\n",
      "        3.0189e-03, 7.3073e-03, 5.6725e-03, 7.8555e-03, 1.4975e-02, 7.7420e-03,\n",
      "        1.4136e-02, 9.7750e-03, 5.3645e-03, 4.6027e-03, 1.0245e-02, 5.2160e-03,\n",
      "        5.1269e-03, 1.4908e-02, 8.9412e-03, 7.4080e-03, 8.2311e-03, 2.9824e-03,\n",
      "        2.7578e-03, 4.5239e-03, 1.4900e-02, 3.0689e-01, 3.5348e-03, 2.8344e-03,\n",
      "        2.9326e-03, 4.8461e-03, 2.2462e-02, 4.9277e-03, 6.8261e-03, 5.0706e-03,\n",
      "        8.1025e-03, 1.1751e-02, 5.2435e-03, 3.1510e-02, 7.1273e-02, 7.2946e-03,\n",
      "        4.9321e-03, 4.2829e-03, 4.5674e-06, 1.8267e-02, 4.9545e-03, 1.5513e-02,\n",
      "        2.1588e-03, 6.5977e-02, 8.5510e-03, 4.0136e-03, 2.6892e-02, 2.1273e-02,\n",
      "        5.3357e-03, 6.7976e-03, 6.4452e-03, 1.3255e-02, 1.1726e-02, 6.9575e-03,\n",
      "        2.0325e-03, 4.3401e-03, 3.9586e-03, 7.7221e-03, 3.4579e-03, 1.7669e-02,\n",
      "        5.7191e-03, 1.0679e-02, 6.7828e-03, 7.2480e-03, 4.1316e-03, 6.4710e-03,\n",
      "        8.3474e-03, 1.6261e+00, 8.0125e-03, 5.8838e-03, 5.4292e-03, 4.7861e-03,\n",
      "        8.4370e-03, 4.7582e-03, 5.6989e-03, 1.0233e-02, 2.3660e-03, 2.7156e-02,\n",
      "        1.9838e-02, 1.2402e-02, 3.1052e-03, 7.0141e-03, 1.5164e-02, 2.3078e-02,\n",
      "        2.1889e-03, 6.8182e-03, 6.1392e-03, 1.4417e-02, 6.6438e-03, 5.0556e-03,\n",
      "        1.0412e-02, 9.2227e-03, 1.1730e-02, 4.3457e-03, 5.1655e-03, 2.6210e-01,\n",
      "        8.7930e-07, 7.0723e-03, 4.7805e-03, 3.2971e-03, 1.0671e-02, 4.8381e-03])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "conv_weight: tensor([[[-0.0594, -0.4303, -0.1201],\n",
      "         [-0.7017,  0.1079, -0.5290],\n",
      "         [-0.0348, -1.0597, -0.1977]],\n",
      "\n",
      "        [[-0.1058, -0.2695, -0.0977],\n",
      "         [-0.2521, -0.0286, -0.3758],\n",
      "         [-0.7839, -1.1095, -1.0151]],\n",
      "\n",
      "        [[ 0.2477,  0.5002,  0.2534],\n",
      "         [ 0.2424, -0.4063,  0.1772],\n",
      "         [-0.0111, -0.3104, -0.0450]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1398,  0.3091,  0.1360],\n",
      "         [ 0.2200,  0.3482,  0.2601],\n",
      "         [ 0.0082, -0.2167,  0.0263]],\n",
      "\n",
      "        [[-0.0681,  0.2263, -0.0707],\n",
      "         [ 0.0586, -1.1997,  0.0512],\n",
      "         [-0.3378, -0.3786, -0.3276]],\n",
      "\n",
      "        [[-0.2235, -0.0396,  0.2974],\n",
      "         [-0.1625, -0.3877,  0.5296],\n",
      "         [-0.0579, -0.0804,  0.2186]]]) conv_bias: tensor([ 2.2196e+00,  1.6793e+00, -5.4547e-01, -1.0724e+00, -9.6062e-01,\n",
      "         1.8357e+00,  1.3056e+00, -9.0053e-02, -3.8436e-01, -1.8104e+00,\n",
      "         2.1295e+00, -1.0958e+00, -2.3575e-01, -7.1926e-01, -7.1727e-01,\n",
      "        -4.0457e-01, -4.3017e-02, -9.1820e-01, -1.1099e+00, -1.1194e+00,\n",
      "        -7.1874e-02, -9.2993e-01,  1.7452e+00, -1.2558e-01, -2.7535e-01,\n",
      "         3.5847e+00,  1.2119e-02, -6.3605e-02, -3.8628e-01,  2.3562e+00,\n",
      "        -8.7714e-01,  2.6665e-03,  1.8554e-02, -5.6176e-01, -8.5195e-01,\n",
      "        -6.0232e-02, -1.2218e-01,  1.3552e+00,  1.3325e+00, -1.1005e+00,\n",
      "         1.5051e+00,  3.2753e+00,  3.3877e+00,  4.5367e-01,  1.7796e+00,\n",
      "        -3.7208e-01, -1.3089e+00, -2.0184e-03, -4.9214e-01,  6.5088e-01,\n",
      "        -6.9450e-01, -2.6170e-01,  1.1819e+00, -1.8689e+00,  1.1509e+00,\n",
      "        -2.0355e+00,  1.4035e+00, -7.1347e-01, -1.5016e+00,  2.6241e+00,\n",
      "        -5.4297e-01, -1.1442e+00, -4.6906e-01,  5.6804e-02,  1.2237e+00,\n",
      "         4.8806e-01,  1.5459e+00, -3.3132e-01,  3.5098e+00, -2.7226e-01,\n",
      "         5.4766e-01,  2.6522e-01,  4.1692e-01,  2.0713e+00,  3.8368e+00,\n",
      "         2.8682e+00,  2.0657e+00, -8.7807e-01,  2.1290e+00, -3.4675e-03,\n",
      "         2.2701e+00, -5.1083e-03,  2.9810e-01, -6.9251e-01, -1.1423e+00,\n",
      "        -1.0037e+00, -1.6679e-01,  1.7974e+00, -1.6174e-01, -1.3017e-01,\n",
      "         1.5692e+00,  1.2994e+00, -3.3979e-01,  1.3469e+00, -9.5082e-02,\n",
      "         3.5958e-01, -2.9796e-01,  2.3300e+00, -7.2561e-02, -1.2009e-03,\n",
      "        -1.3956e-02,  1.7485e+00,  1.2705e+00,  1.9281e+00,  9.8853e-02,\n",
      "        -1.6569e+00, -1.5465e+00, -4.2379e-01,  1.1040e+00,  3.6952e-04,\n",
      "        -3.5833e-01,  1.2885e+00,  2.4706e+00,  2.8385e+00,  1.0202e+00,\n",
      "         6.1038e-02,  1.1775e+00,  1.9849e+00, -3.9899e-01,  1.8098e+00,\n",
      "        -4.2425e-02, -2.9587e-01,  1.8204e+00, -1.4746e+00, -3.9551e-01,\n",
      "        -7.9416e-01,  2.2364e+00, -1.0916e+00,  1.7515e+00, -2.0601e+00,\n",
      "         1.4776e+00, -1.8165e-03,  7.9866e-01, -1.0592e-01,  1.0725e+00,\n",
      "         1.3216e+00,  1.7757e+00, -8.8562e-01, -8.6478e-01,  2.0648e+00,\n",
      "        -1.1038e+00,  6.2899e-02, -1.1208e+00, -7.7508e-01,  1.2578e+00,\n",
      "        -3.6065e-01, -4.8465e-01, -2.3459e+00,  2.5120e+00, -1.5300e+00,\n",
      "         1.3220e+00, -1.5168e+00, -6.6651e-01,  2.2602e+00,  3.4610e+00,\n",
      "        -1.7228e+00, -6.4842e-01,  1.9072e+00, -1.2058e+00, -2.9592e+00,\n",
      "        -8.5996e-02, -1.1135e-01, -1.2090e+00,  1.5510e+00, -7.1306e-01,\n",
      "         1.1734e+00, -2.6114e-01,  9.2107e-01,  1.4909e+00,  1.0860e+00,\n",
      "         3.6287e+00, -5.0157e-01,  2.9988e+00, -1.7193e-01,  1.3171e+00,\n",
      "        -3.4675e-01, -1.1385e+00, -1.0621e+00, -1.2802e+00,  2.1531e+00,\n",
      "         1.4673e+00, -1.3528e+00,  8.7389e-01,  2.1507e+00,  1.3273e+00,\n",
      "         2.0444e+00, -5.4783e-02, -1.0153e+00, -1.7390e-01,  1.3481e+00,\n",
      "         2.1020e+00, -1.7277e-01, -6.1617e-01, -3.5534e-01,  1.0655e+00,\n",
      "         1.3236e+00,  6.1471e-02, -5.9652e-01, -8.5214e-01, -7.0730e-02,\n",
      "         1.2484e+00, -1.7003e+00, -3.8554e-01, -5.6268e-01, -1.2259e-01,\n",
      "        -5.3498e-01, -6.3678e-01,  1.4467e+00, -7.2507e-01,  1.6634e+00,\n",
      "        -1.3266e+00,  3.1565e+00,  4.0509e-01, -5.9628e-01,  6.9874e-01,\n",
      "        -1.2545e+00,  3.2445e+00, -2.5585e+00,  1.7565e+00,  1.7884e+00,\n",
      "        -6.8279e-01,  1.6561e+00, -6.0827e-03,  1.7154e+00,  2.0959e+00,\n",
      "        -2.6270e-01,  1.9517e+00,  2.1649e+00, -2.0730e+00, -9.2467e-01,\n",
      "        -7.8592e-01,  1.8942e+00,  1.7526e+00, -1.3368e-01, -5.2960e-01,\n",
      "         2.1446e+00,  1.7476e+00, -7.7357e-01,  1.9708e+00,  2.6170e+00,\n",
      "        -7.1348e-01,  2.5088e+00, -1.1402e-01,  1.3963e+00,  1.1707e+00,\n",
      "         1.7636e+00, -1.9618e-01,  2.4462e+00,  2.5791e+00,  1.8222e+00,\n",
      "        -2.3194e-01,  1.2754e+00, -8.2576e-01,  3.0701e+00,  1.6740e-03,\n",
      "         4.1042e-02,  1.8233e+00, -1.5160e+00,  4.0358e-02, -6.5625e-01,\n",
      "        -3.0770e-01,  1.7275e+00,  1.0764e+00,  1.5989e+00, -3.1109e-01,\n",
      "         1.3583e+00, -1.9492e-02, -7.2530e-01, -1.6624e-01,  1.4050e+00,\n",
      "         1.4592e+00, -4.2511e-01,  2.2384e+00, -5.9102e-01, -3.5948e-01,\n",
      "         1.7171e+00,  1.2829e+00,  2.0627e+00, -1.3587e+00,  1.6465e+00,\n",
      "        -1.0526e+00,  3.4389e+00, -4.4932e-01, -1.5083e+00,  1.5964e+00,\n",
      "        -2.7424e-01, -1.0280e+00, -6.4133e-01,  3.4416e+00, -1.1158e-01,\n",
      "        -2.5827e-01, -4.2963e-01,  1.7214e+00, -5.3603e-01,  1.3316e+00,\n",
      "         2.9715e+00, -1.1959e+00,  1.6240e+00,  3.1417e+00,  2.1235e+00,\n",
      "        -1.1220e+00,  2.0359e+00, -1.1019e+00, -5.8158e-03,  1.3404e+00,\n",
      "        -1.1519e+00,  1.3461e+00, -1.2028e+00,  1.0113e+00, -1.8678e+00,\n",
      "        -1.4573e+00,  2.6278e-02, -4.7032e-03, -8.4891e-01, -1.9577e+00,\n",
      "        -1.3408e-01, -2.2683e-02,  2.4112e+00, -3.4141e-01, -8.4676e-04,\n",
      "        -5.6085e-01, -8.9273e-01, -6.6195e-02, -3.6034e-01,  2.0415e+00,\n",
      "        -5.6714e-01, -2.8197e-01, -2.2253e-01, -9.5387e-01,  1.6436e+00,\n",
      "        -1.6906e-01, -8.7646e-01,  4.6121e-03,  3.9529e+00,  1.5370e+00,\n",
      "         2.3275e+00,  3.5023e+00, -1.7450e-01, -1.0270e+00, -1.0104e+00,\n",
      "         6.1804e-02,  1.4052e+00, -1.0193e+00,  3.4219e+00,  1.1181e+00,\n",
      "         1.5952e+00,  2.1669e+00,  1.9697e+00, -2.6439e-01,  1.2048e+00,\n",
      "         9.5453e-01,  2.7363e+00, -8.5023e-01, -8.4111e-01, -5.1789e-01,\n",
      "        -6.0959e-01, -4.6730e-01, -7.8429e-01,  1.8653e+00,  5.4771e-01,\n",
      "         1.0407e+00, -2.5405e+00,  1.2331e+00,  1.1204e+00,  1.6618e+00,\n",
      "         1.5147e+00, -2.4429e-01, -1.2823e+00,  3.1945e+00, -1.2718e+00,\n",
      "         2.7753e+00, -3.8421e-01, -8.3947e-01,  2.1954e+00, -5.9294e-02,\n",
      "         1.1247e+00, -7.6355e-01, -7.9154e-01,  1.2741e+00,  1.2311e+00,\n",
      "         2.4430e+00,  2.6961e+00,  3.9018e+00,  3.2382e+00, -1.6615e+00,\n",
      "         4.3713e-01,  1.7273e+00,  1.4615e+00,  2.9621e-01, -3.3726e-01,\n",
      "         2.1938e+00,  1.3234e+00, -1.8429e-01,  1.7540e+00, -9.4102e-03,\n",
      "         1.0324e+00,  1.1243e+00, -7.2466e-02, -3.9007e-01, -6.3066e-01,\n",
      "        -5.0713e-01,  1.8006e+00, -1.5362e+00,  9.7546e-01, -1.5952e+00,\n",
      "        -3.1721e-01, -1.6191e-01,  1.1490e+00, -4.4875e-01,  5.7831e-02,\n",
      "        -3.0548e-01,  1.0719e+00, -4.8403e-01, -7.5981e-02,  1.8559e+00,\n",
      "        -1.4752e+00, -2.0465e-03, -2.5974e-01, -1.4419e+00, -2.6901e-01,\n",
      "         1.3879e+00,  2.9245e+00, -7.1062e-01, -7.7659e-01, -1.2471e-01,\n",
      "        -3.7197e-01, -2.0047e+00,  1.4332e+00, -3.6786e-01,  3.6601e+00,\n",
      "        -1.0487e-01,  9.4470e-01, -1.3340e+00, -5.8776e-01,  9.3129e-01,\n",
      "         1.7422e+00,  2.0020e+00, -5.3787e-01, -4.3537e-01,  2.6555e+00,\n",
      "        -1.5488e-01,  2.7777e-02, -1.2591e-01,  1.4796e-02,  3.0229e+00,\n",
      "        -9.9347e-01, -2.7334e-01, -5.5342e-01,  2.1624e+00, -5.1668e-01,\n",
      "         2.5782e+00,  1.4115e+00, -9.2115e-02, -2.7641e-01,  1.1592e+00,\n",
      "         2.6205e+00,  2.1163e+00,  6.1281e-02,  1.5057e+00,  2.9981e+00,\n",
      "        -8.5925e-01, -3.7862e-01,  1.1953e+00, -7.3633e-01, -4.1697e-01,\n",
      "         4.3558e-01,  3.0016e+00,  1.3345e+00, -5.4701e-01,  1.7301e+00,\n",
      "         2.7366e+00, -8.4843e-01, -8.4100e-01, -1.0986e+00, -2.9565e-04,\n",
      "         6.5130e-02,  1.5601e+00, -3.5154e-01,  2.1150e+00, -4.5721e-02])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "q_weight: tensor([ -5, -33,  -9,  ...,  -9, -12,  32], dtype=torch.int32) q_bias: tensor([ 1724,  1641,  -897,  -139, -3185,  1887,  2196,   -80,  -407, -3400,\n",
      "         2690, -1712,  -303,  -110,  -792,  -131,   -16, -2662, -1492,  -864,\n",
      "          -96,  -911,  2789,   -41,  -145,  1858,     7,   -97,  -139,   647,\n",
      "         -952,     3,    34,  -278,  -653,   -33,   -41,  1686,  2308, -1040,\n",
      "         2719,  1677,  1479,   868,  2528,   -53, -5228, -1073,  -425,  1291,\n",
      "        -1241,  -126,  4005, -2052,  2414, -5160,  2234,  -477, -2698,   973,\n",
      "         -222, -1985,  -735,    58,  2852,  1123,  1742,  -357,  1770,  -179,\n",
      "          407,   476,   481,  4873,  1155,  3848,  3786, -1294,   238,    -2,\n",
      "         2158, -1488,   898, -1349,  -415,   -64,  -173,  1192,  -229,  -134,\n",
      "         3097,  2228,  -136,  1400,   -82,   370,  -119,  1020,   -90, -1017,\n",
      "          -23,  2018,  1810,   572,   123, -1767, -1471,  -155,  2447,  3577,\n",
      "         -247,  2868,  3361,  1353,   551,    46,   840,  1639,  -434,  5173,\n",
      "           -2,   -71,  2344, -3667,  -645, -1919,  7604,   -98,  2987, -2102,\n",
      "         2178,    -1,   969,   -28,  1430,  2457,  1482,  -923,  -432,  2885,\n",
      "        -1160,    70,  -529,  -396,  1739,   -36,  -675, -7832,  3248,  -936,\n",
      "         3790, -3603,  -867,  3448,  1600,  -802,  -905,  1907, -2370, -1156,\n",
      "          -38,  -407, -1430,  9459,  -957,  3391,   -75,   845,  5036,  1616,\n",
      "         1695,  -775,  1972,  -321,  1559,  -568, -1945, -2436, -2069,  4553,\n",
      "         2777, -2079,   590,  1759,  1988,  2468,   -62, -1637,  -214,   384,\n",
      "         4213,   -14,  -276,  -198,  2189,  3110,    62, -1117,  -951,   -95,\n",
      "         3212, -3982,  -357,  -189,  -145,  -421, -1804,  1486,  -241,  2044,\n",
      "        -2742,  1381,   115,  -658,   726, -2679,  1310, -2842,  1329,  1991,\n",
      "        -1103,  2479,  -403,    70,  1552,  -408,  1796,  2788, -1154,  -585,\n",
      "         -774,  2438,  4093,   -31,  -480,  1715,  2382, -1831,  1318,  3032,\n",
      "         -978,  2202,  -359,   949,  3408,  2195,  -210,  2595,  6880,  1843,\n",
      "         -282,  1052, -1169,  1596,     1,    37,  1379, -2470,    20,  -427,\n",
      "         -354,  1650,  1332,  3612,   -89,  2308,   -23, -1689,  -166,  3789,\n",
      "         1730,  -105,  1967,  -748,  -600,  3084,  2176,  2555, -3809,  2297,\n",
      "         -955,  1411,  -234,  -583,  1557,  -324, -1575,  -826,  1948,   -40,\n",
      "         -156,  -173,  2237,  -317,   998,  1664,  -491,  2194,  2877,  4749,\n",
      "        -1592,  2420,  -354,  -620,  4354, -1070,  4333, -2672,  1467,  -741,\n",
      "        -1749,    11, -2316, -1357, -2161,   -53,   -21,  2414,  -358, -1182,\n",
      "          -74,  -474,   -82,  -568,  1939,  -198,  -172,  -422,  -320,  3306,\n",
      "         -172,  -874,     2,  2219,  2208,  2067,  2168,  -230, -1516, -1305,\n",
      "           38,   929,  -372,  3291,  1071,  1918,  5182,  1095,  -369,  4040,\n",
      "          238,  1836,  -937,  -597,   -93,  -614,  -356,  -822,  3289,  1040,\n",
      "          887, -7634,  2288,   844,  2016,  2035, -2725,  -188,   451, -1928,\n",
      "         1424,  -589, -2091,  2772,   -55,   687,   -32, -1318,  3040,  1214,\n",
      "         3103,  2473,  1877,  3013,  -847,   322,  2320,  2288,   208,  -466,\n",
      "         3083,   640,  -148,  1706,    -8,  2494,  2937,  -115,  -189,   -15,\n",
      "        -1034,  4577, -3774,  1450,  -512,  -464,  -171,  1632,  -399,    35,\n",
      "         -420,   245,   -49,   -75,  2711, -2481, -3228,  -102, -2097,  -125,\n",
      "         4632,   319,  -599, -1394,   -33,  -126, -2707,  1519,  -411,  1989,\n",
      "          -64,   978, -4728,  -976,  1695,  1625,  4171,  -219,  -548,  1792,\n",
      "         -165,    28,  -220,    16,  2609,    -4,  -246,  -678,  2869,  -778,\n",
      "         2201,  2137,  -116,  -195,  3529,   695,   769,    36,  3493,  3079,\n",
      "         -408,  -118,  3934,  -778,  -489,   218,  3255,  1902,  -378,  1351,\n",
      "         1681, -1407, -1173,   -30, -2422,    66,  2351,  -768,  1428,   -68],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(0.0007) tensor(0.9158)   bias tensor(-0.0001) tensor(0.0083)\n",
      "features.16.conv.6.weight features.16.conv.8\n",
      "torch.Size([80, 480, 1, 1]) conv_bias= torch.Size([80]) \n",
      "ascale= tensor([0.1316]) torch.Size([1]) \n",
      "wscale= tensor([0.0046, 0.0060, 0.0036, 0.0043, 0.0051, 0.0028, 0.0058, 0.0047, 0.0052,\n",
      "        0.0046, 0.0037, 0.0048, 0.0049, 0.0077, 0.0061, 0.0049, 0.0040, 0.0048,\n",
      "        0.0039, 0.0059, 0.0039, 0.0047, 0.0043, 0.0057, 0.0034, 0.0047, 0.0047,\n",
      "        0.0046, 0.0060, 0.0053, 0.0044, 0.0055, 0.0030, 0.0041, 0.0038, 0.0045,\n",
      "        0.0052, 0.0050, 0.0060, 0.0047, 0.0048, 0.0042, 0.0067, 0.0036, 0.0041,\n",
      "        0.0068, 0.0060, 0.0059, 0.0049, 0.0069, 0.0050, 0.0048, 0.0048, 0.0074,\n",
      "        0.0057, 0.0042, 0.0028, 0.0059, 0.0047, 0.0087, 0.0050, 0.0040, 0.0039,\n",
      "        0.0048, 0.0049, 0.0048, 0.0042, 0.0054, 0.0046, 0.0053, 0.0034, 0.0038,\n",
      "        0.0039, 0.0041, 0.0039, 0.0051, 0.0045, 0.0076, 0.0043, 0.0027]) torch.Size([80, 1, 1, 1]) \n",
      "oscale= tensor([0.1201]) torch.Size([1])\n",
      "###: M= tensor([0.0051, 0.0065, 0.0040, 0.0047, 0.0056, 0.0031, 0.0063, 0.0051, 0.0057,\n",
      "        0.0050, 0.0040, 0.0053, 0.0054, 0.0084, 0.0067, 0.0054, 0.0043, 0.0052,\n",
      "        0.0043, 0.0064, 0.0043, 0.0051, 0.0048, 0.0062, 0.0037, 0.0052, 0.0051,\n",
      "        0.0050, 0.0065, 0.0058, 0.0049, 0.0060, 0.0033, 0.0045, 0.0042, 0.0050,\n",
      "        0.0057, 0.0055, 0.0065, 0.0051, 0.0053, 0.0046, 0.0074, 0.0040, 0.0045,\n",
      "        0.0074, 0.0066, 0.0065, 0.0053, 0.0076, 0.0055, 0.0052, 0.0053, 0.0081,\n",
      "        0.0062, 0.0046, 0.0030, 0.0064, 0.0051, 0.0095, 0.0055, 0.0044, 0.0043,\n",
      "        0.0053, 0.0054, 0.0053, 0.0046, 0.0059, 0.0051, 0.0058, 0.0038, 0.0042,\n",
      "        0.0043, 0.0045, 0.0043, 0.0056, 0.0049, 0.0084, 0.0047, 0.0030])\n",
      "torch.Size([80, 480, 1, 1]) torch.Size([80])\n",
      "conv_weight: tensor([[-0.1184,  0.1422,  0.0452,  ..., -0.0477, -0.0962, -0.0188],\n",
      "        [ 0.1879, -0.0126,  0.0467,  ..., -0.0339, -0.0264, -0.0950],\n",
      "        [ 0.0113,  0.1828, -0.0429,  ...,  0.0128,  0.0036, -0.0146],\n",
      "        ...,\n",
      "        [-0.1245, -0.1057, -0.0205,  ...,  0.0118, -0.0818, -0.0646],\n",
      "        [ 0.2629, -0.1826, -0.1454,  ..., -0.0531, -0.0632,  0.1409],\n",
      "        [-0.0338, -0.0802, -0.1056,  ...,  0.0234,  0.0286,  0.1118]]) conv_bias: tensor([ 0.5329, -2.8953,  2.2479, -4.2329,  0.0213, -0.6219, -4.4977, -1.8536,\n",
      "        -1.1387, -0.4859,  0.4283,  0.6052, -2.0121, -1.5790,  5.1258,  2.2726,\n",
      "        -1.2523,  0.8597, -2.7325, -0.3684, -0.5853, -0.4939, -0.0229, -0.5254,\n",
      "         0.9496,  2.2158, -1.1495,  3.4504,  1.7966,  0.7688, -0.7502, -0.3997,\n",
      "         3.6064,  2.8078, -2.1569,  1.8982,  0.5377, -0.3632, -0.8265, -0.5356,\n",
      "        -0.3933, -1.3875, -0.6341, -2.6898, -1.9396, -1.9055,  2.0524, -1.2106,\n",
      "        -1.3796,  2.1139,  2.0371, -2.0918, -3.3080,  0.7946,  0.1482, -0.2071,\n",
      "        -0.4105,  2.1185, -1.5811,  4.5559,  0.5267, -2.2920, -1.9820, -1.1296,\n",
      "         2.7737, -2.5769,  1.6624,  1.4829, -1.4091, -0.2849, -1.7829, -2.2969,\n",
      "        -1.3329, -1.0936, -1.2399, -0.8897,  0.1005,  0.3328,  2.6773, -0.1400])\n",
      "torch.Size([80, 480, 1, 1]) torch.Size([80])\n",
      "q_weight: tensor([-26,  31,  10,  ...,   9,  10,  41], dtype=torch.int32) q_bias: tensor([  873, -3692,  4705, -7517,    32, -1684, -5915, -3000, -1649,  -803,\n",
      "          882,   953, -3119, -1559,  6376,  3497, -2402,  1374, -5308,  -476,\n",
      "        -1136,  -806,   -40,  -705,  2142,  3569, -1861,  5752,  2287,  1103,\n",
      "        -1285,  -553,  9091,  5172, -4295,  3177,   785,  -551, -1052,  -870,\n",
      "         -618, -2538,  -717, -5633, -3625, -2139,  2601, -1547, -2154,  2323,\n",
      "         3067, -3333, -5232,   814,   199,  -377, -1131,  2742, -2583,  3977,\n",
      "          798, -4342, -3862, -1791,  4302, -4060,  3000,  2103, -2303,  -408,\n",
      "        -3935, -4580, -2567, -2041, -2410, -1318,   170,   331,  4722,  -387],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-8.0812e-06) tensor(0.0043)   bias tensor(-2.9826e-05) tensor(0.0005)\n",
      "features.17.conv.0.weight features.17.conv.2\n",
      "torch.Size([480, 80, 1, 1]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.1201]) torch.Size([1]) \n",
      "wscale= tensor([2.1244e-03, 1.0017e-03, 8.7079e-04, 1.8080e-03, 2.1529e-03, 7.5446e-04,\n",
      "        3.2431e-03, 3.6509e-03, 1.1836e-03, 7.9569e-04, 7.5031e-04, 1.0843e-03,\n",
      "        9.6451e-04, 9.3022e-04, 3.5842e-03, 1.7302e-03, 1.6815e-03, 7.3505e-04,\n",
      "        8.5708e-04, 1.5041e-03, 1.3439e-03, 1.6477e-03, 5.3908e-04, 5.5139e-04,\n",
      "        8.5056e-04, 7.5489e-04, 1.1496e-03, 2.4132e-03, 8.3082e-04, 4.1791e-03,\n",
      "        1.5137e-03, 9.2183e-04, 8.0846e-04, 2.7944e-03, 1.1921e-07, 1.0194e-03,\n",
      "        1.1732e-03, 9.9980e-04, 3.1283e-03, 1.8461e-03, 7.9055e-04, 1.7572e-03,\n",
      "        1.3939e-03, 9.9641e-04, 1.7575e-03, 6.3606e-04, 1.6456e-03, 6.3245e-04,\n",
      "        3.3435e-03, 1.6773e-03, 1.2937e-03, 1.2261e-03, 3.2829e-03, 1.0191e-03,\n",
      "        7.7780e-04, 1.3755e-03, 1.4269e-03, 1.1925e-03, 1.0081e-03, 9.5612e-04,\n",
      "        3.0214e-03, 6.1802e-04, 1.1005e-03, 9.7259e-04, 8.6499e-04, 6.8898e-04,\n",
      "        3.2791e-03, 8.6499e-04, 9.1965e-04, 6.6559e-04, 7.9280e-04, 9.1837e-04,\n",
      "        1.3075e-03, 1.0388e-03, 7.6984e-04, 2.1669e-03, 2.2508e-03, 2.5559e-03,\n",
      "        1.4134e-03, 1.5362e-03, 2.3000e-03, 7.7798e-04, 2.5052e-03, 1.5180e-03,\n",
      "        9.2944e-04, 3.5569e-03, 1.2318e-03, 4.3553e-03, 7.0407e-04, 8.5283e-04,\n",
      "        1.5408e-03, 1.1521e-03, 1.0967e-03, 2.9713e-03, 1.0087e-03, 1.1728e-03,\n",
      "        1.6961e-03, 1.5037e-03, 1.5228e-03, 2.8346e-03, 1.1790e-03, 1.7673e-03,\n",
      "        2.6004e-03, 2.1058e-03, 7.6835e-04, 5.9435e-04, 3.6517e-03, 8.2123e-04,\n",
      "        1.1127e-03, 1.7429e-03, 7.1884e-04, 1.0970e-03, 8.6561e-04, 3.2884e-03,\n",
      "        1.2894e-03, 1.0031e-03, 3.2267e-03, 1.9595e-03, 1.0276e-03, 1.0702e-03,\n",
      "        6.2367e-04, 1.0531e-03, 7.9977e-04, 8.0464e-04, 3.0396e-03, 1.3573e-03,\n",
      "        6.1963e-04, 1.0746e-03, 1.6698e-03, 1.9513e-03, 1.2663e-03, 1.0866e-03,\n",
      "        1.5232e-03, 1.6383e-03, 9.9969e-04, 1.5340e-03, 2.7265e-03, 4.1823e-03,\n",
      "        5.4020e-04, 1.2644e-03, 1.0040e-03, 7.5310e-04, 7.5301e-04, 3.8544e-03,\n",
      "        1.2232e-03, 1.7808e-03, 7.3495e-04, 8.5411e-04, 6.4111e-04, 7.2434e-04,\n",
      "        2.0609e-03, 1.7406e-03, 1.4253e-03, 9.2093e-04, 1.1679e-03, 7.0717e-04,\n",
      "        9.1658e-04, 5.3127e-04, 7.1757e-04, 7.4667e-04, 2.9829e-03, 1.2778e-03,\n",
      "        2.3150e-03, 6.8970e-04, 7.6639e-04, 1.1444e-03, 3.2196e-03, 1.5652e-03,\n",
      "        6.6377e-04, 9.8082e-04, 7.9218e-04, 6.7791e-04, 9.5149e-04, 6.6559e-04,\n",
      "        1.0968e-03, 1.4615e-07, 6.6255e-04, 1.1343e-03, 1.8965e-03, 5.2157e-04,\n",
      "        3.3190e-03, 1.7820e-03, 1.3746e-03, 6.0232e-04, 1.2216e-03, 7.5112e-04,\n",
      "        9.3979e-04, 1.1112e-03, 9.5156e-04, 6.8215e-04, 1.5766e-03, 2.7594e-03,\n",
      "        9.9192e-04, 1.5007e-03, 1.5847e-03, 9.6179e-04, 1.8853e-03, 2.1301e-03,\n",
      "        6.9752e-04, 2.1368e-03, 1.3385e-03, 1.0348e-03, 5.2756e-04, 2.2901e-03,\n",
      "        1.3606e-03, 9.2704e-04, 6.7163e-04, 2.3436e-03, 1.0813e-03, 1.4993e-03,\n",
      "        9.8864e-04, 7.6356e-04, 6.8890e-04, 1.9265e-03, 1.1812e-03, 1.3399e-03,\n",
      "        5.8275e-03, 6.1811e-03, 1.3617e-03, 1.2292e-03, 1.1369e-03, 8.8334e-04,\n",
      "        1.4312e-03, 7.4729e-04, 2.5997e-03, 1.0695e-03, 6.6272e-04, 3.3136e-03,\n",
      "        1.6404e-03, 5.6957e-04, 2.9134e-03, 1.0141e-03, 1.5003e-03, 1.8263e-03,\n",
      "        1.1268e-03, 7.9230e-04, 3.7080e-03, 9.1373e-04, 9.4166e-04, 5.7426e-04,\n",
      "        4.5661e-03, 9.8066e-04, 6.8881e-04, 3.7131e-03, 9.0489e-04, 2.9558e-03,\n",
      "        7.4281e-04, 1.1738e-03, 1.6012e-03, 1.3800e-03, 1.0092e-03, 7.3717e-04,\n",
      "        1.4225e-03, 9.1413e-04, 1.5014e-03, 8.3241e-04, 3.5693e-03, 1.3715e-03,\n",
      "        1.5411e-03, 3.2440e-03, 2.8159e-03, 2.7489e-03, 5.9935e-04, 9.9747e-04,\n",
      "        1.7183e-03, 1.7353e-03, 2.9843e-03, 7.5373e-04, 9.1382e-04, 7.7297e-04,\n",
      "        7.2688e-04, 6.7892e-04, 1.5475e-03, 8.1256e-04, 1.5032e-03, 6.4350e-04,\n",
      "        1.1704e-03, 9.9950e-04, 9.8827e-04, 5.7372e-04, 3.1476e-04, 1.8162e-03,\n",
      "        1.9994e-03, 1.4631e-03, 9.7564e-04, 1.1573e-03, 5.0148e-04, 6.7641e-04,\n",
      "        1.1339e-03, 9.5425e-04, 1.1998e-03, 6.7496e-04, 1.5625e-03, 7.6370e-04,\n",
      "        2.4811e-03, 7.4599e-04, 2.1579e-03, 7.8806e-04, 8.3261e-04, 9.2233e-04,\n",
      "        3.9199e-03, 1.6438e-03, 1.0930e-03, 7.2356e-04, 1.1092e-03, 1.1330e-03,\n",
      "        8.9536e-04, 1.5203e-03, 1.2229e-03, 7.8803e-04, 8.2133e-04, 1.0244e-03,\n",
      "        1.5880e-03, 1.5506e-03, 6.5196e-04, 5.1770e-04, 5.7646e-04, 8.1579e-04,\n",
      "        1.1503e-03, 1.0402e-03, 3.7399e-03, 1.3995e-03, 1.2323e-03, 7.6590e-04,\n",
      "        1.4302e-03, 3.5120e-03, 1.2188e-03, 1.5588e-03, 1.1723e-03, 2.8015e-03,\n",
      "        3.2437e-03, 1.1175e-03, 9.1205e-04, 9.9793e-04, 1.4300e-03, 1.1120e-03,\n",
      "        1.4648e-03, 7.7352e-04, 7.6004e-04, 1.6582e-03, 1.0424e-03, 5.8662e-04,\n",
      "        8.3026e-04, 6.9586e-04, 8.1394e-04, 2.0732e-03, 4.3508e-03, 6.3009e-04,\n",
      "        1.0705e-03, 9.4891e-04, 1.2978e-03, 9.8471e-04, 9.6866e-04, 6.7746e-04,\n",
      "        9.1571e-04, 3.2079e-03, 1.4939e-03, 1.5217e-03, 8.6613e-04, 7.8116e-04,\n",
      "        8.5556e-04, 1.9604e-03, 7.5212e-04, 1.6072e-03, 1.0650e-03, 5.4418e-04,\n",
      "        9.2013e-04, 8.3192e-04, 2.8379e-03, 9.7702e-04, 4.7209e-03, 1.5490e-03,\n",
      "        1.2270e-03, 7.9229e-04, 7.1092e-04, 1.2784e-03, 1.2199e-03, 2.3981e-03,\n",
      "        3.4522e-03, 1.4255e-03, 7.5483e-04, 8.3936e-04, 1.2496e-03, 1.2282e-03,\n",
      "        1.5899e-03, 5.9258e-04, 8.5965e-04, 1.5499e-03, 3.5221e-03, 1.3458e-03,\n",
      "        9.8399e-04, 7.1756e-04, 2.2879e-03, 3.8722e-03, 1.2755e-03, 9.8114e-04,\n",
      "        2.7430e-03, 2.0552e-03, 9.1910e-04, 4.0045e-03, 1.0970e-03, 1.6914e-03,\n",
      "        1.2311e-03, 8.7784e-04, 2.9237e-03, 1.6877e-03, 7.9996e-04, 1.0544e-03,\n",
      "        6.9176e-04, 3.8893e-03, 8.6084e-04, 9.9384e-04, 1.2784e-03, 6.7787e-04,\n",
      "        6.3259e-04, 1.0910e-03, 1.2790e-03, 1.0606e-03, 7.9408e-04, 1.4409e-03,\n",
      "        1.3424e-03, 1.1913e-03, 4.2962e-03, 9.0630e-04, 9.4297e-04, 8.0902e-04,\n",
      "        1.3184e-03, 1.0999e-03, 9.5359e-04, 9.8451e-04, 1.0821e-03, 2.9100e-03,\n",
      "        1.1678e-03, 2.5136e-03, 9.0866e-04, 1.4031e-03, 7.6493e-04, 6.6831e-04,\n",
      "        1.4230e-03, 1.1919e-03, 1.9825e-03, 3.7622e-03, 5.5962e-04, 1.8280e-03,\n",
      "        1.1919e-03, 3.4444e-03, 8.2322e-04, 8.9069e-04, 1.8420e-03, 7.2730e-04,\n",
      "        7.6927e-04, 5.8932e-04, 8.0093e-04, 8.2869e-04, 4.4204e-04, 7.1118e-04,\n",
      "        2.6410e-03, 2.4011e-03, 1.4684e-03, 7.0674e-04, 9.6659e-04, 2.4321e-03,\n",
      "        7.6712e-04, 4.0669e-03, 1.5451e-03, 5.5148e-04, 9.5576e-04, 1.1355e-03,\n",
      "        2.2538e-03, 1.4411e-03, 7.9160e-04, 5.2111e-04, 1.1923e-03, 1.7411e-03,\n",
      "        7.7571e-04, 1.4373e-03, 7.0455e-04, 9.9877e-04, 1.1375e-03, 7.2501e-04]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.1613]) torch.Size([1])\n",
      "###: M= tensor([1.5823e-03, 7.4610e-04, 6.4860e-04, 1.3467e-03, 1.6036e-03, 5.6195e-04,\n",
      "        2.4156e-03, 2.7193e-03, 8.8156e-04, 5.9265e-04, 5.5886e-04, 8.0764e-04,\n",
      "        7.1840e-04, 6.9286e-04, 2.6696e-03, 1.2887e-03, 1.2525e-03, 5.4749e-04,\n",
      "        6.3839e-04, 1.1203e-03, 1.0010e-03, 1.2273e-03, 4.0152e-04, 4.1070e-04,\n",
      "        6.3353e-04, 5.6227e-04, 8.5629e-04, 1.7974e-03, 6.1883e-04, 3.1127e-03,\n",
      "        1.1274e-03, 6.8662e-04, 6.0217e-04, 2.0814e-03, 8.8791e-08, 7.5932e-04,\n",
      "        8.7381e-04, 7.4468e-04, 2.3300e-03, 1.3750e-03, 5.8883e-04, 1.3088e-03,\n",
      "        1.0383e-03, 7.4216e-04, 1.3091e-03, 4.7376e-04, 1.2257e-03, 4.7107e-04,\n",
      "        2.4903e-03, 1.2493e-03, 9.6358e-04, 9.1325e-04, 2.4452e-03, 7.5904e-04,\n",
      "        5.7933e-04, 1.0245e-03, 1.0628e-03, 8.8824e-04, 7.5085e-04, 7.1215e-04,\n",
      "        2.2504e-03, 4.6032e-04, 8.1972e-04, 7.2442e-04, 6.4427e-04, 5.1317e-04,\n",
      "        2.4424e-03, 6.4428e-04, 6.8499e-04, 4.9576e-04, 5.9050e-04, 6.8404e-04,\n",
      "        9.7388e-04, 7.7372e-04, 5.7340e-04, 1.6140e-03, 1.6765e-03, 1.9037e-03,\n",
      "        1.0528e-03, 1.1442e-03, 1.7131e-03, 5.7946e-04, 1.8659e-03, 1.1307e-03,\n",
      "        6.9228e-04, 2.6493e-03, 9.1750e-04, 3.2440e-03, 5.2441e-04, 6.3522e-04,\n",
      "        1.1477e-03, 8.5809e-04, 8.1686e-04, 2.2132e-03, 7.5130e-04, 8.7354e-04,\n",
      "        1.2633e-03, 1.1200e-03, 1.1342e-03, 2.1113e-03, 8.7814e-04, 1.3164e-03,\n",
      "        1.9369e-03, 1.5685e-03, 5.7230e-04, 4.4269e-04, 2.7199e-03, 6.1168e-04,\n",
      "        8.2881e-04, 1.2982e-03, 5.3542e-04, 8.1705e-04, 6.4473e-04, 2.4493e-03,\n",
      "        9.6039e-04, 7.4714e-04, 2.4034e-03, 1.4595e-03, 7.6543e-04, 7.9710e-04,\n",
      "        4.6453e-04, 7.8438e-04, 5.9569e-04, 5.9933e-04, 2.2640e-03, 1.0109e-03,\n",
      "        4.6152e-04, 8.0040e-04, 1.2437e-03, 1.4534e-03, 9.4321e-04, 8.0934e-04,\n",
      "        1.1345e-03, 1.2202e-03, 7.4460e-04, 1.1426e-03, 2.0308e-03, 3.1152e-03,\n",
      "        4.0236e-04, 9.4176e-04, 7.4780e-04, 5.6093e-04, 5.6087e-04, 2.8709e-03,\n",
      "        9.1105e-04, 1.3264e-03, 5.4742e-04, 6.3617e-04, 4.7752e-04, 5.3951e-04,\n",
      "        1.5351e-03, 1.2964e-03, 1.0616e-03, 6.8594e-04, 8.6988e-04, 5.2673e-04,\n",
      "        6.8270e-04, 3.9571e-04, 5.3447e-04, 5.5615e-04, 2.2218e-03, 9.5174e-04,\n",
      "        1.7243e-03, 5.1372e-04, 5.7084e-04, 8.5236e-04, 2.3981e-03, 1.1658e-03,\n",
      "        4.9440e-04, 7.3055e-04, 5.9005e-04, 5.0493e-04, 7.0870e-04, 4.9576e-04,\n",
      "        8.1693e-04, 1.0886e-07, 4.9349e-04, 8.4484e-04, 1.4126e-03, 3.8848e-04,\n",
      "        2.4721e-03, 1.3273e-03, 1.0238e-03, 4.4863e-04, 9.0992e-04, 5.5946e-04,\n",
      "        6.9999e-04, 8.2765e-04, 7.0875e-04, 5.0809e-04, 1.1743e-03, 2.0553e-03,\n",
      "        7.3882e-04, 1.1178e-03, 1.1803e-03, 7.1637e-04, 1.4043e-03, 1.5865e-03,\n",
      "        5.1954e-04, 1.5915e-03, 9.9695e-04, 7.7075e-04, 3.9294e-04, 1.7057e-03,\n",
      "        1.0134e-03, 6.9050e-04, 5.0025e-04, 1.7456e-03, 8.0540e-04, 1.1167e-03,\n",
      "        7.3637e-04, 5.6872e-04, 5.1311e-04, 1.4349e-03, 8.7980e-04, 9.9804e-04,\n",
      "        4.3405e-03, 4.6039e-03, 1.0143e-03, 9.1552e-04, 8.4684e-04, 6.5794e-04,\n",
      "        1.0660e-03, 5.5661e-04, 1.9364e-03, 7.9658e-04, 4.9362e-04, 2.4681e-03,\n",
      "        1.2219e-03, 4.2423e-04, 2.1700e-03, 7.5536e-04, 1.1175e-03, 1.3603e-03,\n",
      "        8.3927e-04, 5.9013e-04, 2.7619e-03, 6.8058e-04, 7.0138e-04, 4.2773e-04,\n",
      "        3.4010e-03, 7.3043e-04, 5.1305e-04, 2.7656e-03, 6.7399e-04, 2.2016e-03,\n",
      "        5.5327e-04, 8.7432e-04, 1.1926e-03, 1.0279e-03, 7.5171e-04, 5.4907e-04,\n",
      "        1.0595e-03, 6.8088e-04, 1.1183e-03, 6.2001e-04, 2.6585e-03, 1.0215e-03,\n",
      "        1.1479e-03, 2.4163e-03, 2.0974e-03, 2.0475e-03, 4.4642e-04, 7.4295e-04,\n",
      "        1.2798e-03, 1.2925e-03, 2.2228e-03, 5.6140e-04, 6.8065e-04, 5.7573e-04,\n",
      "        5.4141e-04, 5.0568e-04, 1.1526e-03, 6.0522e-04, 1.1196e-03, 4.7930e-04,\n",
      "        8.7173e-04, 7.4447e-04, 7.3610e-04, 4.2732e-04, 2.3444e-04, 1.3528e-03,\n",
      "        1.4892e-03, 1.0898e-03, 7.2669e-04, 8.6203e-04, 3.7352e-04, 5.0381e-04,\n",
      "        8.4457e-04, 7.1076e-04, 8.9369e-04, 5.0273e-04, 1.1638e-03, 5.6883e-04,\n",
      "        1.8480e-03, 5.5564e-04, 1.6073e-03, 5.8697e-04, 6.2016e-04, 6.8698e-04,\n",
      "        2.9196e-03, 1.2243e-03, 8.1414e-04, 5.3893e-04, 8.2615e-04, 8.4390e-04,\n",
      "        6.6690e-04, 1.1323e-03, 9.1085e-04, 5.8695e-04, 6.1175e-04, 7.6305e-04,\n",
      "        1.1828e-03, 1.1550e-03, 4.8560e-04, 3.8560e-04, 4.2937e-04, 6.0763e-04,\n",
      "        8.5675e-04, 7.7475e-04, 2.7856e-03, 1.0424e-03, 9.1787e-04, 5.7047e-04,\n",
      "        1.0653e-03, 2.6159e-03, 9.0778e-04, 1.1610e-03, 8.7314e-04, 2.0866e-03,\n",
      "        2.4161e-03, 8.3237e-04, 6.7933e-04, 7.4329e-04, 1.0651e-03, 8.2829e-04,\n",
      "        1.0911e-03, 5.7615e-04, 5.6610e-04, 1.2351e-03, 7.7642e-04, 4.3693e-04,\n",
      "        6.1840e-04, 5.1830e-04, 6.0625e-04, 1.5442e-03, 3.2407e-03, 4.6931e-04,\n",
      "        7.9737e-04, 7.0678e-04, 9.6668e-04, 7.3345e-04, 7.2149e-04, 5.0460e-04,\n",
      "        6.8205e-04, 2.3893e-03, 1.1127e-03, 1.1335e-03, 6.4512e-04, 5.8184e-04,\n",
      "        6.3725e-04, 1.4601e-03, 5.6021e-04, 1.1971e-03, 7.9328e-04, 4.0532e-04,\n",
      "        6.8535e-04, 6.1964e-04, 2.1138e-03, 7.2772e-04, 3.5163e-03, 1.1537e-03,\n",
      "        9.1393e-04, 5.9013e-04, 5.2952e-04, 9.5223e-04, 9.0863e-04, 1.7862e-03,\n",
      "        2.5713e-03, 1.0618e-03, 5.6223e-04, 6.2518e-04, 9.3075e-04, 9.1484e-04,\n",
      "        1.1842e-03, 4.4137e-04, 6.4030e-04, 1.1544e-03, 2.6234e-03, 1.0024e-03,\n",
      "        7.3291e-04, 5.3446e-04, 1.7041e-03, 2.8842e-03, 9.5005e-04, 7.3079e-04,\n",
      "        2.0431e-03, 1.5308e-03, 6.8458e-04, 2.9827e-03, 8.1711e-04, 1.2598e-03,\n",
      "        9.1693e-04, 6.5385e-04, 2.1777e-03, 1.2570e-03, 5.9584e-04, 7.8537e-04,\n",
      "        5.1525e-04, 2.8969e-03, 6.4119e-04, 7.4024e-04, 9.5217e-04, 5.0490e-04,\n",
      "        4.7117e-04, 8.1264e-04, 9.5266e-04, 7.9000e-04, 5.9146e-04, 1.0732e-03,\n",
      "        9.9989e-04, 8.8729e-04, 3.1999e-03, 6.7504e-04, 7.0236e-04, 6.0259e-04,\n",
      "        9.8199e-04, 8.1921e-04, 7.1027e-04, 7.3330e-04, 8.0598e-04, 2.1674e-03,\n",
      "        8.6985e-04, 1.8722e-03, 6.7680e-04, 1.0451e-03, 5.6975e-04, 4.9778e-04,\n",
      "        1.0599e-03, 8.8776e-04, 1.4766e-03, 2.8022e-03, 4.1682e-04, 1.3616e-03,\n",
      "        8.8780e-04, 2.5655e-03, 6.1317e-04, 6.6342e-04, 1.3720e-03, 5.4172e-04,\n",
      "        5.7298e-04, 4.3895e-04, 5.9656e-04, 6.1724e-04, 3.2925e-04, 5.2971e-04,\n",
      "        1.9671e-03, 1.7884e-03, 1.0937e-03, 5.2640e-04, 7.1995e-04, 1.8115e-03,\n",
      "        5.7138e-04, 3.0292e-03, 1.1508e-03, 4.1076e-04, 7.1188e-04, 8.4575e-04,\n",
      "        1.6787e-03, 1.0734e-03, 5.8961e-04, 3.8814e-04, 8.8806e-04, 1.2968e-03,\n",
      "        5.7777e-04, 1.0706e-03, 5.2477e-04, 7.4392e-04, 8.4722e-04, 5.4001e-04])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "conv_weight: tensor([[ 0.1191,  0.0317, -0.1226,  ...,  0.1777,  0.0517, -0.0141],\n",
      "        [-0.0784, -0.0290, -0.0618,  ..., -0.0333, -0.0351,  0.0500],\n",
      "        [ 0.0180,  0.0650,  0.0736,  ...,  0.0129, -0.0788, -0.0724],\n",
      "        ...,\n",
      "        [-0.0022, -0.0255,  0.0322,  ..., -0.0607, -0.0025, -0.0249],\n",
      "        [-0.0696, -0.0054, -0.0167,  ...,  0.0386,  0.0281,  0.0259],\n",
      "        [-0.0083,  0.0122, -0.0144,  ..., -0.0122, -0.0174,  0.0049]]) conv_bias: tensor([ 1.3678e+00, -6.0549e-01, -7.6176e-01, -2.6354e-01, -3.8708e-01,\n",
      "        -9.0896e-01,  2.8487e+00,  2.0253e+00, -8.1032e-01, -9.1156e-01,\n",
      "        -8.6133e-01,  3.5743e-01, -6.8689e-01, -5.7162e-01,  9.1069e-01,\n",
      "         6.8803e-01, -1.1780e-01, -9.1144e-01, -9.1695e-01,  2.3355e-01,\n",
      "        -8.6956e-01, -7.7971e-01, -9.8568e-01, -8.1389e-01, -7.0292e-01,\n",
      "        -8.7262e-01, -9.6498e-01,  2.0133e-01, -5.2003e-01,  1.2097e-01,\n",
      "        -5.9173e-01, -7.0122e-01, -8.5770e-01,  2.1203e-01, -9.1230e-04,\n",
      "        -7.4341e-01, -1.1486e+00, -7.6845e-01,  1.7610e-01, -5.5374e-01,\n",
      "        -6.2264e-01, -6.8099e-01, -7.4227e-01,  6.7709e-01, -5.8768e-01,\n",
      "        -9.0824e-01, -5.3270e-01, -8.8565e-01,  2.0872e-01, -8.8985e-01,\n",
      "        -7.4039e-01, -6.6642e-01,  4.5755e-01, -9.9010e-01, -8.2292e-01,\n",
      "        -7.7441e-01, -4.8704e-02, -8.8826e-01, -7.2767e-01, -8.4169e-01,\n",
      "        -9.7980e-02, -9.4394e-01,  8.2129e-01, -1.1330e+00, -6.1711e-01,\n",
      "        -9.1570e-01, -2.4155e-01, -8.7563e-01, -7.5719e-01, -7.9909e-01,\n",
      "        -9.9147e-01, -9.7328e-01, -5.4474e-01, -6.4114e-01, -9.7383e-01,\n",
      "        -7.6545e-01,  2.0842e+00,  2.7939e-01, -7.8769e-01, -7.0437e-01,\n",
      "        -3.5836e-01, -8.7889e-01,  3.3876e-01, -8.2336e-01, -9.0177e-01,\n",
      "         1.0953e-01, -6.0772e-01,  2.0692e-01,  6.2161e-01, -6.6707e-01,\n",
      "        -7.1722e-01, -6.0769e-01, -8.2924e-01, -8.1943e-02, -8.5871e-01,\n",
      "        -6.7671e-01,  3.9665e-01,  2.8203e+00, -3.7685e-01,  4.7404e-01,\n",
      "        -9.4708e-01, -5.3318e-01, -5.8759e-01, -8.5680e-01, -8.0919e-01,\n",
      "        -9.1537e-01, -8.9501e-02, -9.1069e-01, -7.8593e-01,  7.5581e-02,\n",
      "         1.2196e+00, -8.0578e-01, -9.4342e-01, -6.5265e-01, -6.5168e-01,\n",
      "        -6.6052e-01,  4.4104e+00,  2.5285e-02, -9.1462e-01, -5.7028e-01,\n",
      "        -6.8689e-01, -5.9594e-01, -8.3827e-01, -9.1730e-01,  7.1371e-02,\n",
      "        -7.3748e-01, -9.4842e-01, -9.9562e-01, -2.3830e-02,  6.8740e-01,\n",
      "         5.1538e-01, -4.6901e-01,  4.3274e-01, -4.9986e-01, -5.8229e-01,\n",
      "        -3.9182e-01, -1.0126e-01,  3.7495e+00, -1.0029e+00, -9.6475e-01,\n",
      "        -5.5629e-01, -6.8752e-01,  9.3944e-01,  1.9329e+00, -6.8660e-01,\n",
      "         3.9734e-01, -9.4202e-01, -4.1680e-01, -7.4792e-01, -7.1937e-01,\n",
      "         1.1381e+00,  1.8295e-01, -8.7012e-01, -9.8184e-01, -6.7614e-01,\n",
      "        -8.8153e-01, -7.3538e-01, -8.0396e-01, -8.2587e-01,  8.5839e-01,\n",
      "        -3.1775e-01, -5.9417e-01,  1.0820e+00, -9.5784e-01, -8.9984e-01,\n",
      "        -7.3925e-01, -4.7775e-01, -7.2729e-01, -8.6686e-01, -6.4237e-01,\n",
      "        -8.8204e-01, -8.6049e-01, -7.8508e-01, -9.1272e-01,  7.1724e-01,\n",
      "        -1.0068e-03, -8.4025e-01, -8.3833e-01, -2.9177e-01, -1.0081e+00,\n",
      "         1.2894e+00,  4.4566e-01,  3.2729e-01, -8.1258e-01,  2.6896e-01,\n",
      "        -8.3199e-01, -8.6393e-01, -7.7395e-01, -8.8548e-01, -9.7402e-01,\n",
      "        -5.7869e-01,  3.4882e-01, -7.0451e-01, -8.6883e-01, -6.9075e-01,\n",
      "        -7.2028e-01, -5.3123e-01,  1.2871e-01, -8.0707e-01,  2.3438e+00,\n",
      "        -9.8851e-01, -7.7016e-01, -7.9800e-01,  2.7279e-03, -5.7410e-01,\n",
      "        -5.8758e-01, -8.6772e-01,  5.5375e-01, -8.6485e-01, -6.9904e-01,\n",
      "        -8.6048e-01,  5.6350e-01, -7.9905e-01, -3.8408e-01, -8.4468e-01,\n",
      "        -1.3752e-01, -2.9629e-01,  5.0827e+00, -7.4376e-01, -3.8625e-01,\n",
      "        -7.5124e-01,  9.5001e-01, -7.9228e-01, -9.4996e-01, -3.2418e-01,\n",
      "         7.2749e-01, -1.0419e+00, -4.5300e-01, -9.0626e-01,  1.2578e+00,\n",
      "         1.2182e-02, -8.1983e-01, -6.7161e-01, -6.4863e-01,  6.5449e-01,\n",
      "        -9.3552e-01,  2.1001e+00, -8.2025e-01, -8.2364e-01, -9.4724e-01,\n",
      "        -3.9140e-01, -8.2631e-01, -8.4210e-01,  2.0648e+00, -7.8088e-01,\n",
      "         1.3215e+00, -6.2093e-01, -6.8461e-01, -8.0968e-01, -7.8194e-01,\n",
      "         7.6787e-01,  8.5573e-01,  3.9938e-01, -8.9507e-01, -5.1663e-01,\n",
      "        -7.8438e-01, -6.2334e-01, -3.7374e-01, -3.9758e-01, -8.3346e-01,\n",
      "        -7.9960e-01,  1.3329e-01, -7.9304e-01, -8.2171e-01, -4.8637e-01,\n",
      "         1.4159e+00, -2.0857e-01, -7.6306e-01, -8.4658e-01, -8.5276e-01,\n",
      "        -9.2317e-01, -8.5397e-01, -1.2860e-01, -9.6810e-01,  8.5617e-02,\n",
      "        -8.8625e-01, -6.8980e-01, -7.2181e-01, -9.6452e-01, -8.6765e-01,\n",
      "        -9.3248e-01, -5.4263e-01,  7.4252e-02, -6.9447e-01, -9.0131e-01,\n",
      "        -7.0431e-01, -6.9633e-01, -1.0437e+00, -6.4806e-01, -7.5337e-01,\n",
      "        -7.2438e-01, -9.4663e-01, -4.1113e-01, -8.6185e-01, -5.0270e-01,\n",
      "        -8.6578e-01, -7.2749e-01, -7.8340e-01, -4.6429e-01, -6.3240e-01,\n",
      "         4.7176e-01,  1.4685e-01, -9.3219e-01, -7.5079e-01, -7.1396e-01,\n",
      "        -7.7821e-01,  1.6439e+00, -6.7737e-01, -6.9208e-01, -8.2591e-01,\n",
      "        -9.1538e-01, -7.8620e-01, -3.6205e-01, -7.3614e-01, -8.5940e-01,\n",
      "        -7.3332e-01, -9.5308e-01, -5.3322e-01, -5.3892e-01, -9.1928e-01,\n",
      "         4.7022e-01,  7.1058e-01, -4.2615e-01, -7.8227e-01, -6.5492e-01,\n",
      "         2.0073e-01, -8.1094e-01,  1.2515e-01, -7.3816e-01,  2.2446e-01,\n",
      "         1.9276e+00, -4.0963e-01, -5.9470e-01, -6.5068e-01, -7.9321e-01,\n",
      "        -6.0661e-01,  5.8638e-01, -9.4013e-01, -7.2535e-01, -5.8120e-01,\n",
      "         7.2490e-01, -7.9166e-01, -8.7498e-01, -6.5543e-01, -7.0860e-01,\n",
      "         8.1455e-01,  7.1263e-01, -9.3867e-01, -6.9002e-01, -7.4101e-01,\n",
      "        -8.1562e-01, -8.1886e-01,  7.1470e-01, -9.5033e-01, -8.4029e-01,\n",
      "         2.1667e+00, -3.0282e-01, -4.8478e-01, -6.1947e-01, -9.0187e-01,\n",
      "        -5.7999e-01, -3.3051e-01, -7.8036e-01, -6.9956e-01, -9.6267e-01,\n",
      "        -7.6837e-01, -8.4226e-01,  1.3414e+00, -6.2486e-01, -7.5305e-01,\n",
      "         3.5332e-01, -2.1521e-01, -8.1514e-01, -8.4582e-01, -7.3792e-01,\n",
      "        -2.8775e-01, -8.3518e-01,  1.5140e-01,  8.9055e-01,  4.4458e-01,\n",
      "        -5.0562e-01, -8.7334e-01, -5.6983e-01, -8.8238e-01, -3.8356e-01,\n",
      "        -7.5124e-01, -8.4261e-01,  4.8343e-01,  4.1100e+00, -5.8650e-01,\n",
      "        -8.2687e-01, -6.8144e-01,  2.9158e+00, -9.1526e-02, -6.6844e-01,\n",
      "        -9.1066e-01,  4.1256e-01,  6.8316e-01, -7.4922e-01, -5.0961e-01,\n",
      "        -7.3076e-01, -7.8255e-01, -6.6611e-01, -8.8559e-01,  3.6954e-01,\n",
      "        -9.7055e-01, -8.8414e-01, -9.4687e-01, -8.8368e-01,  1.9309e-01,\n",
      "         1.5138e+00, -8.4422e-01, -6.4960e-01, -1.0091e+00, -8.4203e-01,\n",
      "        -8.4605e-01,  8.5847e-01,  2.4836e+00, -6.2056e-01, -6.2513e-01,\n",
      "        -8.6528e-01, -1.0376e+00,  2.3241e-01, -5.2230e-01, -8.1984e-01,\n",
      "        -9.2464e-01, -7.5736e-01, -4.5249e-01, -8.3578e-01, -3.7938e-01,\n",
      "        -3.2919e-01,  5.9464e-01, -8.7486e-01,  2.8482e+00, -7.8335e-01,\n",
      "        -2.7699e-01, -8.7788e-01, -8.6442e-01, -6.3274e-01, -6.2136e-01,\n",
      "        -8.7669e-01, -5.1273e-01, -9.2221e-01,  5.3140e-01, -9.0132e-01,\n",
      "         3.4787e-02, -9.2429e-01, -8.9664e-01,  1.0912e+00, -7.8367e-01,\n",
      "         7.0197e-01, -8.1823e-01, -9.4021e-01, -6.6373e-01, -8.9095e-01,\n",
      "        -8.6610e-01,  6.3906e-01, -9.8959e-01, -4.9768e-01, -8.3561e-01,\n",
      "        -8.3464e-01,  4.5515e-01, -8.1868e-01, -8.7093e-01, -7.1473e-01,\n",
      "        -9.9438e-01, -9.2089e-01, -7.4757e-01, -2.7876e-01, -7.8281e-01,\n",
      "        -8.6358e-01, -7.0011e-01, -8.8364e-01, -6.8917e-01,  9.1427e-01,\n",
      "        -3.0230e-01, -7.6890e-01, -4.3432e-01, -8.3585e-01, -8.5619e-01])\n",
      "torch.Size([480, 80, 1, 1]) torch.Size([480])\n",
      "q_weight: tensor([ 56,  15, -58,  ..., -17, -24,   7], dtype=torch.int32) q_bias: tensor([  5360,  -5032,  -7283,  -1214,  -1497, -10031,   7313,   4618,  -5700,\n",
      "         -9538,  -9558,   2744,  -5929,  -5116,   2115,   3311,   -583, -10324,\n",
      "         -8907,   1293,  -5387,  -3940, -15223, -12289,  -6880,  -9624,  -6988,\n",
      "           695,  -5211,    241,  -3255,  -6333,  -8833,    632, -63715,  -6071,\n",
      "         -8151,  -6399,    469,  -2497,  -6557,  -3227,  -4433,   5658,  -2784,\n",
      "        -11888,  -2695, -11659,    520,  -4417,  -4765,  -4525,   1160,  -8089,\n",
      "         -8809,  -4687,   -284,  -6201,  -6010,  -7329,   -270, -12716,   6213,\n",
      "         -9699,  -5940, -11065,   -613,  -8428,  -6855,  -9995, -10412,  -8823,\n",
      "         -3469,  -5139, -10532,  -2941,   7709,    910,  -4640,  -3817,  -1297,\n",
      "         -9406,   1126,  -4516,  -8078,    256,  -4107,    396,   7351,  -6512,\n",
      "         -3875,  -4392,  -6295,   -230,  -7088,  -4804,   1947,  15616,  -2060,\n",
      "          1392,  -6688,  -2512,  -1881,  -3387,  -8768, -12823,   -204,  -9233,\n",
      "         -5880,    361,  14125,  -6116,  -9074,  -1652,  -4208,  -5482,  11380,\n",
      "           107,  -7410,  -4437,  -9170,  -4711,  -8726,  -9491,    195,  -4524,\n",
      "        -12743,  -7714,   -119,   2933,   3388,  -3594,   2365,  -2540,  -4849,\n",
      "         -2127,   -309,   7464, -15457,  -6353,  -4613,  -7601,  10387,   4175,\n",
      "         -4673,   1858, -10671,  -4063,  -9713,  -8269,   4597,    875,  -5083,\n",
      "         -8876,  -4820, -10378,  -6680, -12599,  -9582,   9571,   -887,  -3871,\n",
      "          3891, -11562,  -9775,  -5378,  -1235,  -3869, -10873,  -5453,  -9270,\n",
      "        -10568,  -6870, -11417,   5444, -57352, -10559,  -6153,  -1281, -16092,\n",
      "          3234,   2082,   1982, -11232,   1833,  -9222,  -7654,  -5799,  -7747,\n",
      "        -11888,  -3056,   1052,  -5913,  -4820,  -3629,  -6235,  -2346,    503,\n",
      "         -9633,   9132,  -6149,  -6196, -12593,     10,  -3513,  -5277, -10756,\n",
      "          1967,  -6659,  -3882,  -7246,   6144,  -9657,  -1660,  -5954,   -854,\n",
      "          -423,   6846,  -4547,  -2616,  -5501,   8954,  -4609, -10584,  -1038,\n",
      "          5663, -13089,  -1138,  -4599,  18386,     35,  -6730,  -3727,  -2957,\n",
      "          4836,  -9831,   4715,  -7474,  -7282, -13733,   -714,  -7015, -10178,\n",
      "          4630,  -7185,   3722,  -6960,  -4856,  -4210,  -4717,   6335,   9665,\n",
      "          2338,  -8152,  -2865,  -7845,  -1454,  -2269,  -2148,  -2139,  -2364,\n",
      "           404, -11016,  -6859,  -2357,   6793,   -582,  -8429,  -7713,  -9185,\n",
      "        -10574, -10472,   -692,  -9919,    474, -11466,  -4907,  -6013,  -8125,\n",
      "        -12591, -24665,  -2487,    309,  -3952,  -7691,  -5067, -11561, -12847,\n",
      "         -4758,  -6573,  -5026, -11677,  -2191,  -9396,  -1687,  -9663,  -2807,\n",
      "         -8276,  -4643,  -5708,   1002,    744,  -7100,  -8639,  -5359,  -5719,\n",
      "         15286,  -3710,  -4712,  -8726,  -9279,  -6389,  -1898,  -3952, -10975,\n",
      "        -11793, -13765,  -5442,  -3901,  -7358,   1047,   4227,  -2879,  -8504,\n",
      "         -3812,    476,  -5540,    668,  -5243,    667,   4948,  -3052,  -5429,\n",
      "         -5429,  -4618,  -4542,   3333, -10119,  -7946,  -2918,   5790, -11236,\n",
      "         -8774,  -7842,  -7248,   3271,   1364, -12403,  -5366,  -6502,  -5232,\n",
      "         -6923,   6143, -11679,  -7640,   5624,  -1688,  -2652,  -5955,  -9612,\n",
      "         -5644,  -1404,  -8638,  -3624,  -7525, -11756,  -7621,  13425,  -1833,\n",
      "         -6417,    623,  -1157,  -5531,  -8888,  -8642,  -1874,  -5700,    526,\n",
      "          2148,   2597,  -5577,  -8663,  -3797,  -5981,  -2009, -10555,  -8161,\n",
      "          2597,   9715,  -3628,  -6996,  -7907,  10611,   -197,  -4363,  -7728,\n",
      "          1252,   2767,  -6787,  -1060,  -5546,  -3852,  -4505,  -8399,   1052,\n",
      "         -4788,  -9202,  -7476, -10635,    413,  14641,  -7072,  -4231, -12394,\n",
      "        -11082,  -6456,   5588,  19495,  -6506,  -3612,  -5366,  -7251,    450,\n",
      "         -4798,  -7238,  -9515,  -4783,  -3425,  -7297,  -3208,  -2533,   1701,\n",
      "         -6237,   9434,  -7177,  -1644,  -9555, -10769,  -3702,  -4340,  -3682,\n",
      "         -1135, -13720,   2420,  -6296,     84,  -9348,  -8381,   4932,  -8971,\n",
      "          7597, -11560,  -9773,  -6668, -16781, -10139,   2015,  -3431,  -2822,\n",
      "         -9844,  -7189,   1558,  -8885,  -1783,  -3851, -15012,  -8022,  -5481,\n",
      "         -1030,  -4522,  -9083, -11185,  -6170,  -3296,   9813,  -1751,  -9086,\n",
      "         -3620,  -6118,  -9832], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-4.9006e-07) tensor(0.0031)   bias tensor(3.0853e-06) tensor(0.0002)\n",
      "features.17.conv.3.weight features.17.conv.5\n",
      "torch.Size([480, 1, 3, 3]) conv_bias= torch.Size([480]) \n",
      "ascale= tensor([0.1572]) torch.Size([1]) \n",
      "wscale= tensor([1.6375e-02, 2.2418e-02, 2.8327e-02, 1.0647e-02, 9.3247e-03, 3.2302e-02,\n",
      "        1.6262e-02, 1.2098e-02, 1.6943e-02, 3.7939e-02, 9.2542e-02, 7.5913e-03,\n",
      "        2.4307e-02, 2.0623e-02, 4.9234e-03, 1.3873e-02, 6.7254e-03, 3.0324e-02,\n",
      "        5.3770e-01, 5.0307e-03, 5.9743e-02, 1.5511e-02, 8.0399e-02, 8.3843e-01,\n",
      "        2.5655e-02, 3.8646e-02, 5.9176e-02, 8.9674e-03, 1.6192e-02, 3.0393e-03,\n",
      "        8.8446e-03, 3.5347e-02, 3.5511e-02, 8.1143e-03, 1.3183e-06, 1.8855e-02,\n",
      "        2.3506e-02, 3.1715e-02, 7.6866e-03, 1.2334e-02, 1.8960e-02, 1.3096e-02,\n",
      "        2.1772e-02, 9.5367e-03, 1.5863e-02, 6.6690e-02, 9.7978e-03, 3.6739e-02,\n",
      "        8.5334e-03, 2.5523e-02, 1.4478e-02, 1.7857e-02, 7.8693e-03, 5.3890e-02,\n",
      "        3.9401e-02, 1.8575e-02, 6.0730e-03, 1.2506e-02, 1.9860e-02, 3.3361e-02,\n",
      "        6.8622e-03, 4.8395e-02, 1.0499e-02, 3.9602e-02, 1.3574e-02, 3.2389e-02,\n",
      "        9.4750e-03, 5.0423e-02, 6.2419e-02, 3.3152e-02, 4.3502e-02, 3.9917e-02,\n",
      "        3.0539e-02, 2.7522e-02, 3.0612e-02, 2.2275e-02, 1.6383e-02, 6.5448e-03,\n",
      "        3.0068e-02, 1.4950e-02, 1.6166e-02, 7.1639e-02, 5.6741e-03, 2.0921e-02,\n",
      "        5.1434e-02, 9.5018e-03, 1.2844e-02, 6.6446e-03, 1.3191e-02, 2.0960e-02,\n",
      "        2.1039e-02, 1.7512e-02, 4.3471e-02, 1.0203e-02, 3.5337e-02, 1.8119e-02,\n",
      "        4.4852e-03, 2.2540e-02, 1.6022e-02, 7.2768e-03, 3.3685e-02, 6.2594e-03,\n",
      "        8.5065e-03, 1.0248e-02, 5.0438e-02, 5.2063e-02, 6.4863e-03, 5.0426e-02,\n",
      "        1.4320e-02, 7.6904e-03, 1.1481e-02, 5.1893e-02, 3.5739e-02, 1.5606e-02,\n",
      "        1.8660e-02, 1.0613e-02, 2.5128e-02, 5.1055e-03, 2.8822e-02, 7.2485e-03,\n",
      "        3.7726e-02, 2.5973e-02, 3.9986e-02, 1.8146e-01, 4.2404e-03, 2.9911e-02,\n",
      "        2.5109e-02, 3.1995e-02, 7.2318e-03, 1.3476e-02, 7.4076e-03, 9.1169e-03,\n",
      "        5.2289e-03, 1.2974e-02, 2.6953e-02, 1.2729e-02, 7.5400e-03, 2.9036e-02,\n",
      "        7.2187e-02, 4.1383e-02, 2.3838e-02, 2.1748e-02, 9.2780e-03, 1.3430e-02,\n",
      "        2.4728e-02, 5.9262e-03, 2.8375e-02, 2.1451e-02, 2.0747e-02, 4.4873e-02,\n",
      "        1.0045e-02, 5.6480e-03, 2.0367e-02, 2.1006e-02, 1.3361e-02, 3.7240e-02,\n",
      "        1.2077e-02, 9.2504e-02, 7.6663e-02, 1.3180e-02, 6.4577e-03, 1.5656e-02,\n",
      "        1.4642e-02, 5.8102e-02, 5.1704e-02, 3.0649e-02, 7.8496e-03, 1.4874e-02,\n",
      "        8.0230e-02, 1.6234e-02, 3.4407e-02, 6.5395e-02, 2.8976e-02, 1.0323e-01,\n",
      "        1.0373e-02, 7.2984e-07, 8.2080e-02, 2.6283e-02, 1.0503e-02, 6.4532e-02,\n",
      "        9.5959e-03, 4.9904e-03, 8.3238e-03, 4.0204e-02, 4.6258e-03, 2.7814e-02,\n",
      "        3.1235e-02, 2.0730e-02, 2.7699e-02, 6.9446e-02, 2.0998e-02, 6.0958e-03,\n",
      "        2.9532e-02, 2.0603e-02, 2.5011e-02, 4.0791e-02, 1.7075e-02, 4.5064e-03,\n",
      "        5.8890e-02, 1.8971e-02, 2.1679e-02, 1.0610e-02, 8.9697e-01, 6.1458e-03,\n",
      "        1.0323e-02, 1.8282e-02, 5.5092e-02, 8.5744e-03, 2.6021e-02, 1.3909e-02,\n",
      "        3.1519e-02, 6.6840e-03, 2.6342e-02, 6.5110e-03, 4.6347e-02, 6.2190e-03,\n",
      "        6.7691e-03, 3.1182e-02, 3.2221e-02, 3.1827e-02, 1.6851e-02, 1.0105e-02,\n",
      "        1.9291e-02, 3.4104e-02, 9.5757e-03, 8.6700e-03, 5.2901e-02, 1.0052e-02,\n",
      "        2.5675e-02, 1.3526e-02, 4.6810e-03, 5.7038e-02, 1.8161e-02, 2.5362e-02,\n",
      "        6.7123e-03, 3.5618e-02, 1.5246e-02, 2.6071e-02, 3.2387e-02, 6.0385e-02,\n",
      "        7.2608e-03, 3.7299e-02, 3.1859e-02, 1.7742e-02, 3.6382e-02, 1.6063e-02,\n",
      "        3.3750e-01, 1.6717e-02, 4.3180e-02, 1.5899e-02, 5.6095e-03, 7.7384e-03,\n",
      "        1.1355e-02, 3.9025e-02, 1.1033e-02, 2.9049e-02, 1.3173e-02, 1.6195e-02,\n",
      "        1.1204e-02, 6.7431e-03, 9.1878e-03, 8.7473e-03, 2.9214e-02, 4.5137e-02,\n",
      "        1.3826e-02, 1.4459e-02, 6.6039e-03, 4.1006e-02, 3.9419e-02, 4.0397e-02,\n",
      "        1.0202e-01, 4.0408e-02, 7.6161e-03, 4.8024e-02, 8.6486e-03, 4.9040e-02,\n",
      "        2.6620e-02, 3.4640e-02, 2.9099e-02, 8.2199e-02, 2.4415e+00, 1.4826e-02,\n",
      "        6.7928e-03, 2.8437e-02, 2.4432e-02, 1.7398e-02, 3.9636e-02, 5.8465e-02,\n",
      "        1.5762e-02, 1.8762e-02, 1.7553e-02, 4.0122e-02, 2.0006e-02, 3.0030e-02,\n",
      "        8.8398e-03, 4.3479e-02, 2.2271e-02, 2.4948e-02, 1.8018e-02, 1.0629e-02,\n",
      "        9.4372e-03, 4.4070e-03, 3.4260e-02, 2.9775e-02, 3.7806e-02, 3.4338e-02,\n",
      "        1.6876e-02, 1.9658e-02, 2.3906e-02, 2.5650e-02, 3.2614e-02, 2.4125e-02,\n",
      "        2.1639e-02, 1.3129e-02, 5.0551e-02, 3.5185e-02, 8.1511e-02, 1.6384e-02,\n",
      "        3.2816e-02, 1.6277e-02, 6.7096e-03, 5.9085e-03, 1.5219e-02, 4.1205e-02,\n",
      "        2.4821e-02, 8.5449e-03, 4.6377e-02, 5.1599e-03, 1.5191e-02, 7.0317e-03,\n",
      "        1.2629e-02, 1.2298e-02, 3.6365e-02, 2.1682e-02, 4.9194e-02, 3.9731e-02,\n",
      "        4.5851e-03, 6.5483e-02, 2.7855e-02, 1.1969e-02, 8.5849e-03, 4.3223e-02,\n",
      "        2.9363e-02, 2.2484e-02, 4.4913e-02, 1.4117e-02, 8.6076e-03, 4.2882e-01,\n",
      "        2.4460e-02, 3.4883e-02, 3.3419e-02, 1.5840e-02, 1.0701e-02, 3.3400e-02,\n",
      "        2.7010e-02, 1.7562e-02, 1.0736e-02, 2.1695e-02, 1.7643e-02, 6.8500e-02,\n",
      "        1.7683e-02, 1.4785e-02, 2.1001e-02, 1.9295e-02, 2.3087e-02, 1.9489e-01,\n",
      "        3.2576e-02, 1.4153e-02, 1.7891e-02, 1.2165e-02, 6.2106e-03, 1.0128e-02,\n",
      "        2.6362e-02, 3.6791e-02, 2.3779e-02, 8.7853e-03, 2.2145e-02, 4.1910e-03,\n",
      "        1.1548e-02, 9.9684e-03, 1.8269e-02, 4.2934e-02, 2.7198e-02, 3.6306e-02,\n",
      "        1.0852e-02, 3.1169e-02, 1.9659e-02, 7.3329e-03, 2.9765e-02, 3.4377e-02,\n",
      "        1.8614e-02, 1.6658e-02, 2.3032e-02, 7.7831e-03, 2.2224e-02, 3.7617e-02,\n",
      "        4.4411e-03, 5.8089e-03, 3.0334e-02, 9.6030e-03, 2.5824e-02, 3.8510e-02,\n",
      "        2.2108e-02, 2.9760e-02, 6.6635e-03, 3.0148e-02, 3.5673e-02, 1.9800e-02,\n",
      "        7.1421e-02, 5.7229e-03, 1.5707e-02, 3.3082e-02, 3.7557e-02, 3.4508e-02,\n",
      "        6.2708e-02, 5.8398e-02, 1.5159e-02, 3.6410e-02, 3.5692e-02, 1.9268e-02,\n",
      "        2.3094e-02, 2.6489e-02, 6.0321e-03, 1.5548e-02, 2.2656e-02, 4.0491e-02,\n",
      "        2.4410e-02, 1.7919e-02, 4.2884e-02, 1.6158e-02, 1.2588e-02, 5.1463e-03,\n",
      "        2.5288e-02, 2.2764e-02, 1.7614e-02, 8.0370e-03, 9.9777e-02, 2.8600e-02,\n",
      "        2.9220e-02, 1.8283e-02, 1.3845e-02, 1.3611e-02, 1.2106e-01, 5.6699e-03,\n",
      "        2.3429e-02, 1.0435e-02, 4.0830e-02, 4.1848e-02, 9.6583e-03, 2.4141e-02,\n",
      "        1.6025e-02, 7.2702e-02, 2.5750e-02, 2.3030e-02, 6.3684e-02, 1.4510e-01,\n",
      "        1.2443e-02, 2.0466e-02, 9.8167e-03, 3.0984e-02, 1.5530e-02, 4.4805e-03,\n",
      "        7.4871e-02, 7.5410e-03, 3.5862e-02, 4.0934e-02, 2.8856e-02, 2.1416e-02,\n",
      "        6.7614e-03, 4.3196e-02, 4.5711e-02, 4.0870e-02, 3.4060e-02, 2.2778e-02,\n",
      "        1.0368e-02, 8.3430e-03, 4.3218e-02, 1.3452e-02, 1.9567e-02, 3.0342e-02]) torch.Size([480, 1, 1, 1]) \n",
      "oscale= tensor([0.2314]) torch.Size([1])\n",
      "###: M= tensor([1.1123e-02, 1.5227e-02, 1.9241e-02, 7.2323e-03, 6.3338e-03, 2.1942e-02,\n",
      "        1.1046e-02, 8.2173e-03, 1.1509e-02, 2.5770e-02, 6.2859e-02, 5.1564e-03,\n",
      "        1.6511e-02, 1.4008e-02, 3.3443e-03, 9.4230e-03, 4.5682e-03, 2.0598e-02,\n",
      "        3.6523e-01, 3.4171e-03, 4.0581e-02, 1.0536e-02, 5.4611e-02, 5.6951e-01,\n",
      "        1.7426e-02, 2.6250e-02, 4.0195e-02, 6.0911e-03, 1.0998e-02, 2.0645e-03,\n",
      "        6.0077e-03, 2.4009e-02, 2.4121e-02, 5.5116e-03, 8.9545e-07, 1.2807e-02,\n",
      "        1.5966e-02, 2.1542e-02, 5.2211e-03, 8.3778e-03, 1.2879e-02, 8.8956e-03,\n",
      "        1.4789e-02, 6.4779e-03, 1.0775e-02, 4.5299e-02, 6.6551e-03, 2.4955e-02,\n",
      "        5.7964e-03, 1.7337e-02, 9.8343e-03, 1.2129e-02, 5.3452e-03, 3.6605e-02,\n",
      "        2.6763e-02, 1.2617e-02, 4.1251e-03, 8.4947e-03, 1.3490e-02, 2.2660e-02,\n",
      "        4.6612e-03, 3.2872e-02, 7.1317e-03, 2.6900e-02, 9.2205e-03, 2.2001e-02,\n",
      "        6.4359e-03, 3.4250e-02, 4.2398e-02, 2.2519e-02, 2.9549e-02, 2.7113e-02,\n",
      "        2.0744e-02, 1.8695e-02, 2.0793e-02, 1.5130e-02, 1.1128e-02, 4.4455e-03,\n",
      "        2.0424e-02, 1.0155e-02, 1.0981e-02, 4.8661e-02, 3.8541e-03, 1.4211e-02,\n",
      "        3.4937e-02, 6.4541e-03, 8.7242e-03, 4.5134e-03, 8.9597e-03, 1.4237e-02,\n",
      "        1.4291e-02, 1.1895e-02, 2.9528e-02, 6.9302e-03, 2.4003e-02, 1.2308e-02,\n",
      "        3.0466e-03, 1.5311e-02, 1.0883e-02, 4.9428e-03, 2.2881e-02, 4.2517e-03,\n",
      "        5.7780e-03, 6.9611e-03, 3.4260e-02, 3.5364e-02, 4.4059e-03, 3.4252e-02,\n",
      "        9.7267e-03, 5.2237e-03, 7.7986e-03, 3.5248e-02, 2.4276e-02, 1.0600e-02,\n",
      "        1.2675e-02, 7.2087e-03, 1.7068e-02, 3.4679e-03, 1.9577e-02, 4.9235e-03,\n",
      "        2.5625e-02, 1.7642e-02, 2.7160e-02, 1.2325e-01, 2.8803e-03, 2.0317e-02,\n",
      "        1.7056e-02, 2.1732e-02, 4.9122e-03, 9.1536e-03, 5.0316e-03, 6.1927e-03,\n",
      "        3.5517e-03, 8.8127e-03, 1.8308e-02, 8.6461e-03, 5.1215e-03, 1.9723e-02,\n",
      "        4.9033e-02, 2.8110e-02, 1.6192e-02, 1.4772e-02, 6.3021e-03, 9.1221e-03,\n",
      "        1.6796e-02, 4.0254e-03, 1.9274e-02, 1.4571e-02, 1.4093e-02, 3.0480e-02,\n",
      "        6.8234e-03, 3.8364e-03, 1.3834e-02, 1.4269e-02, 9.0751e-03, 2.5296e-02,\n",
      "        8.2036e-03, 6.2834e-02, 5.2074e-02, 8.9528e-03, 4.3864e-03, 1.0635e-02,\n",
      "        9.9459e-03, 3.9466e-02, 3.5120e-02, 2.0819e-02, 5.3318e-03, 1.0103e-02,\n",
      "        5.4497e-02, 1.1027e-02, 2.3371e-02, 4.4420e-02, 1.9682e-02, 7.0122e-02,\n",
      "        7.0460e-03, 4.9574e-07, 5.5753e-02, 1.7853e-02, 7.1342e-03, 4.3833e-02,\n",
      "        6.5180e-03, 3.3897e-03, 5.6539e-03, 2.7309e-02, 3.1421e-03, 1.8892e-02,\n",
      "        2.1216e-02, 1.4081e-02, 1.8815e-02, 4.7171e-02, 1.4263e-02, 4.1406e-03,\n",
      "        2.0059e-02, 1.3994e-02, 1.6989e-02, 2.7707e-02, 1.1598e-02, 3.0610e-03,\n",
      "        4.0001e-02, 1.2886e-02, 1.4725e-02, 7.2066e-03, 6.0927e-01, 4.1745e-03,\n",
      "        7.0118e-03, 1.2418e-02, 3.7421e-02, 5.8242e-03, 1.7675e-02, 9.4474e-03,\n",
      "        2.1409e-02, 4.5401e-03, 1.7893e-02, 4.4226e-03, 3.1481e-02, 4.2243e-03,\n",
      "        4.5979e-03, 2.1180e-02, 2.1886e-02, 2.1619e-02, 1.1446e-02, 6.8636e-03,\n",
      "        1.3103e-02, 2.3165e-02, 6.5043e-03, 5.8891e-03, 3.5933e-02, 6.8279e-03,\n",
      "        1.7440e-02, 9.1878e-03, 3.1795e-03, 3.8743e-02, 1.2336e-02, 1.7227e-02,\n",
      "        4.5593e-03, 2.4194e-02, 1.0356e-02, 1.7709e-02, 2.1999e-02, 4.1017e-02,\n",
      "        4.9319e-03, 2.5336e-02, 2.1640e-02, 1.2051e-02, 2.4712e-02, 1.0911e-02,\n",
      "        2.2925e-01, 1.1355e-02, 2.9330e-02, 1.0800e-02, 3.8103e-03, 5.2563e-03,\n",
      "        7.7128e-03, 2.6508e-02, 7.4940e-03, 1.9732e-02, 8.9477e-03, 1.1000e-02,\n",
      "        7.6104e-03, 4.5803e-03, 6.2408e-03, 5.9416e-03, 1.9844e-02, 3.0660e-02,\n",
      "        9.3915e-03, 9.8215e-03, 4.4857e-03, 2.7853e-02, 2.6775e-02, 2.7440e-02,\n",
      "        6.9295e-02, 2.7447e-02, 5.1733e-03, 3.2621e-02, 5.8746e-03, 3.3311e-02,\n",
      "        1.8082e-02, 2.3529e-02, 1.9766e-02, 5.5834e-02, 1.6584e+00, 1.0070e-02,\n",
      "        4.6140e-03, 1.9316e-02, 1.6595e-02, 1.1817e-02, 2.6923e-02, 3.9712e-02,\n",
      "        1.0706e-02, 1.2744e-02, 1.1923e-02, 2.7253e-02, 1.3589e-02, 2.0398e-02,\n",
      "        6.0044e-03, 2.9533e-02, 1.5128e-02, 1.6946e-02, 1.2239e-02, 7.2200e-03,\n",
      "        6.4102e-03, 2.9935e-03, 2.3271e-02, 2.0225e-02, 2.5680e-02, 2.3324e-02,\n",
      "        1.1463e-02, 1.3352e-02, 1.6238e-02, 1.7423e-02, 2.2153e-02, 1.6387e-02,\n",
      "        1.4699e-02, 8.9179e-03, 3.4337e-02, 2.3900e-02, 5.5367e-02, 1.1129e-02,\n",
      "        2.2290e-02, 1.1056e-02, 4.5575e-03, 4.0134e-03, 1.0338e-02, 2.7989e-02,\n",
      "        1.6859e-02, 5.8041e-03, 3.1501e-02, 3.5048e-03, 1.0318e-02, 4.7763e-03,\n",
      "        8.5783e-03, 8.3535e-03, 2.4701e-02, 1.4728e-02, 3.3415e-02, 2.6988e-02,\n",
      "        3.1144e-03, 4.4480e-02, 1.8920e-02, 8.1301e-03, 5.8313e-03, 2.9359e-02,\n",
      "        1.9945e-02, 1.5272e-02, 3.0507e-02, 9.5889e-03, 5.8467e-03, 2.9127e-01,\n",
      "        1.6615e-02, 2.3695e-02, 2.2700e-02, 1.0759e-02, 7.2685e-03, 2.2687e-02,\n",
      "        1.8346e-02, 1.1929e-02, 7.2925e-03, 1.4736e-02, 1.1984e-02, 4.6529e-02,\n",
      "        1.2011e-02, 1.0043e-02, 1.4265e-02, 1.3106e-02, 1.5682e-02, 1.3238e-01,\n",
      "        2.2127e-02, 9.6135e-03, 1.2153e-02, 8.2633e-03, 4.2186e-03, 6.8798e-03,\n",
      "        1.7906e-02, 2.4991e-02, 1.6152e-02, 5.9674e-03, 1.5042e-02, 2.8468e-03,\n",
      "        7.8443e-03, 6.7710e-03, 1.2409e-02, 2.9163e-02, 1.8474e-02, 2.4661e-02,\n",
      "        7.3713e-03, 2.1172e-02, 1.3353e-02, 4.9809e-03, 2.0218e-02, 2.3351e-02,\n",
      "        1.2644e-02, 1.1315e-02, 1.5645e-02, 5.2867e-03, 1.5096e-02, 2.5552e-02,\n",
      "        3.0166e-03, 3.9457e-03, 2.0604e-02, 6.5229e-03, 1.7541e-02, 2.6158e-02,\n",
      "        1.5017e-02, 2.0214e-02, 4.5262e-03, 2.0478e-02, 2.4231e-02, 1.3449e-02,\n",
      "        4.8513e-02, 3.8873e-03, 1.0669e-02, 2.2471e-02, 2.5511e-02, 2.3440e-02,\n",
      "        4.2595e-02, 3.9667e-02, 1.0297e-02, 2.4732e-02, 2.4244e-02, 1.3088e-02,\n",
      "        1.5687e-02, 1.7993e-02, 4.0973e-03, 1.0561e-02, 1.5389e-02, 2.7504e-02,\n",
      "        1.6581e-02, 1.2171e-02, 2.9129e-02, 1.0975e-02, 8.5502e-03, 3.4956e-03,\n",
      "        1.7177e-02, 1.5463e-02, 1.1964e-02, 5.4591e-03, 6.7773e-02, 1.9426e-02,\n",
      "        1.9848e-02, 1.2419e-02, 9.4039e-03, 9.2452e-03, 8.2231e-02, 3.8513e-03,\n",
      "        1.5914e-02, 7.0883e-03, 2.7734e-02, 2.8425e-02, 6.5604e-03, 1.6398e-02,\n",
      "        1.0885e-02, 4.9383e-02, 1.7491e-02, 1.5643e-02, 4.3258e-02, 9.8557e-02,\n",
      "        8.4522e-03, 1.3902e-02, 6.6680e-03, 2.1046e-02, 1.0549e-02, 3.0434e-03,\n",
      "        5.0856e-02, 5.1222e-03, 2.4359e-02, 2.7805e-02, 1.9600e-02, 1.4547e-02,\n",
      "        4.5927e-03, 2.9341e-02, 3.1049e-02, 2.7761e-02, 2.3136e-02, 1.5472e-02,\n",
      "        7.0428e-03, 5.6670e-03, 2.9356e-02, 9.1373e-03, 1.3291e-02, 2.0610e-02])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "conv_weight: tensor([[[-0.0407, -0.2801, -0.0250],\n",
      "         [-0.3943,  1.2671, -0.3341],\n",
      "         [-0.0234, -0.2552, -0.0094]],\n",
      "\n",
      "        [[-0.2944, -0.2993, -0.0901],\n",
      "         [ 0.2375,  1.3991,  0.5962],\n",
      "         [ 1.2048,  1.9999,  1.3690]],\n",
      "\n",
      "        [[-0.3808, -0.8905, -0.5399],\n",
      "         [-0.7837, -1.7826, -1.2982],\n",
      "         [-0.4126, -0.4564, -0.4532]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5702, -0.6153, -0.5857],\n",
      "         [-1.1068,  0.6355, -1.1206],\n",
      "         [-0.9583, -0.8646, -0.9757]],\n",
      "\n",
      "        [[ 0.1342, -0.1199,  0.3138],\n",
      "         [ 0.0270,  2.0650,  0.0438],\n",
      "         [-0.1868, -1.2703, -0.5693]],\n",
      "\n",
      "        [[ 1.1315,  1.5894,  1.7121],\n",
      "         [ 1.1054,  2.8687,  0.9974],\n",
      "         [-1.7094, -2.6495,  0.0158]]]) conv_bias: tensor([ 3.4669e+00, -3.5068e-01,  3.8957e+00, -4.7045e-01,  3.6027e+00,\n",
      "         1.4130e-01,  7.5212e-01,  3.1694e+00, -9.8502e-02,  9.7643e-02,\n",
      "         1.0197e-01,  3.5773e+00,  1.8865e+00,  9.2453e-02,  3.0143e+00,\n",
      "         4.4217e+00,  4.0186e+00,  3.1188e+00,  2.1085e+00,  2.3169e+00,\n",
      "         1.5896e+00,  2.2004e+00,  1.0389e-01,  1.4305e-01,  5.1277e-01,\n",
      "         7.9192e-02,  9.5464e-02,  2.8488e+00,  1.5150e+00,  5.8129e+00,\n",
      "         2.0685e+00,  3.8001e+00,  4.4591e+00,  3.9120e+00, -3.4195e-04,\n",
      "         2.5341e+00,  4.5897e+00,  5.2025e-01,  4.5538e+00, -4.9684e-01,\n",
      "         1.7030e+00,  2.0107e+00,  1.3257e+00,  1.1496e+00, -7.8013e-01,\n",
      "         2.7096e-03,  1.1483e+00,  9.8797e-02,  1.8324e+00, -1.4378e-01,\n",
      "         1.5120e+00,  5.8788e+00,  4.8373e+00,  4.7583e+00,  2.0156e+00,\n",
      "         1.6164e+00,  2.2096e+00, -1.0094e+00,  7.0431e-02,  1.6353e+00,\n",
      "        -1.0300e+00,  1.0038e-01,  1.5627e+00,  8.8556e-01,  1.3240e+00,\n",
      "         1.0440e-01, -8.8855e-01,  7.8816e-02,  1.0402e+00, -1.8239e-01,\n",
      "         1.0412e-01,  9.2052e-02,  2.1937e+00, -6.9589e-01,  7.8398e-01,\n",
      "         1.0065e-01,  2.1188e+00,  1.2592e+00,  5.7704e+00, -4.8264e-02,\n",
      "        -1.6282e-02,  1.6196e+00,  2.4547e+00,  5.0077e-02,  2.8093e+00,\n",
      "         6.0218e+00,  7.5870e-01,  4.5186e+00,  2.2343e+00,  2.1184e+00,\n",
      "         5.3915e+00, -4.1125e-01,  2.7894e-02,  6.2016e+00, -6.7225e-01,\n",
      "         4.6053e+00,  1.4409e+00,  3.9009e+00, -2.6287e-01,  1.9045e+00,\n",
      "        -3.2751e-01,  3.3510e+00,  4.8226e+00,  3.4663e+00,  4.6760e-02,\n",
      "         9.4335e-02,  1.7430e+00,  3.4059e+00,  3.4704e+00,  4.3511e+00,\n",
      "         3.8258e+00, -5.1572e-03,  9.7552e-02,  1.1172e+00,  1.6388e+00,\n",
      "         3.5764e+00,  4.8728e-01,  1.7985e+00, -2.7238e-01, -9.4669e-01,\n",
      "         3.4680e+00, -2.6252e-01, -1.3176e-01,  7.4663e-01, -1.1157e+00,\n",
      "         1.4770e+00,  9.6731e-01, -8.9088e-01,  2.1984e+00,  1.7874e+00,\n",
      "         1.7502e+00, -4.1147e-01,  1.9278e+00,  3.0752e+00, -7.4891e-01,\n",
      "         3.3899e+00,  4.6654e+00,  9.9578e+00,  7.1472e-02,  3.8502e+00,\n",
      "        -8.8373e-01, -1.2287e-01,  3.0122e+00, -1.5972e+00,  4.6913e+00,\n",
      "         1.8500e+00,  1.7468e+00,  2.3047e+00, -4.6457e-01,  1.2644e+00,\n",
      "         4.3088e+00,  2.2500e+00,  3.3889e+00,  1.8988e+00, -4.2680e-01,\n",
      "         2.2495e+00,  1.8521e+00,  1.9783e-02,  1.1486e+00,  2.0784e+00,\n",
      "        -8.8097e-03, -7.4564e-01,  2.8849e+00,  2.9582e+00,  9.9894e-02,\n",
      "        -1.1371e-03,  2.2425e+00,  4.6529e+00,  1.0684e-01,  1.8242e+00,\n",
      "         3.5305e-01, -3.9225e-04,  1.9814e+00,  1.6227e+00,  1.8858e+00,\n",
      "         9.2789e-06,  1.0020e-01,  2.7196e-02,  1.2870e+00,  2.4831e+00,\n",
      "         2.1781e+00,  1.6808e+00,  1.7936e+00,  1.5021e-01,  1.8335e+00,\n",
      "         1.0478e+00, -6.3139e-02,  3.4814e+00,  2.8795e+00,  1.1502e-01,\n",
      "        -6.4559e-01,  2.5211e+00, -5.8033e-01, -3.8860e-01,  9.0730e-02,\n",
      "         6.0357e-02, -6.4676e-01,  1.9072e+00,  4.0747e-02,  2.2230e+00,\n",
      "        -4.1656e-01,  1.4537e+00,  6.2431e-02,  1.8183e+00,  1.6817e+00,\n",
      "        -6.7882e-02,  3.9051e+00,  1.8489e+00,  3.5518e+00, -5.1103e-01,\n",
      "         1.1923e+00,  2.4613e+00,  3.7023e-02,  2.5034e+00, -6.3180e-02,\n",
      "         1.8883e+00,  5.1309e+00,  3.6589e-01,  5.6697e+00, -7.8719e-01,\n",
      "         1.3587e+00,  2.2661e+00, -1.2227e-01, -8.4671e-02,  3.0988e+00,\n",
      "         2.1073e+00,  5.1729e+00, -3.5318e-01, -9.0465e-02,  4.0666e+00,\n",
      "         1.6057e+00,  1.5929e+00,  8.2078e-01, -1.5223e-01,  1.8395e+00,\n",
      "         1.8776e-02,  2.6615e+00,  4.4316e+00,  9.8194e-02,  8.0828e-02,\n",
      "         1.4607e+00,  3.3906e+00,  4.7050e+00,  5.6541e-01,  2.5374e+00,\n",
      "        -1.4705e+00, -3.9337e-01, -3.6042e-01,  3.9773e+00,  2.3759e+00,\n",
      "         2.3495e+00,  2.5064e+00,  1.9825e+00,  2.5652e+00, -4.4047e-02,\n",
      "        -2.4749e-01,  4.9503e+00, -1.3756e-01,  2.4094e+00,  4.4813e+00,\n",
      "         3.0440e+00,  3.0636e+00,  2.5889e+00, -3.9251e-01,  3.1769e+00,\n",
      "         4.5623e+00,  1.0728e+00, -4.9518e-02, -8.2900e-01,  3.0122e+00,\n",
      "         1.1066e+00,  3.2990e+00,  4.5753e+00,  4.4946e+00,  8.4415e-01,\n",
      "        -6.7389e-03,  1.8726e+00,  1.3931e+00,  4.8868e+00, -6.6018e-03,\n",
      "         8.4845e-03,  5.6117e+00,  9.2601e-01,  1.3887e+00,  2.0190e+00,\n",
      "         1.1977e+00,  2.7846e+00,  2.1836e+00,  2.5566e+00,  1.2922e+00,\n",
      "         4.4013e+00,  1.0766e-01, -7.7580e-01,  2.7432e+00,  1.6374e+00,\n",
      "         4.0472e+00, -9.1586e-02,  6.0337e-01,  2.0888e+00, -6.9127e-01,\n",
      "         3.5117e+00,  1.9137e+00,  3.2309e+00, -1.5746e-01, -5.5623e-01,\n",
      "         1.5832e+00,  3.7438e+00, -2.1387e-01, -8.0051e-01,  3.9578e+00,\n",
      "         1.0576e-01, -5.6481e-01, -8.4755e-01,  2.3495e+00,  4.4877e+00,\n",
      "         1.8417e+00,  1.9383e-02,  1.8522e+00, -2.0729e-01,  3.7225e+00,\n",
      "         6.2677e-02,  2.1923e+00, -3.9028e-01,  1.0379e-01,  1.9519e+00,\n",
      "         3.6048e+00, -6.5767e-01,  1.7071e+00,  3.0829e+00,  2.5796e+00,\n",
      "         6.0830e+00,  1.7156e+00, -6.3861e-01,  3.3251e-02, -2.9929e-01,\n",
      "        -8.0822e-01,  1.7765e+00,  1.2449e+00,  2.4160e+00, -1.4868e+00,\n",
      "         2.6137e+00,  1.7577e-01,  2.4616e+00,  5.2301e-02,  5.2673e-01,\n",
      "         3.7158e+00,  4.7853e+00,  9.0461e-03, -2.9449e-01,  2.0678e+00,\n",
      "         1.6186e+00,  7.7856e-02,  2.2671e+00,  3.7096e-02,  4.4503e+00,\n",
      "         2.1882e+00,  1.7287e+00, -1.1594e+00, -4.8600e-02,  1.3596e+00,\n",
      "         1.9946e+00, -5.1506e-01, -3.3487e-01, -3.1037e-01,  1.6003e+00,\n",
      "        -3.7590e-01,  2.6390e-02,  3.1204e+00, -1.2074e+00,  6.0873e-01,\n",
      "        -7.4370e-01,  1.7833e+00,  1.0815e+00,  2.9193e+00,  6.0094e-01,\n",
      "         1.4737e+00, -1.9773e-01,  1.8481e+00, -7.9796e-01,  2.1329e+00,\n",
      "         1.6010e+00,  7.7867e-01, -6.3978e-01,  8.3105e-02,  2.5786e+00,\n",
      "         1.8793e+00, -1.8921e-01,  1.7805e+00,  7.5184e+00, -2.8378e-01,\n",
      "        -1.0688e-02,  1.8088e+00,  1.6096e+00, -1.2473e+00,  2.7259e+00,\n",
      "        -2.7814e-02,  4.2117e+00,  2.2513e+00, -2.1379e-01, -7.8190e-01,\n",
      "        -9.5591e-02,  6.0526e+00, -4.8191e-01,  1.5162e+00, -4.7760e-01,\n",
      "        -7.8636e-01,  1.3217e-02,  2.7055e+00,  3.2380e-01,  3.6438e+00,\n",
      "         3.0431e+00,  7.3058e-01,  3.7704e+00,  3.3439e-01, -6.6294e-02,\n",
      "        -1.8593e-01,  4.9169e+00,  4.9655e+00,  9.1535e-02,  1.5314e+00,\n",
      "         8.4232e-03,  1.0109e-01, -8.7803e-01,  1.7082e+00,  1.7732e+00,\n",
      "         1.0410e-01,  3.2936e+00,  2.4182e+00,  3.8024e+00,  2.0937e+00,\n",
      "         2.0081e+00, -1.1180e+00, -2.6815e-02,  5.7952e+00, -8.1400e-02,\n",
      "         2.9146e+00,  3.2316e-01,  1.1847e+00,  1.8747e+00,  5.1199e-02,\n",
      "         5.3947e+00, -7.3400e-01,  2.6870e+00,  1.9165e+00, -7.1917e-02,\n",
      "         3.4651e+00,  2.6352e-01, -4.8958e-01,  1.3204e+00,  1.6950e+00,\n",
      "         2.2450e+00,  8.2984e-02,  1.9046e+00,  1.1170e+00,  8.2873e-02,\n",
      "         3.0207e+00,  3.9402e+00,  5.2830e+00, -4.7296e-01,  3.5857e+00,\n",
      "         1.7850e+00,  1.9980e+00,  3.3574e-01,  2.2547e+00,  5.1141e+00,\n",
      "         1.5763e+00,  7.6649e-02,  5.2902e-02, -5.1743e-01, -1.3382e-01,\n",
      "        -2.0676e-02,  7.1872e-02,  1.1907e+00, -1.9146e-01,  2.5612e+00,\n",
      "         1.6027e+00,  6.9157e-02,  1.6286e+00,  1.7587e+00,  4.0727e+00])\n",
      "torch.Size([480, 1, 3, 3]) torch.Size([480])\n",
      "q_weight: tensor([ -2, -17,  -2,  ..., -56, -87,   1], dtype=torch.int32) q_bias: tensor([ 1347,  -100,   875,  -281,  2458,    28,   294,  1667,   -37,    16,\n",
      "            7,  2998,   494,    29,  3895,  2028,  3802,   654,    25,  2930,\n",
      "          169,   903,     8,     1,   127,    13,    10,  2021,   595, 12169,\n",
      "         1488,   684,   799,  3068, -1650,   855,  1242,   104,  3769,  -256,\n",
      "          571,   977,   387,   767,  -313,     0,   746,    17,  1366,   -36,\n",
      "          664,  2095,  3911,   562,   325,   554,  2315,  -514,    23,   312,\n",
      "         -955,    13,   947,   142,   621,    21,  -597,    10,   106,   -35,\n",
      "           15,    15,   457,  -161,   163,    29,   823,  1224,  1221,   -21,\n",
      "           -6,   144,  2753,    15,   348,  4032,   376,  4327,  1078,   643,\n",
      "         1631,  -149,     4,  3867,  -121,  1617,  2044,  1101,  -104,  1665,\n",
      "          -62,  3406,  3607,  2152,     6,    12,  1710,   430,  1542,  3600,\n",
      "         2120,    -1,    17,   455,   559,  2144,   123,  2241,   -60,  -831,\n",
      "          585,   -64,   -21,    26, -1674,   314,   245,  -177,  1934,   844,\n",
      "         1503,  -287,  2346,  1508,  -177,  1694,  3937,  2182,     6,   592,\n",
      "         -236,   -36,  2066,  -757,  1207,  1986,   392,   684,  -142,   179,\n",
      "         2729,  2535,  1059,   575,  -203,   384,   976,     1,    95,  1003,\n",
      "           -9,  -303,  1254,   324,    12,     0,  1818,  1990,     8,   715,\n",
      "           65,     0,   435,   100,  1157,    81,     8,     7,   780,   245,\n",
      "         1444,  2143,  1371,    24,  2522,   240,   -13,  1069,   661,    11,\n",
      "         -196,  2631,  -125,  -120,    23,     9,  -241,  2693,     4,   746,\n",
      "         -122,   872,     0,  1882,  1037,   -24,   451,  1372,   868,  -234,\n",
      "          241,  2343,     9,  2446,    -9,  1932,  4823,    75,  1120,  -157,\n",
      "          513,  1427,   -40,   -16,  2059,  1546,   622,  -224,   -22,  1913,\n",
      "         2183,   178,   288,   -38,  1744,     3,  1111,  1082,    19,     9,\n",
      "         1280,   578,   940,   203,   444,  -582,    -7,  -137,   586,   951,\n",
      "         2665,  2061,  1111,   418,   -25,   -54,  2391,   -54,  1368,  4228,\n",
      "         2108,  2228,   564,   -55,  1462,  2008,  1034,    -8,  -134,   474,\n",
      "           69,   519,  3822,   595,   621,    -1,   448,   256,  1069,    -1,\n",
      "            0,  2408,   867,   311,   526,   438,   447,   238,  1032,   438,\n",
      "         1595,    17,  -247,   581,  1179,   592,   -26,   154,   738,  -414,\n",
      "         2368,  2763,   600,   -34,   -94,   293,  1412,   -69,  -213,   982,\n",
      "           21,  -149,  -249,  1139,   565,   333,     2,   719,   -40,  1455,\n",
      "           59,  2361,  -163,    16,   500,  2684,   -90,  2105,  1291,  2334,\n",
      "         3065,   888,  -112,    10,   -39,  -129,  2465,   121,   552,  -790,\n",
      "         1937,    26,   533,    15,    75,  1675,  3537,     0,   -77,   377,\n",
      "          308,    31,  1348,     7,  1048,   793,  1024,  -340,   -18,   126,\n",
      "          718,  -222,  -101,  -102,   441,   -12,     5,  1403,  -429,   318,\n",
      "         -762,  1120,   261,   505,   161,  1067,   -57,  2806,  -440,  1361,\n",
      "          558,   115,  -150,    15,  1512,   384,   -61,  1545,  1607,   -53,\n",
      "           -4,   691,   445, -1020,   780,    -5,  6034,  2466,   -45,  -518,\n",
      "          -24,  1000,  -139,   324,  -456,  -166,     2,   869,    29,  4051,\n",
      "         1233,   141,   639,    62,    -7,   -20,  2064,   868,    16,   506,\n",
      "            2,    24,  -926,   699,   498,    16,   858,   859,   564,   824,\n",
      "         1015, -1382,    -7,  1620,   -29,  2307,    21,   264,   408,    18,\n",
      "         2479,  -343,   141,  2151,   -20,  2113,    41,   -74,   870,   447,\n",
      "          891,     7,   471,   309,     8,   132,  2015,  1642,  -307,   736,\n",
      "          731,  2837,    29,  1902,   907,   245,    17,    16,  -487,   -20,\n",
      "           -3,    11,   222,   -53,  1572,  1222,    10,   770,   572,   854],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(7.9427e-05) tensor(1.0822)   bias tensor(0.0002) tensor(0.0624)\n",
      "features.17.conv.6.weight features.17.conv.8\n",
      "torch.Size([160, 480, 1, 1]) conv_bias= torch.Size([160]) \n",
      "ascale= tensor([0.2168]) torch.Size([1]) \n",
      "wscale= tensor([0.0018, 0.0017, 0.0020, 0.0019, 0.0016, 0.0016, 0.0018, 0.0016, 0.0018,\n",
      "        0.0019, 0.0015, 0.0018, 0.0018, 0.0019, 0.0016, 0.0017, 0.0014, 0.0020,\n",
      "        0.0019, 0.0022, 0.0017, 0.0019, 0.0019, 0.0046, 0.0016, 0.0019, 0.0019,\n",
      "        0.0025, 0.0019, 0.0019, 0.0018, 0.0022, 0.0016, 0.0018, 0.0021, 0.0017,\n",
      "        0.0013, 0.0018, 0.0018, 0.0017, 0.0017, 0.0025, 0.0013, 0.0017, 0.0015,\n",
      "        0.0016, 0.0022, 0.0021, 0.0017, 0.0017, 0.0019, 0.0022, 0.0021, 0.0017,\n",
      "        0.0014, 0.0018, 0.0019, 0.0021, 0.0022, 0.0017, 0.0016, 0.0023, 0.0020,\n",
      "        0.0021, 0.0034, 0.0027, 0.0020, 0.0019, 0.0016, 0.0016, 0.0018, 0.0021,\n",
      "        0.0020, 0.0018, 0.0022, 0.0017, 0.0017, 0.0015, 0.0020, 0.0017, 0.0016,\n",
      "        0.0020, 0.0016, 0.0021, 0.0018, 0.0015, 0.0023, 0.0019, 0.0019, 0.0017,\n",
      "        0.0017, 0.0016, 0.0019, 0.0017, 0.0016, 0.0018, 0.0021, 0.0019, 0.0012,\n",
      "        0.0020, 0.0022, 0.0017, 0.0019, 0.0019, 0.0014, 0.0020, 0.0018, 0.0016,\n",
      "        0.0020, 0.0021, 0.0019, 0.0020, 0.0023, 0.0019, 0.0022, 0.0017, 0.0019,\n",
      "        0.0020, 0.0020, 0.0019, 0.0015, 0.0020, 0.0015, 0.0022, 0.0022, 0.0022,\n",
      "        0.0017, 0.0019, 0.0018, 0.0021, 0.0021, 0.0020, 0.0019, 0.0019, 0.0016,\n",
      "        0.0026, 0.0011, 0.0019, 0.0017, 0.0018, 0.0024, 0.0022, 0.0013, 0.0020,\n",
      "        0.0016, 0.0018, 0.0018, 0.0020, 0.0018, 0.0017, 0.0022, 0.0020, 0.0018,\n",
      "        0.0021, 0.0019, 0.0016, 0.0018, 0.0019, 0.0018, 0.0015]) torch.Size([160, 1, 1, 1]) \n",
      "oscale= tensor([0.1345]) torch.Size([1])\n",
      "###: M= tensor([0.0029, 0.0028, 0.0032, 0.0031, 0.0025, 0.0026, 0.0029, 0.0025, 0.0029,\n",
      "        0.0030, 0.0024, 0.0029, 0.0029, 0.0031, 0.0026, 0.0028, 0.0022, 0.0032,\n",
      "        0.0030, 0.0035, 0.0027, 0.0031, 0.0031, 0.0075, 0.0026, 0.0030, 0.0030,\n",
      "        0.0040, 0.0030, 0.0031, 0.0028, 0.0035, 0.0025, 0.0030, 0.0033, 0.0027,\n",
      "        0.0020, 0.0029, 0.0028, 0.0027, 0.0028, 0.0041, 0.0021, 0.0027, 0.0024,\n",
      "        0.0025, 0.0035, 0.0033, 0.0027, 0.0027, 0.0030, 0.0035, 0.0035, 0.0028,\n",
      "        0.0023, 0.0030, 0.0030, 0.0034, 0.0036, 0.0028, 0.0026, 0.0036, 0.0033,\n",
      "        0.0034, 0.0055, 0.0043, 0.0032, 0.0031, 0.0026, 0.0026, 0.0029, 0.0034,\n",
      "        0.0033, 0.0029, 0.0036, 0.0028, 0.0028, 0.0024, 0.0032, 0.0028, 0.0027,\n",
      "        0.0032, 0.0025, 0.0033, 0.0028, 0.0024, 0.0037, 0.0031, 0.0031, 0.0027,\n",
      "        0.0028, 0.0026, 0.0030, 0.0027, 0.0026, 0.0029, 0.0033, 0.0030, 0.0020,\n",
      "        0.0033, 0.0036, 0.0027, 0.0030, 0.0031, 0.0023, 0.0032, 0.0029, 0.0026,\n",
      "        0.0032, 0.0034, 0.0031, 0.0032, 0.0037, 0.0030, 0.0035, 0.0027, 0.0031,\n",
      "        0.0032, 0.0033, 0.0030, 0.0025, 0.0032, 0.0023, 0.0036, 0.0036, 0.0035,\n",
      "        0.0027, 0.0030, 0.0029, 0.0033, 0.0034, 0.0032, 0.0031, 0.0030, 0.0025,\n",
      "        0.0042, 0.0019, 0.0031, 0.0027, 0.0030, 0.0039, 0.0035, 0.0022, 0.0032,\n",
      "        0.0026, 0.0029, 0.0030, 0.0033, 0.0030, 0.0028, 0.0035, 0.0032, 0.0029,\n",
      "        0.0034, 0.0031, 0.0025, 0.0030, 0.0030, 0.0029, 0.0025])\n",
      "torch.Size([160, 480, 1, 1]) torch.Size([160])\n",
      "conv_weight: tensor([[ 0.1307,  0.1359, -0.0407,  ..., -0.0967,  0.0345, -0.0246],\n",
      "        [-0.0229,  0.0259,  0.1006,  ...,  0.0517, -0.0613, -0.0679],\n",
      "        [ 0.0174, -0.0273,  0.0204,  ..., -0.0510, -0.0364,  0.0408],\n",
      "        ...,\n",
      "        [-0.1118,  0.0345,  0.0201,  ...,  0.0536,  0.0121,  0.0462],\n",
      "        [-0.0346,  0.0227,  0.0156,  ..., -0.0311,  0.0193,  0.0567],\n",
      "        [-0.0294,  0.0428,  0.0395,  ..., -0.0456, -0.0036,  0.0181]]) conv_bias: tensor([-9.6107e-01,  3.7911e+00, -1.6572e+00, -2.1886e+00, -2.2535e+00,\n",
      "        -1.9553e-01, -4.7365e+00,  2.8342e+00, -1.2130e+00, -2.5877e-01,\n",
      "        -5.5366e-01, -3.5929e+00,  1.0353e+00,  1.7700e+00, -2.5203e+00,\n",
      "        -3.1668e+00, -3.6831e+00,  7.4298e-01,  2.2645e+00, -3.6772e-01,\n",
      "         2.0539e+00, -4.0954e+00,  9.8726e-01, -8.3320e-01,  2.1504e+00,\n",
      "         9.3395e-01,  2.3678e+00, -9.6951e-01,  2.7511e+00,  1.6405e+00,\n",
      "         3.3101e+00, -8.0192e-01, -6.1151e+00, -1.5922e+00, -1.2246e-01,\n",
      "        -2.2154e+00, -4.9878e-01, -3.4130e+00,  1.8668e+00, -2.1164e+00,\n",
      "         5.3578e+00,  2.2288e+00, -6.6679e-01,  4.9740e-04, -2.6446e+00,\n",
      "        -1.0344e+00, -4.0439e+00, -8.7818e-01, -2.2344e+00, -1.0800e+00,\n",
      "         1.0380e+00, -8.0367e-01, -4.0857e+00, -1.3140e-01, -3.4670e+00,\n",
      "        -8.9560e-01, -4.7378e+00,  5.1927e+00, -1.1046e+00,  1.8243e+00,\n",
      "        -5.1145e-01, -1.6050e+00, -1.2157e+00, -3.3460e+00,  3.9136e-01,\n",
      "         2.1528e+00,  5.5003e+00, -5.6851e+00, -2.0669e+00,  2.7597e+00,\n",
      "        -2.1883e+00, -9.0042e-02, -2.2006e-01, -2.9353e+00, -2.0819e+00,\n",
      "        -5.7300e-01, -7.1643e-01,  3.2854e+00,  4.5724e-01, -1.9848e+00,\n",
      "         2.9872e-01, -7.9136e-01, -3.3624e-01,  2.6986e+00, -4.9351e-02,\n",
      "        -3.6827e-01,  2.8469e+00,  2.7349e+00,  2.7596e+00, -1.6384e+00,\n",
      "         2.6527e+00,  1.3327e-01, -1.2601e+00, -4.3883e-01, -1.3627e+00,\n",
      "        -2.2463e+00,  7.6265e-01,  3.4761e+00,  1.1892e+00, -3.4131e+00,\n",
      "        -1.6474e+00, -1.9261e+00,  1.6909e+00,  3.9222e+00,  1.7601e+00,\n",
      "         2.6670e+00, -2.9480e+00,  1.2103e+00, -1.7439e+00,  7.4723e-01,\n",
      "        -1.4813e+00,  1.1534e+00,  2.5081e+00,  1.0681e+00, -2.3824e+00,\n",
      "        -6.9229e-01,  3.2997e+00,  1.5173e+00, -1.2789e+00,  3.4838e+00,\n",
      "         5.7479e-01,  2.8196e-01,  2.0267e+00,  1.1250e-01, -1.2642e+00,\n",
      "        -7.9265e-01,  1.2506e+00, -5.1822e-01, -4.0226e-01,  4.7435e-01,\n",
      "        -3.2812e-01,  2.3373e+00, -9.4848e-02,  1.8365e+00, -2.7058e+00,\n",
      "         4.1162e-01,  2.9262e+00, -1.1714e+00, -5.3513e-01, -3.5723e+00,\n",
      "        -3.8012e-01,  1.1734e+00, -2.6757e-02, -3.5681e+00,  3.0186e+00,\n",
      "         1.6578e+00,  1.6245e-01, -2.4227e+00,  3.5081e+00,  1.1621e+00,\n",
      "         3.1672e+00, -9.2624e-01,  8.4543e-01,  3.2028e+00, -2.7444e+00,\n",
      "        -1.0689e-01,  3.3850e+00,  5.8580e-01, -2.9298e-01, -6.5223e-01])\n",
      "torch.Size([160, 480, 1, 1]) torch.Size([160])\n",
      "q_weight: tensor([ 72,  75, -23,  ..., -30,  -2,  12], dtype=torch.int32) q_bias: tensor([ -2458,  10080,  -3814,  -5227,  -6576,   -558, -11985,   8414,  -3079,\n",
      "          -638,  -1700,  -9099,   2675,   4214,  -7123,  -8480, -12225,   1751,\n",
      "          5611,   -775,   5734,  -9711,   2368,   -831,   6123,   2299,   5808,\n",
      "         -1816,   6842,   3928,   8720,  -1690, -17905,  -3985,   -272,  -6123,\n",
      "         -1819,  -8775,   4880,  -5840,  14173,   4083,  -2357,      1,  -8299,\n",
      "         -3052,  -8637,  -1954,  -6060,  -3013,   2584,  -1716,  -8772,   -349,\n",
      "        -11274,  -2239, -11651,  11206,  -2303,   4872,  -1443,  -3275,  -2771,\n",
      "         -7251,    533,   3727,  12591, -13607,  -5863,   7821,  -5536,   -199,\n",
      "          -495,  -7414,  -4346,  -1549,  -1925,  10392,   1065,  -5235,    836,\n",
      "         -1835,   -999,   6048,   -129,  -1135,   5707,   6517,   6704,  -4523,\n",
      "          7024,    375,  -3117,  -1205,  -3912,  -5693,   1713,   8496,   4467,\n",
      "         -7731,  -3382,  -5242,   4186,   9423,   5711,   6184,  -7624,   3430,\n",
      "         -4028,   1628,  -3564,   2688,   5059,   2625,  -5107,  -1903,   8020,\n",
      "          3476,  -2902,   8673,   1742,    652,   6428,    235,  -2625,  -1674,\n",
      "          3425,  -1269,  -1035,   1066,   -717,   5512,   -227,   4523,  -7950,\n",
      "           735,  11757,  -2835,  -1496,  -8973,   -732,   2468,    -92,  -8209,\n",
      "          8584,   4301,    409,  -5541,   8806,   3115,   6738,  -2124,   2132,\n",
      "          7029,  -6605,   -315,   8500,   1440,   -763,  -1952],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(9.8455e-07) tensor(0.0023)   bias tensor(-8.7100e-06) tensor(0.0002)\n",
      "conv2.0.weight conv2.2\n",
      "torch.Size([128, 160, 1, 1]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.1345]) torch.Size([1]) \n",
      "wscale= tensor([0.0048, 0.0032, 0.0024, 0.0022, 0.0030, 0.0020, 0.0026, 0.0025, 0.0040,\n",
      "        0.0029, 0.0066, 0.0038, 0.0043, 0.0048, 0.0030, 0.0020, 0.0053, 0.0030,\n",
      "        0.0030, 0.0038, 0.0023, 0.0025, 0.0028, 0.0026, 0.0032, 0.0033, 0.0043,\n",
      "        0.0012, 0.0056, 0.0057, 0.0020, 0.0033, 0.0025, 0.0033, 0.0023, 0.0031,\n",
      "        0.0030, 0.0039, 0.0054, 0.0040, 0.0018, 0.0037, 0.0049, 0.0081, 0.0028,\n",
      "        0.0031, 0.0024, 0.0038, 0.0038, 0.0040, 0.0039, 0.0023, 0.0034, 0.0024,\n",
      "        0.0035, 0.0039, 0.0039, 0.0027, 0.0038, 0.0033, 0.0035, 0.0027, 0.0029,\n",
      "        0.0039, 0.0040, 0.0027, 0.0024, 0.0033, 0.0030, 0.0047, 0.0027, 0.0027,\n",
      "        0.0042, 0.0042, 0.0029, 0.0019, 0.0041, 0.0026, 0.0036, 0.0021, 0.0037,\n",
      "        0.0024, 0.0047, 0.0039, 0.0032, 0.0042, 0.0018, 0.0030, 0.0053, 0.0034,\n",
      "        0.0029, 0.0036, 0.0048, 0.0040, 0.0025, 0.0051, 0.0042, 0.0046, 0.0038,\n",
      "        0.0041, 0.0026, 0.0046, 0.0026, 0.0047, 0.0054, 0.0032, 0.0039, 0.0047,\n",
      "        0.0027, 0.0034, 0.0037, 0.0023, 0.0034, 0.0052, 0.0041, 0.0023, 0.0030,\n",
      "        0.0043, 0.0029, 0.0041, 0.0015, 0.0050, 0.0071, 0.0061, 0.0040, 0.0030,\n",
      "        0.0019, 0.0048]) torch.Size([128, 1, 1, 1]) \n",
      "oscale= tensor([0.3217]) torch.Size([1])\n",
      "###: M= tensor([0.0020, 0.0013, 0.0010, 0.0009, 0.0012, 0.0008, 0.0011, 0.0010, 0.0017,\n",
      "        0.0012, 0.0028, 0.0016, 0.0018, 0.0020, 0.0013, 0.0008, 0.0022, 0.0012,\n",
      "        0.0013, 0.0016, 0.0010, 0.0010, 0.0012, 0.0011, 0.0013, 0.0014, 0.0018,\n",
      "        0.0005, 0.0023, 0.0024, 0.0008, 0.0014, 0.0010, 0.0014, 0.0010, 0.0013,\n",
      "        0.0012, 0.0016, 0.0022, 0.0017, 0.0008, 0.0015, 0.0021, 0.0034, 0.0012,\n",
      "        0.0013, 0.0010, 0.0016, 0.0016, 0.0017, 0.0016, 0.0009, 0.0014, 0.0010,\n",
      "        0.0015, 0.0016, 0.0016, 0.0011, 0.0016, 0.0014, 0.0015, 0.0011, 0.0012,\n",
      "        0.0016, 0.0017, 0.0011, 0.0010, 0.0014, 0.0012, 0.0020, 0.0011, 0.0011,\n",
      "        0.0018, 0.0017, 0.0012, 0.0008, 0.0017, 0.0011, 0.0015, 0.0009, 0.0016,\n",
      "        0.0010, 0.0020, 0.0016, 0.0013, 0.0018, 0.0008, 0.0012, 0.0022, 0.0014,\n",
      "        0.0012, 0.0015, 0.0020, 0.0017, 0.0010, 0.0021, 0.0018, 0.0019, 0.0016,\n",
      "        0.0017, 0.0011, 0.0019, 0.0011, 0.0019, 0.0023, 0.0013, 0.0016, 0.0020,\n",
      "        0.0011, 0.0014, 0.0016, 0.0010, 0.0014, 0.0022, 0.0017, 0.0010, 0.0013,\n",
      "        0.0018, 0.0012, 0.0017, 0.0006, 0.0021, 0.0030, 0.0025, 0.0017, 0.0013,\n",
      "        0.0008, 0.0020])\n",
      "torch.Size([128, 160, 1, 1]) torch.Size([128])\n",
      "conv_weight: tensor([[-0.1278, -0.0154,  0.1474,  ...,  0.0261,  0.0142, -0.0611],\n",
      "        [ 0.2105,  0.1647, -0.0086,  ...,  0.2826,  0.0177,  0.0989],\n",
      "        [-0.0130, -0.0349,  0.1823,  ...,  0.2132, -0.2976,  0.0857],\n",
      "        ...,\n",
      "        [ 0.2105,  0.2148,  0.0485,  ...,  0.2094, -0.0748, -0.1492],\n",
      "        [-0.0273, -0.0685,  0.1247,  ...,  0.1176, -0.1778,  0.0819],\n",
      "        [ 0.4366,  0.0845,  0.3188,  ...,  0.1835, -0.2234,  0.1217]]) conv_bias: tensor([ 0.5991, -1.3085,  2.4982,  1.2812,  1.8787,  2.5348,  2.2330,  0.6571,\n",
      "         0.2883,  1.9193,  0.2331,  0.6968, -0.7527,  1.1619,  2.2389, -0.9113,\n",
      "         0.2375,  1.3905,  2.2334,  0.9726,  3.3302,  1.5245,  2.2390,  2.1248,\n",
      "         0.7423, -0.7939,  2.1478,  1.3137,  0.7192, -0.0840,  2.4536,  0.4925,\n",
      "         1.3643,  0.5170,  2.4046,  1.0497,  2.0896, -0.2960,  0.5572,  0.6990,\n",
      "         1.6252,  1.2949,  0.7370, -0.3732,  1.6216,  1.8266, -1.0655, -0.6149,\n",
      "         1.7924,  1.2710, -0.7739,  2.2104,  1.9015,  0.8008,  1.9346,  0.1535,\n",
      "         1.8420,  2.1849,  0.1645,  2.1527,  0.9665,  1.4506,  2.0851,  0.3991,\n",
      "         2.9227,  1.9753,  1.1953,  1.3056,  1.6805,  0.3860, -0.8763,  1.8040,\n",
      "         1.6129, -0.7772,  1.6987,  2.9282, -0.0515,  1.4569,  1.7996,  2.4248,\n",
      "         1.9515,  0.7180, -0.6851,  1.0704,  1.0372,  0.3491,  2.1359,  1.2620,\n",
      "        -0.6453,  0.6059,  2.0715, -0.3609,  0.0972,  0.6129,  1.8394, -0.2855,\n",
      "        -0.4108, -0.5628,  0.9092, -0.1709,  2.4123, -0.4650,  2.1554,  0.3095,\n",
      "        -0.4747,  0.9358, -0.6155,  1.2605,  1.9964,  0.5376,  0.9903,  1.5948,\n",
      "         1.7396, -0.2537,  1.0423,  2.0404,  1.8718,  0.7321,  1.2548,  1.2699,\n",
      "         1.4758, -0.0697, -0.0045,  0.0735,  1.3222,  1.3233,  1.3781,  0.5361])\n",
      "torch.Size([128, 160, 1, 1]) torch.Size([128])\n",
      "q_weight: tensor([-26,  -3,  30,  ...,  38, -46,  25], dtype=torch.int32) q_bias: tensor([  920, -3051,  7705,  4390,  4730,  9381,  6333,  1985,   537,  5000,\n",
      "          261,  1362, -1302,  1798,  5565, -3437,   335,  3502,  5511,  1912,\n",
      "        10639,  4530,  5915,  6016,  1739, -1799,  3680,  7882,   953,  -110,\n",
      "         9253,  1125,  4086,  1170,  7846,  2531,  5224,  -565,   773,  1305,\n",
      "         6547,  2633,  1114,  -341,  4383,  4387, -3302, -1206,  3473,  2365,\n",
      "        -1491,  7235,  4178,  2464,  4090,   295,  3547,  6125,   323,  4913,\n",
      "         2052,  3962,  5437,   763,  5383,  5454,  3746,  2936,  4232,   606,\n",
      "        -2402,  4907,  2853, -1386,  4375, 11639,   -95,  4130,  3672,  8388,\n",
      "         3890,  2203, -1078,  2028,  2430,   619,  8769,  3172,  -905,  1307,\n",
      "         5357,  -750,   150,  1140,  5511,  -418,  -719,  -906,  1802,  -311,\n",
      "         6966,  -758,  6134,   495,  -654,  2198, -1188,  2007,  5426,  1162,\n",
      "         1981,  5145,  3808,  -366,  1883,  6543,  4615,  1269,  3207,  2307,\n",
      "         7242,  -104,    -5,    90,  2482,  3261,  5284,   827],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(6.7591e-06) tensor(0.0041)   bias tensor(-5.7939e-06) tensor(0.0003)\n",
      "deconv_layers.0.weight deconv_layers.2\n",
      "torch.Size([128, 1, 4, 4]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.3039]) torch.Size([1]) \n",
      "wscale= tensor([0.0238]) torch.Size([1]) \n",
      "oscale= tensor([0.3050]) torch.Size([1])\n",
      "###: M= tensor([0.0237])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "conv_weight: tensor([[[-3.5592e-02,  4.5561e-02,  4.9936e-02,  3.1816e-02],\n",
      "         [ 6.3404e-02,  1.2018e-01,  1.5556e-01,  4.2618e-02],\n",
      "         [ 3.6930e-01,  3.5953e-01,  3.3463e-01,  2.9751e-01],\n",
      "         [ 5.1342e-01,  5.5290e-01,  4.7657e-01,  4.3110e-01]],\n",
      "\n",
      "        [[ 6.2215e-01,  6.7391e-01,  7.1861e-01,  6.0191e-01],\n",
      "         [ 4.3161e-01, -6.6534e-02, -4.5232e-01, -7.0439e-02],\n",
      "         [ 5.0573e-01, -4.6100e-01, -2.7562e-01,  4.3997e-01],\n",
      "         [ 3.2370e-01, -6.9977e-02,  3.1909e-01, -7.4031e-02]],\n",
      "\n",
      "        [[-1.6757e-02, -1.2164e-02,  4.8713e-01, -1.8296e-02],\n",
      "         [ 6.1682e-02, -1.2972e-02,  1.4287e+00, -1.8241e-02],\n",
      "         [-5.9343e-02, -1.4111e-02,  4.3894e-01, -1.4266e-02],\n",
      "         [-2.2484e-02, -1.3175e-03, -1.8338e-01, -1.1989e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3125e-01,  5.8357e-01,  3.4712e-01, -1.0930e-01],\n",
      "         [ 4.0603e-01,  7.5521e-01,  5.3539e-01,  9.1310e-02],\n",
      "         [ 8.8282e-03,  4.1224e-01,  5.0289e-01,  1.7883e-01],\n",
      "         [-1.2678e-01, -4.6692e-02,  1.7713e-01,  8.5342e-02]],\n",
      "\n",
      "        [[-1.6081e-01, -3.1906e-01, -4.1391e-01, -1.7025e-01],\n",
      "         [-5.4062e-01, -6.6436e-01, -6.2104e-01, -6.4825e-01],\n",
      "         [-7.8268e-01, -1.2937e+00, -1.1346e+00, -6.1859e-01],\n",
      "         [-3.7194e-01, -8.0388e-01, -7.0715e-01, -2.4369e-01]],\n",
      "\n",
      "        [[ 8.2834e-02, -6.3588e-02, -2.7481e-01, -7.3104e-02],\n",
      "         [-1.7185e-04,  1.6895e-01, -1.2131e-02, -3.1892e-01],\n",
      "         [ 4.6385e-01,  4.7995e-01,  1.2008e-02, -3.9040e-01],\n",
      "         [-5.8165e-02,  5.3758e-01, -2.8052e-01, -6.8512e-02]]]) conv_bias: tensor([-1.0106,  0.1422,  0.1873,  3.9203, -3.6285,  0.2338, -2.4311,  4.3717,\n",
      "         3.5058, -1.3109, -1.3841, -1.2254, -1.0964, -0.2747,  0.2201,  5.3355,\n",
      "        -1.8814, -2.5356, -2.2353, -1.5786,  0.2202,  7.1188,  5.8762,  7.3579,\n",
      "         3.6554, -0.2531, -2.2390,  3.8262, -0.3197, -0.8245,  5.1672,  4.5471,\n",
      "         3.7771,  4.5928,  7.7121,  2.8604,  0.6466,  0.0387,  0.0617, -0.2805,\n",
      "         4.7575,  0.0490, -0.8745, -2.1877,  0.8037,  0.1423, -0.1790,  6.1173,\n",
      "         0.0367, -2.0882, -0.3273,  7.5341, -2.5701,  7.9461, -0.9551, -0.0230,\n",
      "         0.1491,  0.3527,  7.9420, -2.6574, -1.4067,  6.9430,  0.1685,  6.8186,\n",
      "         3.7020,  0.2980, -2.7369, -0.1950, -1.7583,  3.2890, -0.4817, -0.1245,\n",
      "        -1.8877, -0.3781,  0.1845,  2.3721, -0.8361, -0.2269, -1.9923,  6.8758,\n",
      "        -3.8230,  3.4768, -0.7423, -0.0854,  7.2069,  1.5251,  5.5949,  7.9775,\n",
      "         8.4413,  3.7906,  0.5474,  7.5673, -0.3898, -1.4885, -0.0999, -0.0299,\n",
      "        -0.0838,  6.8309,  0.0617, -0.3062,  2.1038,  1.6038,  0.1083, -0.0462,\n",
      "        -0.3400, -1.8814, -0.4226, -1.1749,  4.9211,  5.5721,  4.7864, -2.0029,\n",
      "        -0.9641, -2.0638, -0.5374,  0.1501, -0.1101, -0.5022,  3.9264, -1.9733,\n",
      "         4.1255, -0.6746, -1.2065, -1.0544, -0.3204, -1.9992,  3.7551,  0.0572])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "q_weight: tensor([ -1,   2,   2,  ...,  23, -12,  -3], dtype=torch.int32) q_bias: tensor([-140,   20,   26,  542, -502,   32, -336,  605,  485, -181, -191, -170,\n",
      "        -152,  -38,   30,  738, -260, -351, -309, -218,   30,  985,  813, 1018,\n",
      "         506,  -35, -310,  529,  -44, -114,  715,  629,  523,  635, 1067,  396,\n",
      "          89,    5,    9,  -39,  658,    7, -121, -303,  111,   20,  -25,  846,\n",
      "           5, -289,  -45, 1042, -356, 1099, -132,   -3,   21,   49, 1099, -368,\n",
      "        -195,  961,   23,  943,  512,   41, -379,  -27, -243,  455,  -67,  -17,\n",
      "        -261,  -52,   26,  328, -116,  -31, -276,  951, -529,  481, -103,  -12,\n",
      "         997,  211,  774, 1104, 1168,  524,   76, 1047,  -54, -206,  -14,   -4,\n",
      "         -12,  945,    9,  -42,  291,  222,   15,   -6,  -47, -260,  -58, -163,\n",
      "         681,  771,  662, -277, -133, -286,  -74,   21,  -15,  -69,  543, -273,\n",
      "         571,  -93, -167, -146,  -44, -277,  520,    8], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0001) tensor(0.0119)   bias tensor(-5.3878e-05) tensor(0.0035)\n",
      "deconv_layers.3.weight deconv_layers.5\n",
      "torch.Size([128, 128, 1, 1]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.2949]) torch.Size([1]) \n",
      "wscale= tensor([0.0118, 0.0094, 0.0070, 0.0126, 0.0055, 0.0031, 0.0060, 0.0027, 0.0085,\n",
      "        0.0084, 0.0024, 0.0044, 0.0023, 0.0063, 0.0079, 0.0041, 0.0104, 0.0045,\n",
      "        0.0068, 0.0056, 0.0086, 0.0029, 0.0024, 0.0063, 0.0049, 0.0088, 0.0030,\n",
      "        0.0051, 0.0026, 0.0035, 0.0085, 0.0044, 0.0083, 0.0088, 0.0062, 0.0057,\n",
      "        0.0035, 0.0075, 0.0098, 0.0040, 0.0035, 0.0035, 0.0047, 0.0044, 0.0027,\n",
      "        0.0103, 0.0056, 0.0072, 0.0076, 0.0078, 0.0051, 0.0025, 0.0036, 0.0108,\n",
      "        0.0081, 0.0058, 0.0032, 0.0031, 0.0051, 0.0028, 0.0029, 0.0048, 0.0048,\n",
      "        0.0061, 0.0063, 0.0084, 0.0034, 0.0031, 0.0044, 0.0058, 0.0026, 0.0072,\n",
      "        0.0069, 0.0065, 0.0056, 0.0039, 0.0070, 0.0043, 0.0076, 0.0098, 0.0081,\n",
      "        0.0054, 0.0062, 0.0040, 0.0022, 0.0067, 0.0082, 0.0030, 0.0058, 0.0050,\n",
      "        0.0062, 0.0054, 0.0104, 0.0066, 0.0080, 0.0101, 0.0028, 0.0064, 0.0067,\n",
      "        0.0022, 0.0017, 0.0133, 0.0070, 0.0055, 0.0064, 0.0032, 0.0092, 0.0030,\n",
      "        0.0106, 0.0111, 0.0074, 0.0054, 0.0043, 0.0028, 0.0035, 0.0064, 0.0024,\n",
      "        0.0066, 0.0103, 0.0067, 0.0106, 0.0064, 0.0067, 0.0068, 0.0039, 0.0035,\n",
      "        0.0082, 0.0065]) torch.Size([128, 1, 1, 1]) \n",
      "oscale= tensor([0.4940]) torch.Size([1])\n",
      "###: M= tensor([0.0070, 0.0056, 0.0042, 0.0075, 0.0033, 0.0019, 0.0036, 0.0016, 0.0051,\n",
      "        0.0050, 0.0014, 0.0026, 0.0014, 0.0037, 0.0047, 0.0024, 0.0062, 0.0027,\n",
      "        0.0041, 0.0034, 0.0051, 0.0017, 0.0014, 0.0038, 0.0029, 0.0053, 0.0018,\n",
      "        0.0031, 0.0016, 0.0021, 0.0051, 0.0026, 0.0050, 0.0053, 0.0037, 0.0034,\n",
      "        0.0021, 0.0045, 0.0058, 0.0024, 0.0021, 0.0021, 0.0028, 0.0027, 0.0016,\n",
      "        0.0061, 0.0033, 0.0043, 0.0046, 0.0046, 0.0030, 0.0015, 0.0022, 0.0064,\n",
      "        0.0049, 0.0035, 0.0019, 0.0018, 0.0030, 0.0017, 0.0017, 0.0029, 0.0029,\n",
      "        0.0036, 0.0037, 0.0050, 0.0020, 0.0019, 0.0026, 0.0035, 0.0016, 0.0043,\n",
      "        0.0041, 0.0039, 0.0033, 0.0023, 0.0042, 0.0026, 0.0046, 0.0058, 0.0048,\n",
      "        0.0032, 0.0037, 0.0024, 0.0013, 0.0040, 0.0049, 0.0018, 0.0035, 0.0030,\n",
      "        0.0037, 0.0032, 0.0062, 0.0039, 0.0048, 0.0060, 0.0017, 0.0038, 0.0040,\n",
      "        0.0013, 0.0010, 0.0079, 0.0042, 0.0033, 0.0038, 0.0019, 0.0055, 0.0018,\n",
      "        0.0063, 0.0066, 0.0044, 0.0032, 0.0026, 0.0017, 0.0021, 0.0038, 0.0014,\n",
      "        0.0039, 0.0062, 0.0040, 0.0063, 0.0038, 0.0040, 0.0040, 0.0023, 0.0021,\n",
      "        0.0049, 0.0039])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "conv_weight: tensor([[-1.0636e-01,  1.5741e-01, -1.4672e-01,  ..., -1.2891e-01,\n",
      "         -2.7206e-01,  4.0615e-02],\n",
      "        [-6.7764e-01, -2.4022e-02, -4.3736e-02,  ..., -2.4998e-01,\n",
      "          1.6031e-02,  2.4056e-02],\n",
      "        [ 3.4159e-01,  3.3909e-01, -2.7857e-01,  ...,  5.2850e-02,\n",
      "         -3.0635e-01,  8.7105e-02],\n",
      "        ...,\n",
      "        [ 4.6138e-03,  9.7369e-03,  1.8960e-02,  ...,  8.7932e-04,\n",
      "         -3.3904e-02,  2.2128e-01],\n",
      "        [ 2.7609e-01, -1.2848e-01,  1.6090e-01,  ..., -1.0053e+00,\n",
      "          4.6450e-02, -2.0055e-01],\n",
      "        [-2.7031e-01, -1.3911e-02, -4.9018e-01,  ...,  1.4791e-01,\n",
      "          1.3651e-01, -4.9350e-02]]) conv_bias: tensor([ -5.1140,  -2.1059,  -2.2623,  -0.0962, -13.5326,   0.5331,  -3.6019,\n",
      "         13.8012,  -9.7563,  -2.2032,   1.1838,  -1.6638,   3.8972,  -6.2943,\n",
      "         -7.2530,   2.8228,  -7.2251,  -3.6564,  -0.6964,  -0.8055,  -1.8649,\n",
      "         -0.4332,   7.9959,   8.9545,   0.9957,  -6.8093,   4.8186,  -6.5261,\n",
      "          6.5024,   8.5702,   4.2940, -10.3296,  -0.2333, -18.4598,  -6.4635,\n",
      "         -2.9784,  -3.5492,  -9.2760, -15.3079,  -0.7590,   3.8145,   2.4272,\n",
      "         -2.9625,   1.7660,  -6.4461,  -2.4864,  -0.3508, -11.2675,  -7.4925,\n",
      "         -1.2290,  13.2508,  -1.2662,  -1.0194,  -3.6556,  -5.7890,  -6.4687,\n",
      "          2.9196,   1.6063,  -6.1297,  -0.5022,   6.6015,  10.7163,   0.6798,\n",
      "         -6.8355,  -1.8306,  -4.1104,   5.6750,  -1.7055,  -3.1110,  -2.4604,\n",
      "          1.1331,  -3.9768,   7.9945,   2.1825,  -9.4462,  -3.3216,   7.0348,\n",
      "          5.6601,   1.2674,   3.0580,  -3.6579,   3.4025,  -2.1031,   3.9125,\n",
      "          1.0174,  -3.8987,  -6.6408,   7.8088,  -5.7684,  -5.9704,  -6.1729,\n",
      "         -0.6526,  -3.4003,   2.7702,  -0.8373,   3.6747,   5.3725,  -7.3311,\n",
      "        -10.0147,   2.2633,   1.0010,  -0.2149,  -8.2698,   1.1257,   2.8793,\n",
      "         -7.2306,  -8.7154,   6.0037,  -4.8860,  -3.3335, -10.5993,  -4.7320,\n",
      "         -9.4525,   1.6561,   5.7085,  15.5672,   1.4765,  11.6140,   5.7764,\n",
      "         -7.9726, -13.2605,   8.1583, -13.9813,  -8.9657,   2.7664,   0.6017,\n",
      "          5.7783,   3.6123])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "q_weight: tensor([ -9,  13, -12,  ...,  23,  21,  -8], dtype=torch.int32) q_bias: tensor([-1472,  -762, -1097,   -26, -8324,   578, -2038, 17242, -3871,  -886,\n",
      "         1676, -1282,  5717, -3404, -3119,  2353, -2346, -2730,  -347,  -486,\n",
      "         -737,  -504, 11367,  4795,   690, -2622,  5449, -4311,  8348,  8402,\n",
      "         1715, -7942,   -95, -7105, -3531, -1763, -3460, -4192, -5309,  -643,\n",
      "         3747,  2328, -2153,  1348, -8138,  -822,  -214, -5320, -3327,  -538,\n",
      "         8799, -1737,  -950, -1153, -2411, -3779,  3132,  1767, -4078,  -615,\n",
      "         7647,  7521,   482, -3818,  -990, -1667,  5637, -1838, -2401, -1437,\n",
      "         1477, -1864,  3927,  1145, -5764, -2892,  3418,  4434,   564,  1062,\n",
      "        -1533,  2122, -1147,  3293,  1534, -1969, -2761,  8735, -3351, -4040,\n",
      "        -3356,  -410, -1110,  1421,  -356,  1238,  6536, -3868, -5075,  3428,\n",
      "         2024,   -55, -4008,   694,  1518, -7670, -3217,  6792, -1569, -1023,\n",
      "        -4857, -2986, -7447,  1992,  5490,  8194,  2119,  5983,  1893, -4060,\n",
      "        -4245,  4355, -7069, -4492,  2395,   584,  2379,  1896],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-4.8313e-05) tensor(0.0065)   bias tensor(5.3460e-05) tensor(0.0013)\n",
      "deconv_layers.6.weight deconv_layers.8\n",
      "torch.Size([128, 1, 4, 4]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.4139]) torch.Size([1]) \n",
      "wscale= tensor([0.0674]) torch.Size([1]) \n",
      "oscale= tensor([0.3350]) torch.Size([1])\n",
      "###: M= tensor([0.0833])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "conv_weight: tensor([[[ 0.1006,  0.2939,  0.2343,  0.1008],\n",
      "         [ 0.2964,  0.4307,  0.4147,  0.2692],\n",
      "         [ 0.2302,  0.3674,  0.3224,  0.1670],\n",
      "         [ 0.0919,  0.1830,  0.2142,  0.0335]],\n",
      "\n",
      "        [[-0.0344, -0.1019, -0.1135, -0.0348],\n",
      "         [ 0.1360,  0.1503,  0.1042,  0.1025],\n",
      "         [ 0.3771,  0.5864,  0.5263,  0.2170],\n",
      "         [ 0.3063,  0.6809,  0.5151,  0.1330]],\n",
      "\n",
      "        [[ 0.1014,  0.2032,  0.1679,  0.0338],\n",
      "         [ 0.2418,  0.4482,  0.3724,  0.1052],\n",
      "         [ 0.2368,  0.5095,  0.4386,  0.1669],\n",
      "         [ 0.1012,  0.2336,  0.1696,  0.1005]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1027, -0.3259, -0.3610, -0.1008],\n",
      "         [-0.2270, -0.4780, -0.7682, -0.4355],\n",
      "         [ 0.0185, -0.5798, -0.7624, -0.4538],\n",
      "         [-0.1214, -0.2521, -0.4296, -0.1687]],\n",
      "\n",
      "        [[-0.1010, -0.1681, -0.1163, -0.0819],\n",
      "         [ 0.0336,  0.1681,  0.1008, -0.0335],\n",
      "         [ 0.3024,  0.5555,  0.5427,  0.3036],\n",
      "         [ 0.3040,  0.6058,  0.5062,  0.2394]],\n",
      "\n",
      "        [[-0.1009,  0.0243,  0.3662,  0.2392],\n",
      "         [-0.2352, -0.0894,  0.5037,  0.4418],\n",
      "         [-0.2962, -0.0987,  0.5009,  0.4346],\n",
      "         [-0.2457, -0.0338,  0.4351,  0.2248]]]) conv_bias: tensor([-2.3368, -1.9225, -3.4187, -2.9990, -0.3377,  4.6269, -4.7998, -0.0150,\n",
      "        -2.9870, -2.4478,  4.6785, -0.1048,  3.5622, -1.2391, -3.3057,  6.0429,\n",
      "        -2.5015, -4.2115, -2.1423, -3.2743, -2.0083,  5.8686,  7.9281, -1.8380,\n",
      "         4.8045, -1.3562,  6.4557,  1.0992,  4.8017,  4.4379, -4.0667,  0.1525,\n",
      "        -2.8142, -2.2075, -2.6594, -2.9454,  4.4096, -4.4118, -2.2702,  7.0722,\n",
      "         4.7656,  3.2724,  3.5379,  4.9570, -0.1169, -1.3779, -1.4731, -3.1673,\n",
      "        -1.5809,  5.5813,  4.5953,  4.8850,  4.7848, -2.5373, -0.7902, -0.7670,\n",
      "         7.3194,  4.3471, -1.4284,  6.0004,  5.0259, -0.4702, -3.8286, -0.4430,\n",
      "        -3.2203, -2.4081,  5.6774,  4.3563, -0.5985, -2.7470,  6.2847, -1.8234,\n",
      "        -2.6032, -0.7945,  5.6600,  4.6272, -0.9675,  6.3147, -1.9078, -2.5141,\n",
      "        -2.2000,  3.0198, -0.8125,  5.5181,  3.8923, -1.8586, -0.6307,  6.1204,\n",
      "        -2.1194, -0.9387, -0.5304, -2.0734, -2.0470,  4.3548, -2.9564, -2.8428,\n",
      "         5.4659, -1.8097,  0.1379,  4.4932,  4.1239, -2.4760, -0.7968, -0.7336,\n",
      "        -2.3525,  0.5163, -1.7245,  3.9543, -2.0258, -2.8667, -3.7817, -1.9021,\n",
      "        -1.2332,  5.1591,  5.3269, -9.9747,  5.0302, -1.2932, -2.4092, -2.0738,\n",
      "        -2.5679, -0.2831, -3.5585, -3.6894,  4.2237,  4.0265, -1.8126, -0.8264])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "q_weight: tensor([ 1,  4,  3,  ..., -1,  6,  3], dtype=torch.int32) q_bias: tensor([ -84,  -69, -123, -107,  -12,  166, -172,   -1, -107,  -88,  168,   -4,\n",
      "         128,  -44, -118,  217,  -90, -151,  -77, -117,  -72,  210,  284,  -66,\n",
      "         172,  -49,  231,   39,  172,  159, -146,    5, -101,  -79,  -95, -106,\n",
      "         158, -158,  -81,  253,  171,  117,  127,  178,   -4,  -49,  -53, -114,\n",
      "         -57,  200,  165,  175,  171,  -91,  -28,  -27,  262,  156,  -51,  215,\n",
      "         180,  -17, -137,  -16, -115,  -86,  203,  156,  -21,  -98,  225,  -65,\n",
      "         -93,  -28,  203,  166,  -35,  226,  -68,  -90,  -79,  108,  -29,  198,\n",
      "         139,  -67,  -23,  219,  -76,  -34,  -19,  -74,  -73,  156, -106, -102,\n",
      "         196,  -65,    5,  161,  148,  -89,  -29,  -26,  -84,   19,  -62,  142,\n",
      "         -73, -103, -136,  -68,  -44,  185,  191, -357,  180,  -46,  -86,  -74,\n",
      "         -92,  -10, -128, -132,  151,  144,  -65,  -30], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0012) tensor(0.0337)   bias tensor(0.0003) tensor(0.0139)\n",
      "deconv_layers.9.weight deconv_layers.11\n",
      "torch.Size([128, 128, 1, 1]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.3231]) torch.Size([1]) \n",
      "wscale= tensor([0.0026, 0.0045, 0.0031, 0.0036, 0.0044, 0.0015, 0.0057, 0.0012, 0.0013,\n",
      "        0.0022, 0.0030, 0.0034, 0.0017, 0.0018, 0.0070, 0.0012, 0.0031, 0.0015,\n",
      "        0.0031, 0.0035, 0.0025, 0.0027, 0.0036, 0.0038, 0.0060, 0.0038, 0.0047,\n",
      "        0.0019, 0.0061, 0.0026, 0.0014, 0.0045, 0.0049, 0.0021, 0.0027, 0.0035,\n",
      "        0.0082, 0.0026, 0.0047, 0.0031, 0.0063, 0.0028, 0.0028, 0.0020, 0.0032,\n",
      "        0.0041, 0.0040, 0.0026, 0.0040, 0.0038, 0.0039, 0.0049, 0.0018, 0.0020,\n",
      "        0.0029, 0.0023, 0.0036, 0.0055, 0.0046, 0.0050, 0.0025, 0.0027, 0.0059,\n",
      "        0.0029, 0.0027, 0.0024, 0.0037, 0.0033, 0.0036, 0.0035, 0.0033, 0.0045,\n",
      "        0.0028, 0.0041, 0.0022, 0.0029, 0.0039, 0.0057, 0.0094, 0.0036, 0.0031,\n",
      "        0.0037, 0.0032, 0.0023, 0.0079, 0.0018, 0.0031, 0.0036, 0.0063, 0.0031,\n",
      "        0.0050, 0.0032, 0.0039, 0.0039, 0.0030, 0.0063, 0.0047, 0.0046, 0.0035,\n",
      "        0.0048, 0.0032, 0.0038, 0.0026, 0.0020, 0.0046, 0.0049, 0.0024, 0.0028,\n",
      "        0.0025, 0.0015, 0.0019, 0.0053, 0.0018, 0.0015, 0.0074, 0.0047, 0.0033,\n",
      "        0.0039, 0.0031, 0.0020, 0.0031, 0.0038, 0.0029, 0.0040, 0.0032, 0.0030,\n",
      "        0.0026, 0.0013]) torch.Size([128, 1, 1, 1]) \n",
      "oscale= tensor([0.2363]) torch.Size([1])\n",
      "###: M= tensor([0.0036, 0.0062, 0.0042, 0.0050, 0.0060, 0.0020, 0.0079, 0.0017, 0.0017,\n",
      "        0.0030, 0.0041, 0.0047, 0.0023, 0.0025, 0.0096, 0.0017, 0.0042, 0.0021,\n",
      "        0.0042, 0.0048, 0.0035, 0.0037, 0.0049, 0.0052, 0.0082, 0.0052, 0.0064,\n",
      "        0.0026, 0.0083, 0.0036, 0.0019, 0.0061, 0.0067, 0.0029, 0.0036, 0.0048,\n",
      "        0.0113, 0.0035, 0.0064, 0.0042, 0.0087, 0.0038, 0.0038, 0.0028, 0.0044,\n",
      "        0.0056, 0.0054, 0.0035, 0.0054, 0.0052, 0.0053, 0.0066, 0.0024, 0.0028,\n",
      "        0.0040, 0.0032, 0.0049, 0.0075, 0.0063, 0.0068, 0.0034, 0.0036, 0.0080,\n",
      "        0.0040, 0.0037, 0.0033, 0.0050, 0.0045, 0.0049, 0.0047, 0.0045, 0.0062,\n",
      "        0.0039, 0.0056, 0.0030, 0.0040, 0.0054, 0.0078, 0.0129, 0.0049, 0.0042,\n",
      "        0.0051, 0.0043, 0.0031, 0.0107, 0.0024, 0.0042, 0.0050, 0.0086, 0.0042,\n",
      "        0.0068, 0.0044, 0.0054, 0.0053, 0.0041, 0.0086, 0.0064, 0.0062, 0.0048,\n",
      "        0.0066, 0.0043, 0.0052, 0.0036, 0.0027, 0.0063, 0.0067, 0.0033, 0.0039,\n",
      "        0.0034, 0.0021, 0.0026, 0.0073, 0.0024, 0.0021, 0.0101, 0.0064, 0.0046,\n",
      "        0.0053, 0.0043, 0.0027, 0.0042, 0.0052, 0.0040, 0.0055, 0.0043, 0.0042,\n",
      "        0.0035, 0.0018])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "conv_weight: tensor([[-0.0125, -0.0477,  0.0135,  ...,  0.0111,  0.0241,  0.0354],\n",
      "        [ 0.0366, -0.0045, -0.0792,  ..., -0.0937,  0.0587, -0.0292],\n",
      "        [-0.2199,  0.0078,  0.0174,  ..., -0.0240, -0.0023,  0.0118],\n",
      "        ...,\n",
      "        [ 0.0015, -0.2425, -0.0815,  ..., -0.1391, -0.0563,  0.0137],\n",
      "        [ 0.0091,  0.0324,  0.0082,  ..., -0.0444,  0.0176, -0.0241],\n",
      "        [ 0.0051,  0.0011,  0.0036,  ...,  0.0949, -0.0734, -0.0650]]) conv_bias: tensor([ 0.0726, -0.5172, -1.4366, -1.2512, -1.8709,  2.0620, -0.5094,  1.9820,\n",
      "         2.4578,  1.9732, -2.6329, -0.9737, -0.7767, -0.2501,  1.5207,  0.5995,\n",
      "        -0.2924,  1.3296, -1.8923, -1.6162,  0.3124, -0.7650, -2.9430, -1.9492,\n",
      "         0.8123, -0.8519, -0.6620, -0.9936, -1.4413,  1.6082,  2.5804, -2.9173,\n",
      "         1.7690,  1.4377,  0.2500,  1.6642,  3.6086, -1.5595,  1.0815, -2.5734,\n",
      "         1.4116, -0.8566, -0.5022, -1.3846, -1.1172, -1.5582, -0.0174,  0.1225,\n",
      "        -0.1927, -0.6025,  2.4888,  0.1816, -0.7840,  2.6804, -0.2483,  0.2621,\n",
      "        -0.3042,  3.1380,  0.6758, -1.6185, -1.5741, -1.4692,  0.3029, -2.2852,\n",
      "         1.9841,  0.3677, -0.1138, -2.2819, -1.2062, -1.0451, -0.5407, -1.3934,\n",
      "         1.7846,  0.1803, -1.4310, -0.0451, -0.8782, -1.3756,  0.8067, -1.8500,\n",
      "        -0.0147, -0.9896, -0.3352,  0.4026, -0.8737,  2.3339, -0.4673, -1.4069,\n",
      "         3.1128, -0.9836, -0.1294, -0.6858,  1.2769, -0.5488,  0.2685,  0.1301,\n",
      "         1.2111, -2.1655, -1.0967, -0.1189, -1.2370, -0.9454, -1.7524, -0.4592,\n",
      "        -0.2367,  1.2457,  1.9367, -0.3053, -1.4256,  2.7119,  0.7236,  2.4697,\n",
      "         1.8913, -1.2184,  0.9754, -2.4494,  1.1680, -1.5068,  0.2246, -1.2381,\n",
      "        -1.0508, -0.0364,  0.2410, -0.2159,  1.2402, -0.5069, -1.1525,  1.9794])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "q_weight: tensor([ -5, -18,   5,  ...,  71, -55, -49], dtype=torch.int32) q_bias: tensor([   86,  -353, -1451, -1066, -1309,  4261,  -275,  5073,  5960,  2808,\n",
      "        -2718,  -882, -1454,  -430,   668,  1500,  -295,  2698, -1918, -1426,\n",
      "          380,  -875, -2538, -1591,   417,  -690,  -435, -1627,  -732,  1888,\n",
      "         5749, -2010,  1122,  2073,   291,  1456,  1357, -1863,   715, -2593,\n",
      "          690,  -953,  -564, -2095, -1067, -1171,   -14,   148,  -150,  -489,\n",
      "         1993,   116, -1378,  4091,  -265,   346,  -260,  1775,   457, -1007,\n",
      "        -1969, -1705,   160, -2419,  2293,   468,   -96, -2166, -1049,  -932,\n",
      "         -507,  -954,  1944,   136, -1990,   -48,  -690,  -751,   265, -1582,\n",
      "          -15,  -819,  -328,   552,  -344,  4104,  -471, -1202,  1524,  -980,\n",
      "          -80,  -655,  1009,  -440,   278,    64,   803, -1472,  -961,   -77,\n",
      "        -1204,  -766, -2053,  -710,  -160,   783,  2478,  -332, -1755,  5469,\n",
      "         1166,  1437,  3301, -2458,   408, -1607,  1083, -1193,   222, -1923,\n",
      "        -1049,   -29,   258,  -166,  1217,  -515, -1379,  4595],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-6.5561e-06) tensor(0.0047)   bias tensor(-3.2947e-05) tensor(0.0009)\n",
      "deconv_layers.12.weight deconv_layers.14\n",
      "torch.Size([128, 1, 4, 4]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.2333]) torch.Size([1]) \n",
      "wscale= tensor([0.1680]) torch.Size([1]) \n",
      "oscale= tensor([0.8969]) torch.Size([1])\n",
      "###: M= tensor([0.0437])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "conv_weight: tensor([[[ 0.5720,  2.0668,  2.4880,  1.1960],\n",
      "         [ 1.9576,  5.8473,  6.3903,  2.9908],\n",
      "         [ 2.1433,  5.9646,  6.4854,  3.0559],\n",
      "         [ 0.8742,  2.4536,  2.8167,  1.2674]],\n",
      "\n",
      "        [[-5.9798,  0.3328, -1.4188,  0.0810],\n",
      "         [-0.8830,  0.5451,  0.5249, -0.6872],\n",
      "         [ 1.3948, -0.2029, 13.4580, -0.4404],\n",
      "         [-0.5157, -0.9265, -0.2277,  0.5868]],\n",
      "\n",
      "        [[ 2.4985,  4.8384,  4.1317,  1.5366],\n",
      "         [ 5.4074,  9.7132,  8.9905,  3.8724],\n",
      "         [ 5.2672,  9.9427,  9.4115,  4.3220],\n",
      "         [ 2.3641,  4.6872,  4.7696,  2.2465]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4181,  1.2478,  1.4191,  0.4231],\n",
      "         [ 1.2453,  2.9807,  3.0050,  1.1503],\n",
      "         [ 1.4231,  3.2141,  2.9253,  1.1239],\n",
      "         [ 0.5845,  1.4600,  1.2744,  0.4143]],\n",
      "\n",
      "        [[ 2.1708,  4.4309,  4.1167,  1.6408],\n",
      "         [ 4.8309,  9.2752,  8.4510,  3.5368],\n",
      "         [ 4.9149,  9.4411,  8.6451,  3.6244],\n",
      "         [ 2.3318,  4.4912,  4.2934,  1.8443]],\n",
      "\n",
      "        [[ 0.5872, -1.3792, -1.9449, -0.0869],\n",
      "         [-1.4353, -3.6390, -3.6564, -1.5151],\n",
      "         [-1.5607, -3.3016, -3.1544, -1.4225],\n",
      "         [ 0.4214, -1.0022, -1.4063,  0.0414]]]) conv_bias: tensor([-2.8788e-02, -5.9502e-01,  5.0378e-01,  4.2264e-01, -1.6525e+00,\n",
      "         1.0971e+01, -9.4264e-02,  1.5914e+01,  1.5694e+01,  1.0096e+01,\n",
      "        -4.3432e-01, -4.6715e-01,  4.2294e-01, -6.2443e-01, -5.1523e-01,\n",
      "         7.3369e+00, -1.7045e+00,  8.9347e+00,  2.6277e-01,  4.1908e-01,\n",
      "         4.9271e+00, -2.9175e-02,  4.1702e-01,  3.9909e-01,  5.0838e+00,\n",
      "         4.0483e-01,  3.7155e-01,  2.4569e-01,  3.7914e-01,  6.6635e+00,\n",
      "         9.6067e+00, -1.9700e-01,  7.4477e+00,  1.2670e+01,  2.9977e-01,\n",
      "         8.1316e+00,  9.0749e+00,  5.1453e-01,  6.7493e+00, -3.8046e-01,\n",
      "        -1.7850e-01,  4.2097e-01,  3.8868e-01, -3.8241e-01,  4.0296e-01,\n",
      "         3.8428e-01, -1.9009e-01,  2.8262e-01,  4.0514e-01,  4.2346e-01,\n",
      "         1.4355e+01, -2.0444e-01,  4.9291e-01,  1.0873e+01, -8.3675e-01,\n",
      "         2.7744e+00, -2.0258e-01,  9.7013e+00,  6.5916e+00,  4.1018e-01,\n",
      "         3.9756e-01, -3.8351e-01,  3.0833e-01, -1.7265e-01,  8.6578e+00,\n",
      "         4.1082e-01,  3.8639e-02, -8.7487e-02,  3.5360e-01, -2.0872e+00,\n",
      "         4.0510e-01, -8.5461e-01,  7.9983e+00,  3.6347e-01,  4.1083e-01,\n",
      "         5.3530e+00, -4.2004e-01, -1.1832e+00, -2.4541e+00,  4.7785e+00,\n",
      "         3.9504e-01, -8.7439e-01, -9.5472e-01,  5.8501e+00,  5.6821e-02,\n",
      "         1.0609e+01,  3.9897e-01,  4.1167e-01,  3.6254e-02, -1.2290e+00,\n",
      "        -2.0485e+00,  3.9028e-01,  7.3418e+00,  3.9131e-01, -2.3618e+00,\n",
      "         5.0681e-02, -7.1227e-01, -1.0378e+00,  3.1467e-01,  7.8974e+00,\n",
      "         1.9906e-02,  3.9912e-01, -1.3983e+00,  4.2041e-01,  3.2562e-01,\n",
      "        -4.5271e-01,  1.2026e+01, -5.0325e-01, -2.5188e-01,  2.0790e+01,\n",
      "         2.9765e-01,  7.2982e+00,  1.2001e+01, -4.7548e-01,  8.1600e+00,\n",
      "        -6.7563e-01,  6.8402e+00,  4.1530e-01,  5.1450e+00, -3.8783e-01,\n",
      "         3.9961e-01, -4.3124e-01, -7.4081e-01, -2.9795e-03, -2.3357e-01,\n",
      "         3.7853e-01, -2.5315e-01,  1.3723e+01])\n",
      "torch.Size([128, 1, 4, 4]) torch.Size([128])\n",
      "q_weight: tensor([ 3, 12, 15,  ..., -6, -8,  0], dtype=torch.int32) q_bias: tensor([ -1, -15,  13,  11, -42, 280,  -2, 406, 400, 258, -11, -12,  11, -16,\n",
      "        -13, 187, -43, 228,   7,  11, 126,  -1,  11,  10, 130,  10,   9,   6,\n",
      "         10, 170, 245,  -5, 190, 323,   8, 208, 232,  13, 172, -10,  -5,  11,\n",
      "         10, -10,  10,  10,  -5,   7,  10,  11, 366,  -5,  13, 277, -21,  71,\n",
      "         -5, 248, 168,  10,  10, -10,   8,  -4, 221,  10,   1,  -2,   9, -53,\n",
      "         10, -22, 204,   9,  10, 137, -11, -30, -63, 122,  10, -22, -24, 149,\n",
      "          1, 271,  10,  11,   1, -31, -52,  10, 187,  10, -60,   1, -18, -26,\n",
      "          8, 202,   1,  10, -36,  11,   8, -12, 307, -13,  -6, 531,   8, 186,\n",
      "        306, -12, 208, -17, 175,  11, 131, -10,  10, -11, -19,   0,  -6,  10,\n",
      "         -6, 350], dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-0.0004) tensor(0.0840)   bias tensor(-0.0010) tensor(0.0189)\n",
      "deconv_layers.15.weight deconv_layers.17\n",
      "torch.Size([128, 128, 1, 1]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.8468]) torch.Size([1]) \n",
      "wscale= tensor([0.0002, 0.0008, 0.0012, 0.0004, 0.0002, 0.0007, 0.0003, 0.0006, 0.0016,\n",
      "        0.0007, 0.0018, 0.0005, 0.0010, 0.0007, 0.0004, 0.0007, 0.0006, 0.0007,\n",
      "        0.0018, 0.0008, 0.0006, 0.0013, 0.0004, 0.0022, 0.0014, 0.0006, 0.0012,\n",
      "        0.0009, 0.0008, 0.0007, 0.0006, 0.0007, 0.0004, 0.0008, 0.0006, 0.0010,\n",
      "        0.0008, 0.0005, 0.0006, 0.0006, 0.0002, 0.0007, 0.0005, 0.0007, 0.0016,\n",
      "        0.0004, 0.0012, 0.0005, 0.0004, 0.0008, 0.0011, 0.0003, 0.0005, 0.0008,\n",
      "        0.0005, 0.0006, 0.0006, 0.0006, 0.0004, 0.0025, 0.0015, 0.0007, 0.0008,\n",
      "        0.0006, 0.0007, 0.0008, 0.0005, 0.0005, 0.0006, 0.0006, 0.0004, 0.0005,\n",
      "        0.0004, 0.0008, 0.0006, 0.0014, 0.0006, 0.0006, 0.0008, 0.0009, 0.0006,\n",
      "        0.0008, 0.0002, 0.0010, 0.0008, 0.0005, 0.0002, 0.0002, 0.0010, 0.0009,\n",
      "        0.0013, 0.0008, 0.0005, 0.0006, 0.0007, 0.0005, 0.0009, 0.0006, 0.0002,\n",
      "        0.0016, 0.0005, 0.0005, 0.0011, 0.0009, 0.0005, 0.0010, 0.0014, 0.0011,\n",
      "        0.0009, 0.0006, 0.0005, 0.0010, 0.0008, 0.0005, 0.0003, 0.0007, 0.0015,\n",
      "        0.0004, 0.0007, 0.0002, 0.0001, 0.0007, 0.0004, 0.0007, 0.0010, 0.0010,\n",
      "        0.0005, 0.0003]) torch.Size([128, 1, 1, 1]) \n",
      "oscale= tensor([0.2014]) torch.Size([1])\n",
      "###: M= tensor([0.0008, 0.0034, 0.0052, 0.0019, 0.0009, 0.0030, 0.0015, 0.0025, 0.0068,\n",
      "        0.0029, 0.0074, 0.0022, 0.0042, 0.0029, 0.0016, 0.0030, 0.0025, 0.0030,\n",
      "        0.0075, 0.0034, 0.0024, 0.0053, 0.0019, 0.0092, 0.0057, 0.0023, 0.0052,\n",
      "        0.0038, 0.0035, 0.0030, 0.0024, 0.0031, 0.0017, 0.0036, 0.0026, 0.0044,\n",
      "        0.0034, 0.0020, 0.0023, 0.0027, 0.0010, 0.0029, 0.0021, 0.0029, 0.0065,\n",
      "        0.0015, 0.0052, 0.0023, 0.0015, 0.0033, 0.0045, 0.0014, 0.0020, 0.0034,\n",
      "        0.0023, 0.0024, 0.0025, 0.0024, 0.0016, 0.0105, 0.0065, 0.0029, 0.0033,\n",
      "        0.0024, 0.0028, 0.0032, 0.0022, 0.0022, 0.0027, 0.0023, 0.0016, 0.0019,\n",
      "        0.0016, 0.0035, 0.0023, 0.0059, 0.0025, 0.0024, 0.0033, 0.0038, 0.0027,\n",
      "        0.0035, 0.0009, 0.0042, 0.0032, 0.0020, 0.0010, 0.0007, 0.0043, 0.0036,\n",
      "        0.0053, 0.0033, 0.0020, 0.0024, 0.0030, 0.0020, 0.0036, 0.0025, 0.0010,\n",
      "        0.0067, 0.0020, 0.0019, 0.0046, 0.0039, 0.0022, 0.0042, 0.0058, 0.0048,\n",
      "        0.0040, 0.0027, 0.0022, 0.0043, 0.0034, 0.0023, 0.0011, 0.0031, 0.0063,\n",
      "        0.0015, 0.0030, 0.0010, 0.0006, 0.0031, 0.0018, 0.0031, 0.0043, 0.0042,\n",
      "        0.0022, 0.0013])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "conv_weight: tensor([[-3.5449e-04,  1.1252e-03,  1.6719e-04,  ..., -8.9389e-04,\n",
      "         -6.0898e-05, -9.0981e-04],\n",
      "        [ 2.8677e-03, -3.1664e-03, -1.2754e-02,  ..., -4.2821e-02,\n",
      "          4.6378e-03,  6.3825e-03],\n",
      "        [-1.8352e-03,  5.5254e-03, -5.8093e-03,  ...,  5.5373e-03,\n",
      "         -4.1442e-03, -1.0195e-02],\n",
      "        ...,\n",
      "        [-1.5869e-02, -1.0078e-03, -1.2691e-02,  ..., -8.2321e-03,\n",
      "         -1.8638e-03,  3.0914e-03],\n",
      "        [-7.0623e-03,  2.2633e-03, -3.0895e-03,  ..., -1.2702e-02,\n",
      "          1.9606e-04, -7.3925e-03],\n",
      "        [-2.2022e-02, -2.0693e-03, -9.2263e-03,  ..., -6.4286e-03,\n",
      "          4.9486e-04,  5.1472e-04]]) conv_bias: tensor([-0.1021, -0.5232, -0.3846, -0.2507, -0.1557, -0.4401, -0.2534, -0.4857,\n",
      "        -0.1975, -0.1530, -0.3698, -0.4119, -0.6086, -0.0886, -0.2381, -0.4714,\n",
      "        -0.3866, -0.3206, -0.2412, -0.5859, -0.8935, -0.4972, -0.2255, -0.4225,\n",
      "        -0.1396, -0.4111, -0.0969, -0.0059, -0.2312, -0.2856, -0.3847, -0.2499,\n",
      "        -0.1873, -0.4423, -0.2526, -0.2403, -0.3550, -0.4524, -0.3844, -0.5814,\n",
      "        -0.3282, -0.3576, -0.3547, -0.3690, -0.8266, -0.1995, -0.1006, -0.3264,\n",
      "        -0.2515, -0.1787, -0.6433, -0.2242, -0.2062, -0.2028, -0.4085, -0.2171,\n",
      "        -0.3300, -0.2798, -0.1675, -0.0799, -0.4057, -0.4827, -0.3909, -0.5528,\n",
      "        -0.3059, -0.2783, -0.1773, -0.2572, -0.0571, -0.3602, -0.1979, -0.3350,\n",
      "        -0.3448, -0.5256, -0.2684, -0.3533, -0.2903, -0.2896, -0.2505, -0.0591,\n",
      "        -0.5427, -0.3714, -0.1462, -0.9097, -0.4137, -0.1456, -0.1278, -0.1571,\n",
      "        -0.5060, -0.3200, -0.3759, -0.2467, -0.3216, -0.1622, -0.3370, -0.1238,\n",
      "        -0.5211, -0.2832, -0.1667, -0.2245, -0.3497, -0.3229, -0.6023, -0.4806,\n",
      "        -0.2935, -0.3807, -0.2550, -0.0970, -0.3512, -0.3779, -0.2178, -0.1898,\n",
      "        -0.3752, -0.3199, -0.1313, -0.4207, -0.8010, -0.2424, -0.6150, -0.1762,\n",
      "        -0.1395, -0.2528, -0.3438, -0.3867, -0.8464, -0.3888, -0.3399, -0.7621])\n",
      "torch.Size([128, 128, 1, 1]) torch.Size([128])\n",
      "q_weight: tensor([ -2,   6,   1,  ..., -21,   2,   2], dtype=torch.int32) q_bias: tensor([ -665,  -771,  -368,  -660,  -875,  -717,  -866,  -955,  -144,  -261,\n",
      "         -247,  -951,  -722,  -151,  -752,  -785,  -761,  -529,  -159,  -859,\n",
      "        -1828,  -465,  -601,  -228,  -122,  -876,   -92,    -8,  -328,  -476,\n",
      "         -804,  -399,  -557,  -616,  -481,  -274,  -522, -1143,  -818, -1068,\n",
      "        -1659,  -622,  -837,  -639,  -629,  -670,   -96,  -713,  -820,  -265,\n",
      "         -715,  -804,  -510,  -300,  -886,  -454,  -666,  -573,  -513,   -38,\n",
      "         -309,  -832,  -592, -1137,  -541,  -438,  -401,  -583,  -106,  -765,\n",
      "         -620,  -866, -1040,  -747,  -567,  -296,  -569,  -597,  -377,   -77,\n",
      "        -1012,  -525,  -836, -1080,  -634,  -356,  -667, -1060,  -586,  -436,\n",
      "         -352,  -371,  -807,  -337,  -561,  -304,  -715,  -563,  -846,  -166,\n",
      "         -877,  -844,  -654,  -611,  -663,  -451,  -217,  -101,  -438,  -687,\n",
      "         -492,  -219,  -553,  -695,  -577,  -672,  -627,  -783, -1025,  -882,\n",
      "        -1193,  -411,  -957,  -615,  -969,  -465,  -761, -3008],\n",
      "       dtype=torch.int32)\n",
      "**量化误差**   weight: tensor(-2.0244e-07) tensor(0.0012)   bias tensor(-1.9028e-05) tensor(0.0005)\n",
      "It is final_layer\n",
      "torch.Size([17, 128, 1, 1])\n",
      "torch.Size([17, 128, 1, 1]) conv_bias= torch.Size([128]) \n",
      "ascale= tensor([0.0653]) torch.Size([1]) \n",
      "wscale= tensor([0.0036, 0.0037, 0.0039, 0.0038, 0.0042, 0.0033, 0.0034, 0.0049, 0.0039,\n",
      "        0.0033, 0.0037, 0.0034, 0.0032, 0.0041, 0.0038, 0.0079, 0.0048]) torch.Size([17, 1, 1, 1]) \n",
      "oscale= tensor([1.]) torch.Size([1])\n",
      "final_layer: M= tensor([0.0002, 0.0002, 0.0003, 0.0002, 0.0003, 0.0002, 0.0002, 0.0003, 0.0003,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003, 0.0005, 0.0003])\n",
      "tensor(0.0001) tensor(0.0039)\n",
      "['conv1', 'features.0.conv1', 'features.0.conv2', 'features.1.conv1', 'features.1.conv2', 'features.1.conv3', 'features.2.conv1', 'features.2.conv2', 'features.2.conv3', 'features.3.conv1', 'features.3.conv2', 'features.3.conv3', 'features.4.conv1', 'features.4.conv2', 'features.4.conv3', 'features.5.conv1', 'features.5.conv2', 'features.5.conv3', 'features.6.conv1', 'features.6.conv2', 'features.6.conv3', 'features.7.conv1', 'features.7.conv2', 'features.7.conv3', 'features.8.conv1', 'features.8.conv2', 'features.8.conv3', 'features.9.conv1', 'features.9.conv2', 'features.9.conv3', 'features.10.conv1', 'features.10.conv2', 'features.10.conv3', 'features.11.conv1', 'features.11.conv2', 'features.11.conv3', 'features.12.conv1', 'features.12.conv2', 'features.12.conv3', 'features.13.conv1', 'features.13.conv2', 'features.13.conv3', 'features.14.conv1', 'features.14.conv2', 'features.14.conv3', 'features.15.conv1', 'features.15.conv2', 'features.15.conv3', 'features.16.conv1', 'features.16.conv2', 'features.16.conv3', 'conv2', 'deconv_layers0', 'deconv_layers1', 'deconv_layers2', 'deconv_layers3', 'deconv_layers4', 'deconv_layers5', 'final_layer']\n"
     ]
    }
   ],
   "source": [
    "############################################################## 定点结果导出 类似后训练量化，直接从权重中得到最大值最小值 ##############################################\n",
    "remapped_state = {}\n",
    "M_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "M_key=[]  #存储M_list中的索引键值\n",
    "oscale_list={} #储存 浮点和整型的oscale\n",
    "ascale_list={} #储存 浮点和整型的ascale\n",
    "wscale_list={} #储存 浮点和整型的wscale\n",
    "\n",
    "count=0\n",
    "#导出权重和偏置至二进制文件中\n",
    "print('Model.state_dict:')\n",
    "for n,param_key in enumerate(model.state_dict()): # AttributeError: 'collections.OrderedDict' object has no attribute 'key',所以这里不使用model.state_dict().keys()\n",
    "    #打印 key value字典\n",
    "    # print(n, param_key,'\\t',model.state_dict()[param_key].size())\n",
    "    if(n<=434): #if(n<4*2): if(n<=434):  n==16 or n==8\n",
    "        # print(n, param_key,'\\t',model.state_dict()[param_key].size()) #param_key: features.0.0.activation_quantizer.scale \n",
    "        ############################################## 以下得到浮点权重值 ###################################################\n",
    "        if(param_key.split('.')[-1]=='weight'):  #最后一层final_layer没有bias,但最后一层本来就应该要单独设计的？\n",
    "            layer_name=('.').join(param_key.split('.')[0:-1])\n",
    "            next_layer=''\n",
    "            # print(layer_name+'.weight')\n",
    "            conv_weight=model.state_dict()[layer_name+'.weight'].detach().cpu()\n",
    "            ascale=model.state_dict()[layer_name+'.activation_quantizer.scale'].detach().cpu()  #对称量化，因此zero_point为0\n",
    "            ######################################## 使用量化感知训练的权重 #########################################\n",
    "            wscale=model.state_dict()[layer_name+'.weight_quantizer.scale'].detach().cpu()  # 通道量化  torch.Size([16, 1, 1, 1])\n",
    "            ######################################## 直接后训练量化得到权重 #########################################\n",
    "            # inter = torch.flatten(conv_weight, start_dim=1)  #变成两维 [out_channel,-1]\n",
    "            # frange=torch.max(torch.abs(inter), 1)[0].reshape(-1,1,1,1)\n",
    "            # wscale=torch.clamp(frange/127.5, min=1.1920928955078125e-7)  #1.1920928955078125e-7*127.5=1.519918441772461e-05\n",
    "            # print('frange=',frange.flatten(),'\\nwscale=',wscale.flatten())\n",
    "\n",
    "            if(param_key.split('.')[0]!='final_layer'):\n",
    "                conv_bias=model.state_dict()[layer_name+'.bias'].detach().cpu()  # final_layer其实是没有bias的\n",
    "                tmp=param_key.split('.')[0:-1]\n",
    "                tmp[-1]=str(int(tmp[-1])+2)\n",
    "                next_layer=('.').join(tmp)\n",
    "                print(param_key, next_layer)\n",
    "            else:\n",
    "                print('It is final_layer')\n",
    "                print(conv_weight.shape)\n",
    "            \n",
    "            if((next_layer+'.activation_quantizer.scale') in model.state_dict()):\n",
    "                oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()  #存在relu的情况 包括网络第一层、InvertedResidual中包含relu的层、conv2以及deconv_layers\n",
    "                # print('0:',next_layer, oscale)\n",
    "            elif(param_key.split('.')[1]!='17' and next_layer!=''): #不存在relu的情况  此时是mobilenet 每个InvertedResidual模块的末尾（线性直通，无relu)   但features.17的oscale应该是conv2的ascale\n",
    "                tmp2=param_key.split('.')[0:-1]\n",
    "                tmp2[1]=str(int(tmp[1])+1)\n",
    "                tmp2[-1]='0'\n",
    "                next_layer=('.').join(tmp2)\n",
    "                oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()\n",
    "                # print('1:',next_layer,oscale)\n",
    "            elif(param_key.split('.')[1]=='17'): #features.17的oscale应该是final_layer的ascale\n",
    "                oscale=model.state_dict()['conv2.0.activation_quantizer.scale'].detach().cpu()\n",
    "                # print('2: conv2.0',oscale)\n",
    "            else:  #final_layer 不需要oscale    next_layer=='' 没有relu的都不需要oscale\n",
    "                oscale=torch.tensor([1.])\n",
    "                # print('3: final_layer',oscale)\n",
    "            print(conv_weight.shape, 'conv_bias=',conv_bias.shape,'\\nascale=',ascale, ascale.shape, '\\nwscale=',wscale.flatten(), wscale.shape, '\\noscale=',oscale,oscale.shape) #wscale.flatten()\n",
    "\n",
    "            ############################################## 以下进行浮点权重的量化，得到int权重和M ###################################################\n",
    "            if(param_key.split('.')[0]!='final_layer'):\n",
    "                #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "                # if(param_key.split('.')[0]=='features'and param_key.split('.')[1]=='0'): #第一层的M需要特殊处理，将输入ascale放入图像预处理中实现，输入网络的数据直接是[-128,127] 似乎又不需要...\n",
    "                #     M=wscale/oscale\n",
    "                # else:\n",
    "                #     M=wscale*ascale/oscale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "                M=wscale*ascale/oscale\n",
    "                # M0=(M*2**16).type(torch.int32)\n",
    "                # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(-16))/M).flatten()) #\n",
    "                print('###: M=',M.flatten())\n",
    "\n",
    "                print(conv_weight.shape, conv_bias.shape)\n",
    "                #*********************************************************************************************************************************\n",
    "                print('conv_weight:',conv_weight.squeeze(), 'conv_bias:',conv_bias.flatten())\n",
    "                \n",
    "                #计算权重和偏置int量化结果\n",
    "                q_weight,q_bias = quantize_tensor(conv_weight, conv_bias, wscale, ascale, num_bits=8)\n",
    "                print(q_weight.shape, q_bias.shape)\n",
    "                print('q_weight:',q_weight.flatten(), 'q_bias:',q_bias.flatten())\n",
    "                \n",
    "                #反量化回浮点数的结果\n",
    "                dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "                # print(dq_weight, dq_bias)\n",
    "                print('**量化误差**   weight:', torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight),'  bias', torch.mean(conv_bias-dq_bias), torch.max(conv_bias-dq_bias))\n",
    "                # print(conv_bias-dq_bias)\n",
    "            else: #final_layer\n",
    "                #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "                M=wscale*ascale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "                # M0=(M*2**16).type(torch.int32) #如果最后一层直接使用浮点数进行运算，则不用计算M0\n",
    "                # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(16))/M).flatten()) #\n",
    "                print('final_layer: M=',M.flatten())\n",
    "\n",
    "                #计算权重和偏置int量化结果\n",
    "                q_weight,q_bias = quantize_tensor(conv_weight, torch.zeros([17]), wscale, ascale, num_bits=8) #这儿的bias是上一层的bias,是没有用的\n",
    "                # print(q_weight, q_bias)\n",
    "                # print(q_bias.shape)\n",
    "                #反量化回浮点数的结果\n",
    "                dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "                # print(dq_weight, dq_bias)\n",
    "                print(torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight))\n",
    "                # print(conv_bias-dq_bias)\n",
    "\n",
    "            # ################################################### 浮点权重导出 ################################################################\n",
    "            # q_weight=conv_weight #浮点权重的导出，需要控制变量呀！！！\n",
    "            # q_bias=conv_bias\n",
    "            # ################################################################################################################################\n",
    "\n",
    "            ############################################## 以下将int权重映射给bnfuse_model ###################################################\n",
    "            k = param_key.split('.') # pytorch  ['features', '0', '0', 'weight']\n",
    "            if(k[0]=='features' and k[1]=='0'): # 网络第一层  features.0. -> conv1\n",
    "                remapped_state_key = 'conv1.weight'\n",
    "                remapped_state[remapped_state_key]=q_weight\n",
    "                remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "            elif(k[0]=='features'): #除了第一层外的其他层\n",
    "                k[1]=str(int(k[1])-1)\n",
    "                number = int(k[-2])//3 + 1 \n",
    "                # print(number)\n",
    "                k[2]=k[2]+str(number)\n",
    "                # k[3]='0' #现在不需要了\n",
    "                # print(k)\n",
    "                remapped_state_key=('.').join(k[0:3])+'.weight' #进行重映射\n",
    "                # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "                remapped_state[remapped_state_key]=q_weight\n",
    "                remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "                # print(count, n, remapped_state_key.replace('weight','bias'), bnfuse_model.state_dict()[remapped_state_key.replace('weight','bias')].shape)\n",
    "            elif(k[0]=='deconv_layers'): #deconv_layers0-5\n",
    "                number = int(k[-2])//3\n",
    "                remapped_state_key=k[0]+str(number)+'.weight' #进行重映射\n",
    "                remapped_state[remapped_state_key]=q_weight\n",
    "                remapped_state[k[0]+str(number)+'.bias']=q_bias\n",
    "                # print(count, n, remapped_state_key.replace('weight','bias'), bnfuse_model.state_dict()[remapped_state_key.replace('weight','bias')].shape)\n",
    "            elif(k[0]=='final_layer'): #final_layer\n",
    "                remapped_state_key=param_key\n",
    "                remapped_state[remapped_state_key]=q_weight\n",
    "                # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "            else: #conv2 无需进行重映射\n",
    "                remapped_state_key = 'conv2.weight'\n",
    "                remapped_state[remapped_state_key]=q_weight\n",
    "                remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "            # print(n, state_key, model.state_dict()[remapped_state_key].shape)\n",
    "            # remapped_state[state_key]= model.state_dict()[remapped_state_key]   \n",
    "            if(remapped_state_key.split('.')[0]=='features'):\n",
    "                M_key_name = '.'.join(remapped_state_key.split('.')[0:-1])\n",
    "            else:\n",
    "                M_key_name = remapped_state_key.split('.')[0]\n",
    "            M_key.append(M_key_name)\n",
    "            M_list[M_key_name] = torch.squeeze(M, dim=-1) #M.flatten() torch.Size([16]);  M通道量化torch.Size([16, 1, 1, 1]) -> 需要转换为torch.Size([16, 1, 1])\n",
    "            oscale_list[M_key_name]=oscale  #储存 浮点和整形的Oscale 是一个值  类似这样oscale= tensor([0.9272]) torch.Size([1])\n",
    "            ascale_list[M_key_name]=ascale  \n",
    "            wscale_list[M_key_name]=torch.squeeze(wscale, dim=-1)  \n",
    "            count += 1\n",
    "\n",
    "#保存M结果\n",
    "print(M_key)\n",
    "# np.save('../output/weights_quan/M_key.npy', M_key) #这才真的是list\n",
    "\n",
    "# #其实下面的都是假的list,实际是字典\n",
    "# # np.save('../output/weights_quan/post_Mrefactor.npy', M_list)\n",
    "# np.save('../output/weights_quan/M_refactor_noreluq.npy', M_list)\n",
    "# np.save('../output/weights_quan/oscale.npy', oscale_list)\n",
    "# np.save('../output/weights_quan/ascale.npy', ascale_list)\n",
    "# # np.save('../output/weights_quan/post_wscale.npy', wscale_list)\n",
    "\n",
    "# np.save('../output/weights_quan/M_refactor.npy', M_list)\n",
    "# np.save('../output/weights_quan/wscale.npy', wscale_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#127.0 **量化误差**   weight: tensor(0.0004) tensor(0.0275)   bias tensor(7.7337e-06) tensor(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################################## 定点结果导出 refactor后 ##############################################\n",
    "# remapped_state = {}\n",
    "# M_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "# M_key=[]  #存储M_list中的索引键值\n",
    "# oscale_list={} #储存 浮点和整型的oscale\n",
    "# ascale_list={} #储存 浮点和整型的ascale\n",
    "# wscale_list={} #储存 浮点和整型的wscale\n",
    "\n",
    "# count=0\n",
    "# #导出权重和偏置至二进制文件中\n",
    "# print('Model.state_dict:')\n",
    "# for n,param_key in enumerate(model.state_dict()): # AttributeError: 'collections.OrderedDict' object has no attribute 'key',所以这里不使用model.state_dict().keys()\n",
    "#     #打印 key value字典\n",
    "#     # print(n, param_key,'\\t',model.state_dict()[param_key].size())\n",
    "#     if(n<=434): #if(n<4*2): if(n<=434):  n==16 or n==8\n",
    "#         # print(n, param_key,'\\t',model.state_dict()[param_key].size()) #param_key: features.0.0.activation_quantizer.scale \n",
    "#         ############################################## 以下得到浮点权重值 ###################################################\n",
    "#         if(param_key.split('.')[-1]=='weight'):  #最后一层final_layer没有bias,但最后一层本来就应该要单独设计的？\n",
    "#             layer_name=('.').join(param_key.split('.')[0:-1])\n",
    "#             next_layer=''\n",
    "#             # print(layer_name+'.weight')\n",
    "#             conv_weight=model.state_dict()[layer_name+'.weight'].detach().cpu()\n",
    "#             ascale=model.state_dict()[layer_name+'.activation_quantizer.scale'].detach().cpu()  #对称量化，因此zero_point为0\n",
    "#             wscale=model.state_dict()[layer_name+'.weight_quantizer.scale'].detach().cpu()  # 通道量化  torch.Size([16, 1, 1, 1])\n",
    "\n",
    "#             if(param_key.split('.')[0]!='final_layer'):\n",
    "#                 conv_bias=model.state_dict()[layer_name+'.bias'].detach().cpu()  # final_layer其实是没有bias的\n",
    "#                 tmp=param_key.split('.')[0:-1]\n",
    "#                 tmp[-1]=str(int(tmp[-1])+2)\n",
    "#                 next_layer=('.').join(tmp)\n",
    "#                 print(param_key, next_layer)\n",
    "#             else:\n",
    "#                 print('It is final_layer')\n",
    "#                 print(conv_weight.shape)\n",
    "            \n",
    "#             if((next_layer+'.activation_quantizer.scale') in model.state_dict()):\n",
    "#                 oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()  #存在relu的情况 包括网络第一层、InvertedResidual中包含relu的层、conv2以及deconv_layers\n",
    "#                 # print('0:',next_layer, oscale)\n",
    "#             elif(param_key.split('.')[1]!='17' and next_layer!=''): #不存在relu的情况  此时是mobilenet 每个InvertedResidual模块的末尾（线性直通，无relu)   但features.17的oscale应该是conv2的ascale\n",
    "#                 tmp2=param_key.split('.')[0:-1]\n",
    "#                 tmp2[1]=str(int(tmp[1])+1)\n",
    "#                 tmp2[-1]='0'\n",
    "#                 next_layer=('.').join(tmp2)\n",
    "#                 oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()\n",
    "#                 # print('1:',next_layer,oscale)\n",
    "#             elif(param_key.split('.')[1]=='17'): #features.17的oscale应该是final_layer的ascale\n",
    "#                 oscale=model.state_dict()['conv2.0.activation_quantizer.scale'].detach().cpu()\n",
    "#                 # print('2: conv2.0',oscale)\n",
    "#             else:  #final_layer 不需要oscale    next_layer=='' 没有relu的都不需要oscale\n",
    "#                 oscale=torch.tensor([1.])\n",
    "#                 # print('3: final_layer',oscale)\n",
    "#             print(conv_weight.shape, 'conv_bias=',conv_bias.shape,'\\nascale=',ascale, ascale.shape, '\\nwscale=',wscale.flatten(), wscale.shape, '\\noscale=',oscale,oscale.shape) #wscale.flatten()\n",
    "\n",
    "#             ############################################## 以下进行浮点权重的量化，得到int权重和M ###################################################\n",
    "#             if(param_key.split('.')[0]!='final_layer'):\n",
    "#                 #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "#                 # if(param_key.split('.')[0]=='features'and param_key.split('.')[1]=='0'): #第一层的M需要特殊处理，将输入ascale放入图像预处理中实现，输入网络的数据直接是[-128,127] 似乎又不需要...\n",
    "#                 #     M=wscale/oscale\n",
    "#                 # else:\n",
    "#                 #     M=wscale*ascale/oscale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "#                 M=wscale*ascale/oscale\n",
    "#                 # M0=(M*2**16).type(torch.int32)\n",
    "#                 # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(-16))/M).flatten()) #\n",
    "#                 print('###: M=',M.flatten())\n",
    "\n",
    "#                 print(conv_weight.shape, conv_bias.shape)\n",
    "#                 #*********************************************************************************************************************************\n",
    "#                 print('conv_weight:',conv_weight.squeeze(), 'conv_bias:',conv_bias.flatten())\n",
    "                \n",
    "#                 #计算权重和偏置int量化结果\n",
    "#                 q_weight,q_bias = quantize_tensor(conv_weight, conv_bias, wscale, ascale, num_bits=8)\n",
    "#                 print(q_weight.shape, q_bias.shape)\n",
    "#                 print(q_weight.flatten(), q_bias.flatten())\n",
    "                \n",
    "#                 #反量化回浮点数的结果\n",
    "#                 dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "#                 # print(dq_weight, dq_bias)\n",
    "#                 print('weight:', torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight),'  bias', torch.mean(conv_bias-dq_bias), torch.max(conv_bias-dq_bias))\n",
    "#                 # print(conv_bias-dq_bias)\n",
    "#             else: #final_layer\n",
    "#                 #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "#                 M=wscale*ascale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "#                 # M0=(M*2**16).type(torch.int32) #如果最后一层直接使用浮点数进行运算，则不用计算M0\n",
    "#                 # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(16))/M).flatten()) #\n",
    "#                 print('final_layer: M=',M.flatten())\n",
    "\n",
    "#                 #计算权重和偏置int量化结果\n",
    "#                 q_weight,q_bias = quantize_tensor(conv_weight, torch.zeros([17]), wscale, ascale, num_bits=8) #这儿的bias是上一层的bias,是没有用的\n",
    "#                 # print(q_weight, q_bias)\n",
    "#                 # print(q_bias.shape)\n",
    "#                 #反量化回浮点数的结果\n",
    "#                 dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "#                 # print(dq_weight, dq_bias)\n",
    "#                 print(torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight))\n",
    "#                 # print(conv_bias-dq_bias)\n",
    "\n",
    "#             # ################################################### 浮点权重导出 ################################################################\n",
    "#             # q_weight=conv_weight #浮点权重的导出，需要控制变量呀！！！\n",
    "#             # q_bias=conv_bias\n",
    "#             # ################################################################################################################################\n",
    "\n",
    "#             ############################################## 以下将int权重映射给bnfuse_model ###################################################\n",
    "#             k = param_key.split('.') # pytorch  ['features', '0', '0', 'weight']\n",
    "#             if(k[0]=='features' and k[1]=='0'): # 网络第一层  features.0. -> conv1\n",
    "#                 remapped_state_key = 'conv1.weight'\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "#             elif(k[0]=='features'): #除了第一层外的其他层\n",
    "#                 k[1]=str(int(k[1])-1)\n",
    "#                 number = int(k[-2])//3 + 1 \n",
    "#                 # print(number)\n",
    "#                 k[2]=k[2]+str(number)\n",
    "#                 # k[3]='0' #现在不需要了\n",
    "#                 # print(k)\n",
    "#                 remapped_state_key=('.').join(k[0:3])+'.weight' #进行重映射\n",
    "#                 # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "#                 # print(count, n, remapped_state_key.replace('weight','bias'), bnfuse_model.state_dict()[remapped_state_key.replace('weight','bias')].shape)\n",
    "#             elif(k[0]=='deconv_layers'): #deconv_layers0-5\n",
    "#                 number = int(k[-2])//3\n",
    "#                 remapped_state_key=k[0]+str(number)+'.weight' #进行重映射\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 remapped_state[k[0]+str(number)+'.bias']=q_bias\n",
    "#                 # print(count, n, remapped_state_key.replace('weight','bias'), bnfuse_model.state_dict()[remapped_state_key.replace('weight','bias')].shape)\n",
    "#             elif(k[0]=='final_layer'): #final_layer\n",
    "#                 remapped_state_key=param_key\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "#             else: #conv2 无需进行重映射\n",
    "#                 remapped_state_key = 'conv2.weight'\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "#             # print(n, state_key, model.state_dict()[remapped_state_key].shape)\n",
    "#             # remapped_state[state_key]= model.state_dict()[remapped_state_key]   \n",
    "#             if(remapped_state_key.split('.')[0]=='features'):\n",
    "#                 M_key_name = '.'.join(remapped_state_key.split('.')[0:-1])\n",
    "#             else:\n",
    "#                 M_key_name = remapped_state_key.split('.')[0]\n",
    "#             M_key.append(M_key_name)\n",
    "#             M_list[M_key_name] = torch.squeeze(M, dim=-1) #M.flatten() torch.Size([16]);  M通道量化torch.Size([16, 1, 1, 1]) -> 需要转换为torch.Size([16, 1, 1])\n",
    "#             oscale_list[M_key_name]=oscale  #储存 浮点和整形的Oscale 是一个值  类似这样oscale= tensor([0.9272]) torch.Size([1])\n",
    "#             ascale_list[M_key_name]=ascale  \n",
    "#             wscale_list[M_key_name]=torch.squeeze(M, dim=-1)  \n",
    "#             count += 1\n",
    "\n",
    "# #保存M结果\n",
    "# print(M_key)\n",
    "# np.save('../output/weights_quan/M_refactor.npy', M_list)\n",
    "# np.save('../output/weights_quan/oscale.npy', oscale_list)\n",
    "# np.save('../output/weights_quan/ascale.npy', ascale_list)\n",
    "# np.save('../output/weights_quan/wscale.npy', wscale_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################## 定点结果导出 refactor前 ##############################################\n",
    "# remapped_state = {}\n",
    "# M_list = {}\n",
    "# count=0\n",
    "# #导出权重和偏置至二进制文件中\n",
    "# print('Model.state_dict:')\n",
    "# for n,param_key in enumerate(model.state_dict()): # AttributeError: 'collections.OrderedDict' object has no attribute 'key',所以这里不使用model.state_dict().keys()\n",
    "#     #打印 key value字典\n",
    "#     # print(n, param_key,'\\t',model.state_dict()[param_key].size())\n",
    "#     if(n<=434): #if(n<4*2): if(n<=434):\n",
    "#         # print(n, param_key,'\\t',model.state_dict()[param_key].size()) #param_key: features.0.0.activation_quantizer.scale \n",
    "#         ############################################## 以下得到浮点权重值 ###################################################\n",
    "#         if(param_key.split('.')[-1]=='weight'):  #最后一层final_layer没有bias,但最后一层本来就应该要单独设计的？\n",
    "#             layer_name=('.').join(param_key.split('.')[0:-1])\n",
    "#             next_layer=''\n",
    "#             # print(layer_name+'.weight')\n",
    "#             conv_weight=model.state_dict()[layer_name+'.weight'].detach().cpu()\n",
    "#             ascale=model.state_dict()[layer_name+'.activation_quantizer.scale'].detach().cpu()  #对称量化，因此zero_point为0\n",
    "#             wscale=model.state_dict()[layer_name+'.weight_quantizer.scale'].detach().cpu()  # 通道量化  torch.Size([16, 1, 1, 1])\n",
    "\n",
    "#             if(param_key.split('.')[0]!='final_layer'):\n",
    "#                 conv_bias=model.state_dict()[layer_name+'.bias'].detach().cpu()  # final_layer其实是没有bias的\n",
    "#                 tmp=param_key.split('.')[0:-1]\n",
    "#                 tmp[-1]=str(int(tmp[-1])+2)\n",
    "#                 next_layer=('.').join(tmp)\n",
    "#             else:\n",
    "#                 print('It is final_layer')\n",
    "#                 print(conv_weight.shape)\n",
    "            \n",
    "#             if((next_layer+'.activation_quantizer.scale') in model.state_dict()):\n",
    "#                 # print('0:',next_layer)\n",
    "#                 oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()  #存在relu的情况\n",
    "#             elif(param_key.split('.')[1]!='17' and next_layer!=''): #不存在relu的情况  此时是mobilenet InvertedResidual模块的末尾\n",
    "#                 tmp2=param_key.split('.')[0:-1]\n",
    "#                 tmp2[1]=str(int(tmp[1])+1)\n",
    "#                 tmp2[-1]='0'\n",
    "#                 next_layer=('.').join(tmp2)\n",
    "#                 # print('1:',next_layer)\n",
    "#                 oscale=model.state_dict()[next_layer+'.activation_quantizer.scale'].detach().cpu()\n",
    "#             elif(param_key.split('.')[1]!='17'):\n",
    "#                 oscale=model.state_dict()['conv2.0.activation_quantizer.scale'].detach().cpu()\n",
    "#             # print(conv_weight.shape, 'conv_bias=',conv_bias.shape,'\\nascale=',ascale, ascale.shape, '\\nwscale=',wscale.flatten(),wscale.shape, '\\noscale=',oscale,oscale.shape)\n",
    "\n",
    "#             ############################################## 以下进行浮点权重的量化，得到int权重和M ###################################################\n",
    "#             if(param_key.split('.')[0]!='final_layer'):\n",
    "#                 #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "#                 M=wscale*ascale/oscale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "#                 M0=(M*2**16).type(torch.int32)\n",
    "#                 # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(16))/M).flatten()) #\n",
    "\n",
    "#                 #计算权重和偏置int量化结果\n",
    "#                 q_weight,q_bias = quantize_tensor(conv_weight, conv_bias, wscale, ascale, num_bits=8)\n",
    "#                 # print(q_weight, q_bias)\n",
    "#                 # print(q_bias.shape)\n",
    "#                 #反量化回浮点数的结果\n",
    "#                 dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "#                 # print(dq_weight, dq_bias)\n",
    "#                 print(torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight))\n",
    "#                 # print(conv_bias-dq_bias)\n",
    "#             else: #final_layer\n",
    "#                 #计算移位值  不同通道的wscale还相差蛮大的（e-02,e-07) 2**16好像还不够  所以先使用M来验证\n",
    "#                 M=wscale*ascale  #一开始的不同通道间M差距很大（e-03,e-09)， 后面就挺均匀的  \n",
    "#                 # M0=(M*2**16).type(torch.int32) #如果最后一层直接使用浮点数进行运算，则不用计算M0\n",
    "#                 # print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(16))/M).flatten()) #\n",
    "\n",
    "#                 #计算权重和偏置int量化结果\n",
    "#                 q_weight,q_bias = quantize_tensor(conv_weight, torch.zeros([17]), wscale, ascale, num_bits=8) #这儿的bias是上一层的bias,是没有用的\n",
    "#                 # print(q_weight, q_bias)\n",
    "#                 # print(q_bias.shape)\n",
    "#                 #反量化回浮点数的结果\n",
    "#                 dq_weight, dq_bias = dequantize_tensor(q_weight, q_bias, wscale, ascale)\n",
    "#                 # print(dq_weight, dq_bias)\n",
    "#                 print(torch.mean(conv_weight-dq_weight), torch.max(conv_weight-dq_weight))\n",
    "#                 # print(conv_bias-dq_bias)\n",
    "\n",
    "                \n",
    "#             ############################################## 以下将int权重映射给bnfuse_model ###################################################\n",
    "#             k = param_key.split('.') # pytorch  ['features', '0', '0', 'weight']\n",
    "#             if(k[0]!='final_layer'):\n",
    "#                 number = int(k[-2])//3*2 \n",
    "#                 # print(number)\n",
    "#                 k[-2]=str(number)\n",
    "#                 # print(k)\n",
    "#                 remapped_state_key=('.').join(k) #进行重映射\n",
    "#                 # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 remapped_state[remapped_state_key.replace('weight','bias')]=q_bias\n",
    "#                 # print(count, n, remapped_state_key.replace('weight','bias'), bnfuse_model.state_dict()[remapped_state_key.replace('weight','bias')].shape)\n",
    "#             else: #final_layer\n",
    "#                 remapped_state_key=param_key\n",
    "#                 remapped_state[remapped_state_key]=q_weight\n",
    "#                 # print(count, n, remapped_state_key, bnfuse_model.state_dict()[remapped_state_key].shape)\n",
    "#             # print(n, state_key, model.state_dict()[remapped_state_key].shape)\n",
    "#             # remapped_state[state_key]= model.state_dict()[remapped_state_key]   \n",
    "#             M_list[remapped_state_key] = M.flatten()\n",
    "#             count += 1\n",
    "\n",
    "# #保存M结果\n",
    "# np.save('../output/weights_quan/M.npy', M_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\nconv1\n2\nfeatures.0.conv1\n"
     ]
    }
   ],
   "source": [
    "# print(len(M_key), type(M_key), M_key)\n",
    "import numpy as np\n",
    "import torch\n",
    "Mkey_load = np.load('../output/weights_quan/M_key.npy', allow_pickle=True)  #type:<class 'numpy.ndarray'>\n",
    "Mkey_load=list(Mkey_load)\n",
    "print(type(Mkey_load))\n",
    "print(Mkey_load[0])\n",
    "print(Mkey_load.index('features.0.conv2'))\n",
    "print(Mkey_load[Mkey_load.index('features.0.conv2')-1])\n",
    "\n",
    "\n",
    "# 59 ['conv1', 'features.0.conv1', 'features.0.conv2', 'features.1.conv1', 'features.1.conv2', 'features.1.conv3', 'features.2.conv1', 'features.2.conv2', 'features.2.conv3', 'features.3.conv1', 'features.3.conv2', 'features.3.conv3', 'features.4.conv1', 'features.4.conv2', 'features.4.conv3', 'features.5.conv1', 'features.5.conv2', 'features.5.conv3', 'features.6.conv1', 'features.6.conv2', 'features.6.conv3', 'features.7.conv1', 'features.7.conv2', 'features.7.conv3', 'features.8.conv1', 'features.8.conv2', 'features.8.conv3', 'features.9.conv1', 'features.9.conv2', 'features.9.conv3', 'features.10.conv1', 'features.10.conv2', 'features.10.conv3', 'features.11.conv1', 'features.11.conv2', 'features.11.conv3', 'features.12.conv1', 'features.12.conv2', 'features.12.conv3', 'features.13.conv1', 'features.13.conv2', 'features.13.conv3', 'features.14.conv1', 'features.14.conv2', 'features.14.conv3', 'features.15.conv1', 'features.15.conv2', 'features.15.conv3', 'features.16.conv1', 'features.16.conv2', 'features.16.conv3', 'conv2', 'deconv_layers0', 'deconv_layers1', 'deconv_layers2', 'deconv_layers3', 'deconv_layers4', 'deconv_layers5', 'final_layer']\n",
    "\n",
    "''' ******************************************************************  计算M0 *************************************************************** '''\n",
    "Mscale_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "M0_float_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "M0_int_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "ascale_load = np.load('../output/weights_quan/ascale.npy', allow_pickle=True) \n",
    "oscale_load = np.load('../output/weights_quan/oscale.npy', allow_pickle=True) \n",
    "wscale_load = np.load('../output/weights_quan/wscale.npy', allow_pickle=True) \n",
    "M_list = np.load('../output/weights_quan/M_refactor.npy', allow_pickle=True) #量化感知训练得到的scale   有relu的量化反量化，因此需要转换\n",
    "for n,key in enumerate(Mkey_load):\n",
    "    if(n==58): # 最后一层没有output_scale\n",
    "        Mscale=wscale_load.item()[key]*ascale_load.item()[key]\n",
    "    else:\n",
    "        key_post = Mkey_load[Mkey_load.index(key)+1] \n",
    "        Mscale=wscale_load.item()[key]*ascale_load.item()[key]/ascale_load.item()[key_post]\n",
    "    Mscale_list[key] = Mscale #torch.squeeze(Mscale, dim=-1) \n",
    "    # print(n, key, M_list.item()[key].flatten(), M_list.item()[key].shape)\n",
    "    # print(ascale_load.item()[key], ascale_load.item()[key_post], oscale_load.item()[key])\n",
    "    # print(wscale_load.item()[key].flatten())\n",
    "    if(n!=58):\n",
    "        M0=(Mscale*2**16).type(torch.int32)\n",
    "        M0_float=M0*2**(-16)\n",
    "    else:  #此时还没有管最后一层的M0（最后一层应该不用*M0）\n",
    "        M0_float=Mscale\n",
    "        M0=torch.tensor(2**16) #乘以2**16,再除以2**16是原值\n",
    "    M0_float_list[key] = M0_float\n",
    "    M0_int_list[key] = M0\n",
    "    # print('M=',Mscale.flatten(),'\\nM0_float=',M0_float.flatten(),'\\nM0=',M0.flatten(),'\\nerror=',(Mscale-M0_float).flatten())\n",
    "    # print(n, key, Mscale.flatten(), Mscale_list[key].shape)\n",
    "\n",
    "# np.save('../output/weights_quan/mscale_norelu_quant.npy', Mscale_list)\n",
    "np.save('../output/weights_quan/M0_quant_requant.npy', M0_float_list)\n",
    "np.save('../output/weights_quan/M0_int.npy', M0_int_list)\n",
    "# # 读取M结果\n",
    "# M_load = np.load('../output/weights_quan/mscale_norelu_quant.npy', allow_pickle=True) #M_list\n",
    "# # M_load = np.load('../output/weights_quan/M0_int.npy', allow_pickle=True) #M_list\n",
    "# # print('M_list=',M_load.item())\n",
    "# print('conv1', M_load.item()['conv1'])#, M_load.item()[key])\n",
    "# for n,key in enumerate(M_key):\n",
    "#     if(n<=150):\n",
    "#         print(n, key, M_load.item()[key].shape)#, M_load.item()[key])\n",
    "#         M0=(M*2**16).type(torch.int32)\n",
    "#         print('M=',M.flatten(),'  M0=',M0.flatten(),'   error=',((M-M0*2**(-16))/M).flatten()) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ******************************************************************  shortcut处的另一种计算方式 *************************************************************** '''\n",
    "\n",
    "shortcut_list=['features.2.conv1','features.4.conv1','features.5.conv1','features.7.conv1','features.8.conv1','features.9.conv1','features.11.conv1','features.12.conv1','features.14.conv1','features.15.conv1']\n",
    "Mscale_list = {}  #存储int推断时每个conv之后的*M scale\n",
    "ascale_load = np.load('../output/weights_quan/ascale.npy', allow_pickle=True) \n",
    "oscale_load = np.load('../output/weights_quan/oscale.npy', allow_pickle=True) \n",
    "wscale_load = np.load('../output/weights_quan/wscale.npy', allow_pickle=True) \n",
    "M_list = np.load(convert_path+'M_refactor.npy', allow_pickle=True) #量化感知训练得到的scale   有relu的量化反量化，因此需要转换\n",
    "for n,key in enumerate(M_key):\n",
    "    \n",
    "    Mscale_list[key] = Mscale #torch.squeeze(Mscale, dim=-1) \n",
    "    print(n, key, M_list.item()[key].flatten(), M_list.item()[key].shape)\n",
    "    # print(ascale_load.item()[key], ascale_load.item()[key_post], oscale_load.item()[key])\n",
    "    # print(wscale_load.item()[key].flatten())\n",
    "    print(n, key, Mscale.flatten(), Mscale_list[key].shape)\n",
    "\n",
    "np.save('../output/weights_quan/ascale_shortcut0.npy', Mscale_list)\n",
    "# 读取M结果\n",
    "M_load = np.load('../output/weights_quan/mscale_norelu_quant.npy', allow_pickle=True) #M_list\n",
    "# print('M_list=',M_load.item())\n",
    "print('conv1', M_load.item()['conv1'])#, M_load.item()[key])\n",
    "for n,key in enumerate(M_key):\n",
    "    if(n<=150):\n",
    "        print(n, key, M_load.item()[key].shape)#, M_load.item()[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight', 'conv1.bias', 'features.0.conv1.weight', 'features.0.conv1.bias', 'features.0.conv2.weight', 'features.0.conv2.bias', 'features.1.conv1.weight', 'features.1.conv1.bias', 'features.1.conv2.weight', 'features.1.conv2.bias', 'features.1.conv3.weight', 'features.1.conv3.bias', 'features.2.conv1.weight', 'features.2.conv1.bias', 'features.2.conv2.weight', 'features.2.conv2.bias', 'features.2.conv3.weight', 'features.2.conv3.bias', 'features.3.conv1.weight', 'features.3.conv1.bias', 'features.3.conv2.weight', 'features.3.conv2.bias', 'features.3.conv3.weight', 'features.3.conv3.bias', 'features.4.conv1.weight', 'features.4.conv1.bias', 'features.4.conv2.weight', 'features.4.conv2.bias', 'features.4.conv3.weight', 'features.4.conv3.bias', 'features.5.conv1.weight', 'features.5.conv1.bias', 'features.5.conv2.weight', 'features.5.conv2.bias', 'features.5.conv3.weight', 'features.5.conv3.bias', 'features.6.conv1.weight', 'features.6.conv1.bias', 'features.6.conv2.weight', 'features.6.conv2.bias', 'features.6.conv3.weight', 'features.6.conv3.bias', 'features.7.conv1.weight', 'features.7.conv1.bias', 'features.7.conv2.weight', 'features.7.conv2.bias', 'features.7.conv3.weight', 'features.7.conv3.bias', 'features.8.conv1.weight', 'features.8.conv1.bias', 'features.8.conv2.weight', 'features.8.conv2.bias', 'features.8.conv3.weight', 'features.8.conv3.bias', 'features.9.conv1.weight', 'features.9.conv1.bias', 'features.9.conv2.weight', 'features.9.conv2.bias', 'features.9.conv3.weight', 'features.9.conv3.bias', 'features.10.conv1.weight', 'features.10.conv1.bias', 'features.10.conv2.weight', 'features.10.conv2.bias', 'features.10.conv3.weight', 'features.10.conv3.bias', 'features.11.conv1.weight', 'features.11.conv1.bias', 'features.11.conv2.weight', 'features.11.conv2.bias', 'features.11.conv3.weight', 'features.11.conv3.bias', 'features.12.conv1.weight', 'features.12.conv1.bias', 'features.12.conv2.weight', 'features.12.conv2.bias', 'features.12.conv3.weight', 'features.12.conv3.bias', 'features.13.conv1.weight', 'features.13.conv1.bias', 'features.13.conv2.weight', 'features.13.conv2.bias', 'features.13.conv3.weight', 'features.13.conv3.bias', 'features.14.conv1.weight', 'features.14.conv1.bias', 'features.14.conv2.weight', 'features.14.conv2.bias', 'features.14.conv3.weight', 'features.14.conv3.bias', 'features.15.conv1.weight', 'features.15.conv1.bias', 'features.15.conv2.weight', 'features.15.conv2.bias', 'features.15.conv3.weight', 'features.15.conv3.bias', 'features.16.conv1.weight', 'features.16.conv1.bias', 'features.16.conv2.weight', 'features.16.conv2.bias', 'features.16.conv3.weight', 'features.16.conv3.bias', 'conv2.weight', 'conv2.bias', 'deconv_layers0.weight', 'deconv_layers0.bias', 'deconv_layers1.weight', 'deconv_layers1.bias', 'deconv_layers2.weight', 'deconv_layers2.bias', 'deconv_layers3.weight', 'deconv_layers3.bias', 'deconv_layers4.weight', 'deconv_layers4.bias', 'deconv_layers5.weight', 'deconv_layers5.bias', 'final_layer.weight'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入量化后的int权重  但由于模型中的weight/bias参数仍是float32类型的，因此保存时还是会保存成float32.\n",
    "print(remapped_state.keys())\n",
    "bnfuse_model.load_state_dict(remapped_state)\n",
    "#修改权重数据的类型为int32\n",
    "# for n,param_key in enumerate(bnfuse_model.state_dict()):\n",
    "#     #打印 key value字典\n",
    "#     print(n, param_key,'\\t',bnfuse_model.state_dict()[param_key].size())\n",
    "#     eval('bnfuse_model.'+param_key+'.data.type(torch.int32)')\n",
    "\n",
    "# for name, module in bnfuse_model.named_modules():\n",
    "#     if type(module) in [torch.nn.Conv2d, torch.nn.ConvTranspose2d]:\n",
    "#         print(name, module)\n",
    "#         if(name=='final_layer'): #没有bias\n",
    "#             eval('bnfuse_model.'+name+'.weight.data.type(torch.int32)')\n",
    "#         else: #conv2d, ConvTranspose2d\n",
    "#             eval('bnfuse_model.'+name+'.weight.data.type(torch.int32)')\n",
    "#             eval('bnfuse_model.'+name+'.bias.data.type(torch.int32)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {'model': bnfuse_model.module.state_dict() if hasattr(bnfuse_model, 'module') else bnfuse_model.state_dict()}\n",
    "# torch.save(ckpt, '../output/weights_quan/float_mobilenetpose_nobn_refactor_likeint5_8.pt')\n",
    "# torch.save(ckpt, '../output/weights_quan/float_mobilenetpose_nobn_refactor.pt')\n",
    "# torch.save(ckpt, '../output/weights_quan/post_int_mobilenetpose_nobn_refactor.pt')\n",
    "torch.save(ckpt, '../output/weights_quan/int_mobilenetpose_nobn_refactor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './0_weight.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-73bb369dc102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0_weight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'0_bias'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1_weight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1_bias'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2_weight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2_bias'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3_weight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'3_bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.bin'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##一维的数据排列 ->[kernel_size1*kernel_size0*out_ch*in_ch]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#是weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './0_weight.bin'"
     ]
    }
   ],
   "source": [
    "###验证导出的权重是否正确\n",
    "######################以下是bnfuse后的权重，与bnfuse_model.pt对应######################\n",
    "###格式： [out_ch,in_ch,kernel_size1,kernel_size0]\n",
    "###第一个是普通卷积\n",
    "weight0_shape=[8,3,3,3]\n",
    "bias0_shape=[8]\n",
    "###接下来是深度可分离卷积\n",
    "weight1_shape=[8,8,1,1]\n",
    "bias1_shape=[8]\n",
    "weight2_shape=[8,1,3,3]\n",
    "bias2_shape=[8]\n",
    "weight3_shape=[4,8,1,1]\n",
    "bias3_shape=[4]\n",
    "\n",
    "list=[[8,3,3,3],[8],[8,8,1,1],[8],[8,1,3,3],[8],[4,8,1,1],[4]]\n",
    "\n",
    "#####################给的bin文件是权重重排后的结果######################\n",
    "###格式： [kernel_size1,kernel_size0,out_ch,in_ch]\n",
    "#以下可以将.bin文件中的权重返回.pt的数据排列，以便进行数据比对\n",
    "result_path='./'\n",
    "filename=['0_weight','0_bias','1_weight','1_bias','2_weight','2_bias','3_weight','3_bias']\n",
    "for i in range(4*2):\n",
    "    b=np.fromfile(result_path+filename[i]+'.bin',dtype=np.float32) ##一维的数据排列 ->[kernel_size1*kernel_size0*out_ch*in_ch]\n",
    "    if(i==1):\n",
    "        if(filename[i].split('_')[-1]=='weight'): #是weight\n",
    "            b=b.reshape(list[i][2]*list[i][3],list[i][0],list[i][1]) #->[kernel_size1*kernel_size0,out_ch,in_ch]\n",
    "            print(b.shape)\n",
    "            b=b.transpose(1,2,0) #->[out_ch,in_ch,kernel_size1*kernel_size0]\n",
    "            print(b.shape)\n",
    "            b=b.reshape(list[i][0],list[i][1],list[i][2],list[i][3]) #->[out_ch,in_ch,kernel_size1,kernel_size0]\n",
    "            print(b.shape)\n",
    "            print(b)\n",
    "        else: #否则是bias 无需转换，直接打印\n",
    "            print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=np.fromfile(result_path+filename+'.bin',dtype=np.float32)\n",
    "# b=np.loadtxt(result_path+filename+'.txt', dtype=np.float32, delimiter='  ')\n",
    "# print(b.shape)\n",
    "# b=b.reshape(9,8,3)\n",
    "# print(b.shape)\n",
    "# b=b.transpose(1,2,0) #[9,8,3]->[8,3,9]\n",
    "# print(b.shape)\n",
    "# b=b.reshape(8,3,3,3)\n",
    "# print(b.shape)\n",
    "# print(b)\n",
    "\n",
    "# print(a.shape)\n",
    "# print(a.shape[0],a.shape[1],a.shape[2],a.shape[3])\n",
    "# #a_resize=a.reshape([8,3,-1])\n",
    "# a_reshape=a.reshape([a.shape[0],a.shape[1],-1])\n",
    "# print(a_reshape.shape)\n",
    "# a_reshape=a_reshape.transpose(2,0,1) #[8,3,9]->[9,8,3]\n",
    "# print(a_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.reshape(8,3,9).transpose(2,1,0).shape #一次可以置换三个\n",
    "#a.swapaxes(1,2)  #swapaxes只能两两置换 对于swapaxes来说，括号内的两参数，交换位置和不交换，实际结果相同。\n",
    "\n",
    "# import cv2\n",
    "# image=cv2.imread('/home/ytwang/dataset/VOC/images/val/000001.jpg')\n",
    "# cv2.imshow(\"image\",image)\n",
    "# cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 352, 256])\n",
      "(3, 352, 256)\n",
      "(352, 256, 3)\n",
      "(90112, 3)\n"
     ]
    }
   ],
   "source": [
    "##################################### 权重、feature map导出 ##################################\n",
    "x0=torch.randn(1,3,352,256)\n",
    "print(x0.shape) #[1,3,352,256]\n",
    "x=x0.numpy().squeeze()\n",
    "print(x.shape) #(3, 352, 256)\n",
    "x=x.transpose(1,2,0)\n",
    "print(x.shape) #(352,256,3)\n",
    "#x.astype(np.float32).tofile(result_path+'input000001_352x256.bin') # 二进制文件导出\n",
    "x=x.reshape([-1,x.shape[-1]]) #(90112,3)=(352*256,3)\n",
    "print(x.shape)\n",
    "#np.savetxt(result_path+'input.txt', x, fmt=\"%f\", delimiter=',\\t') # .txt文件导出\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./input.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5952c7f42c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# b=torch.tensor(b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# type(b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'input.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m',\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ./input.txt not found."
     ]
    }
   ],
   "source": [
    "#b=np.fromfile(result_path+'input000001_352x256.bin',dtype=np.float32)\n",
    "# b=np.loadtxt(result_path+'input.txt', dtype=np.float32, delimiter=',\\t')\n",
    "# print(b.shape)\n",
    "# b=b.reshape(352,256,3).transpose(2,0,1)\n",
    "# print(b.shape)\n",
    "# b=b.reshape(1,3,352,256)\n",
    "# print(b.shape)\n",
    "# b=torch.tensor(b)\n",
    "# type(b)\n",
    "b=np.loadtxt(result_path+'input.txt', dtype=np.float32, delimiter=',\\t')\n",
    "print(b.shape)\n",
    "print(x0.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 352, 256)\n",
      "(1, 3, 352, 256)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "b=b.reshape(x0.shape[2],x0.shape[3],x0.shape[1]).transpose(2,0,1)\n",
    "print(b.shape)\n",
    "b=np.expand_dims(b,0) #[3,352,256]->[1,3,352,256]\n",
    "print(b.shape)\n",
    "x=torch.tensor(b)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.81406e-01, -8.01516e-01,  3.28198e-01, -7.11460e-01, -9.71156e-01, -2.00248e-02, -1.63450e+00,  9.71171e-01, -7.00366e-01,  1.60246e+00, -1.78841e+00,  3.63713e-01,  9.74244e-01,  1.33411e+00, -3.02220e-01, -4.06555e-01,  1.37745e-01, -6.31540e-01, -1.46539e+00,  2.76620e-01,  1.23277e+00, -1.40946e+00,\n",
      "        -1.51452e+00,  1.19671e-01,  4.42624e-01, -7.22908e-01, -4.04740e-01, -4.34604e-01,  2.06584e-01, -1.40587e+00,  5.70870e-01,  1.07140e-01,  1.61050e+00,  1.02770e+00, -3.53327e-01,  2.04177e-01,  2.31896e-02,  1.28927e+00, -5.48752e-01,  1.42098e-01,  9.03911e-01, -1.20936e+00,  9.63919e-01, -1.01060e+00,\n",
      "         8.54119e-02, -1.53845e-01, -1.54839e+00, -6.02410e-02, -2.57630e+00,  3.93433e-01,  2.39229e-01, -1.21564e-01, -1.15327e+00,  1.26149e+00,  1.45040e+00, -9.07547e-01,  1.31109e+00, -1.65926e-02, -3.07028e-01,  6.83296e-01, -5.43891e-01,  6.85024e-01,  4.69522e-01,  1.76420e+00,  1.61510e+00,  1.25916e+00,\n",
      "        -1.77150e-01,  2.47641e+00, -1.46249e+00, -2.80018e-01,  6.05029e-02,  5.44458e-01,  2.67465e+00, -1.15849e+00, -5.81707e-01,  4.31597e-01,  2.43441e+00,  2.65851e-01, -1.14425e+00,  2.25560e+00,  1.77140e+00, -7.80207e-01,  6.53952e-02, -4.71407e-01,  1.57048e+00, -9.17719e-01,  8.72730e-01,  9.31447e-01,\n",
      "         1.77649e+00,  1.00942e+00, -7.18745e-01, -2.77709e-01,  4.57021e-01, -2.23519e-01,  2.16158e-01, -1.34371e+00, -4.63412e-01,  1.40616e+00, -8.71267e-01, -2.05477e+00,  1.82690e+00, -9.64664e-02, -1.37564e+00, -3.15296e-02,  5.58746e-01, -1.83691e-01, -6.04123e-01,  7.66482e-01, -4.03121e-01,  2.93691e-01,\n",
      "         8.41161e-01,  2.42523e+00,  6.69548e-01,  1.93673e-01, -1.15198e+00,  4.01391e-01,  8.17872e-02,  1.89599e-01, -6.67637e-01,  1.04472e+00,  2.86891e-01,  8.68945e-01, -1.60576e+00, -3.06741e-04,  2.12187e+00,  4.09882e-01, -1.14038e+00, -1.76595e+00, -1.55876e-01, -1.18096e+00, -4.73746e-02,  1.64630e-01,\n",
      "        -6.96033e-01,  1.18123e+00,  2.55200e+00, -1.55258e+00, -5.07378e-02,  5.74990e-02, -3.31153e-01,  4.79517e-01,  8.98099e-02,  1.49721e+00,  4.27276e-02,  2.24228e+00,  9.64584e-01,  1.06729e+00,  1.11198e+00,  1.89691e+00, -1.34978e+00,  1.04962e+00,  1.25740e+00,  4.83465e-01,  9.00648e-01,  6.93612e-01,\n",
      "        -1.32085e+00,  6.34273e-01,  7.02246e-02,  3.29396e-01,  1.19658e+00, -3.61629e-01,  1.82372e+00, -8.15059e-01,  5.58395e-02, -1.26954e+00, -2.69953e-01, -6.87627e-01, -8.86588e-01,  6.98368e-01, -1.29626e+00, -6.38218e-01,  6.82183e-01, -4.30375e-01, -2.36423e+00,  4.34401e-01,  1.94347e+00, -1.14078e-01,\n",
      "         4.15629e-01,  9.99400e-01,  9.41885e-01,  5.68806e-01, -2.00598e-01,  7.16138e-01, -9.69121e-01, -1.51415e-01,  4.58058e-01,  6.32497e-01,  1.45279e+00, -2.12141e-01,  8.35680e-01,  6.50394e-01, -5.15632e-01, -5.69040e-01,  3.28715e-01,  1.17557e+00,  1.30806e+00,  1.56861e+00, -2.23972e+00,  4.16258e-01,\n",
      "         4.63714e-02, -3.72965e-01, -8.45543e-01, -8.86618e-01,  2.44351e-01,  9.09960e-01, -3.21582e-01, -1.45642e+00, -1.95657e+00, -3.57767e-01, -1.44434e+00,  8.81572e-01,  3.95041e-01,  7.41678e-01,  1.47994e+00,  7.90388e-01, -6.65410e-01, -3.59384e-01,  6.13578e-01,  8.22294e-01, -5.26904e-01,  8.14695e-01,\n",
      "        -3.81759e-01,  2.36013e+00, -3.96305e-01,  1.66977e+00, -2.11435e-01,  5.07760e-01, -3.10217e-01,  4.52953e-01, -7.71852e-01, -3.66158e-01,  3.17449e-01, -2.57260e+00, -8.96794e-01,  9.62500e-02,  1.30173e+00, -7.75847e-01, -1.38639e+00, -5.68825e-01,  4.10178e-01,  5.41091e-01, -1.68622e-02,  6.18837e-01,\n",
      "        -8.45662e-01, -6.51488e-01, -6.27133e-01,  7.43690e-01,  2.00255e-01, -3.11761e-01,  1.16924e+00,  1.51702e+00,  1.01467e+00, -2.29272e+00, -5.90515e-01, -6.66745e-01,  1.29226e+00, -2.55041e+00])\n"
     ]
    }
   ],
   "source": [
    "# (x0==b).all()\n",
    "print(x0[0][0][0]) #torch.Size([1, 3, 352, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### 验证bnfuse后结果是否正确 #########################################\n",
    "bn_weight=torch.tensor([\n",
    "    0.9627532362937927,\n",
    "    1.6811193227767944,\n",
    "    1.0011911392211914,\n",
    "    1.6239477396011353,\n",
    "    1.3853583335876465,\n",
    "    0.9575594663619995,\n",
    "    1.325505256652832,\n",
    "    0.9901668429374695])\n",
    "bn_bias=torch.tensor([\n",
    "    -24.751123428344727,\n",
    "    16.553693771362305,\n",
    "    -21.58427619934082,\n",
    "    13.835719108581543,\n",
    "    7.6066741943359375,\n",
    "    12.691370010375977,\n",
    "    24.215431213378906,\n",
    "    -10.96066665649414])\n",
    "bn_running_mean=torch.tensor([\n",
    "    0.2264288365840912,\n",
    "    -1.438944935798645,\n",
    "    -0.012756695970892906,\n",
    "    -1.1514368057250977,\n",
    "    2.064279079437256,\n",
    "    -1.000322699546814,\n",
    "    1.4272160530090332,\n",
    "    -0.01157035119831562])\n",
    "bn_running_var=torch.tensor([\n",
    "    0.018602905794978142,\n",
    "    0.7236471176147461,\n",
    "    0.0006818491965532303,\n",
    "    0.586725652217865,\n",
    "    1.5904737710952759,\n",
    "    0.3611223101615906,\n",
    "    0.7421475648880005,\n",
    "    0.00004840613837586716])\n",
    "bn_eps=torch.tensor([1E-4]).expand([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-26.34514,  19.39717, -21.12751,  16.27666,   5.33914,  14.28511,  22.01961, -10.02023])\n",
      "tensor([-26.34514,  19.39717, -21.12751,  16.27666,   5.33914,  14.28511,  22.01961, -10.02023])\n"
     ]
    }
   ],
   "source": [
    "# bn.bias=\n",
    "# bn.weight=\n",
    "# bn.running_mean=\n",
    "# bn.running_var=\n",
    "# bn.eps=\n",
    "afterfuse_b=bn_bias-bn_weight*bn_running_mean/(torch.sqrt(bn_running_var+bn_eps))\n",
    "print(afterfuse_b)\n",
    "\n",
    "b_bn = bn_bias - bn_weight.mul(bn_running_mean).div(torch.sqrt(bn_running_var + bn_eps))\n",
    "print(b_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### torch_utils.py中的bu_fuse实现 ##########################\n",
    "def fuse_conv_and_bn(conv, bn):\n",
    "    # https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    with torch.no_grad():\n",
    "        # init\n",
    "        fusedconv = torch.nn.Conv2d(conv.in_channels,\n",
    "                                    conv.out_channels,\n",
    "                                    kernel_size=conv.kernel_size,\n",
    "                                    stride=conv.stride,\n",
    "                                    padding=conv.padding,\n",
    "                                    groups=conv.groups,\n",
    "                                    bias=True)\n",
    "\n",
    "        # prepare filters\n",
    "        w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "        w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "        fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.size()))\n",
    "\n",
    "        # prepare spatial bias\n",
    "        if conv.bias is not None:\n",
    "            b_conv = conv.bias\n",
    "        else:\n",
    "            b_conv = torch.zeros(conv.weight.size(0))\n",
    "        b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "        fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "\n",
    "        return fusedconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab342d38c9089b27086ef2ff31e6c6863533cd1c8642810b45a542962dd3699"
  },
  "kernelspec": {
   "name": "python383jvsc74a57bd0aab342d38c9089b27086ef2ff31e6c6863533cd1c8642810b45a542962dd3699",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 5
}